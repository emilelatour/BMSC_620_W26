{
  "hash": "a6bd8fc96cdcf5b3d9ba0f36803a893b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sampling Distributions and Confidence Intervals\"\nsubtitle: \"Textbook Sections 4.1–4.2\"\nauthor: \"Emile Latour, Nicky Wakim, Meike Niederhausen\"\ndate: \"2026-02-02\"\ndate-format: long\nformat:\n  revealjs:\n    theme: \"../../assets/css/reveal-bmsc620_v5.scss\"\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"BMSC 620 | Sampling & Confidence Intervals\"\n    html-math-method: mathjax\n    chalkboard: true\nexecute:\n  echo: true\n  warning: false\n  message: false\n  freeze: auto\n---\n\n\n\n\n\n# Learning Objectives \n\nBy the end of today's lecture, you will be able to:\n\n1. Distinguish between population parameters and sample statistics\n2. Explain the concept of sampling variability and the sampling distribution\n3. Apply the Central Limit Theorem to describe the distribution of sample means\n4. Calculate and interpret confidence intervals for a population mean\n5. Understand when to use the t-distribution vs. the normal distribution\n\n## Roadmap for Today\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Part 1: Sampling Fundamentals**\n\n- Population parameters vs. sample statistics\n- Point estimates\n- Sampling variability\n\n**Part 2: Sampling Distributions**\n\n- What is a sampling distribution?\n- Properties of the sampling distribution of means\n- Standard error\n\n**Part 3: Central Limit Theorem**\n\n- Statement of the CLT\n- When the CLT applies\n- Applications with R\n:::\n\n::: {.column width=\"50%\"}\n**Part 4: Introduction to Inference**\n\n- From point estimates to interval estimates\n- Confidence intervals: concept and interpretation\n\n**Part 5: Confidence Intervals in Practice**\n\n- CI when σ is known (z-based)\n- CI when σ is unknown (t-based)\n- The t-distribution\n\n**Part 6: Wrap-up**\n\n- Summary\n- Common misconceptions\n- Next steps\n:::\n::::\n\n# Sampling Fundamentals\n\n## Why do we sample?\n\n::: {.callout-note icon=\"false\"}\n## The fundamental challenge of statistics\n\nWe want to learn about a **population**, but we can only observe a **sample**.\n:::\n\n\\\n\n**Populations:**\n\n- Too large to measure everyone\n- Too expensive or time-consuming\n- Sometimes impossible (would you destroy every lightbulb to test lifespan?)\n\n\\\n\n**Samples:**\n\n- Smaller, manageable\n- If chosen properly, can tell us about the population\n- But there's uncertainty...\n\n## Population vs. Sample: Visual\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-1-1.png){width=1152}\n:::\n:::\n\n\n\n## Population parameters vs. Sample statistics\n\nUnderstanding the notation is crucial for clear statistical thinking.\n\n\\\n\n:::: {.columns}\n::: {.column width=\"48%\"}\n::: {.callout-important icon=\"false\"}\n## Population Parameter\n\nFixed (but unknown) values describing the population\n\n**For the mean:**\n\n- Symbol: $\\mu$ (mu)\n- We want to know it but usually can't measure it\n\n**For standard deviation:**\n\n- Symbol: $\\sigma$ (sigma)\n- Also fixed and unknown\n\n**For proportion:**\n\n- Symbol: $p$ or $\\pi$ (pi)\n:::\n:::\n\n::: {.column width=\"48%\"}\n::: {.callout-tip icon=\"false\"}\n## Sample Statistic\n\nCalculated values from our sample data\n\n**For the mean:**\n\n- Symbol: $\\bar{x}$ (x-bar)\n- Our best guess at $\\mu$\n\n**For standard deviation:**\n\n- Symbol: $s$\n- Our estimate of $\\sigma$\n\n**For proportion:**\n\n- Symbol: $\\hat{p}$ (p-hat)\n:::\n:::\n::::\n\n## What is a point estimate?\n\nA **point estimate** is a single value calculated from sample data used to estimate a population parameter.\n\n\\\n\n**Examples:**\n\n- Sample mean ($\\bar{x}$) estimates population mean ($\\mu$)\n- Sample proportion ($\\hat{p}$) estimates population proportion ($p$)\n- Sample standard deviation ($s$) estimates population SD ($\\sigma$)\n\n\\\n\n::: {.callout-warning icon=\"false\"}\n## The problem with point estimates\n\nThey're just single numbers. They don't tell us:\n\n- How much uncertainty there is\n- How close we might be to the true value\n- Whether our sample was typical or unusual\n:::\n\n## Sampling variability: A demonstration in R\n\nLet's see what happens when we take multiple samples from the same population.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a population\nset.seed(123)\npopulation <- tibble(\n  height = rnorm(100000, mean = 65, sd = 3)\n)\n\n# Take 5 samples of size 50\nset.seed(456)\nresults <- tibble(\n  sample_num = 1:5,\n  mean_height = map_dbl(1:5, ~ mean(sample(population$height, 50)))\n)\n\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  sample_num mean_height\n       <int>       <dbl>\n1          1        64.5\n2          2        64.1\n3          3        64.8\n4          4        65.4\n5          5        65.3\n```\n\n\n:::\n:::\n\n\n\n**Notice:** Even from the same population, our sample means vary!\n\nThis is **sampling variability** - it's not error, it's natural variation.\n\n## Visualizing sampling variability\n\nWhat if we took many, many samples?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Take 1000 samples, each of size 50\nset.seed(789)\nmany_samples <- tibble(\n  sample_num = 1:1000\n) %>%\n  mutate(\n    mean_height = map_dbl(sample_num, ~ mean(sample(population$height, 50)))\n  )\n\nggplot(many_samples, aes(x = mean_height)) +\n  geom_histogram(bins = 40, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = 65, color = \"red\", linewidth = 1.5, linetype = \"dashed\") +\n  labs(\n    title = \"Distribution of 1000 sample means (n = 50)\",\n    subtitle = \"Red line shows true population mean (μ = 65)\",\n    x = \"Sample mean (x̄)\",\n    y = \"Count\"\n  )\n```\n\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n# The Sampling Distribution\n\n## What is a sampling distribution?\n\n::: {.callout-note icon=\"false\"}\n## Definition\n\nThe **sampling distribution** of a statistic is the distribution of that statistic's values across all possible samples of a given size from a population.\n:::\n\n\\\n\n**Think of it this way:**\n\n1. Imagine taking a sample of size $n$\n2. Calculate a statistic (like the mean)\n3. Write it down\n4. Repeat steps 1-3 for **all possible samples**\n5. The distribution of those statistics is the sampling distribution\n\n\\\n\n**Key insight:** The sampling distribution tells us how our estimates behave across different samples.\n\n## Three distributions to keep straight\n\nIt's crucial to distinguish between these three concepts:\n\n\\\n\n:::: {.columns}\n::: {.column width=\"30%\"}\n**Population Distribution**\n\n- Distribution of the variable in the population\n- Mean: $\\mu$\n- SD: $\\sigma$\n:::\n\n::: {.column width=\"30%\"}\n**Sample Distribution**\n\n- Distribution of the variable in one sample\n- Mean: $\\bar{x}$\n- SD: $s$\n:::\n\n::: {.column width=\"30%\"}\n**Sampling Distribution**\n\n- Distribution of sample means across all samples\n- Mean: $\\mu_{\\bar{X}} = \\mu$\n- SD: $SE = \\frac{\\sigma}{\\sqrt{n}}$\n:::\n::::\n\n## Visual: Three distributions\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-4-1.png){width=1248}\n:::\n:::\n\n\n\n## Standard error: A special name\n\nThe standard deviation of a sampling distribution has a special name:\n\n::: {.callout-tip icon=\"false\"}\n## Standard Error (SE)\n\nThe **standard error** is the standard deviation of a sampling distribution.\n\nFor the sampling distribution of sample means:\n\n$$SE = \\frac{\\sigma}{\\sqrt{n}}$$\n\nwhere:\n\n- $\\sigma$ = population standard deviation  \n- $n$ = sample size\n:::\n\n\\\n\n**Key points:**\n\n- Larger samples → smaller SE → more precise estimates\n- SE decreases as $\\sqrt{n}$, not as $n$\n- In practice, we often use $s$ instead of $\\sigma$: $SE = \\frac{s}{\\sqrt{n}}$\n\n## Why does sample size matter?\n\nLet's see the effect of sample size on the sampling distribution:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n\n# Central Limit Theorem\n\n## The Central Limit Theorem (CLT)\n\n::: {.callout-important icon=\"false\"}\n## Central Limit Theorem\n\nFor **sufficiently large** sample sizes ($n \\geq 30$), the sampling distribution of the sample mean is approximately normal, regardless of the shape of the population distribution.\n\nSpecifically, if we have a random sample of size $n$ from a population with mean $\\mu$ and standard deviation $\\sigma$:\n\n$$\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)$$\n\nor equivalently:\n\n$$\\bar{X} \\sim N\\left(\\mu_{\\bar{X}} = \\mu, \\quad SE = \\frac{\\sigma}{\\sqrt{n}}\\right)$$\n:::\n\n## Why the CLT is remarkable\n\n**The CLT works even if the population is:**\n\n- Highly skewed\n- Uniform\n- Bimodal\n- Anything else!\n\n\\\n\n**As long as $n \\geq 30$, the sampling distribution of $\\bar{X}$ is approximately normal.**\n\n\\\n\n::: {.callout-note icon=\"false\"}\n## Exception\n\nIf the population itself is normally distributed, then the sampling distribution is exactly normal for any sample size (even $n < 30$).\n:::\n\n## CLT in action: Starting with a skewed population\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-6-1.png){width=1248}\n:::\n:::\n\n\n\n## When can we use the CLT?\n\n**General rule:** $n \\geq 30$ for most distributions\n\n\\\n\n**More nuanced guidelines:**\n\n- If population is approximately normal → CLT works for any $n$\n- If population is slightly skewed → $n \\geq 30$ is usually fine\n- If population is very skewed → $n \\geq 50$ or larger may be needed\n- If population has extreme outliers → even larger $n$ may be needed\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n## In practice\n\nWhen in doubt, look at your sample data:\n\n- Is it approximately symmetric?\n- Are there extreme outliers?\n- If yes to both, you're probably okay with $n \\geq 30$\n:::\n\n## Applying the CLT: Example\n\n::: {.callout-note icon=\"false\"}\n## Example: Heights\n\nSuppose the heights of adults in a population have mean $\\mu = 65$ inches and standard deviation $\\sigma = 3.5$ inches. We take a random sample of 50 adults.\n\n**What is the probability that the sample mean is greater than 66 inches?**\n:::\n\n\\\n\n**Step 1:** Check if we can use CLT\n\n- $n = 50 \\geq 30$ ✓\n- We can assume the sampling distribution of $\\bar{X}$ is approximately normal\n\n**Step 2:** Find the distribution of $\\bar{X}$\n\n$$\\bar{X} \\sim N\\left(\\mu = 65, \\quad SE = \\frac{3.5}{\\sqrt{50}} = 0.495\\right)$$\n\n## Example continued: Using R\n\n**Step 3:** Calculate the probability\n\nWe want $P(\\bar{X} > 66)$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate SE\nn <- 50\nmu <- 65\nsigma <- 3.5\nSE <- sigma / sqrt(n)\n\nSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4949747\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate probability\npnorm(q = 66, mean = mu, sd = SE, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02167588\n```\n\n\n:::\n:::\n\n\n\n**Interpretation:** There is about a 2.2% chance of observing a sample mean greater than 66 inches if the true population mean is 65 inches.\n\n## What the CLT tells us in plain language\n\nThe Central Limit Theorem means:\n\n1. **Sample means are normally distributed** (for large enough $n$)\n2. **Sample means cluster around the population mean** ($\\mu$)\n3. **The spread depends on sample size** (larger $n$ → smaller spread)\n\n\\\n\n**This gives us a framework to:**\n\n- Understand how estimates vary\n- Quantify uncertainty\n- Make probability statements about sample means\n- Eventually, construct confidence intervals!\n\n# Introduction to Inference\n\n## From estimation to inference\n\nSo far we've learned:\n\n- Population parameters vs. sample statistics\n- Sampling distributions\n- The Central Limit Theorem\n\n\\\n\n**Now we ask a bigger question:**\n\n::: {.callout-note icon=\"false\"}\n## The inference question\n\nGiven a sample statistic (like $\\bar{x} = 66.1$), what can we say about the population parameter ($\\mu$)?\n:::\n\n\\\n\n**Point estimates aren't enough** - they give us one number but no sense of uncertainty.\n\n**Solution:** Use interval estimates!\n\n## Point estimates vs. Interval estimates\n\n:::: {.columns}\n::: {.column width=\"48%\"}\n::: {.callout-warning icon=\"false\"}\n## Point Estimate\n\nA single value used to estimate a parameter\n\n**Example:** \"The mean height is 66.1 inches\"\n\n**Pros:**\n\n- Simple\n- Easy to communicate\n\n**Cons:**\n\n- No uncertainty quantified\n- Doesn't acknowledge sampling variability\n:::\n:::\n\n::: {.column width=\"48%\"}\n::: {.callout-tip icon=\"false\"}\n## Interval Estimate\n\nA range of plausible values for a parameter\n\n**Example:** \"The mean height is between 65.1 and 67.1 inches\"\n\n**Pros:**\n\n- Quantifies uncertainty\n- More honest about what we know\n\n**Cons:**\n\n- Less precise\n- Requires interpretation\n:::\n:::\n::::\n\n## What is a confidence interval?\n\n::: {.callout-important icon=\"false\"}\n## Confidence Interval\n\nA **confidence interval** is a range of values that is likely to contain the true population parameter with a specified level of confidence.\n\n**General form:**\n\n$$\\text{point estimate} \\pm \\text{margin of error}$$\n\nFor a mean:\n\n$$\\bar{x} \\pm \\text{(critical value)} \\times SE$$\n:::\n\n\\\n\n**The critical value depends on:**\n\n- The confidence level (commonly 95%)\n- The distribution we're using (normal or t)\n\n## Some new notation\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n\\\n\n- $\\pm z_{1-\\alpha/2}$ is the value of $z$ such that $(1 - \\alpha) \\times 100\\%$ of the standard normal distribution is contained between $- z_{1-\\alpha/2}$ and $+ z_{1-\\alpha/2}$.\n- Equivalently, $\\alpha \\times 100\\%$ is greater than $+ z_{1-\\alpha/2}$ and less than $- z_{1-\\alpha/2}$ combined. \n\n# Confidence Intervals: The Basics\n\n## Visualizing confidence intervals\n\nLet's look at what confidence intervals represent:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-9-1.png){width=1152}\n:::\n:::\n\n\n\n## Confidence interval when σ is known\n\nWhen we **know** the population standard deviation $\\sigma$:\n\n::: {.callout-tip icon=\"false\"}\n## CI for μ (with known σ)\n\n$$\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}$$\n\nwhere:\n\n- $\\bar{x}$ = sample mean\n- $z^*$ = critical value from standard normal distribution\n- $\\sigma$ = population standard deviation (known)\n- $n$ = sample size\n:::\n\n\\\n\n**For a 95% confidence interval:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(0.975)  # 2.5% in each tail\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.959964\n```\n\n\n:::\n:::\n\n\n\nSo $z^* = 1.96$\n\n## Example: CI with known σ\n\n::: {.callout-note icon=\"false\"}\n## Example\n\nA random sample of 50 adults has mean height $\\bar{x} = 66.1$ inches. Assume the population standard deviation is known to be $\\sigma = 3$ inches. Find a 95% confidence interval for the population mean height.\n:::\n\n\\\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxbar <- 66.1\nsigma <- 3\nn <- 50\nz_star <- 1.96\n\n# Calculate SE\nSE <- sigma / sqrt(n)\nSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4242641\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate CI\nlower <- xbar - z_star * SE\nupper <- xbar + z_star * SE\n\nc(lower, upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.26844 66.93156\n```\n\n\n:::\n:::\n\n\n\n**We are 95% confident that the population mean height is between 65.27 and 66.93 inches.**\n\n## Interpreting confidence intervals: What they mean\n\n::: {.callout-important icon=\"false\"}\n## Correct interpretation\n\n\"We are 95% confident that the interval (65.27, 66.93) contains the true population mean height.\"\n\n**What this really means:**\n\nIf we were to take many samples and construct a 95% CI from each one, about 95% of those intervals would contain the true population mean $\\mu$.\n:::\n\n\\\n\n**Helpful analogy:**\n\nThink of each CI as a \"net\" trying to catch the true parameter. With 95% confidence, our net catches the parameter 95% of the time.\n\n## Interpreting confidence intervals: What they DON'T mean\n\n::: {.callout-warning icon=\"false\"}\n## Common misconceptions\n\n**WRONG:** \"There is a 95% probability that μ is in this interval.\"\n\n- The parameter μ is fixed (not random)\n- It either is or isn't in the interval\n- The randomness comes from the sampling process\n\n**WRONG:** \"95% of the data falls in this interval.\"\n\n- The CI is about the parameter, not the data\n- The data is in the sample, not in the CI\n\n**WRONG:** \"If we repeat the study, there's a 95% chance the new mean will be in this interval.\"\n\n- CIs are for parameters, not future statistics\n:::\n\n## Different confidence levels\n\nWe can construct CIs at different confidence levels:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 90% CI\nz_90 <- qnorm(0.95)  # 5% in each tail\nc(xbar - z_90 * SE, xbar + z_90 * SE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.40215 66.79785\n```\n\n\n:::\n\n```{.r .cell-code}\n# 95% CI\nz_95 <- qnorm(0.975)  # 2.5% in each tail\nc(xbar - z_95 * SE, xbar + z_95 * SE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.26846 66.93154\n```\n\n\n:::\n\n```{.r .cell-code}\n# 99% CI\nz_99 <- qnorm(0.995)  # 0.5% in each tail\nc(xbar - z_99 * SE, xbar + z_99 * SE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.00717 67.19283\n```\n\n\n:::\n:::\n\n\n\n**Trade-off:** Higher confidence → wider interval (less precision)\n\n# The t-Distribution\n\n## What if we don't know σ?\n\n**Reality check:** We almost never know the population standard deviation $\\sigma$.\n\n\\\n\n**Problem:** If we replace $\\sigma$ with $s$ in our CI formula:\n\n$$\\bar{x} \\pm z^* \\times \\frac{s}{\\sqrt{n}}$$\n\nThis **adds extra uncertainty** - we're now estimating both $\\mu$ and $\\sigma$!\n\n\\\n\n**Solution:** Use a different distribution that accounts for this extra uncertainty - the **t-distribution**.\n\n## The t-distribution\n\n::: {.callout-important icon=\"false\"}\n## Student's t-distribution\n\nThe t-distribution:\n\n- Is symmetric and bell-shaped (like the normal)\n- Has **heavier tails** than the normal distribution\n- Depends on **degrees of freedom** ($df = n - 1$)\n- Approaches the normal distribution as $df$ increases\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11_sampling_ci_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n## Why degrees of freedom = n - 1?\n\n**Degrees of freedom** = number of independent pieces of information\n\n\\\n\nWhen calculating the sample standard deviation $s$:\n\n- We use $n$ observations\n- But we first calculate $\\bar{x}$ (which uses all $n$ values)\n- This \"uses up\" one degree of freedom\n- We're left with $n - 1$ independent pieces of information\n\n\\\n\n**Intuition:** If you know the mean and $n-1$ values, the $n$th value is determined.\n\n## Confidence interval with unknown σ\n\nWhen $\\sigma$ is **unknown** (which is almost always):\n\n::: {.callout-tip icon=\"false\"}\n## CI for μ (with unknown σ)\n\n$$\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}$$\n\nwhere:\n\n- $\\bar{x}$ = sample mean\n- $t^*$ = critical value from t-distribution with $df = n - 1$\n- $s$ = sample standard deviation\n- $n$ = sample size\n:::\n\n\\\n\n**Finding the critical value in R:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For 95% CI with n = 50 (so df = 49)\nqt(0.975, df = 49)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.009575\n```\n\n\n:::\n:::\n\n\n\nCompare to $z^* = 1.96$ - slightly larger!\n\n## Example: CI with unknown σ\n\n::: {.callout-note icon=\"false\"}\n## Example\n\nA random sample of 50 adults has:\n\n- Mean height: $\\bar{x} = 66.1$ inches\n- Sample SD: $s = 3.5$ inches\n\nFind a 95% confidence interval for the population mean height.\n:::\n\n\\\n\n**Solution:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxbar <- 66.1\ns <- 3.5\nn <- 50\ndf <- n - 1\n\n# Critical value\nt_star <- qt(0.975, df = df)\nt_star\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.009575\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate SE (using s instead of σ)\nSE <- s / sqrt(n)\n\n# Calculate CI\nlower <- xbar - t_star * SE\nupper <- xbar + t_star * SE\n\nc(lower, upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.10531 67.09469\n```\n\n\n:::\n:::\n\n\n\n## Comparing z-based vs. t-based CIs\n\nFor our example ($n = 50$):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# If we knew σ = 3.5 (z-based)\nz_star <- qnorm(0.975)\nci_z <- xbar + c(-1, 1) * z_star * (3.5 / sqrt(n))\nci_z\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.12987 67.07013\n```\n\n\n:::\n\n```{.r .cell-code}\n# Using s = 3.5 (t-based)\nt_star <- qt(0.975, df = 49)\nci_t <- xbar + c(-1, 1) * t_star * (s / sqrt(n))\nci_t\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 65.10531 67.09469\n```\n\n\n:::\n:::\n\n\n\n**Notice:** The t-based CI is slightly wider (because $t^* > z^*$) - this reflects the extra uncertainty from estimating σ.\n\n## When to use t vs. z?\n\n::: {.callout-important icon=\"false\"}\n## Decision rule\n\n**Use t-distribution when:**\n\n- You don't know the population standard deviation $\\sigma$\n- You're using the sample standard deviation $s$\n- **(This is almost always in practice!)**\n\n**Use normal (z) distribution when:**\n\n- You know the population standard deviation $\\sigma$\n- **(This is rare in real applications)**\n:::\n\n\\\n\n**Rule of thumb we'll use in this class:**\n\nAlways use the t-distribution unless explicitly told you know $\\sigma$.\n\n# Summary and Key Takeaways\n\n## What you need to know: Sampling distributions\n\n**Key concepts:**\n\n1. **Sampling variability** is natural - different samples give different estimates\n2. The **sampling distribution** describes how statistics vary across samples\n3. **Standard error** (SE) measures the variability of sample means: $SE = \\frac{\\sigma}{\\sqrt{n}}$\n4. The **Central Limit Theorem** says that for $n \\geq 30$, sample means follow a normal distribution\n\n\\\n\n**In plain language:**\n\nIf we repeatedly sample from a population and calculate the mean each time, those means will form a normal distribution centered at the true population mean, with spread determined by the standard error.\n\n## What you need to know: Confidence intervals\n\n**Key concepts:**\n\n1. A **confidence interval** gives a range of plausible values for a parameter\n2. **95% confidence** means that 95% of such intervals would contain the true parameter\n3. Use the **t-distribution** when $\\sigma$ is unknown (almost always)\n4. General form: $\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}$\n\n\\\n\n**Critical R functions:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Finding critical values\nqt(0.975, df = n - 1)  # For 95% CI\n\n# Or for different confidence levels\nqt(0.95, df = n - 1)   # For 90% CI\nqt(0.995, df = n - 1)  # For 99% CI\n```\n:::\n\n\n\n## Common mistakes to avoid\n\n::: {.callout-warning icon=\"false\"}\n## Watch out for these!\n\n1. **Confusing the three distributions**\n   - Population distribution ≠ sample distribution ≠ sampling distribution\n\n2. **Misinterpreting confidence intervals**\n   - Not \"95% chance μ is in the interval\"\n   - Rather \"95% of such intervals contain μ\"\n\n3. **Using z when you should use t**\n   - If you calculated $s$ from your data, use t!\n\n4. **Forgetting the assumptions**\n   - CLT needs $n \\geq 30$ (or normal population)\n   - Or: smaller $n$ is okay if data is approximately symmetric\n:::\n\n## Key formulas for reference\n\nYou don't need to memorize these, but understand what they mean:\n\n\\\n\n**Standard Error:**\n$$SE = \\frac{\\sigma}{\\sqrt{n}} \\quad \\text{or} \\quad SE = \\frac{s}{\\sqrt{n}}$$\n\n\\\n\n**Confidence Interval (t-based):**\n$$\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}$$\n\nwhere $t^*$ comes from a t-distribution with $df = n - 1$\n\n\\\n\n**Confidence Interval (z-based, if σ known):**\n$$\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}$$\n\n## Looking ahead\n\n**Next time:**\n\n- More practice with confidence intervals\n- Introduction to hypothesis testing\n- The logic of statistical inference\n\n\\\n\n**For now:**\n\n- Practice calculating CIs with different confidence levels\n- Get comfortable with the t-distribution in R\n- Work on understanding (not just calculating) what CIs mean\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n## Remember\n\nStatistical inference is about quantifying uncertainty. Confidence intervals give us a principled way to say \"we don't know exactly, but here's a plausible range.\"\n:::\n",
    "supporting": [
      "11_sampling_ci_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}