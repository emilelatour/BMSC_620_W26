{
  "hash": "0ab94ff832255d3436d87d0a87845351",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis Testing: Concepts and One-Sample t-Tests\"\nsubtitle: \"Textbook Sections 4.3, 5.1\"\nauthor: \"Emile Latour, Nicky Wakim, Meike Niederhausen\"\ndate: \"2026-02-04\"\ndate-format: long\nformat:\n  revealjs:\n    theme: \"../../assets/css/reveal-bmsc620_v5.scss\"\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"BMSC 620 | Hypothesis Testing\"\n    html-math-method: mathjax\n    chalkboard: true\nexecute:\n  echo: true\n  warning: false\n  message: false\n  freeze: auto\n---\n\n\n\n\n\n\n# Learning Objectives\n\nBy the end of today's lecture, you will be able to:\n\n1.  Understand the relationship between confidence intervals and hypothesis tests\n2.  State null and alternative hypotheses for a one-sample test\n3.  Calculate and interpret test statistics and p-values\n4.  Conduct a one-sample t-test in R\n5.  Make appropriate conclusions from hypothesis tests\n\n## Roadmap for Today\n\n::::: columns\n::: {.column width=\"50%\"}\n**Part 1: From CIs to Hypothesis Tests**\n\n-   Review: CIs answer \"what are plausible values?\"\n-   New question: \"Is a specific value plausible?\"\n-   The logic of hypothesis testing\n\n**Part 2: Hypothesis Testing Framework**\n\n-   Null and alternative hypotheses\n-   Significance level (α)\n-   Test statistics\n-   P-values\n:::\n\n::: {.column width=\"50%\"}\n**Part 3: One-Sample t-Tests**\n\n-   When to use a one-sample t-test\n-   Calculating the t-statistic\n-   Interpreting p-values\n-   Making conclusions\n\n**Part 4: Conducting Tests in R**\n\n-   Using `t.test()` function\n-   Interpreting R output\n-   Connecting CIs and hypothesis tests\n\n**Part 5: Wrap-up**\n\n-   Common mistakes\n-   Best practices\n:::\n:::::\n\n# Connecting CIs and Hypothesis Tests\n\n## Review: What we learned last time\n\n**Last time we learned about confidence intervals:**\n\n-   A 95% CI gives us a range of plausible values for $\\mu$\n-   It's based on sample data: $\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}$\n-   Interpretation: \"We are 95% confident that $\\mu$ is in this interval\"\n\n\\\n\n**Example from last time:**\n\nSample of 50 adults: $\\bar{x} = 66.1$ inches, $s = 3.5$ inches\n\n95% CI: (65.12, 67.08)\n\n**Conclusion:** We're 95% confident the population mean height is between 65.12 and 67.08 inches.\n\n## A different kind of question\n\n**CIs answer:** \"What are plausible values for $\\mu$?\"\n\n\\\n\n**But sometimes we want to know:** \"Is a *specific* value plausible?\"\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n**CI approach:**\n\n-   Calculate interval (65.12, 67.08)\n-   See if our value of interest is in it\n-   If 65 inches is in the interval → plausible\n-   If 70 inches is NOT in the interval → implausible\n:::\n\n::: {.column width=\"48%\"}\n**Hypothesis test approach:**\n\n-   Start with a specific claim about $\\mu$\n-   Use our data to evaluate evidence *against* that claim\n-   Get a number (p-value) that quantifies the strength of evidence\n:::\n:::::\n\n\\\n\n**Both approaches use the same underlying statistics - just framed differently!**\n\nIn fact, for two-sided tests, a hypothesis test at $\\alpha = 0.05$ will always agree with a 95% confidence interval.\n\n## Motivating example: Body temperature\n\n**The traditional claim:** Average human body temperature is 98.6°F\n\n\\\n\n**Historical context:**\n\n-   German physician Carl Wunderlich established 98.6°F in 1851\n-   Based on 25,000 patients in Leipzig, Germany\n-   This value has been used for over 170 years\n\n\\\n\n**Recent evidence suggests it might be lower:**\n\n-   1992 JAMA study: sample mean = 98.25°F (n = 130, s = 0.733)\n-   More recent studies suggest even lower (around 97.9°F)\n\n\\\n\n::: {.callout-note icon=\"false\"}\n## Research Question\n\nBased on the 1992 data, is there evidence that the population mean body temperature is **different from** 98.6°F?\n:::\n\n## Two approaches to answer this question\n\n::::::: columns\n:::: {.column width=\"48%\"}\n::: {.callout-tip icon=\"false\"}\n## Approach 1: Confidence Interval\n\n**Question:** Is 98.6°F a plausible value?\n\n\\\n\n**Method:**\n\n-   Calculate 95% CI for $\\mu$\n-   See if 98.6 falls in the interval\n\n\\\n\n**What we get:**\n\n-   A range of plausible values\n-   Yes/no answer: \"Is 98.6 plausible?\"\n:::\n::::\n\n:::: {.column width=\"48%\"}\n::: {.callout-important icon=\"false\"}\n## Approach 2: Hypothesis Test\n\n**Question:** How strong is evidence against 98.6°F?\n\n\\\n\n**Method:**\n\n-   Assume $\\mu = 98.6$ is true\n-   Calculate how unusual our data is\n-   Get a p-value\n\n\\\n\n**What we get:**\n\n-   Strength of evidence against 98.6\n-   Can compare to different values\n:::\n::::\n:::::::\n\n**Key point:** Both use the same math, different framing!\n\n## Approach 1: Using a confidence interval\n\nFrom our data: $\\bar{x} = 98.25$, $s = 0.733$, $n = 130$\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate 95% CI\nn <- 130\nxbar <- 98.25\ns <- 0.733\n\nt_star <- qt(0.975, df = n - 1)\nSE <- s / sqrt(n)\n\nlower <- xbar - t_star * SE\nupper <- xbar + t_star * SE\n\nc(lower, upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 98.1228 98.3772\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**Conclusion:** We are 95% confident that the (population) mean body temperature is between 98.12°F and 98.38°F, which is discernibly different than 98.6°F.\n\n\\\n\n98.6°F is NOT in this interval, so it's not a plausible value for the population mean. There's evidence the true mean is lower than 98.6°F.\n\n## Visualizing the CI approach\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_hypothesis_testing_files/figure-revealjs/unnamed-chunk-2-1.png){width=1152}\n:::\n:::\n\n\n\n\nThe claimed value (98.6°F) falls outside our confidence interval - this suggests it's not plausible.\n\n# Hypothesis Testing Framework\n\n## The logic of hypothesis testing\n\n<!-- **Core idea:** Proof by contradiction -->\n\n\\\n\n1.  **Start with an assumption** (the null hypothesis)\n    -   \"The population mean is 98.6°F\"\n2.  **Collect data** and see if it's consistent with that assumption\n    -   We observed $\\bar{x} = 98.25°F$\n3.  **Ask:** \"If the assumption were true, how unusual would our data be?\"\n    -   This gives us the p-value\n4.  **If our data would be very unusual** under the assumption\n    -   We have evidence against the assumption\n    -   We reject the null hypothesis\n\n\\\n\n**Analogy:** Like a jury trial - we assume innocence (null hypothesis) unless evidence is strong enough to reject it.\n\n## What is random here? (Revisited)\n\nRemember from our sampling distribution lecture:\n\n\\\n\n**If the null hypothesis is true (**$\\mu = 98.6$):\n\n-   The population has mean $\\mu = 98.6$\n-   Our sample is random\n-   Our sample mean $\\bar{x}$ is random\n-   $\\bar{x}$ has a sampling distribution centered at 98.6\n\n\\\n\n**The hypothesis test asks:**\n\n\"Given that the sampling distribution is centered at 98.6, how likely is it to get a sample mean as extreme as 98.25 (or more extreme)?\"\n\n\\\n\nIf that's very unlikely → evidence against the null hypothesis\n\n## Step 1: State the hypotheses\n\nEvery hypothesis test has two competing hypotheses:\n\n\\\n\n::: {.callout-important icon=\"false\"}\n## Null Hypothesis ($H_0$)\n\nThe **null hypothesis** is the status quo or claim of \"no effect/no difference\"\n\n-   Usually states that a parameter equals a specific value\n-   What we assume is true unless we have strong evidence against it\n-   For our example: $H_0: \\mu = 98.6$\n:::\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n## Alternative Hypothesis ($H_A$)\n\nThe **alternative hypothesis** is what the researcher wants to show\n\n-   Claims the parameter is different from (or greater/less than) the null value\n-   What we conclude if we have sufficient evidence\n-   For our example: $H_A: \\mu \\neq 98.6$\n:::\n\n## Writing hypotheses: Symbols and words\n\n**For our body temperature example:**\n\n\\\n\n**In symbols:**\n\n$$H_0: \\mu = 98.6$$ $$H_A: \\mu \\neq 98.6$$\n\n\\\n\n**In words:**\n\n-   $H_0$: The population mean body temperature is 98.6°F\n-   $H_A$: The population mean body temperature is not 98.6°F\n\n\\\n\n**Key points:**\n\n-   The null hypothesis uses = (equals sign)\n-   The alternative uses $\\neq$, $>$, or $<$\n-   $\\mu_0$ represents the \"null value\" (98.6 in this case)\n\n## One-sided vs. two-sided alternatives\n\nThe alternative hypothesis can take three forms:\n\n\\\n\n::::::::: columns\n:::: {.column width=\"32%\"}\n::: {.callout-note icon=\"false\"}\n## Two-sided\n\n$$H_A: \\mu \\neq \\mu_0$$\n\n**Use when:** You don't have a prior belief about direction\n\n**Example:** Is the mean different from 98.6?\n\n**Most conservative and common**\n:::\n::::\n\n:::: {.column width=\"32%\"}\n::: {.callout-note icon=\"false\"}\n## One-sided (greater)\n\n$$H_A: \\mu > \\mu_0$$\n\n**Use when:** You only care if it's higher\n\n**Example:** Is the mean greater than 98.6?\n\n**Less common**\n:::\n::::\n\n:::: {.column width=\"32%\"}\n::: {.callout-note icon=\"false\"}\n## One-sided (less)\n\n$$H_A: \\mu < \\mu_0$$\n\n**Use when:** You only care if it's lower\n\n**Example:** Is the mean less than 98.6?\n\n**Less common**\n:::\n::::\n:::::::::\n\n\\\n\n**Default:** Use two-sided unless you have a strong reason to be one-sided\n\nImportantly, the choice of one- vs two-sided must be made before seeing the data — not after.\n\n## Step 2: Set the significance level ($\\alpha$)\n\n**Before** collecting data, we decide our threshold for \"strong evidence\"\n\n\\\n\n::: {.callout-important icon=\"false\"}\n## Significance Level ($\\alpha$)\n\nThe **significance level** is the threshold below which we'll reject $H_0$\n\n-   Most common: $\\alpha = 0.05$ (5%)\n-   Means we're willing to wrongly reject $H_0$ at most 5% of the time\n    -   If $H_0$ were true and we repeated this study many times, about 5% of those studies would lead us to reject it just by chance\n-   Connected to confidence level: $\\alpha = 1 - \\text{confidence level}$\n:::\n\n**Common choices:**\n\n-   $\\alpha = 0.05$ (95% confidence) - most common\n-   $\\alpha = 0.01$ (99% confidence) - more stringent\n-   $\\alpha = 0.10$ (90% confidence) - more lenient\n\n\\\n\n**For our example:** We'll use $\\alpha = 0.05$\n\n## Step 3: Check assumptions\n\nBefore conducting any hypothesis test, verify the assumptions:\n\n**For a one-sample t-test:**\n\n1.  **Independence:** Observations are independent of each other\n    -   Random sampling helps ensure this\n2.  **Normality or large sample:**\n    -   Data are approximately normally distributed, OR\n    -   Sample size is large ($n \\geq 30$) so we can use CLT\n\n\\\n\n**For our body temperature example:**\n\n-   [x] Sample of 130 individuals (presumably independent)\n-   [x] $n = 130 \\geq 30$, so CLT applies\n-   We can proceed with the test!\n\n::: {.callout-warning icon=\"false\"}\n## Important\n\nIf assumptions are violated, the test may not be valid. Consider non-parametric alternatives.\n:::\n\n## Step 4: Calculate the test statistic\n\nThe **test statistic** measures how far our sample mean is from the null value, in standard error units.\n\n::: {.callout-tip icon=\"false\"}\n## t-statistic formula\n\n$$t = \\frac{\\bar{x} - \\mu_0}{SE} = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}$$\n\nwhere:\n\n-   $\\bar{x}$ = sample mean\n-   $\\mu_0$ = null value (from $H_0$)\n-   $s$ = sample standard deviation\n-   $n$ = sample size\n:::\n\n\\\n\n**Interpretation:**\n\n-   $t$ tells us how many standard errors $\\bar{x}$ is from $\\mu_0$\n-   Large absolute values of $t$ → strong evidence against $H_0$\n-   Under $H_0$, $t$ follows a t-distribution with $df = n - 1$\n\n## Calculating the t-statistic: Example\n\nFor our body temperature data:\n\n-   $\\bar{x} = 98.25$\n-   $\\mu_0 = 98.6$ (from $H_0$)\n-   $s = 0.733$\n-   $n = 130$\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate t-statistic\nxbar <- 98.25\nmu_0 <- 98.6\ns <- 0.733\nn <- 130\n\nSE <- s / sqrt(n)\nt_stat <- (xbar - mu_0) / SE\n\nSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06428835\n```\n\n\n:::\n\n```{.r .cell-code}\nt_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -5.444221\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**Interpretation:** Our sample mean is about 5.45 standard errors below the null value. This seems pretty far!\n\n## Calculating the t-statistic: Example\n\n::::: columns\n::: {.column width=\"50%\"}\nFor our body temperature data:\n\n-   $\\bar{x} = 98.25$\n-   $\\mu_0 = 98.6$ (from $H_0$)\n-   $s = 0.733$\n-   $n = 130$\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate t-statistic\nxbar <- 98.25\nmu_0 <- 98.6\ns <- 0.733\nn <- 130\n\nSE <- s / sqrt(n)\nt_stat <- (xbar - mu_0) / SE\n\nSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06428835\n```\n\n\n:::\n\n```{.r .cell-code}\nt_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -5.444221\n```\n\n\n:::\n:::\n\n\n\n:::\n:::::\n\n\\\n\n**Interpretation:** Our sample mean is about 5.45 standard errors below the null value. This seems pretty far!\n\n## Visualizing the test statistic\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_hypothesis_testing_files/figure-revealjs/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n\n\nOur observed t-statistic is way out in the tail - this will lead to a small p-value!\n\n## Step 5: Calculate the p-value (1/2)\n\n::: {.callout-important icon=\"false\"}\n## What is a p-value?\n\nThe **p-value** is the probability of observing a test statistic as extreme as (or more extreme than) what we actually observed, **assuming** $H_0$ is true.\n:::\n\n\\\n\n**For a two-sided test:** We care about both tails\n\n$$\\text{p-value} = P(|T| \\geq |t_{observed}| \\mid H_0 \\text{ is true})$$\n\nWhere: - $T$ = a randomly chosen t-statistic from the null distribution - $t_{observed}$ = the t-statistic computed from our sample\n\n\\\n\n**In plain language:**\n\n\"Given the null hypothesis is true, what's the probability of getting a sample mean at least as far from $\\mu_0$ as ours?\"\n\n## Step 5: Calculate the p-value (2/2)\n\n**In R:**\n\nFor a two-sided hypothesis test, the p-value is the probability of seeing a test statistic at least as far from zero as the one we observed, in either direction. So we\n\n1.  Take the absolute value of the t-statistic (distance from zero),\n2.  Find the probability of being that far out in one tail,\n3.  Multiply by 2 to account for both tails.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate t-statistic\nxbar <- 98.25\nmu_0 <- 98.6\ns <- 0.733\nn <- 130\n\nSE <- s / sqrt(n)\nt_stat <- (xbar - mu_0) / SE\n\n# Calculate p-value (two-sided)\np_value <- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.530265e-07\n```\n\n\n:::\n:::\n\n\n\n\n## Interpreting p-values\n\n:::::: {.callout-note icon=\"false\"}\n## P-value interpretation guidelines\n\n::::: columns\n::: {.column width=\"50%\"}\n**Small p-value (\\< α):**\n\n-   Our data would be very unusual if $H_0$ were true\n-   Strong evidence **against** $H_0$\n-   We **reject** $H_0$\n:::\n\n::: {.column width=\"50%\"}\n**Large p-value (≥ α):**\n\n-   Our data are not that unusual if $H_0$ were true\n-   Insufficient evidence against $H_0$\n-   We **fail to reject** $H_0$ (we don't say \"accept\"!)\n:::\n:::::\n::::::\n\n\\\n\n**For our example:**\n\n-   p-value $\\approx$ 0.0000003 (very small!)\n-   This is way less than $\\alpha = 0.05$\n-   We reject $H_0$\n\n## Common p-value misconceptions\n\n::: {.callout-warning icon=\"false\"}\n## What p-values ARE NOT\n\n**WRONG:** \"The probability that $H_0$ is true\"\n\n-   $H_0$ is either true or false (not a probability)\n-   P-value assumes $H_0$ IS true\n\n**WRONG:** \"The probability of making a mistake by rejecting $H_0$\"\n\n-   That's the significance level α (set in advance)\n-   P-value is calculated from data\n\n**WRONG:** \"The effect size or importance\"\n\n-   Small p-value just means \"unusual under $H_0$\"\n-   Doesn't tell you if the difference matters practically\n:::\n\n\\\n\n**CORRECT:** P-value = \"How surprising is our data if $H_0$ were true?\"\n\n## Step 6: Make a conclusion\n\n**Decision rule:**\n\n-   If p-value \\< α: Reject $H_0$\n-   If p-value ≥ α: Fail to reject $H_0$\n\n\\\n\n**For our example:**\n\np-value $\\approx$ 0.0000003 \\< 0.05, so we **reject** $H_0$\n\n\\\n\n**Formal conclusion:**\n\n\"At the α = 0.05 significance level, we reject the null hypothesis. There is statistically significant evidence that the population mean body temperature is different from 98.6°F.\"\n\n\\\n\n**Contextual conclusion:**\n\n\"Based on this sample of 130 individuals, the data provide strong evidence that the average human body temperature is not 98.6°F. The sample suggests the true average is closer to 98.25°F.\"\n\n# One-Sample t-Tests in R\n\n## The `t.test()` function\n\nR makes hypothesis testing easy with the `t.test()` function:\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x, mu = 0, alternative = \"two.sided\", conf.level = 0.95)\n```\n:::\n\n\n\n\n\\\n\n**Key arguments:**\n\n-   `x` = vector of data (or formula)\n-   `mu` = null value ($\\mu_0$)\n-   `alternative` = \"two.sided\", \"less\", or \"greater\"\n-   `conf.level` = confidence level (default 0.95)\n\n\\\n\n**For our example (using summary statistics):**\n\nWe don't have the raw data, but we can work with what we have...\n\n## Using t.test() with summary statistics\n\nWhen you only have summary statistics (not raw data), you can still test:\n\n<!-- ```{r} -->\n\n<!-- # Our summary statistics -->\n\n<!-- xbar <- 98.25 -->\n\n<!-- s <- 0.733 -->\n\n<!-- n <- 130 -->\n\n<!-- mu_0 <- 98.6 -->\n\n<!-- # Calculate t-statistic -->\n\n<!-- t_stat <- (xbar - mu_0) / (s / sqrt(n)) -->\n\n<!-- # Calculate p-value (two-sided) -->\n\n<!-- p_value <- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE) -->\n\n<!-- # Calculate 95% CI -->\n\n<!-- t_crit <- qt(0.975, df = n - 1) -->\n\n<!-- ci_lower <- xbar - t_crit * (s / sqrt(n)) -->\n\n<!-- ci_upper <- xbar + t_crit * (s / sqrt(n)) -->\n\n<!-- # Display results -->\n\n<!-- list( -->\n\n<!--   t_statistic = t_stat, -->\n\n<!--   p_value = p_value, -->\n\n<!--   conf_interval = c(ci_lower, ci_upper) -->\n\n<!-- ) -->\n\n<!-- ``` -->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Our summary statistics\nxbar <- 98.25\ns <- 0.733\nn <- 130\nmu_0 <- 98.6\n\n# Calculate t-statistic\nt_stat <- (xbar - mu_0) / (s / sqrt(n))\nt_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -5.444221\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate p-value (two-sided)\np_value <- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.530265e-07\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate 95% CI\nt_crit <- qt(0.975, df = n - 1)\nci <- c(xbar - t_crit * (s / sqrt(n)),\n        xbar + t_crit * (s / sqrt(n)))\nci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 98.1228 98.3772\n```\n\n\n:::\n:::\n\n\n\n\n## Example with raw data\n\nLet's use the full body temperature dataset:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the data\n# See ?readr::read_csv\nbodytemp <- readr::read_csv(here::here(\"data\", \n                                       \"BodyTemperatures.csv\"))\n\n# See ?janitor::clean_names\nbodytemp <- bodytemp |> \n  janitor::clean_names()\n\n# Look at the data\ndplyr::glimpse(bodytemp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 130\nColumns: 3\n$ temperature <dbl> 96.3, 96.7, 96.9, 97.0, 97.1, 97.1, 97.1, 97.2, 97.3, 97.4…\n$ gender      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ heart_rate  <dbl> 70, 71, 74, 80, 73, 75, 82, 64, 69, 70, 68, 72, 78, 70, 75…\n```\n\n\n:::\n:::\n\n\n\n\n## Conducting the t-test in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform one-sample t-test\n# H0: mu = 98.6 vs HA: mu != 98.6\ntest_result <- t.test(bodytemp$temperature, \n                      mu = 98.6, \n                      alternative = \"two.sided\")\n\n# Display results\ntest_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  bodytemp$temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923 \n```\n\n\n:::\n:::\n\n\n\n\n## Understanding the R output\n\nLet's break down what R tells us:\n\n**t.test() output includes:**\n\n-   **t-statistic:** how many SEs away from $\\mu_0$\n-   **degrees of freedom:** $n - 1$\n-   **p-value:** probability of seeing this (or more extreme) if $H_0$ true\n-   **confidence interval:** 95% CI for $\\mu$\n-   **sample estimate:** our sample mean\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n**From our output:**\n\n-   $t = -5.45$\n-   $df = 129$\n-   p-value \\< 0.0001\n-   95% CI: (98.12, 98.38)\n-   $\\bar{x} = 98.25$\n:::\n\n::: {.column width=\"48%\"}\n**What this means:**\n\n-   Sample mean is 5.45 SEs below 98.6\n-   Very strong evidence against $H_0$\n-   We're 95% confident the true mean is between 98.12 and 98.38\n-   Both approaches agree: 98.6 is not plausible\n:::\n:::::\n\n\n## Using the broom package for tidy output\n\nThe `broom` package makes output easier to work with:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n\n# Tidy the output\ntidy_result <- tidy(test_result)\ntidy_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  estimate statistic     p.value parameter conf.low conf.high method alternative\n     <dbl>     <dbl>       <dbl>     <dbl>    <dbl>     <dbl> <chr>  <chr>      \n1     98.2     -5.45 0.000000241       129     98.1      98.4 One S… two.sided  \n```\n\n\n:::\n\n```{.r .cell-code}\n# Now it's a nice tibble we can manipulate\ntidy_result %>%\n  select(estimate, statistic, p.value, conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  estimate statistic     p.value conf.low conf.high\n     <dbl>     <dbl>       <dbl>    <dbl>     <dbl>\n1     98.2     -5.45 0.000000241     98.1      98.4\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\nThis is especially useful when running multiple tests or creating tables!\n\n## Using rstatix\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\n\nt_test(data = bodytemp, \n       temperature ~ 1, \n       mu = 98.6, \n       conf.level = 0.95, \n       detailed = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 12\n  estimate .y.    group1 group2     n statistic       p    df conf.low conf.high\n*    <dbl> <chr>  <chr>  <chr>  <int>     <dbl>   <dbl> <dbl>    <dbl>     <dbl>\n1     98.2 tempe… 1      null …   130     -5.45 2.41e-7   129     98.1      98.4\n# ℹ 2 more variables: method <chr>, alternative <chr>\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Visualizing our test\n\nThis plot is descriptive — the hypothesis test is not based on the histogram, but on the sampling distribution of the mean\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_hypothesis_testing_files/figure-revealjs/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\n\n\n## Connection between CIs and hypothesis tests\n\n::: {.callout-important icon=\"false\"}\n## Key relationship\n\nFor a two-sided test at significance level $\\alpha$:\n\n\n\n::: columns\n::: {.column width=\"50%\"}\n**If the $(1-\\alpha)×100\\%$ CI does NOT contain** $\\mu_0$:\n\n→ We reject $H_0$ at level α\n:::\n\n::: {.column width=\"50%\"}\n**If the $(1-\\alpha)×100\\%$ CI DOES contain** $\\mu_0$:\n\n→ We fail to reject $H_0$ at level α\n:::\n:::\n\n\n:::\n\n\\\n\n**For our example:**\n\n-   95% CI: (98.12, 98.38)\n-   Does NOT contain 98.6\n-   So we reject $H_0$ at α = 0.05\n-   This matches our p-value \\< 0.05 conclusion\n\n\\\n\n**They're two ways of saying the same thing!**\n\n# Common Mistakes and Best Practices\n\n## Common mistakes to avoid\n\n::: {.callout-warning icon=\"false\"}\n## Mistake 1: \"Accepting\" the null hypothesis\n\n**WRONG:** \"We accept $H_0$\"\n\n**CORRECT:** \"We fail to reject $H_0$\"\n\n**Why?** Absence of evidence ≠ evidence of absence. We never \"prove\" $H_0$ true.\n:::\n\n\\\n\n::: {.callout-warning icon=\"false\"}\n## Mistake 2: Confusing practical and statistical significance\n\n**Small p-value** = statistically significant (unusual under $H_0$)\n\n**BUT** doesn't mean the effect is large or important!\n\nWith large $n$, even tiny differences can be \"significant\"\n:::\n\n## More common mistakes\n\n::: {.callout-warning icon=\"false\"}\n## Mistake 3: P-hacking\n\n**DON'T:**\n\n-   Run multiple tests and only report significant ones\n-   Try different cutoffs until you get p \\< 0.05\n-   Add data until you get significance\n\n**This inflates Type I error rate!**\n:::\n\n\n::: {.callout-warning icon=\"false\"}\n## Mistake 4: Ignoring assumptions\n\n**Always check:**\n\n-   Independence of observations\n-   Sample size or normality\n-   No extreme outliers (for small samples)\n\n**If violated, results may not be trustworthy**\n:::\n\n## Best practices for hypothesis testing\n\n\\\n\n::: columns\n::: {.column width=\"50%\"}\n**Before collecting data:**\n\n1.  State your hypotheses clearly\n2.  Choose your significance level ($\\alpha$)\n3.  Determine your sample size\n4.  Plan your analysis\n\n\\\n\n**After collecting data:**\n\n1.  Check assumptions\n2.  Calculate test statistic and p-value\n3.  Make a decision (reject or fail to reject)\n4.  State conclusion in context\n5.  Report confidence interval too!\n:::\n\n::: {.column width=\"50%\"}\n**Always:**\n\n-   Be transparent about your methods\n-   Report exact p-values (not just \"\\< 0.05\")\n-   Discuss practical significance, not just statistical\n:::\n:::\n\n\n## Reporting your results\n\n**Good statistical reporting includes:**\n\n1.  **Descriptive statistics:** $\\bar{x}$, $s$, $n$\n2.  **Test details:** Which test, hypotheses, α level\n3.  **Results:** Test statistic, df, p-value\n4.  **Confidence interval:** Gives effect size estimate\n5.  **Conclusion in context:** What does it mean?\n\n\\\n\n**Example:**\n\n\"A one-sample t-test was conducted to determine if mean body temperature differs from 98.6°F. The sample (n = 130) had a mean of 98.25°F (SD = 0.733). The test was statistically significant (t(129) = -5.45, p \\< 0.001, 95% CI: \\[98.12, 98.38\\]), indicating that population mean body temperature is likely lower than the traditional 98.6°F value.\"\n\nOr\n\n\"There is strong evidence (p \\< 0.001) suggesting the population mean body temperature is no longer 98.6°F (one-sample t-test). \n\n# Summary\n\n## What we learned today\n\n**Conceptual understanding:**\n\n-   Hypothesis tests evaluate evidence against a claim ($H_0$)\n-   P-values measure \"how surprising\" our data are if $H_0$ is true\n-   Small p-value → reject $H_0$, large p-value → fail to reject $H_0$\n-   Hypothesis tests and CIs are two sides of the same coin\n\n\\\n\n**Technical skills:**\n\n-   State null and alternative hypotheses\n-   Calculate t-statistics and p-values\n-   Use `t.test()` in R\n-   Interpret output correctly\n-   Connect CIs and hypothesis tests\n\n## The six steps of hypothesis testing\n\n1.  **Check assumptions** (independence, normality/large n)\n\n2.  **Set significance level** (usually α = 0.05)\n\n3.  **State hypotheses** ($H_0$ and $H_A$)\n\n4.  **Calculate test statistic** ($t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}$)\n\n5.  **Find p-value** (probability of seeing this or more extreme)\n\n6.  **Make conclusion** (reject or fail to reject $H_0$, with context)\n\n\\\n\n**Remember:** The p-value is NOT the probability that $H_0$ is true!\n\n## Key formulas for reference\n\n**Test statistic:**\n\n$$t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}$$\n\n\\\n\n**Degrees of freedom:**\n\n$$df = n - 1$$\n\n\\\n\n**Decision rule:**\n\n-   If p-value \\< \\alpha → Reject $H_0$\n-   If p-value ≥ \\alpha → Fail to reject $H_0$\n\n\\\n\n**Connection to CI:**\n\n-   If $(1-\\alpha)×100\\%$ CI excludes $\\mu_0$ → Reject $H_0$\n-   If $(1-\\alpha)×100\\%$ CI includes $\\mu_0$ → Fail to reject $H_0$\n\n## Looking ahead\n\n**Next time:**\n\n-   Paired t-tests (dependent samples)\n-   Two-sample t-tests (independent samples)\n-   More hypothesis testing practice\n\n\\\n\n**For now:**\n\n-   Practice stating hypotheses correctly\n-   Get comfortable with p-value interpretation\n-   Work on connecting CIs and hypothesis tests\n-   Use R to conduct tests\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n## Remember\n\nStatistical significance (p \\< 0.05) doesn't automatically mean practical importance. Always think about the context and effect size!\n:::\n\n\n## What's next? \n\nCI's and hypothesis testing for different scenarios:\n\n\n| Day | Section |  Population parameter   |       Symbol        |       Point estimate       |            Symbol             |\n|:----:|:------:|:----------:|:--------:|:----------:|:-------:|\n| 10  |   5.1   |        Pop mean         |        $\\mu$        |        Sample mean         |           $\\bar{x}$           |\n| 10  |   5.2   | Pop mean of paired diff | $\\mu_d$ or $\\delta$ | Sample mean of paired diff |         $\\bar{x}_{d}$         |\n| 11  |   5.3   |    Diff in pop means    |    $\\mu_1-\\mu_2$    |    Diff in sample means    |    $\\bar{x}_1 - \\bar{x}_2$    |\n| 12  |   8.1   |     Pop proportion      |         $p$         |        Sample prop         |         $\\widehat{p}$         |\n| 12  |   8.2   |   Diff in pop prop's    |      $p_1-p_2$      |   Diff in sample prop's    | $\\widehat{p}_1-\\widehat{p}_2$ |",
    "supporting": [
      "12_hypothesis_testing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}