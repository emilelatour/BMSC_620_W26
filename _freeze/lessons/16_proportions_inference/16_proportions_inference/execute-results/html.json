{
  "hash": "785b0b2c3fd09fba2400d3151c22f380",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference for Proportions and 2×2 Tables\"\nsubtitle: \"Textbook Sections 8.1, 8.2\"\nauthor: \"Emile Latour, Nicky Wakim, Meike Niederhausen\"\ndate: \"2026-02-23\"\ndate-format: long\nformat:\n  revealjs:\n    theme: \"../../assets/css/reveal-bmsc620_v5.scss\"\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"BMSC 620 | Inference for Proportions\"\n    html-math-method: mathjax\n    chalkboard: true\n    header-includes: |\n      <style>\n      #wrap {\n        width: 1650px;\n        height: 900px;\n        margin: 0 auto;\n        overflow: hidden;\n        border: 1px solid #999;\n        border-radius: 8px;\n      }\n      #frame {\n        width: 1650px;\n        height: 900px;\n        border: 0;\n        zoom: 1.25;\n        -moz-transform: scale(1.25);\n        -moz-transform-origin: 0 0;\n      }\n      /* Make selected tables bigger in RevealJS slides (robust to flextable output) */\n      .reveal .tbl-big {\n        font-size: 28px !important;\n        /* center the output block inside the column */\n        display: flex;\n        justify-content: center;\n      \n        /* scale from center */\n        transform: scale(1.6);\n        transform-origin: top center;\n      }\n      .reveal .tbl-big table,\n      .reveal .tbl-big .flextable,\n      .reveal .tbl-big .flextable table {\n        font-size: 28px !important;\n      }\n      .reveal .tbl-big td,\n      .reveal .tbl-big th {\n        padding: 6px 10px !important;\n      }\n      </style>\nexecute:\n  echo: true\n  warning: false\n  message: false\n  freeze: auto\n---\n\n\n\n\n\n\n# Learning Objectives\n\nBy the end of today's lecture, you will be able to:\n\n1. Apply the normal approximation to the sampling distribution of a sample proportion\n2. Conduct hypothesis tests for a single proportion\n3. Construct and interpret confidence intervals for a single proportion\n4. Test for differences between two independent proportions\n5. Interpret data displayed in 2×2 tables\n6. Choose the appropriate inference method based on study design\n\n## Roadmap for Today\n\n::::: columns\n::: {.column width=\"50%\"}\n**Part 1: Moving from Means to Proportions**\n\n- Why categorical outcomes matter\n- From binomial to proportions\n- Sampling distribution of $\\hat{p}$\n- Success-failure condition\n\n**Part 2: Single Proportion Inference**\n\n- The melanoma immunotherapy example\n- Hypothesis testing for proportions\n- Confidence intervals for proportions\n- Using `prop.test()` in R\n:::\n\n::: {.column width=\"50%\"}\n**Part 3: Comparing Two Proportions**\n\n- Difference in proportions: $p_1 - p_2$\n- The aspirin and heart attack example\n- Two-sample tests with `prop.test()`\n- Interpreting results\n\n**Part 4: Understanding 2×2 Tables**\n\n- Organizing categorical data\n- Risk difference, relative risk, odds ratio\n- When to use each measure\n- Common mistakes to avoid\n:::\n:::::\n\n## CI's and hypothesis testing for different scenarios (1/2)\n\n\n| Day | Section |  Population parameter   |       Symbol        |       Point estimate       |            Symbol             |\n|:----:|:------:|:----------:|:--------:|:----------:|:-------:|\n| 9  |   5.1   |        Population mean         |        $\\mu$        |        Sample mean         |           $\\bar{x}$           |\n| 10  |   5.2   | Population mean of paired differences | $\\mu_d$ or $\\delta$ | Sample mean of paired differences |         $\\bar{x}_{d}$         |\n| 10  |   5.3   |    Differences in population means    |    $\\mu_1-\\mu_2$    |    Differences in sample means    |    $\\bar{x}_1 - \\bar{x}_2$    |\n| **13**  |   **8.1**   |     **Population proportion**      |         **$p$**         |        **Sample proportion**         |         **$\\widehat{p}$**         |\n| **13**  |   **8.2**   |   **Differences in population proportions**    |      **$p_1-p_2$**      |   **Differences in sample proportions**    | **$\\widehat{p}_1-\\widehat{p}_2$** |\n\n\\\n\n**Today we add proportions to our inference toolkit!**\n\n## CI's and hypothesis testing for different scenarios (2/2)\n\n\\\n\n$$\\text{point estimate} \\pm z^*(or~t^*)\\cdot SE$$\n\n\\\n$$\\text{test stat} = \\frac{\\text{point estimate}-\\text{null value}}{SE}$$\n\n\n\n# Part 1: Moving from Means to Proportions\n\n## Where are we in the course?\n\nWe've been building up our inference toolkit for **numerical outcomes**:\n\n\\\n\n**So far:**\n\n- One-sample mean: $\\mu$ \n- Paired differences: $\\mu_d$\n- Difference in means (independent): $\\mu_1 - \\mu_2$\n- Understanding power and sample size\n\n\\\n\n**Today we shift to categorical outcomes:**\n\n- Single proportion: $p$\n- Difference in proportions: $p_1 - p_2$\n- Data organized in 2×2 tables\n\n\\\n\n**Why this matters:** Many medical outcomes are categorical (disease/no disease, response/no response, alive/dead)!\n\n## Why do we care about categorical data?\n\n::: {.callout-note icon=\"false\"}\n## Categorical Data in Medical Research\n\n**Categorical outcomes arise constantly in biomedical research because:**\n\n- Disease states are often binary: diabetes vs. no diabetes, cancer vs. no cancer\n- Treatment responses: complete response, partial response, no response\n- Vital status: alive vs. deceased at follow-up\n- Screening results: positive vs. negative test\n- Patient characteristics: smoker vs. non-smoker, male vs. female\n:::\n\n\\\n\n**Examples from recent research:**\n\n- Does a new immunotherapy increase the proportion of melanoma patients who respond?\n- Do statins reduce the proportion of patients who experience cardiovascular events?\n- Is there a difference in COVID-19 infection rates between vaccinated and unvaccinated individuals?\n\n\n## Reminder: The binomial distribution\n\n\\\n\nFrom Week 4, we learned about binomial random variables:\n\n::: {.callout-important icon=\"false\"}\n### Binomial Random Variable\n::: columns\n::: {.column width=\"48%\"}\n\n\n$X$ is a binomial random variable if it represents the **number of successes** in $n$ independent trials where:\n\n- Each trial has two possible outcomes: success or failure\n- The probability of success is $p$ (same for all trials)\n- Trials are independent of each other\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n**Notation:** $X \\sim \\text{Binomial}(n, p)$\n\n**Parameters:** \n\n- $n$ = number of trials\n- $p$ = probability of success\n- Mean: $E(X) = np$\n- SD: $SD(X) = \\sqrt{np(1-p)}$\n\n\n:::\n:::\n\n\n:::\n\n## From counts to proportions\n\nThe **sample proportion** is just a rescaled version of the count:\n\n\\\n\n$$\\hat{p} = \\frac{X}{n} = \\frac{\\text{number of successes}}{n}$$\n\n\\\n\n**Example:** In a study of 52 melanoma patients treated with immunotherapy:\n\n- 21 patients responded to treatment (success)\n- $\\hat{p} = \\frac{21}{52} = 0.404$ or 40.4%\n\n\\\n\n**Important distinction:**\n\n- $X$ = number of successes (a count: 21)\n- $\\hat{p}$ = proportion of successes (a ratio: 0.404)\n- Both give us information about the same thing, just scaled differently\n\n\n\n## The sampling distribution of $\\hat{p}$\n\n\\\n\nJust like with $\\bar{x}$, the sample proportion $\\hat{p}$ has a sampling distribution!\n\n\\\n\n**If we repeated the study many times with different samples:**\n\n- Each sample would give us a different $\\hat{p}$\n- These $\\hat{p}$ values would cluster around the true $p$\n- The distribution of $\\hat{p}$ would be approximately normal (under certain conditions)\n\n\\\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_proportions_inference_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n\n<!-- ::: {.callout-important icon=\"false\"} -->\n<!-- ## Sampling Distribution of $\\hat{p}$ -->\n\n<!-- When the **success-failure condition** is met, the sampling distribution of $\\hat{p}$ is approximately: -->\n\n<!-- $$\\hat{p} \\sim N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)$$ -->\n\n<!-- **Mean:** $E(\\hat{p}) = p$ (unbiased!) -->\n\n<!-- **Standard error:** $SE_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}}$ -->\n<!-- ::: -->\n\n\n## Sampling distribution of $\\hat{p}$ (cont.)\n\n* $\\hat{p}=\\frac{X}{n}$ where $X$ is the number of \"successes\" and $n$ is the sample size.\n* $X \\sim Bin(n,p)$, where $p$ is the population proportion.\n* For $n$ \"big enough\", the normal distribution can be used to approximate a binomial distribution:\n\n$$X \\sim Bin(n,p) \\longrightarrow X \\sim N\\Big(\\mu = np, \\sigma = \\sqrt{np(1-p)} \\Big)$$\n\n* Since $\\hat{p}=\\frac{X}{n}$ is a linear transformation of $X$, we have for large n: \n\n$$\\hat{p} \\sim N\\Big(\\mu_{\\hat{p}} = p, \\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}} \\Big)$$\n\n\n\n\n\n## The success-failure condition\n\n::: {.callout-warning icon=\"false\"}\n## When Can We Use the Normal Approximation?\n\nThe sampling distribution of $\\hat{p}$ is approximately normal when:\n\n\\\n\n**1. Independence:** Observations are independent of each other\n\n- Usually satisfied with random sampling\n- Can be approximately satisfied in well-designed studies\n\n\\\n\n**2. Success-failure condition:** At least 10 expected successes AND 10 expected failures\n\n- **For confidence intervals:** Check $n\\hat{p} \\geq 10$ and $n(1-\\hat{p}) \\geq 10$\n- **For hypothesis tests:** Check $np_0 \\geq 10$ and $n(1-p_0) \\geq 10$\n  - Use the hypothesized $p_0$ for tests because we're checking conditions under $H_0$!\n:::\n\n\n## Why does the success-failure condition matter?\n\nThe binomial distribution is **discrete** (counts: 0, 1, 2, 3, ...)\n\nThe normal distribution is **continuous**\n\n\\\n\n**When $n$ is small or $p$ is extreme:**\n\n- The binomial distribution is skewed\n- Normal approximation is poor\n- Our p-values and CIs will be inaccurate\n\n\\\n\n**When $np \\geq 10$ and $n(1-p) \\geq 10$:**\n\n- The binomial distribution looks approximately symmetric\n- Normal approximation works well\n- Our inferences are valid\n\n\\\n\n**Visual intuition:** Think about flipping a coin 5 times ($n=5, p=0.5$) vs. 50 times ($n=50, p=0.5$). Which will look more normal?\n\n# Part 2: Single Proportion Inference\n\n## Reminder: The six steps of hypothesis testing\n\nWe'll use our familiar framework for proportions:\n\n1.  **State hypotheses** ($H_0$ and $H_A$)\n2.  **Set significance level** (usually $\\alpha$ = 0.05)\n3.  **Check assumptions** (independence, success-failure condition)\n4.  **Calculate test statistic** \n    - For proportions: $z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$\n5.  **Find p-value** (probability of seeing this or more extreme)\n6.  **Make conclusion** (reject or fail to reject $H_0$, with context)\n\n\\\n\n**Note:** We use $z$ not $t$ because we know the population SD exactly under $H_0$!\n\n## Today's example: Advanced melanoma immunotherapy\n\n::: {.callout-note icon=\"false\"}\n## Research Context\n\n**Background:**\n\n- Advanced melanoma is an aggressive form of skin cancer\n- Until recently, it was almost uniformly fatal\n- Researchers noticed rare cases where patients' immune systems successfully attacked the cancer\n- This led to development of immunotherapy drugs\n\n\n**Study (Wolchok et al., 2013 in *NEJM*):**\n\n- 52 patients with advanced melanoma were treated with **two new therapies concurrently**: nivolumab and ipilimumab\n- Both drugs work by releasing \"brakes\" on the immune system\n- **Outcome:** Response to therapy (tumor shrinkage or disappearance)\n- **Result:** 21 of 52 patients (40%) responded\n\n\\\n\n**Historical context:** Previous studies with single-agent therapy showed response rates of 30% or less.\n:::\n\n## Research question\n\n::: {.callout-important icon=\"false\"}\n## The Question\n\nDo these results provide evidence that the response probability with **concurrent** therapy is **greater than 30%** (the historical benchmark)?\n\n\\\n\n**Why this matters:**\n\n- Combination therapy is more toxic and expensive than single-agent\n- We need evidence it's better before recommending it widely\n- This was an early study to justify larger clinical trials\n:::\n\n\\\n\n**Let's walk through the six steps!**\n\n## Step 1: State the hypotheses\n\n**In symbols:**\n\n$$H_0: p = 0.30$$\n$$H_A: p > 0.30$$\n\n\\\n\n**In words:**\n\n- $H_0$: The proportion of advanced melanoma patients who respond to concurrent immunotherapy is 30% (same as historical single-agent rate)\n- $H_A$: The proportion who respond to concurrent immunotherapy is **greater than** 30%\n\n\\\n\n**Note:** This is a one-sided test because we only care if the new treatment is *better*. We wouldn't adopt it if it were worse!\n\n## Step 2: Set the significance level\n\n\\\n\nWe'll use the conventional $\\alpha = 0.05$\n\n\\\n\n**Interpretation:** We're willing to accept a 5% chance of incorrectly rejecting $H_0$ (Type I error)\n\n\\\n\n\\ \n\n\\ \n\n**Note:** In practice, one-sided tests are sometimes held to $\\alpha = 0.025$ to \nmaintain stringency comparable to a two-sided test at $\\alpha = 0.05$. \nWe'll use $\\alpha = 0.05$ here for simplicity.\n\n## Step 3: Check the assumptions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Study data\nn <- 52           # Sample size\nx <- 21           # Number of responders\np_hat <- x / n    # Sample proportion\np0 <- 0.30        # Null hypothesis value\n\n# Print values\np_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4038462\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**1. Independence:** Patients in a clinical trial are reasonably independent (one patient's response doesn't affect another's)\n\n\\\n\n**2. Success-failure condition under** $H_0$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn * p0              # Expected successes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15.6\n```\n\n\n:::\n\n```{.r .cell-code}\nn * (1 - p0)        # Expected failures\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 36.4\n```\n\n\n:::\n:::\n\n\n\n\nBoth $\\geq 10$ ✓ — the normal approximation is appropriate!\n\n## Step 4: Calculate the test statistic\n\n**Formula:**\n\n$$z = \\frac{\\hat{p} - p_0}{SE_{\\hat{p}}} = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$$\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate standard error under H0\nSE_p <- sqrt(p0 * (1 - p0) / n)\nSE_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06354889\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate z-statistic\nz_stat <- (p_hat - p0) / SE_p\nz_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.634114\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\nOur observed proportion (0.404) is about **1.64 standard errors** above the null value (0.30).\n\n## Step 5: Find the p-value\n\nThe p-value is the probability of observing $\\hat{p} \\geq$ 0.404 (or more extreme) if $H_0$ were true.\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-sided p-value (upper tail)\np_value <- pnorm(abs(z_stat), lower.tail = FALSE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05111742\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**Interpretation:** \n\n- If the true response rate were 30.0%, we'd see a sample proportion of 40.4% or higher in about **5.1%** of samples of size 52.\n\n## Step 6: Make a conclusion\n\n\\\n\n**Statistical conclusion:**\n\nAt $\\alpha = 0.05$, the p-value = 0.051 is right at our threshold. We would barely **fail to reject** $H_0$.\n\n\\\n\n**Contextual conclusion:**\n\nThe data provide **marginal evidence** that concurrent immunotherapy produces a response rate higher than the historical 30% benchmark. However:\n\n- The result is borderline significant\n- This is a small, early-phase study\n- Further investigation with larger trials is warranted\n\n\\\n\n**Why researchers continued:** The 40.4% response rate, even if barely not significant statistically, is **clinically meaningful** for patients with a disease that was previously nearly 100% fatal!\n\n\n## Confidence intervals for proportions\n\nWe can also construct a confidence interval for $p$:\n\n\\\n\n**Formula:**\n\n$$\\hat{p} \\pm z^* \\cdot SE_{\\hat{p}} = \\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n\n\\\n\n**Important difference from hypothesis testing:**\n\n- For **CIs**, use $\\hat{p}$ in the SE formula (because we're estimating the SE)\n- For **tests**, use $p_0$ in the SE formula (because we're checking conditions under $H_0$)\n\n## Calculating a 95% CI for the melanoma data\n\nWe have a one sided test where we were testing if the proportion who respond to concurrent immunotherapy is *greater than* 0.30, a minimum threshold, not just different than it.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate SE using p-hat (not p0!)\nSE_ci <- sqrt(p_hat * (1 - p_hat) / n)\nSE_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06804332\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get z* for 95% CI (one-sided)\nz_star <- qnorm(0.95)\nz_star\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.644854\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate margin of error\nmargin <- z_star * SE_ci\nmargin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1119213\n```\n\n\n:::\n\n```{.r .cell-code}\n# Construct one-sided\nci_lower <- p_hat - margin\n\nci_lower\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2919249\n```\n\n\n:::\n:::\n\n\n\n\n## Calculating a 95% CI for the melanoma data (two-sided)\n\nIf we had wanted a two-sided 95% confidence interval:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate SE using p-hat (not p0!)\nSE_ci <- sqrt(p_hat * (1 - p_hat) / n)\nSE_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06804332\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get z* for 95% CI (two-sided)\nz_star <- qnorm(0.975)\nz_star\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.959964\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate margin of error\nmargin <- z_star * SE_ci\nmargin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1333625\n```\n\n\n:::\n\n```{.r .cell-code}\n# Construct two-sided 95% CI\nci_lower <- p_hat - margin\nci_upper <- p_hat + margin\n\nc(ci_lower, ci_upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2704837 0.5372086\n```\n\n\n:::\n:::\n\n\n\n\n## The `prop.test()` function\n\nR has a built in function for performing hypothesis test of proportions:\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(x, n, \n          p = NULL,\n          alternative = c(\"two.sided\", \"less\", \"greater\"),\n          conf.level = 0.95, \n          correct = TRUE)\n```\n:::\n\n\n\n\n\\\n\n**Key arguments:**\n\n-   `x` = number of successes\n-   `n` = number of trials\n-   `p` = null value ($p_0$)\n-   `alternative` = \"two.sided\", \"less\", or \"greater\"\n-   `conf.level` = confidence level (default 0.95)\n-   `correct` = whether to use continuity correction or not\n\n## Melanoma data with `prop.test()`\n\nInstead of calculating by hand, we can use R's built-in function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-sample proportion test\ntest_result <- prop.test(\n  x = 21,                     # Number of successes\n  n = 52,                     # Sample size  \n  p = 0.30,                   # Null hypothesis value\n  alternative = \"greater\",    # One-sided test\n  conf.level = 0.95,\n  correct = FALSE             # Default is TRUE, set to FALSE for now\n)\n\ntest_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test without continuity correction\n\ndata:  21 out of 52, null probability 0.3\nX-squared = 2.6703, df = 1, p-value = 0.05112\nalternative hypothesis: true p is greater than 0.3\n95 percent confidence interval:\n 0.2993794 1.0000000\nsample estimates:\n        p \n0.4038462 \n```\n\n\n:::\n:::\n\n\n\n\n## Different confidence intervals\n\n::: {.callout-note}\n`prop.test()` reports a Wilson score confidence interval, not the Wald interval from our hand calculation — hence the slight difference in the lower bound. Wilson is preferred in practice.\n\nAffects two-sided and one-sided intervals. Two-sided shown here.\n:::\n\n\n::: columns\n::: {.column width=\"30%\"}\n\n#### From the by hand calculations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(ci_lower, ci_upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2704837 0.5372086\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.column width=\"70%\"}\n#### From `prop.test()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_result_2sided <- prop.test(x = 21, n = 52,\n                                p = 0.30, \n                                alternative = \"two.sided\",\n                                conf.level = 0.95,\n                                correct = FALSE)\n\ntest_result_2sided %>% \n  tidy() %>% \n  dplyr::select(conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  conf.low conf.high\n     <dbl>     <dbl>\n1    0.282     0.539\n```\n\n\n:::\n:::\n\n\n\n\n:::\n:::\n\n\n\n## Continuity correction: review\n\n\\\n\nWhen we approximate the binomial distribution with a normal distribution, \nwe apply a **continuity correction (CC)** to account for the fact that \nthe binomial is discrete while the normal is continuous.\n\n\\\n\nWe adjust the number of successes by ±0.5 before calculating the probability:\n\n| Goal | Binomial | Normal approximation |\n|---|---|---|\n| $P(X \\leq k)$ | exact | use $P(X \\leq k + 0.5)$ |\n| $P(X \\geq k)$ | exact | use $P(X \\geq k - 0.5)$ |\n\n\\\n\n`prop.test()` applies this same correction to the z-test for proportions \n(`correct = TRUE` is the default).\n\n## CC matters more with small samples\n\n\\\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n#### Without CC (`correct = FALSE`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(x = 21, n = 52, p = 0.30,\n          alternative = \"greater\",\n          correct = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test without continuity correction\n\ndata:  21 out of 52, null probability 0.3\nX-squared = 2.6703, df = 1, p-value = 0.05112\nalternative hypothesis: true p is greater than 0.3\n95 percent confidence interval:\n 0.2993794 1.0000000\nsample estimates:\n        p \n0.4038462 \n```\n\n\n:::\n:::\n\n\n\n:::\n::: {.column width=\"50%\"}\n#### With CC (`correct = TRUE`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(x = 21, n = 52, p = 0.30,\n          alternative = \"greater\",\n          correct = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  21 out of 52, null probability 0.3\nX-squared = 2.1987, df = 1, p-value = 0.06906\nalternative hypothesis: true p is greater than 0.3\n95 percent confidence interval:\n 0.2906582 1.0000000\nsample estimates:\n        p \n0.4038462 \n```\n\n\n:::\n:::\n\n\n\n:::\n::::\n\n## CC matters less with large samples\n\n\\\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n#### Without CC (`correct = FALSE`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(x = 210, n = 520, p = 0.30,\n          alternative = \"greater\",\n          correct = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test without continuity correction\n\ndata:  210 out of 520, null probability 0.3\nX-squared = 26.703, df = 1, p-value = 1.186e-07\nalternative hypothesis: true p is greater than 0.3\n95 percent confidence interval:\n 0.3690394 1.0000000\nsample estimates:\n        p \n0.4038462 \n```\n\n\n:::\n:::\n\n\n\n:::\n::: {.column width=\"50%\"}\n#### With CC (`correct = TRUE`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(x = 210, n = 520, p = 0.30,\n          alternative = \"greater\",\n          correct = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  210 out of 520, null probability 0.3\nX-squared = 26.211, df = 1, p-value = 1.53e-07\nalternative hypothesis: true p is greater than 0.3\n95 percent confidence interval:\n 0.3680964 1.0000000\nsample estimates:\n        p \n0.4038462 \n```\n\n\n:::\n:::\n\n\n\n:::\n::::\n\n\\\n\n::: {.callout-note icon=\"false\"}\n#### Takeaway:\n\np-values and CIs converge as n grows — the correction \nbecomes negligible. For small samples, CC makes the test more conservative \n(larger p-value), which is the safer choice.\n:::\n\n\n## What should I use in practice?\n\n::: {.callout-important icon=\"false\"}\n## Recommendation: Use `prop.test()` defaults\n\nFor inference on proportions, use `prop.test()` with its default settings:\n\n- **Wilson score interval** — better than Wald, especially for small samples or extreme proportions\n- **Continuity correction** (`correct = TRUE`) — more conservative, accounts for the discrete-to-continuous approximation\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is what you should use by default\nprop.test(x = 21, n = 52, \n          p = 0.30,\n          alternative = \"greater\",\n          conf.level = 0.95)   # correct = TRUE is the default!\n```\n:::\n\n\n\n\n\\\n\n**Why did we show `correct = FALSE` earlier?**\n\nTo match our hand calculations and illustrate the method. In practice, always let R apply the continuity correction unless you have a specific reason not to.\n\n## Back to the Melanoma data with `prop.test()`\n\nInstead of calculating by hand, we can use R's built-in function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-sample proportion test\ntest_result <- prop.test(\n  x = 21,                     # Number of successes\n  n = 52,                     # Sample size  \n  p = 0.30,                   # Null hypothesis value\n  alternative = \"greater\",    # One-sided test\n  conf.level = 0.95,\n  correct = TRUE              # Use continuity correction\n)\n\n\nlibrary(broom)\ntidy(test_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     <dbl>     <dbl>   <dbl>     <int>    <dbl>     <dbl> <chr>      <chr>      \n1    0.404      2.20  0.0691         1    0.291         1 1-sample … greater    \n```\n\n\n:::\n:::\n\n\n\n\n\n## Conclusions from the Melanoma data\n\n**Key pieces:**\n\n- `estimate`: $\\hat{p} =$ 0.404 (our sample proportion)\n- `statistic`: $\\chi^2 =$ 2.199 (different test statistic than $z$, but equivalent)\n- `p.value`: $p =$ 0.069 (slightly different due to continuity correction)\n- `conf.low`, `conf.high`: (0.291, 1.000), one-sided 95% CI for $p$\n\n\n**Note:** The continuity correction makes the test more conservative (higher p-value) than when we calculated $p =$ 0.051 before.\n\n\\\n\n::: {.callout-note icon=\"false\"}\n#### Interpretation\n\nThe actual percentage of advanced melanoma patients who respond to concurrent immunotherapy is not significantly greater than 30% (one-sided *p*-value = 0.069, one-sample proportions test with continuity correction). Based on the study, it is estimated that 40% of those with advanced melanoma respond to concurrent immunotherapy (95% one-sided CI: at least 29%).\n:::\n\n\n## `prop_test` function in `Rstatix`\n\n\\\n\nThe `rstatix` package offers a tidy-friendly wrapper that integrates well with pipelines.\n\n\\\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\nprop_test(\n  x = 21,                       # Number of successes\n  n = 52,                       # Sample size  \n  p = 0.30,                     # Null hypothesis value\n  alternative = \"greater\",      # One-sided test\n  conf.level = 0.95,\n  correct = TRUE,               # Use continuity correction\n  detailed = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 11\n      n    n1 estimate statistic      p    df conf.low conf.high method   \n* <dbl> <dbl>    <dbl>     <dbl>  <dbl> <int>    <dbl>     <dbl> <chr>    \n1    52    21    0.404      2.20 0.0691     1    0.291         1 Prop test\n# ℹ 2 more variables: alternative <chr>, p.signif <chr>\n```\n\n\n:::\n:::\n\n\n\n\n<!-- ## Binom.test -->\n\n<!-- ```{r} -->\n<!-- binom_res <- binom.test( -->\n<!--   x = 21,                         # Number of successes -->\n<!--   n = 52,                         # Sample size   -->\n<!--   p = 0.30,                       # Null hypothesis value -->\n<!--   alternative = \"greater\",        # One-sided test -->\n<!--   conf.level = 0.95) -->\n\n\n<!-- binom_res -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- rstatix::binom_test(x = 21,                       # Number of successes -->\n<!--   n = 52,                       # Sample size   -->\n<!--   p = 0.30,                     # Null hypothesis value -->\n<!--   alternative = \"greater\",      # One-sided test -->\n<!--   conf.level = 0.95,  -->\n<!--   detailed = TRUE) -->\n<!-- ``` -->\n\n## Exact binomial test: motivation\n\n\\\n\nOur z-test for proportions relies on the **normal approximation** to the binomial.\n\n\\\n\nBut what if we want an **exact** result — no approximation needed?\n\n\\\n\n::: {.callout-note icon=\"false\"}\n#### The exact binomial test\n\nInstead of approximating with a normal distribution, `binom.test()` computes \nthe p-value **directly from the binomial distribution**:\n\n$$p\\text{-value} = P(X \\geq 21 \\mid n = 52, p_0 = 0.30)$$\n\n- No success-failure condition required\n- Works for any sample size, any $p$\n- Always valid — but less commonly taught because it's harder to do by hand\n:::\n\n\\\n\n**When to use it:** Small samples, extreme proportions, or when you want \nexact inference without relying on the normal approximation.\n\n## Exact binomial test with `binom.test()`\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinom_res <- binom.test(\n  x = 21,                   # Number of successes\n  n = 52,                   # Sample size\n  p = 0.30,                 # Null hypothesis value\n  alternative = \"greater\",  # One-sided test\n  conf.level = 0.95\n)\n\nbinom_res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact binomial test\n\ndata:  21 and 52\nnumber of successes = 21, number of trials = 52, p-value = 0.07167\nalternative hypothesis: true probability of success is greater than 0.3\n95 percent confidence interval:\n 0.2889045 1.0000000\nsample estimates:\nprobability of success \n             0.4038462 \n```\n\n\n:::\n:::\n\n\n\n\n## Comparing `binom.test()` to `prop.test()`\n\n\\\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n#### Exact binomial (`binom.test`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(binom_res) %>% \n  dplyr::select(estimate, p.value, \n                conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  estimate p.value conf.low conf.high\n     <dbl>   <dbl>    <dbl>     <dbl>\n1    0.404  0.0717    0.289         1\n```\n\n\n:::\n:::\n\n\n\n- p-value computed directly from binomial\n- Uses **Clopper-Pearson** CI (exact)\n- Always valid\n:::\n::: {.column width=\"50%\"}\n#### Normal approximation (`prop.test`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(test_result) %>% \n  dplyr::select(estimate, p.value, \n                conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  estimate p.value conf.low conf.high\n     <dbl>   <dbl>    <dbl>     <dbl>\n1    0.404  0.0691    0.291         1\n```\n\n\n:::\n:::\n\n\n\n- p-value based on normal approximation + CC\n- Uses **Wilson score** CI\n- Requires success-failure condition\n:::\n::::\n\n\\\n\n::: {.callout-note icon=\"false\"}\n#### Takeaway\n\nResults are similar here because $n = 52$ is large enough for the normal \napproximation to work well. For small samples or extreme $p$, they can \ndiverge more — and `binom.test()` is the safer choice.\n:::\n\n## Confidence intervals: three methods compared{.tbl-big}\n\n\n\n\n\n\n\n\n\n**Note:** Switching to a two-sided 95% CI here to better illustrate \nhow the three methods differ at both bounds.\n\n\\\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pxyxpexmzs\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pxyxpexmzs table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pxyxpexmzs thead, #pxyxpexmzs tbody, #pxyxpexmzs tfoot, #pxyxpexmzs tr, #pxyxpexmzs td, #pxyxpexmzs th {\n  border-style: none;\n}\n\n#pxyxpexmzs p {\n  margin: 0;\n  padding: 0;\n}\n\n#pxyxpexmzs .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pxyxpexmzs .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pxyxpexmzs .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pxyxpexmzs .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pxyxpexmzs .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pxyxpexmzs .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pxyxpexmzs .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pxyxpexmzs .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pxyxpexmzs .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pxyxpexmzs .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pxyxpexmzs .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pxyxpexmzs .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pxyxpexmzs .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pxyxpexmzs .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pxyxpexmzs .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pxyxpexmzs .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pxyxpexmzs .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pxyxpexmzs .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pxyxpexmzs .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pxyxpexmzs .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pxyxpexmzs .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pxyxpexmzs .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pxyxpexmzs .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pxyxpexmzs .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pxyxpexmzs .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pxyxpexmzs .gt_left {\n  text-align: left;\n}\n\n#pxyxpexmzs .gt_center {\n  text-align: center;\n}\n\n#pxyxpexmzs .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pxyxpexmzs .gt_font_normal {\n  font-weight: normal;\n}\n\n#pxyxpexmzs .gt_font_bold {\n  font-weight: bold;\n}\n\n#pxyxpexmzs .gt_font_italic {\n  font-style: italic;\n}\n\n#pxyxpexmzs .gt_super {\n  font-size: 65%;\n}\n\n#pxyxpexmzs .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pxyxpexmzs .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pxyxpexmzs .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pxyxpexmzs .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pxyxpexmzs .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pxyxpexmzs .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pxyxpexmzs .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pxyxpexmzs .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pxyxpexmzs div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Method\">Method</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Lower\">Lower</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Upper\">Upper</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Width\">Width</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Method\" class=\"gt_row gt_left\">Wald (by hand)</td>\n<td headers=\"Lower\" class=\"gt_row gt_right\">0.2705</td>\n<td headers=\"Upper\" class=\"gt_row gt_right\">0.5372</td>\n<td headers=\"Width\" class=\"gt_row gt_right\">0.2667</td></tr>\n    <tr><td headers=\"Method\" class=\"gt_row gt_left\">Wilson (prop.test)</td>\n<td headers=\"Lower\" class=\"gt_row gt_right\">0.2731</td>\n<td headers=\"Upper\" class=\"gt_row gt_right\">0.5487</td>\n<td headers=\"Width\" class=\"gt_row gt_right\">0.2756</td></tr>\n    <tr><td headers=\"Method\" class=\"gt_row gt_left\">Clopper-Pearson (binom.test)</td>\n<td headers=\"Lower\" class=\"gt_row gt_right\">0.2701</td>\n<td headers=\"Upper\" class=\"gt_row gt_right\">0.5490</td>\n<td headers=\"Width\" class=\"gt_row gt_right\">0.2789</td></tr>\n  </tbody>\n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\\\n\n- **Wald**: simplest formula, least accurate (especially at boundaries)\n- **Wilson**: good balance of accuracy and simplicity — `prop.test()` default\n- **Clopper-Pearson**: exact, slightly conservative (wider interval)\n\n\\\n\n**In practice:** Wilson or Clopper-Pearson are both defensible. \nWald is taught for conceptual understanding, not for real use.\n\n# Part 3: Comparing Two Proportions\n\n## From one proportion to two\n\nWe've learned to make inferences about a **single** proportion.\n\n\\\n\n**Now:** What if we want to **compare** proportions from two independent groups?\n\n\\\n\n**Examples:**\n\n- Does aspirin reduce the proportion of people who have heart attacks compared to placebo?\n- Is the proportion of smokers higher among lung cancer patients than controls?\n- Does a new vaccine produce antibody responses in a higher proportion than the old vaccine?\n\n\\\n\n**This is analogous to:**\n\n- One-sample mean ($\\mu$) → Two independent sample means ($\\mu_1 - \\mu_2$)\n\n## The sampling distribution of $\\hat{p}_1 - \\hat{p}_2$\n\nJust like with the difference in means, we need to know the sampling distribution of the difference in proportions!\n\n\\\n\n::: {.callout-important icon=\"false\"}\n## Sampling Distribution of $\\hat{p}_1 - \\hat{p}_2$\n\nWhen conditions are met, the sampling distribution of $\\hat{p}_1 - \\hat{p}_2$ is approximately:\n\n$$\\hat{p}_1 - \\hat{p}_2 \\sim N\\left(p_1 - p_2, \\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}\\right)$$\n\n\\\n\n**Mean:** $E(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2$\n\n**Standard error:** $SE_{\\hat{p}_1 - \\hat{p}_2} = \\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}$\n:::\n\n\\\n\n**Note the similarity to the SE for difference in means!**\n\n## Conditions for comparing two proportions\n\n::: {.callout-warning icon=\"false\"}\n## Success-Failure Condition for Two Proportions\n\n::: columns\n::: {.column width=\"50%\"}\n**For confidence intervals:**\n\n- At least 10 successes and 10 failures in **each** group\n- Check: \n  - $n_1\\hat{p}_1 \\geq 10$, \n  - $n_1(1-\\hat{p}_1) \\geq 10$, \n  - $n_2\\hat{p}_2 \\geq 10$, \n  - $n_2(1-\\hat{p}_2) \\geq 10$\n:::\n\n::: {.column width=\"50%\"}\n**For hypothesis tests** (testing $H_0: p_1 = p_2$):\n\n- Use the **pooled proportion** to check conditions\n- Pooled: $\\hat{p}_{pool} = \\frac{x_1 + x_2}{n_1 + n_2}$ (combines both groups under $H_0$)\n- Check: \n  - $n_1\\hat{p}_{pool} \\geq 10$, \n  - $n_1(1-\\hat{p}_{pool}) \\geq 10$, \n  - $n_2\\hat{p}_{pool} \\geq 10$, \n  - $n_2(1-\\hat{p}_{pool}) \\geq 10$\n:::\n:::\n\n:::\n\n\n::: {.callout-tip icon=\"false\"}\n## Independence\n\n- Observations within each group are independent\n- The two groups are independent of each other\n:::\n\n## Example: Aspirin and heart attacks\n\n::: {.callout-note icon=\"false\"}\n## The Physicians' Health Study\n\n**Study design (1989):**\n\n- 22,071 male physicians enrolled\n- **Random assignment** to one of two groups:\n  - Aspirin: 325 mg every other day (n = 11,037)\n  - Placebo: Identical-looking pill (n = 11,034)\n- Follow-up for heart attacks over ~5 years\n\n\\\n\n**Results:**\n\n- Aspirin group: 104 heart attacks\n- Placebo group: 189 heart attacks\n\n\\\n\n**Research question:** Does aspirin reduce the risk of heart attack in healthy men?\n:::\n\n## Setting up the hypothesis test\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Study data\nn_aspirin <- 11037\nn_placebo <- 11034\nx_aspirin <- 104   # Heart attacks in aspirin group\nx_placebo <- 189   # Heart attacks in placebo group\n\n# Calculate sample proportions\np_hat_aspirin <- x_aspirin / n_aspirin\np_hat_placebo <- x_placebo / n_placebo\n\np_hat_aspirin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00942285\n```\n\n\n:::\n\n```{.r .cell-code}\np_hat_placebo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01712887\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**Observed difference:**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff_hat <- p_hat_aspirin - p_hat_placebo\ndiff_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.007706024\n```\n\n\n:::\n:::\n\n\n\n\nThe aspirin group had about **0.77%** fewer heart attacks (about 8 per 1000 people).\n\n## Hypotheses for comparing two proportions\n\n**Let:**\n\n- $p_{aspirin}$ = proportion who have heart attacks in the aspirin group\n- $p_{placebo}$ = proportion who have heart attacks in the placebo group\n\n\\\n\n**Hypotheses:**\n\n::: columns\n::: {.column width=\"40%\"}\n\n\\\n\n$$H_0: p_{aspirin} = p_{placebo}$$\n$$H_A: p_{aspirin} < p_{placebo} $$\n:::\n\n::: {.column width=\"40%\"}\nOr equivalently\n\n$$H_0: p_{aspirin} - p_{placebo} = 0$$\n$$H_A: p_{aspirin} - p_{placebo} < 0$$\n\n:::\n::: {.column width=\"20%\"}\n\n:::\n:::\n\n\n\\\n\n**In words:**\n\n- $H_0$: Aspirin and placebo have the same heart attack rate\n- $H_A$: Aspirin has a **lower** heart attack rate than placebo\n\n\\\n\nThis is a **one-sided** test (we're only interested in whether aspirin *reduces* risk).\n\n## Check assumptions\n\n**1. Independence:**\n\n- Random assignment ✓\n- Observations within groups are independent ✓\n\n**2. Success-failure condition:**\n\nFor a hypothesis test, we check using the **pooled proportion** under $H_0$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pooled proportion\np_pool <- (x_aspirin + x_placebo) / (n_aspirin + n_placebo)\np_pool\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01327534\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check success-failure for each group\n```\n:::\n\n\n\n\n::: columns\n::: {.column width=\"57%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Expected \"successes\" (heart attacks) in aspirin\nn_aspirin * p_pool        \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 146.5199\n```\n\n\n:::\n\n```{.r .cell-code}\n# Expected \"failures\" in aspirin \nn_aspirin * (1 - p_pool)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10890.48\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"43%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Expected \"successes\" in placebo\nn_placebo * p_pool\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 146.4801\n```\n\n\n:::\n\n```{.r .cell-code}\n# Expected \"failures\" in placebo\nn_placebo * (1 - p_pool)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10887.52\n```\n\n\n:::\n:::\n\n\n\n\n:::\n:::\nAll $\\geq 10$ ✓ — normal approximation is valid!\n\n## Using R: `prop.test()` for two proportions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-sample proportion test\naspirin_test <- prop.test(\n  x = c(x_aspirin, x_placebo),    # Vector of successes: c(104, 189)\n  n = c(n_aspirin, n_placebo),    # Vector of sample sizes: c(11037, 11034)\n  alternative = \"less\",           # Aspirin < Placebo\n  conf.level = 0.95,\n  correct = TRUE\n)\n\naspirin_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t2-sample test for equality of proportions with continuity correction\n\ndata:  c(x_aspirin, x_placebo) out of c(n_aspirin, n_placebo)\nX-squared = 24.429, df = 1, p-value = 3.855e-07\nalternative hypothesis: less\n95 percent confidence interval:\n -1.000000000 -0.005082393\nsample estimates:\n    prop 1     prop 2 \n0.00942285 0.01712887 \n```\n\n\n:::\n:::\n\n\n\n\n## Interpreting the results\n\n\n\\\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(aspirin_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 9\n  estimate1 estimate2 statistic     p.value parameter conf.low conf.high method \n      <dbl>     <dbl>     <dbl>       <dbl>     <dbl>    <dbl>     <dbl> <chr>  \n1   0.00942    0.0171      24.4 0.000000385         1       -1  -0.00508 2-samp…\n# ℹ 1 more variable: alternative <chr>\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n::: {.callout-note icon=\"false\"}\n#### Conclusion\n\nThe percentage of male physicians that experienced a heart attack in the 5-year follow-up was 0.94% in the aspirin group compared to 1.71% in the placebo group. There is strong evidence that aspirin reduces the risk of heart attack ($p$ < 0.001, two-sample test of proportions). The true difference in heart attack rates is estimated to be 0.77 percentage points lower in the aspirin group (95% one-sided CI: at least 0.51 percentage points lower).\n:::\n\n## Clinical vs. statistical significance\n\n**Statistical significance:** $p$ < 0.001 — the difference is real, not due to chance.\n\n\\\n\n**Clinical significance:** Is an absolute risk reduction of 0.77 percentage points (from 1.71% to 0.94%) clinically meaningful?\n\n\\\n\n**Consider:**\n\n- **Number Needed to Treat (NNT):** How many people need to take aspirin to prevent one heart attack?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NNT = 1 / absolute risk reduction\nNNT <- 1 / abs(diff_hat)\nNNT\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 129.7686\n```\n\n\n:::\n:::\n\n\n\n\nAbout **130 people** (men) need to take aspirin for 5 years to prevent **one** heart attack.\n\n\\\n\n**Trade-off:** Aspirin has side effects (bleeding, ulcers). Is preventing one heart attack per 130 people (men) worth the risk?\n\n\\\n\n**For healthy individuals:** Guidelines now suggest aspirin primarily for those at higher cardiovascular risk!\n\n# Part 4: Understanding 2×2 Tables\n\n## Organizing categorical data in tables\n\nWhen we have two categorical variables, we often display the data in a **contingency table** (also called a **cross-tabulation** or **2×2 table** when each variable has two categories).\n\n\\\n\n**General structure:**\n\n|                | Group 1 | Group 2 | Total |\n|----------------|:-------:|:-------:|:-----:|\n| **Outcome Y**  | $a$     | $b$     | $a+b$ |\n| **Outcome N**  | $c$     | $d$     | $c+d$ |\n| **Total**      | $a+c$   | $b+d$   | $n$   |\n\n\\\n\n**Example (Aspirin study):**\n\n|                | Aspirin | Placebo | Total |\n|----------------|:-------:|:-------:|:-----:|  \n| **Heart attack**| 104    | 189     | 293   |\n| **No heart attack** | 10,933 | 10,845 | 21,778 |\n| **Total**      | 11,037  | 11,034  | 22,071|\n\n## Creating 2×2 tables in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the data as a table\naspirin_table <- matrix(\n  c(104, 189,      # Heart attacks (aspirin, placebo)\n    10933, 10845), # No heart attacks\n  nrow = 2,\n  byrow = TRUE,\n  dimnames = list(\n    Outcome = c(\"Heart attack\", \"No heart attack\"),\n    Group = c(\"Aspirin\", \"Placebo\")\n  )\n)\n\naspirin_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Group\nOutcome           Aspirin Placebo\n  Heart attack        104     189\n  No heart attack   10933   10845\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\nWe can also use `janitor::tabyl()` with raw data, or `table()` for quick summaries.\n\n## Three ways to measure association\n\nFrom a 2×2 table, we can calculate three important measures:\n\n\\\n\n**1. Risk Difference (RD)** — also called Absolute Risk Reduction (ARR)\n\n$$RD = p_1 - p_2$$\n\n\"How much does the risk change in absolute terms?\"\n\n\\\n\n**2. Relative Risk (RR)** — also called Risk Ratio\n\n$$RR = \\frac{p_1}{p_2}$$\n\n\"How many **times** higher/lower is the risk?\"\n\n\\\n\n**3. Odds Ratio (OR)**\n\n$$OR = \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}$$\n\n\"How much do the **odds** of the outcome change?\"\n\n## Calculating measures for the aspirin study\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Proportions\np_aspirin <- 104 / 11037\np_placebo <- 189 / 11034\n\n# Risk Difference\nRD <- p_aspirin - p_placebo\nRD\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.007706024\n```\n\n\n:::\n\n```{.r .cell-code}\n# Relative Risk  \nRR <- p_aspirin / p_placebo\nRR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.550115\n```\n\n\n:::\n\n```{.r .cell-code}\n# Odds Ratio\nodds_aspirin <- p_aspirin / (1 - p_aspirin)\nodds_placebo <- p_placebo / (1 - p_placebo)\nOR <- odds_aspirin / odds_placebo\nOR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5458355\n```\n\n\n:::\n:::\n\n\n\n\n## Interpreting the measures\n\n**Risk Difference = -0.77 percentage points**\n\n- Aspirin **reduces** absolute risk by -0.77 percentage points\n- Out of 1000 people, about 8 fewer heart attacks with aspirin\n- **Not percent or %**\n\n\\\n\n**Relative Risk = 0.55 times the risk**\n\n- People taking aspirin have **0.55 times** the risk (or 55% of the risk)\n- Equivalently: aspirin reduces risk by **45%** (1 - 0.55 = 0.45)\n- This sounds more impressive than 0.77 percentage points!\n\n\\\n\n**Odds Ratio = 0.55**\n\n- The odds of a heart attack among those taking aspirin are 0.55 times the odds among those taking a placebo\n- When risks are small (like 1-2%), OR ≈ RR\n\n## When to use each measure\n\n::: {.callout-tip icon=\"false\"}\n## Choosing the Right Measure\n\n**Risk Difference (Absolute Risk Reduction):**\n\n- Most intuitive for patients and clinicians\n- Useful for calculating Number Needed to Treat ($NNT = 1/RD$)\n- **Use when:** Communicating clinical impact\n\n\n**Relative Risk:**\n\n- Shows proportional change in risk\n- Often used in epidemiology\n- **Use when:** Comparing effect sizes across studies with different baseline risks\n- **Be careful:** Can make small absolute differences seem large\n\n\n**Odds Ratio:**\n\n- Required for certain study designs (case-control studies)\n- Approximates RR when outcome is rare (<10%)\n- **Use when:** Doing logistic regression or case-control studies\n:::\n\n## Common mistakes with 2×2 tables\n\n**1. Confusing relative and absolute risk**\n\n\"Aspirin reduces heart attack risk by 45%!\" (Relative)\n\nvs.\n\n\"Aspirin reduces heart attack risk from 1.7% to 0.9%\" (Absolute)\n\nBoth are true, but they feel very different!\n\n\\\n\n**2. Not considering baseline risk**\n\n- A 50% relative reduction means more when baseline risk is 40% (→20%) than when it's 2% (→1%)\n- Always report both relative and absolute effects\n\n\\\n\n**3. Misinterpreting odds ratios as relative risks**\n\n- When outcomes are common (>10%), OR and RR diverge\n- OR always exaggerates effect size when RR > 1 or RR < 1\n\n## Example: Misinterpreting odds ratios\n\nSuppose a treatment increases recovery from 40% to 60%:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate both measures\np_treated <- 0.60\np_control <- 0.40\n\nRR <- p_treated / p_control\nRR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.5\n```\n\n\n:::\n\n```{.r .cell-code}\nodds_treated <- p_treated / (1 - p_treated)  \nodds_control <- p_control / (1 - p_control)\nOR <- odds_treated / odds_control\nOR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.25\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n- **RR = 1.5:** Treatment increases recovery rate by 50%\n- **OR = 2.25:** Odds of recovery are 2.25 times higher\n\n\\\n\nIf you report OR = 2.25 as \"125% increase in recovery,\" you're overstating the effect! When outcomes are common, stick with RR.\n\n## Practice: Interpreting a 2×2 table\n\nA study investigates whether screening mammography reduces breast cancer mortality:\n\n|                | Screened | Not screened | Total |\n|----------------|:--------:|:------------:|:-----:|\n| **Died from breast cancer** | 500 | 505 | 1,005 |\n| **Did not die** | 63,500 | 63,495 | 126,995 |\n| **Total** | 64,000 | 64,000 | 128,000 |\n\n\\\n\n**Calculate:**\n\n1. The proportion who died in each group\n2. Risk difference\n3. Relative risk\n4. Interpret: Does screening reduce mortality?\n\n---\n\n**Solution on next slide...**\n\n## Practice solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Proportions\np_screened <- 500 / 64000\np_not_screened <- 505 / 64000\n\np_screened\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0078125\n```\n\n\n:::\n\n```{.r .cell-code}\np_not_screened\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007890625\n```\n\n\n:::\n\n```{.r .cell-code}\n# Risk Difference\nRD_screen <- p_screened - p_not_screened\nRD_screen\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -7.8125e-05\n```\n\n\n:::\n\n```{.r .cell-code}\n# Relative Risk\nRR_screen <- p_screened / p_not_screened\nRR_screen\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.990099\n```\n\n\n:::\n:::\n\n\n\n\n\\\n\n**Interpretation:** Screening reduces breast cancer mortality from 0.789% to 0.781%, a very small absolute difference (RD = -0.00008). The relative risk is estimated to be 0.99, meaning screened women have 99% the mortality of unscreened (a 1 percentage point relative reduction). Whether this benefit justifies screening depends on costs, false positives, and patient preferences!\n\n# Summary and Key Takeaways\n\n## What we learned today\n\n**Core concepts:**\n\n1. **Single proportion inference**\n   - Sampling distribution of $\\hat{p}$ is approximately normal when success-failure condition is met\n   - Use `prop.test()` for both hypothesis tests and confidence intervals\n   - SE for tests uses $p_0$; SE for CIs uses $\\hat{p}$\n\n\n2. **Two proportion inference**\n   - Compare independent proportions with $\\hat{p}_1 - \\hat{p}_2$\n   - Check success-failure condition for **both** groups\n   - Pooled proportion used for hypothesis tests under $H_0$\n\n3. **2×2 tables and measures of association**\n   - Risk difference: absolute change\n   - Relative risk: proportional change  \n   - Odds ratio: for case-control studies and regression\n   - Each measure tells a different story!\n\n## Looking ahead\n\n\\\n\n**Next class:** \n\n- Chi-squared tests for larger contingency tables (3×3, 4×2, etc.)\n- Fisher's exact test for small samples\n- Testing independence vs. testing association\n\n\n## Key formulas to know about (not memorize)\n\n**Single proportion:**\n\n- SE (test): $\\sqrt{\\frac{p_0(1-p_0)}{n}}$\n- SE (CI): $\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$\n- Test statistic: $z = \\frac{\\hat{p} - p_0}{SE}$\n\n\\\n\n**Two proportions:**\n\n- SE: $\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}$\n- For tests, use pooled $\\hat{p}$ in SE\n\n\\\n\n**2×2 table measures:**\n\n- Risk Difference: $p_1 - p_2$\n- Relative Risk: $p_1 / p_2$\n- Odds Ratio: $\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}$\n\n## Final thoughts: Why proportions matter in medicine\n\n**Many critical health outcomes are binary:**\n\n- Survival vs. death\n- Disease vs. no disease  \n- Response vs. no response\n- Adverse event vs. no adverse event\n\n\\\n\n**Public health impact:**\n\n- Even small absolute differences can matter at population scale\n- A vaccine that reduces infection risk by 1% (absolute) could prevent millions of cases\n- Understanding both relative and absolute effects is essential for informed decision-making\n\n\\\n\n**Your job as a researcher:**\n\n- Report both absolute and relative effects\n- Consider baseline risk and clinical context\n- Don't overstate findings by cherry-picking metrics!\n\n\\\n\n**Next time we'll extend these ideas to more complex categorical data!**\n",
    "supporting": [
      "16_proportions_inference_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}