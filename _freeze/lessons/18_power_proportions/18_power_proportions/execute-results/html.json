{
  "hash": "f5c571e71c70ff4d9d4c7ac9191562be",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Power and Sample Size for Proportions\"\nsubtitle: \"Not covered in textbook\"\nauthor: \"Emile Latour\"\ndate: \"2026-03-02\"\ndate-format: long\nformat:\n  revealjs:\n    theme: \"../../assets/css/reveal-bmsc620_v5.scss\"\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: \"BMSC 620 | Power for Proportions\"\n    html-math-method: mathjax\n    chalkboard: true\nexecute:\n  echo: true\n  warning: false\n  message: false\n  freeze: auto\n---\n\n\n\n\n\n# Learning Objectives\n\nBy the end of today's lecture, you will be able to:\n\n1. Recall and apply the four components of power analysis\n2. Explain how effect size for proportions differs from Cohen's *d* for means\n3. Calculate power and sample size for a **single proportion** using `pwr.p.test()`\n4. Calculate power and sample size for **two independent proportions** using `pwr.2p.test()`\n5. Explain when **correlated (paired) proportions** arise in biomedical research\n6. Conduct McNemar's test in R and interpret results\n7. Describe the key inputs needed to estimate power for paired proportion designs\n\n## Roadmap for Today\n\n\\\n\n::::: columns\n::: {.column width=\"50%\"}\n**Part 1: Connecting Back to What We Know**\n\n- The four components, revisited\n- What changes when outcomes are binary?\n- Effect size for proportions: Cohen's *h*\n- Using the `pwr` package for proportions\n\n**Part 2: Power for a Single Proportion**\n\n- One-sample proportion test recap\n- The melanoma immunotherapy example\n- Using `pwr.p.test()`\n- Interpreting results\n:::\n\n::: {.column width=\"50%\"}\n**Part 3: Power for Two Independent Proportions**\n\n- Two-proportion test recap\n- A new treatment comparison example\n- Using `pwr.2p.test()`\n- Sensitivity analysis: varying assumptions\n\n**Part 4: Correlated Proportions and McNemar's Test**\n\n- When observations are paired\n- McNemar's test: the idea\n- Running McNemar's test in R\n- Power considerations for paired proportions\n:::\n:::::\n\n# Part 1: Connecting Back to What We Know\n\n## Recall: The four components of power\n\n\\\n\nFrom Lesson 12, every power calculation involves four quantities in equilibrium:\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n\n::: {.callout-important icon=\"false\"}\n### The Four Components\n\n1. **Significance level** ($\\alpha$) — usually 0.05\n2. **Power** ($1 - \\beta$) — usually 80–90%\n3. **Sample size** ($n$) — what we typically solve for\n4. **Effect size** ($\\Delta$) — a property of reality\n:::\n\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n**The key rule:** Specify any 3 to solve for the 4th.\n\n\\\n\n| Study type | What we solve for |\n|---|:-:|\n| Prospective | Sample size ($n$) |\n| Pilot/budget-limited | Effect size ($\\Delta$) |\n| Retrospective | Power ($1-\\beta$) |\n\n:::\n:::::\n\n## What changed in Lessons 13–14?\n\n\\\n\nIn Lesson 12, we worked with **continuous outcomes** (means):\n\n- One-sample t-test: detect difference from a known mean\n- Paired t-test: detect before/after change\n- Two-sample t-test: detect difference between groups\n\n\\\n\n**In Lessons 13–14, we shifted to categorical outcomes (proportions):**\n\n- One proportion: Is $p$ different from some $p_0$?\n- Two proportions: Is $p_1 - p_2 \\neq 0$?\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### Today: Power for proportions\n\nThe **logic** of power is identical — we just need a different way to define effect size when our outcome is binary.\n:::\n\n## Effect size for proportions: Cohen's *h*\n\n\\\n\nFor **means**, we used Cohen's *d*: a standardized difference (one number)\n\n$$d = \\frac{\\mu_1 - \\mu_2}{\\sigma}$$\n\n\\\n\nFor **proportions**, effect size is called Cohen's *h*:\n\n$$h = 2\\arcsin(\\sqrt{p_1}) - 2\\arcsin(\\sqrt{p_2})$$\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n### You don't need to memorize this!\n\nThe `pwr` package computes *h* for you using `ES.h(p1, p2)`.\n\nWhat you **do** need to specify are the **two proportions** themselves — not a single standardized number.\n:::\n\n## Cohen's *h* in practice\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\n\n# Effect size between p1 = 0.50 and p2 = 0.45\nES.h(p1 = 0.50, p2 = 0.45)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1001674\n```\n\n\n:::\n\n```{.r .cell-code}\n# Effect size between p1 = 0.10 and p2 = 0.05\nES.h(p1 = 0.10, p2 = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1924743\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### Key insight\n\nThe same **absolute difference** of 0.05 between two proportions is not always the same effect size! A difference between 0.50 and 0.45 has a smaller effect size than a difference between 0.10 and 0.05.\n\nThis is why we need the arcsine transformation — it accounts for the fact that variance depends on the proportion itself.\n:::\n\n## Why we need the arcsine transformation\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18_power_proportions_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=3450}\n:::\n:::\n\n\n\n::: {.callout-note icon=\"false\"}\n### The key insight\n\n**Left:** The variance of a proportion estimate is not constant — a difference of 0.10 near *p* = 0.50 is much noisier than the same difference near *p* = 0.05 or *p* = 0.95.\n\n**Right:** The arcsine transformation stretches the scale near 0 and 1, so that equal *transformed* gaps correspond to equal statistical difficulty — regardless of where on the [0,1] scale you are. This is what Cohen's *h* captures.\n:::\n\n## The `pwr` functions for proportions\n\n\\\n\nTwo main functions in the `pwr` package:\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n\n**One proportion:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.p.test(\n  h = ES.h(p1, p0),     # effect size\n  n = NULL,             # solve for n\n  sig.level = 0.05,\n  power = 0.80,\n  alternative = \"two.sided\"\n)\n```\n:::\n\n\n\nUse when: comparing a sample proportion to a known historical value\n\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n**Two proportions (equal n):**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.2p.test(\n  h = ES.h(p1, p2),     # effect size\n  n = NULL,             # n PER GROUP\n  sig.level = 0.05,\n  power = 0.80,\n  alternative = \"two.sided\"\n)\n```\n:::\n\n\n\nUse when: comparing two independent groups\n\n:::\n:::::\n\n\\\n\nJust like `pwr.t.test()` — leave the quantity you want to solve for as `NULL`!\n\n# Part 2: Power for a Single Proportion\n\n## Recall: The melanoma immunotherapy example\n\n\\\n\nFrom Lesson 13, we worked with a melanoma immunotherapy study:\n\n\n::: {.callout-note icon=\"false\"}\n### The question\n\nHistorical data show that approximately **30%** of melanoma patients respond to standard treatment.\n\nA new immunotherapy is hypothesized to increase the response rate to **50%**.\n\nBefore running the trial, researchers want to know: **how many patients do we need?**\n:::\n\n\\\n\n**This is a one-sample proportion test:**\n\n- $H_0: p = 0.30$\n- $H_A: p \\neq 0.30$\n\n## Power for a single proportion\n\n\\\n\n**Step 1:** Define the proportions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_null <- 0.30      # historical/null proportion\np_alt  <- 0.50      # expected proportion under new treatment\n```\n:::\n\n\n\n\\\n\n**Step 2:** Calculate the effect size\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh <- ES.h(p1 = p_alt, p2 = p_null)\nh\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4115168\n```\n\n\n:::\n:::\n\n\n\n\\\n\n**Step 3:** Solve for sample size\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.p.test(h = h, sig.level = 0.05, power = 0.80, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4115168\n              n = 46.34804\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n## Interpreting the result\n\n\\\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4115168\n              n = 46.34804\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::: {.callout-important icon=\"false\"}\n### Interpretation\n\nTo detect an increase in response rate from 30% to 50% (Cohen's *h* = 0.412) with 80% power and $\\alpha$ = 0.05, we would need **n = 47 patients**.\n\nNote: always **round up** when solving for sample size — you can't have a fraction of a person!\n:::\n\n## What if we can only enroll 40 patients?\n\n\\\n\nSometimes enrollment is limited by budget or feasibility. We can flip the question: what is our power with a fixed $n$?\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_null <- 0.30      # historical/null proportion\np_alt  <- 0.50      # expected proportion under new treatment\n\npwr.p.test(h = ES.h(p1 = p_alt, p2 = p_null),\n           n = 40,\n           sig.level = 0.05,\n           alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4115168\n              n = 40\n      sig.level = 0.05\n          power = 0.7397922\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-tip icon=\"false\"}\n### Discussion\n\nWith only 40 patients, our power drops substantially. Is that acceptable? **This depends on the context**. For an early-phase pilot study, lower power may be acceptable. For a confirmatory trial, probably not.\n:::\n\n## Sensitivity analysis: varying the alternative proportion\n\n\\\n\nWhat if we're not sure the new treatment achieves 50%? We can calculate sample size for a range of alternatives:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenarios <- tibble(\n  p_alt = c(0.40, 0.45, 0.50, 0.55, 0.60),\n  p_null = 0.30,\n  h = ES.h(p_alt, p_null)) %>%\n  rowwise() %>%\n  mutate(\n    n_needed = ceiling(pwr.p.test(h = h,\n                                  sig.level = 0.05,\n                                  power = 0.80,\n                                  alternative = \"two.sided\")$n)\n    ) %>%\n  ungroup()\n\nscenarios\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  p_alt p_null     h n_needed\n  <dbl>  <dbl> <dbl>    <dbl>\n1  0.4     0.3 0.210      178\n2  0.45    0.3 0.311       81\n3  0.5     0.3 0.412       47\n4  0.55    0.3 0.512       30\n5  0.6     0.3 0.613       21\n```\n\n\n:::\n:::\n\n\n\n## Visualizing the sensitivity analysis\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18_power_proportions_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n\nThe further the true proportion is from the null, the smaller the sample we need — because the effect is easier to detect.\n\n# Part 3: Power for Two Independent Proportions\n\n## A new treatment comparison\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### Research scenario\n\nA clinical trial is planned to compare two immunotherapy regimens for melanoma:\n\n- **Standard immunotherapy** (control): historical response rate of **40%**\n- **Novel combination therapy** (treatment): expected response rate of **60%**\n\nTwo groups of equal size will be randomized. **How many patients per group do we need?**\n:::\n\n\\\n\nThis is a **two independent proportions** problem:\n\n- $H_0: p_1 = p_2$\n- $H_A: p_1 \\neq p_2$\n\n## Power for two proportions: sample size\n\n\n**Step 1:** Define the two proportions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_control   <- 0.40    # response rate, standard treatment\np_treatment <- 0.60    # expected response rate, novel treatment\n```\n:::\n\n\n\n\\\n\n**Step 2:** Compute effect size and solve for n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.2p.test(\n  h = ES.h(p1 = p_treatment, p2 = p_control),\n  sig.level = 0.05,\n  power = 0.80,\n  alternative = \"two.sided\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4027158\n              n = 96.79194\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n```\n\n\n:::\n:::\n\n\n\n<!-- ::: {.callout-important icon=\"false\"} -->\n<!-- **n is per group!** Always multiply by the number of groups to get the total sample size. -->\n<!-- ::: -->\n\n## Interpreting the result\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4027158\n              n = 96.79194\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::: {.callout-important icon=\"false\"}\n### Interpretation\n\nTo detect a difference in response rates from 40% to 60% (Cohen's *h* = 0.403) with 80% power and $\\alpha$ = 0.05:\n\n- **n = 97 per group**\n- **Total N = 194** (both groups combined)\n\nAdd 10–20% buffer for dropout: plan for approximately **112 per group** in practice.\n:::\n\n## What difference can we detect with fixed resources?\n\n\\\n\nSuppose budget limits enrollment to **50 patients per group**. What's our power, and what minimum difference can we detect?\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What is our power with n = 50 per group?\npwr.2p.test(\n  h = ES.h(p1 = p_treatment, p2 = p_control),\n  n = 50,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4027158\n              n = 50\n      sig.level = 0.05\n          power = 0.5214145\n    alternative = two.sided\n\nNOTE: same sample sizes\n```\n\n\n:::\n:::\n\n\n\n## Sensitivity analysis: varying the treatment proportion (1/2)\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenarios2 <- tibble(\n  p_tx   = c(0.50, 0.55, 0.60, 0.65, 0.70),\n  p_ctrl = 0.40,\n  h = ES.h(p_tx, p_ctrl)\n) %>%\n  rowwise() %>%\n  mutate(\n    n_per_group = ceiling(pwr.2p.test(h = h,\n                                      sig.level = 0.05,\n                                      power = 0.80,\n                                      alternative = \"two.sided\")$n),\n    n_total = n_per_group * 2\n  ) %>%\n  ungroup()\n```\n:::\n\n\n\n\n## Sensitivity analysis: varying the treatment proportion (2/2)\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenarios2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n   p_tx p_ctrl     h n_per_group n_total\n  <dbl>  <dbl> <dbl>       <dbl>   <dbl>\n1  0.5     0.4 0.201         388     776\n2  0.55    0.4 0.302         173     346\n3  0.6     0.4 0.403          97     194\n4  0.65    0.4 0.506          62     124\n5  0.7     0.4 0.613          42      84\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n**Ask:** For each scenario, is the required sample size feasible given your study constraints? Is the assumed treatment effect realistic? Is it clinically meaningful?\n:::\n\n## Comparing power calculations: means vs. proportions\n\n\\\n\n| | Means | Proportions |\n|---|---|---|\n| Effect size | Cohen's *d*: one standardized number | Cohen's *h*: computed from two proportions |\n| Key inputs | $\\mu_1, \\mu_2, \\sigma$ | $p_1, p_2$ |\n| R function (one group) | `pwr.t.test(type = \"one.sample\")` | `pwr.p.test()` |\n| R function (two groups) | `pwr.t.test(type = \"two.sample\")` | `pwr.2p.test()` |\n| R function (paired) | `pwr.t.test(type = \"paired\")` | *Today: Part 4* |\n| Solve for n? | Leave `n = NULL` | Leave `n = NULL` |\n| Solve for power? | Leave `power = NULL` | Leave `power = NULL` |\n\n\\\n\n**The workflow is the same — just different inputs and functions!**\n\n# Part 4: Correlated Proportions and McNemar's Test\n\n## When are proportions correlated?\n\n\\\n\nRecall from earlier in the course: observations can be **paired or matched**\n\n\\\n\nWe've seen this with means:\n\n- Paired t-test: cholesterol before/after treatment in the *same patient*\n- Within-subject design: measurements are correlated\n\n\\\n\n**The same situation arises with proportions:**\n\n- Does a screening test result change before and after a training intervention?\n- In a matched case-control study: does exposure status differ between cases and their matched controls?\n- Pre/post binary outcomes measured in the same individuals\n\n\n::: {.callout-note icon=\"false\"}\n### Key idea\nWhen binary outcomes are paired or matched, the observations are **correlated** — we cannot treat them as independent. Using the two-proportion test would be wrong!\n:::\n\n## A matched study example (1/2)\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### Study design\n\nResearchers want to evaluate a new patient education program for melanoma early detection. They recruit **50 patients** and test each patient's ability to correctly identify suspicious lesions **before** and **after** the program.\n\n- **Outcome:** Correctly identified suspicious lesion (Yes/No)\n- **Design:** Each patient is their own control (paired)\n:::\n\n## A matched study example (2/2)\n\n\\\n\n**The data structure:** Each patient has two binary outcomes (before, after)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulated data\nset.seed(620)\n\neducation_data <- tibble(\n  patient_id = 1:50,\n  before = rbinom(50, 1, 0.40),   # 40% correct before\n  after  = rbinom(50, 1, 0.70)    # 70% correct after (simulated improvement)\n) %>%\n  mutate(before = if_else(before == 1, \"Correct\", \"Incorrect\"),\n    after  = if_else(after == 1, \"Correct\", \"Incorrect\"))\n\nhead(education_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  patient_id before    after    \n       <int> <chr>     <chr>    \n1          1 Incorrect Correct  \n2          2 Incorrect Correct  \n3          3 Incorrect Incorrect\n4          4 Incorrect Incorrect\n5          5 Incorrect Correct  \n6          6 Correct   Correct  \n```\n\n\n:::\n:::\n\n\n\n## The 2×2 table for paired proportions\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cross-tabulate before vs. after\nedu_table <- education_data %>%\n  janitor::tabyl(before, after) %>% \n  janitor::adorn_title(placement = \"combined\")\n\nedu_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n before/after Correct Incorrect\n      Correct      17         4\n    Incorrect      16        13\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::::: columns\n::: {.column width=\"50%\"}\n\n**What these cells mean:**\n\n| | After: Correct | After: Incorrect |\n|---|---|---|\n| **Before: Correct** | Concordant (+/+) | Discordant (+/−) |\n| **Before: Incorrect** | Discordant (−/+) | Concordant (−/−) |\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.callout-tip icon=\"false\"}\n### Key insight\n\nThe **concordant pairs** (where before = after) give us no information about change.\n\nOnly the **discordant pairs** tell us something changed — and McNemar's test focuses entirely on those.\n:::\n\n:::\n:::::\n\n## McNemar's test: the big idea\n\nMcNemar's test asks: **among the discordant pairs, are they evenly split?**\n\n\\\n\nLet:\n\n- $b$ = pairs where outcome changed from **correct → incorrect**\n- $c$ = pairs where outcome changed from **incorrect → correct**\n\n\\\n\n::: {.callout-important icon=\"false\"}\n### Hypotheses\n\n$H_0$: The probability of changing in each direction is equal ($p_{12} = p_{21}$, or equivalently $b = c$)\n\n$H_A$: The probability of changing differs by direction ($p_{12} \\neq p_{21}$)\n:::\n\n\\\n\n**Test statistic:**\n\n$$\\chi^2 = \\frac{(b - c)^2}{b + c}$$\n\nThis follows a chi-squared distribution with 1 degree of freedom.\n\n## McNemar's test in R\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a table for mcnemar.test()\nedu_tab <- table(education_data$before, education_data$after)\n\nedu_tab\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           \n            Correct Incorrect\n  Correct        17         4\n  Incorrect      16        13\n```\n\n\n:::\n:::\n\n\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run McNemar's test\nmcnemar.test(edu_tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMcNemar's Chi-squared test with continuity correction\n\ndata:  edu_tab\nMcNemar's chi-squared = 6.05, df = 1, p-value = 0.01391\n```\n\n\n:::\n:::\n\n\n\n\n## Interpreting the result\n\n\\\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMcNemar's Chi-squared test with continuity correction\n\ndata:  edu_tab\nMcNemar's chi-squared = 6.05, df = 1, p-value = 0.01391\n```\n\n\n:::\n:::\n\n\n\n\\\n\n::: {.callout-important icon=\"false\"}\n### Interpretation\n\n21 / 50 (42%) patients correctly identified suspicious lesions before the education program compared to 33 / 50 (66%) after.\n\nMcNemar's chi-squared test ($\\chi^2$ = 6.05, df = 1, *p* = 0.014) provides evidence that the patient education program changed the proportion of patients who correctly identified suspicious lesions.\n\n:::\n\n\\\n\n::: {.callout-tip icon=\"false\"}\n### What makes this different from a chi-squared test?\n\nA regular chi-squared test would treat the before/after observations as independent. McNemar's test correctly accounts for the paired structure by focusing only on discordant pairs.\n:::\n\n\n## McNemar's test in R with `janitor` or `rstatix`\n\n\\\n\n**Using `janitor`:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neducation_data %>%\n  tabyl(before, after) %>%\n  column_to_rownames(\"before\") %>% # Extra step using tibble::column_to_rownames\n  as.matrix() %>%                  # Extra step to convert to matrix\n  mcnemar.test() %>% \n  broom::tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  statistic p.value parameter method                                            \n      <dbl>   <dbl>     <dbl> <chr>                                             \n1      6.05  0.0139         1 McNemar's Chi-squared test with continuity correc…\n```\n\n\n:::\n:::\n\n\n\n\\\n\n**Using `rstatix`:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a table for mcnemar.test()\nedu_tab <- table(education_data$before, education_data$after)\n\nrstatix::mcnemar_test(edu_tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n      n statistic    df      p p.signif method      \n* <int>     <dbl> <dbl>  <dbl> <chr>    <chr>       \n1    50      6.05     1 0.0139 *        McNemar test\n```\n\n\n:::\n:::\n\n\n\n\n## McNemar's test vs. two-proportion test\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n\n**Two-proportion test (Lesson 13)**\n\n- Two **independent** groups\n- Example: treatment A vs. treatment B in different patients\n- Test: `prop.test()`\n- Asks: are the proportions the same across groups?\n\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n**McNemar's test (today)**\n\n- **Paired/matched** observations on the same individuals\n- Example: before vs. after in the same patients, or matched case-control pairs\n- Test: `mcnemar.test()`\n- Asks: are the discordant pairs symmetric?\n\n:::\n:::::\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### The parallel to t-tests\n\nThis mirrors the distinction between the **independent two-sample t-test** (different people) and the **paired t-test** (same person measured twice). Using the wrong test leads to incorrect inference!\n:::\n\n## Paired proportions: the 2×2 table\n\n\\\n\nEach pair produces two binary outcomes (e.g., before vs. after treatment):\n\n|  | **Post: +** | **Post: −** |\n|---|:---:|:---:|\n| **Pre: +** | $p_{11}$ (concordant) | $p_{12}$ (discordant) |\n| **Pre: −** | $p_{21}$ (discordant) | $p_{22}$ (concordant) |\n\n- **Concordant pairs** ($p_{11}$, $p_{22}$): outcome is the same at both time points\n- **Discordant pairs** ($p_{12}$, $p_{21}$): outcome changes\n  - $p_{12}$: changed from **+** to **−** (e.g., \"got worse\")\n  - $p_{21}$: changed from **−** to **+** (e.g., \"improved\")\n\nMcNemar's test asks: among the discordant pairs, is the split between $p_{12}$ and $p_{21}$ different from 50/50?\n\n## Power for paired proportions: the key inputs\n\n\\\n\nPower analysis for McNemar's test is more complex than for independent proportions. The key insight:\n\n\\\n\n**McNemar's test only uses the discordant pairs.** So power depends on:\n\n1. **Total sample size** ($n$) — total number of matched pairs\n2. **Proportion of discordant pairs** ($p_d = p_{12} + p_{21}$) — pairs where the outcome changes\n3. **The direction of discordance** — which way is the change expected to go?\n\n\\\n\n::: {.callout-note icon=\"false\"}\n### Practical implication\n\nA study with a high proportion of concordant pairs (most people don't change) is effectively working with a smaller sample — and thus has lower power — than the total $n$ would suggest.\n\nWhen planning a study using McNemar's test, you need estimates of the **discordant pair proportions** from prior literature or pilot data.\n:::\n\n## Estimating power for McNemar's: a simplified approach\n\n\\\n\nOne practical approach: McNemar's test on $n$ total pairs is equivalent to a one-sample proportion test on the **discordant pairs** only.\n\n\nIf we expect:\n\n- Proportion of pairs with outcome change: $p_d = p_{12} + p_{21}$ (total discordant pairs)\n- Among discordant pairs, proportion \"improving\" ($p_{21}$): $\\phi = p_{21} / p_d$\n- Under $H_0$: $\\phi = 0.50$ (changes equally likely in both directions)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: 25% of pairs expected to be discordant\n# Among discordant pairs, 70% are \"improvements\" (phi = 0.70)\n\np_discordant <- 0.25\nphi_alt <- 0.70       # expected proportion of discordant pairs that are \"improvements\"\n\n# Effective n for the test = n_total * p_discordant\n# Use pwr.p.test on the discordant pairs\npwr.p.test(\n  h = ES.h(p1 = phi_alt, p2 = 0.50),\n  sig.level = 0.05,\n  power = 0.80,\n  alternative = \"two.sided\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4115168\n              n = 46.34804\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n## Interpreting power for McNemar's\n\n\\\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.4115168\n              n = 46.34804\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n\\\n\nThis tells us we need **47 discordant pairs**. To get the total sample size:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_discordant_needed <- ceiling(mcnemar_power$n)\np_discordant <- 0.25\n\nn_total_needed <- ceiling(n_discordant_needed / p_discordant)\nn_total_needed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 188\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note icon=\"false\"}\nIf only 25% of pairs are expected to be discordant, we need to enroll **188 total pairs** to get enough discordant pairs for adequate power.\n:::\n\n# Wrap-up and Key Takeaways\n\n## Summary: Power for proportions\n\n\\\n\n::::: columns\n::: {.column width=\"48%\"}\n\n**What's the same as means:**\n\n- Four components still in equilibrium ($\\alpha$, power, $n$, effect)\n- Leave one `= NULL` to solve for it\n- 80% power is the standard target\n- Always round $n$ up\n- Report your power analysis!\n\n\\\n\n**Key R functions:**\n\n- `ES.h(p1, p2)` — compute effect size\n- `pwr.p.test()` — one proportion\n- `pwr.2p.test()` — two independent proportions\n- `mcnemar.test()` — test for paired proportions\n\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n**What's different for proportions:**\n\n- Effect size requires **two** proportions, not a single *d*\n- The same absolute difference has different effect sizes at different baseline proportions\n- For paired proportions: McNemar's test focuses on discordant pairs\n- Power for McNemar's requires knowing the proportion of discordant pairs\n\n\\\n\n**Decision guide:**\n\n| Design | Analysis | Power function |\n|---|---|---|\n| One proportion vs. $p_0$ | `prop.test()` | `pwr.p.test()` |\n| Two independent groups | `prop.test()` | `pwr.2p.test()` |\n| Paired/matched binary | `mcnemar.test()` | `pwr.p.test()` on discordant $n$ |\n\n:::\n:::::\n\n## Connecting the course together\n\n\\\n\nWe've now covered power and sample size for the full set of tests we've studied:\n\n\\\n\n| Test | Outcome | Power function |\n|---|---|---|\n| One-sample t-test | Continuous | `pwr.t.test(type = \"one.sample\")` |\n| Paired t-test | Continuous | `pwr.t.test(type = \"paired\")` |\n| Two-sample t-test | Continuous | `pwr.t.test(type = \"two.sample\")` |\n| One proportion | Binary | `pwr.p.test()` |\n| Two independent proportions | Binary | `pwr.2p.test()` |\n| Paired proportions (McNemar's) | Binary | `pwr.p.test()` on discordant *n* |\n\n\\\n\n::: {.callout-tip icon=\"false\"}\nThe framework is always the same: four components, three known, one to solve for. The function changes, but the logic doesn't.\n:::\n\n## Looking ahead\n\n\\\n\n**Next class (Lesson 16):** ANOVA — Comparing means across 3 or more groups\n\n- When the two-sample t-test isn't enough\n- The F-test\n- Post-hoc comparisons\n\n\\\n\n**Remaining lectures:**\n\n- Lesson 17: Nonparametric tests\n- Lesson 18: Correlation and Simple Linear Regression\n- Lesson 19: Finals review\n- Lesson 20: TBD\n\n\\\n\n**HW 7 due Sunday 03/08** — will cover material from \n\n- Lesson 14: Chi-squared tests, Fishers exact test\n- Lesson 15 (today): Power for proportions and correlated proportions\n\n## Additional resources\n\n\\\n\n**For deeper reading on power for proportions:**\n\n- PASS documentation: [Two Proportions](https://www.ncss.com/software/pass/pass-documentation/#Proportions)\n- [Sample size calculators from UCSF](https://sample-size.net/calculator-finder) — web-based, user friendly\n- [G\\*Power](https://stats.oarc.ucla.edu/other/gpower/) — free desktop software with proportion-specific calculators\n\n\\\n\n**For power analysis with chi-squared tests (beyond this course):**\n\n- Abdul Rahman et al. (2025). \"Practical guide to calculate sample size for chi-square test in biomedical research.\" *BMC Medical Research Methodology.* [https://pmc.ncbi.nlm.nih.gov/articles/PMC12107878/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12107878/) — introduces Cohen's *w*, includes a free web-based calculator\n- `pwr.chisq.test()` in the `pwr` package and `PowerChisqTest()` in the `DescTools` package are available in R if you need to do this programmatically\n\n\\\n\n**For McNemar's test and power:**\n\n- PASS documentation: [McNemar's Test](https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Two_Correlated_Proportions-McNemar_Test.pdf)\n- The `exact2x2` package in R has additional tools for exact McNemar's calculations\n\n\\\n\n**Interactive visualization:**\n\n- [Understanding Statistical Power](https://rpsychologist.com/d3/NHST/) — drag sliders to see how components relate\n",
    "supporting": [
      "18_power_proportions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}