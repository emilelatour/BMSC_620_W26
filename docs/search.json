[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "üé• Lecture Recordings (OneDrive folder) ‚Äì Lectures except Part 2 of Lecture 3\nüé• Lecture Recordings (loom.com) ‚Äì Part 2 of Lecture 3\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nLesson\nTopics\nChapter sections\n\n\n\n\n1\nMon, 01/05\n0\nWelcome\n\n\n\n\n\n1\nIntro to Data, Summarizing numerical data\n1.1-1.4\n\n\n\nWed, 01/07\n2\nIntroduction to R & RStudio\n\n\n\n\nSun, 01/11\n\nHW 0 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n2\nMon, 01/12\n3\nSummarizing categorical data and contingency tables\n1.5-1.7\n\n\n\nWed, 01/14\n4\nProbability and conditional probability\n2.1-2.4\n\n\n\nSun, 01/18\n\nHW 1 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n3\nMon, 01/19\n\nNo class, Martin Luther King Jr.¬†Day\n\n\n\n\nWed, 01/21\n5\nExploratory data analysis (EDA) and data visualization\n1.5-1.7\n\n\n\n\n\n\n\n\n\n4\nMon, 01/26\n6\nRandom variables and the binomial distribution\n3.1-3.2\n\n\n\nTue, 01/27\n\nHW 2 due @ 11 pm\n\n\n\n\nWed, 01/28\n7\nNormal distribution and sampling distributions\n3.3-3.4\n\n\n\nSun, 02/01\n\nHW 3 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n5\nMon, 02/02\n8\nEstimation and confidence intervals\n4.1-4.2\n\n\n\nWed, 02/04\n9\nHypothesis testing concepts; One-sample t-tests\n4.3, 5.1\n\n\n\nSun, 02/08\n\nHW 4 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n6\nMon, 02/09\n10\nPaired data and paired t-tests; Two-sample independent t-tests\n5.2-5.3\n\n\n\nWed, 02/11\n11\nMidterm review\n\n\n\n\nWed, 02/11\n\nMIDTERM opens at 3pm\n\n\n\n\n\n\nMidterm will cover Lessons 1‚Äì9\n\n\n\n\n\n\n\n\n\n\n7\nMon, 02/16\n\nNo class, Presidents Day\n\n\n\n\nMon, 02/16\n\nMIDTERM closes at 11pm\n\n\n\n\nWed, 02/18\n12\nPower\n5.4, extra\n\n\n\nSun, 02/22\n\nHW 5 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n8\nMon, 02/23\n13\nInference for proportions and 2x2 tables\n8.1-8.2\n\n\n\nWed, 02/25\n14\nChi-squared tests, Fishers exact test\n8.3-8.4\n\n\n\nSun, 03/01\n\nHW 6 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n9\nMon, 03/02\n15\nComparing Means with ANOVA\n5.5, extra\n\n\n\nWed, 03/04\n16\nNonparametric tests\nExtra\n\n\n\nSun, 03/08\n\nHW 7 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n10\nMon, 03/09\n17\nCorrelation and association\n1.6, extra\n\n\n\nWed, 03/11\n18\nSimple Linear Regression\n6.1-6.2\n\n\n\nSun, 03/15\n\nHW 8 due @ 11 pm\n\n\n\n\n\n\n\n\n\n\n11\nMon, 03/16\n19\nSimple Linear Regression; Finals review\n6.3-6.4\n\n\n\nMon, 03/16\n\nFINAL opens at 3pm\n\n\n\n\n\n\nFinal exam is cumulative, with emphasis on Lessons 10‚Äì19\n\n\n\n\nWed, 03/18\n20\nOptional: Review and questions (no new material)\n7.1\n\n\n\nFri, 03/20\n\nFINAL closes at 5pm",
    "crumbs": [
      "Home",
      "Schedule"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course website: This site is the hub for schedules and materials. Assignments and grades will be managed in Sakai.\nSoftware: We will use R and RStudio for homework and in-class examples. (Instructions will be posted on the Resources page.)\nOne-day room change: Class will meet in MAC 3198 on January 21 only.",
    "crumbs": [
      "Home",
      "Course info",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#homework-40",
    "href": "syllabus.html#homework-40",
    "title": "Syllabus",
    "section": "Homework (40%)",
    "text": "Homework (40%)\nHomework assignments are designed to help you practice core concepts, develop familiarity with R, and build confidence interpreting statistical results. Homework is primarily a formative assessment, meaning its purpose is to support learning rather than to assess perfection.\nThere will be regular homework assignments throughout the term. Assignments will typically include a mix of conceptual questions, interpretation, and applied work using R.\n\nGrading\nEach homework assignment will be graded on a 10-point scale using the following criteria:\n\nSubstantial completion (6 points)\nMost required parts of the assignment are attempted (approximately 75‚Äì80%). Code and written responses show a genuine effort to engage with the problems, even if some answers are incorrect.\nDemonstrated process (2 points)\nRelevant work is shown, including R code and intermediate steps where appropriate. The focus is on showing how you approached the problem rather than arriving at a perfect solution.\nInterpretation and communication (2 points)\nAnswers include written interpretation where appropriate, with an attempt to explain results in context (e.g., direction, magnitude, units, or meaning of statistical output).\n\nHomework will be graded primarily for effort, reasoning, and clarity, not strict correctness.\n\n\nFeedback and solutions\nHomework solutions will be released immediately after the submission deadline. This allows you to review the material and apply feedback while working on the next assignment, even if grading is still in progress.\nFor homework submitted on time, the TA will provide feedback on one or more problems.\nTurnaround time: Homework will be graded and returned within one week of the due date, with a target of Friday when possible.\n\n\nLate and dropped homework\n\nLate homework will be accepted for partial credit (up to 80% of the total points). Feedback will only be provided for homework submitted on time.\nThe lowest homework score will be dropped when calculating the final homework grade. HW 0 is excluded from this policy, as it is intended to ensure technical readiness for the course.\n\nThese policies are intended to provide flexibility for busy schedules while encouraging consistent engagement with the course material.",
    "crumbs": [
      "Home",
      "Course info",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#midterm-exam-20",
    "href": "syllabus.html#midterm-exam-20",
    "title": "Syllabus",
    "section": "Midterm exam (20%)",
    "text": "Midterm exam (20%)\nThe midterm exam is a take-home assessment designed to evaluate your understanding of the material covered in the first half of the course. The emphasis is on conceptual understanding, interpretation, and clear communication, rather than speed or memorization.\nThe midterm will be available for several days, with the exact release and due dates listed on the course schedule and in Sakai. The exam is designed to take approximately 3‚Äì5 hours to complete, though you may choose when and how to distribute that time during the availability window.\n\nFormat and resources\nThe midterm will consist of a small number of multi-part questions and may include conceptual questions, interpretation of statistical output or visualizations, and applied tasks using R.\nYou may use:\n\nCourse notes and slides\nThe course website\nR and RStudio\n\n\n\nCollaboration and academic integrity\nYou may discuss general concepts related to the exam with classmates. However, you must work independently on the midterm and submit your own work. Sharing code, written responses, or specific solutions is not permitted.\n\n\nUse of AI tools\nGenerative AI tools (e.g., ChatGPT) may be used for limited support such as clarifying R error messages or syntax. They may not be used to generate solutions, interpret results, or write responses for the exam. Any use of AI tools must be consistent with the course‚Äôs academic integrity policy.\n\n\nSubmission and grading\nYou will submit your midterm exam via Sakai. Instructions regarding file formats and submission details will be provided with the exam.\nThe midterm will be graded based on correctness, reasoning, and clarity of interpretation. Partial credit will be awarded where appropriate.\n\n\nLate policy\n\nExtensions may be granted by request and should be discussed with me as soon as possible.\nUnexcused late submissions will be penalized by 10% per day late.",
    "crumbs": [
      "Home",
      "Course info",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#final-exam-30",
    "href": "syllabus.html#final-exam-30",
    "title": "Syllabus",
    "section": "Final exam (30%)",
    "text": "Final exam (30%)\nThe final exam is a take-home assessment designed to evaluate your ability to synthesize course concepts and communicate statistical results clearly and accurately. The exam is cumulative, with an emphasis on material covered after the midterm. As with the midterm, the emphasis is on understanding, interpretation, and reasoning, rather than speed or memorization.\nThe final exam will be available for several days, with the exact release and due dates listed on the course schedule and in Sakai. The exam is designed to take approximately 4‚Äì6 hours to complete, though you may choose when and how to distribute that time during the availability window.\n\nFormat and resources\nThe final exam will consist of a small number of multi-part questions that may include:\n\nInterpretation of numerical summaries, confidence intervals, hypothesis tests, or regression output\nInterpretation of data visualizations\nApplied tasks using R\nQuestions that require integrating multiple concepts covered throughout the course\n\nYou may use:\n\nCourse notes and slides\nThe course website\nR and RStudio\n\n\n\nCollaboration and academic integrity\nYou may discuss general concepts related to the exam with classmates. However, you must work independently on the final exam and submit your own work. Sharing code, written responses, or specific solutions is not permitted.\n\n\nUse of AI tools\nGenerative AI tools (e.g., ChatGPT) may be used for limited support such as clarifying R error messages or syntax. They may not be used to generate solutions, interpret results, or write responses for the exam. Any use of AI tools must be consistent with the course‚Äôs academic integrity policy.\n\n\nSubmission and grading\nYou will submit your final exam via Sakai. Instructions regarding file formats and submission details will be provided with the exam.\nThe final exam will be graded based on correctness, reasoning, and clarity of interpretation. Partial credit will be awarded where appropriate.\n\n\nLate policy\n\nExtensions may be granted by request and should be discussed with me as soon as possible.\nUnexcused late submissions will be penalized by 10% per day late.",
    "crumbs": [
      "Home",
      "Course info",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#attendance-and-post-class-surveys-10",
    "href": "syllabus.html#attendance-and-post-class-surveys-10",
    "title": "Syllabus",
    "section": "Attendance and post-class surveys (10%)",
    "text": "Attendance and post-class surveys (10%)\nAttendance and engagement will be assessed through brief post-class surveys submitted after class meetings. These surveys are intended to encourage reflection on the day‚Äôs material and to provide feedback that helps improve the course.\nSurveys may include short questions about key takeaways, points of confusion, or course logistics. Surveys are designed to be low-effort and should take only a few minutes to complete.\n\nCredit and expectations\n\nYou will receive full credit for completing at least 15 out of 20 post-class surveys during the term.\nSurveys are graded for completion, not correctness.\nNo make-up surveys will be offered, but the 15-of-20 policy is intended to provide flexibility for absences, illness, or scheduling conflicts.\n\n\n\nPurpose\nPost-class surveys serve two purposes:\n\nThey encourage regular engagement with course material.\nThey allow me to identify common questions or areas of confusion and adjust instruction accordingly.\n\nThis component is designed to reward consistent participation without penalizing occasional absences.",
    "crumbs": [
      "Home",
      "Course info",
      "Syllabus"
    ]
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you for your feedback on Monday‚Äôs lecture! The pacing feedback was excellent - 69% felt it was ‚Äúabout right‚Äù and 31% ‚Äúslightly too fast,‚Äù which tells me most of you are keeping up well. I‚Äôll continue with strategic pauses and check-ins to help everyone stay on track.\nSeveral clear themes emerged from your muddy points. Let me address them:"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#overview",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#overview",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you for your feedback on Monday‚Äôs lecture! The pacing feedback was excellent - 69% felt it was ‚Äúabout right‚Äù and 31% ‚Äúslightly too fast,‚Äù which tells me most of you are keeping up well. I‚Äôll continue with strategic pauses and check-ins to help everyone stay on track.\nSeveral clear themes emerged from your muddy points. Let me address them:"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#what-do-i-need-to-memorizeknow-how-to-do",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#what-do-i-need-to-memorizeknow-how-to-do",
    "title": "Muddy Points",
    "section": "What Do I Need to Memorize/Know How to Do?",
    "text": "What Do I Need to Memorize/Know How to Do?\nThe Question:\n\n‚ÄúWhat should we memorize in terms of formulas? Are we supposed to know how to do these formulas by hand, or using the R functions?‚Äù\n\nThe Answer:\nFor this course, I care about three things:\n\n1. Conceptual understanding\nYou should be able to explain, in words:\n\nWhat kind of random variable you are working with (discrete vs continuous)\nWhen a binomial model is appropriate\nWhat the parameters mean (for example: n and p)\nWhat a probability, mean, or variance is describing in context\n\nYou do not need to reproduce derivations, but you should understand what the formulas are doing.\n\n\n2. Using R correctly\nYou should be comfortable with:\n\nChoosing the right R function (dbinom(), pbinom(), etc.)\nKnowing what each argument represents\nInterpreting the output in words\n\nFor example:\n\n‚ÄúExactly k successes‚Äù ‚Üí dbinom()\n‚ÄúAt most k successes‚Äù ‚Üí pbinom()\n\nBeing able to explain why you chose a function matters more than the numeric answer itself.\n\n\n3. Explaining your reasoning\nOn homework and exams, you should be able to:\n\nDescribe your approach in plain language\nExplain what distribution you used and why\nInterpret results in the context of the problem\n\n\n\nWhat you are not expected to do\nYou do not need to:\n\nMemorize probability formulas\nCalculate probabilities by hand\nDerive distributions from scratch\nMemorize every symbol used on slides\n\nFormulas are shown to build understanding and connect to R ‚Äî not because I expect you to reproduce them from memory."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#variable-notation-confusion",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#variable-notation-confusion",
    "title": "Muddy Points",
    "section": "Variable Notation Confusion",
    "text": "Variable Notation Confusion\nThe Issue:\n\n‚ÄúThe way variables were switching from X to k was confusing. It would be helpful if there was a legend on each slide for what each variable means.‚Äù\n\nWhy This Happens:\nDifferent contexts use different notation conventions:\n\nX = the random variable itself (e.g., ‚Äúnumber of successes‚Äù)\nx or k = a specific value X might take (e.g., ‚Äúexactly 3 successes‚Äù)\nn = number of trials\np = probability of success on each trial\n\nI‚Äôll be more explicit about this on slides going forward.\n\nCommon Notation Guide\n\n\n\nSymbol\nMeaning\nExample\n\n\n\n\n\\(X\\)\nRandom variable\n‚ÄúNumber of heads in 10 flips‚Äù\n\n\n\\(x\\) or \\(k\\)\nSpecific value\n‚ÄúExactly 3 heads‚Äù\n\n\n\\(n\\)\nNumber of trials\n10 flips\n\n\n\\(p\\)\nProbability of success\n0.5 for fair coin\n\n\n\\(\\mu\\)\nMean/Expected value\nAverage outcome\n\n\n\\(\\sigma\\)\nStandard deviation\nSpread of outcomes\n\n\n\\(\\sigma^2\\)\nVariance\nSquared spread"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#too-many-formulas-feeling-abstract",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#too-many-formulas-feeling-abstract",
    "title": "Muddy Points",
    "section": "Too Many Formulas / Feeling Abstract",
    "text": "Too Many Formulas / Feeling Abstract\nThe Concern:\n\n‚ÄúFelt like there were just a whole lot of formulas‚Ä¶ Some of the formulas started to feel a bit abstract.‚Äù\n\nMy Response:\nYou‚Äôre absolutely right. There are a lot of formulas. Here‚Äôs how to think about them:\n\nThe Core Ideas (Not the Formulas)\nFor any distribution, we care about:\n\nWhat values can it take? (support)\nHow likely is each value? (probability/density)\nWhat‚Äôs the typical value? (mean/expected value)\nHow spread out is it? (variance/standard deviation)\n\nFor binomial specifically:\n\n‚ÄúHow many successes in n tries?‚Äù ‚Üí use dbinom() or pbinom()\nThat‚Äôs it. The formulas are just showing why R gives you those answers.\n\n\n\nPlain Language Interpretations\nI‚Äôll make sure to add these after formulas. For example:\nFormula: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\nPlain English: ‚ÄúThe probability of getting exactly k successes in n trials, when each trial has probability p of success‚Äù\nR Code: dbinom(k, size = n, prob = p)\nEven Plainer: ‚ÄúUse this when you want to know: What are the chances of getting exactly this many successes?‚Äù"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#variance-of-linear-combinations",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#variance-of-linear-combinations",
    "title": "Muddy Points",
    "section": "Variance of Linear Combinations",
    "text": "Variance of Linear Combinations\nThe Concern:\n\n‚ÄúVariance of linear combinations was confusing to me, especially if it will need to be applied to real/our data.‚Äù\n\nMy Response:\nThis is a very reasonable concern.\nFor this course, variance of linear combinations is not something you will be expected to apply directly to real data by hand.\nWhat I want you to take away is the idea, not the formula:\n\nWhen you combine independent random variables, their variances add\nStandard deviations do not add directly\nIn practice, software (R) handles these calculations for us\n\nYou will not be asked to derive or memorize variance formulas for linear combinations.\nLater in the course, you will see variance show up in applied settings (for example, through standard errors and uncertainty in estimates), but at that point we will rely on:\n\nInterpretation\nSoftware output\nIntuition about variability\nnot manual variance calculations.\n\nBottom line: Understand the concept that variances add, but don‚Äôt worry about doing these calculations by hand. This topic is covered in introductory probability courses because it is important in fields like finance and engineering, but in this course we focus on understanding the idea rather than doing the calculations by hand."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#clarifying-bernoulli-variance-conceptual",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#clarifying-bernoulli-variance-conceptual",
    "title": "Muddy Points",
    "section": "Clarifying Bernoulli Variance (Conceptual)",
    "text": "Clarifying Bernoulli Variance (Conceptual)\nThe Question:\n\n‚ÄúIt is a bit unclear where the equation for the variance for the Bernoulli distribution came from. I don‚Äôt understand how it relates to other variance equations.‚Äù\n\nMy Response:\nThis is a great question.\nThe Bernoulli variance formula is not a new or special definition of variance. It comes from the same definition of variance we use for any random variable ‚Äî it just simplifies nicely because a Bernoulli variable can only take two values (0 and 1).\nWhat‚Äôs important to know:\n\nVariance always measures how spread out values are around the mean\nFor a Bernoulli variable:\n\nThe mean is \\(p\\)\nOutcomes are either 0 or 1\n\nBecause of that simplicity, the general variance definition reduces to the compact result:\n\n\\[\\text{Var}(X) = p(1 - p)\\]\nYou do not need to derive this yourself. The key takeaway is the behavior of the variance:\n\nIt is largest when outcomes are most uncertain (\\(p\\) near 0.5)\n\nExample: \\(p = 0.5 \\rightarrow \\text{Var}(X) = 0.5(0.5) = 0.25\\)\n\nIt is smaller when outcomes are more predictable (\\(p\\) near 0 or 1)\n\nExample: \\(p = 0.9 \\rightarrow \\text{Var}(X) = 0.9(0.1) = 0.09\\) (less variable)\nExample: \\(p = 0.1 \\rightarrow \\text{Var}(X) = 0.1(0.9) = 0.09\\) (less variable)\n\n\nWe‚Äôll continue to rely on this intuition and on R for calculations, rather than algebraic derivations."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#r-functions-still-confusing",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#r-functions-still-confusing",
    "title": "Muddy Points",
    "section": "R Functions Still Confusing",
    "text": "R Functions Still Confusing\nThe Concern:\n\n‚ÄúI‚Äôm still a little confused on some of the different binomial functions in R, and pbinom‚Äôs link to p-values.‚Äù\n\nLet Me Break This Down:\n\nThe Four Binomial Functions\n# d = density/probability (exactly)\ndbinom(x = 3, size = 10, prob = 0.5)\n# \"What's P(X = 3)? Probability of EXACTLY 3 successes\"\n\n# p = cumulative probability (at most)\npbinom(q = 3, size = 10, prob = 0.5)\n# \"What's P(X ‚â§ 3)? Probability of 3 OR FEWER successes\"\n\n# q = quantile (what value gives this cumulative probability?)\nqbinom(p = 0.25, size = 10, prob = 0.5)\n# \"What value of x has 25% of the distribution below it?\"\n\n# r = random (generate random samples)\nrbinom(n = 100, size = 10, prob = 0.5)\n# \"Simulate 100 draws from this distribution\"\n\n\nVisual Guide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout p-values\nImportant: pbinom() calculates cumulative probabilities, but it‚Äôs not directly a p-value.\nA p-value is ‚Äúthe probability of getting results as extreme or more extreme than what we observed, assuming the null hypothesis is true.‚Äù\nWe can use pbinom() to calculate p-values, but they‚Äôre not the same thing:\n\npbinom() = general cumulative probability function\np-value = specific probability used for hypothesis testing\n\nWe‚Äôll cover this more when we get to hypothesis testing!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#expected-value-calculation-question",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#expected-value-calculation-question",
    "title": "Muddy Points",
    "section": "Expected Value Calculation Question",
    "text": "Expected Value Calculation Question\nThe Question:\n\n‚ÄúI didn‚Äôt understand the expected value (mean) calculations. Why does the value of the dice face factor into the equation since it‚Äôs an equal chance of rolling any value? Additionally, where did the 1/9 value come from?‚Äù\n\nLet Me Walk Through This:\n\nFair Die Expected Value\nFor a fair 6-sided die, each outcome has probability 1/6:\n\\[E(X) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6}\\]\n\\[E(X) = \\frac{1+2+3+4+5+6}{6} = \\frac{21}{6} = 3.5\\]\nWhy do the face values matter?\n\nEven though each face has equal probability (1/6), the values are different (1, 2, 3, 4, 5, 6)\nWe‚Äôre calculating the average value we‚Äôd get in the long run\nRolling a 6 contributes more to the average than rolling a 1!\n\n\n\nWhere did 1/9 come from?\nI just made up the probabilities for the rolls with the unfair dice. I aimed to show that the probabilities don‚Äôt have to be the same for all possible outcomes.\n\nRolls of 1, 2, 3, or 4 all had the same probability: \\(1/9\\)\nA roll of 5 had a probability of \\(2/9\\)\nA roll of 6 had a probability of \\(3/9\\)\nProbabilities add to 1. Check: \\(1/9 + 1/9 + 1/9 + 1/9 + 2/9 + 3/9 = 1\\)\n\nThe dice is loaded toward higher numbers.\n\n\nThe big picture for expected value\nExpected value is best thought of as a long-run average, not a prediction of what will happen on a single trial.\n\nIt combines all possible values of a random variable\nEach value is weighted by how likely it is\nLarger values contribute more to the average than smaller values\n\nThis same idea applies to any random variable (not just dice) and is why expected value shows up throughout statistics.\nYou do not need to compute expected values by hand beyond simple examples like this. In practice, we‚Äôll often:\n\nrely on formulas (for known distributions), or\nlet software do the calculation for us.\n\nThe important skill is understanding what expected value represents, not the mechanics of summing terms."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#questions",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial_muddy_points.html#questions",
    "title": "Muddy Points",
    "section": "Questions?",
    "text": "Questions?\nIf anything is still muddy, please:\n\nCome to office hours\nAsk in class on Wednesday\n\nThanks for the thoughtful feedback! üé≤"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. I‚Äôm pleased to see that so many of you found the live coding helpful, and I appreciate the specific questions about R syntax, packages, and workflow."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#thanks-for-the-feedback",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#thanks-for-the-feedback",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. I‚Äôm pleased to see that so many of you found the live coding helpful, and I appreciate the specific questions about R syntax, packages, and workflow."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#a-note-on-pacing",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#a-note-on-pacing",
    "title": "Muddy Points",
    "section": "A note on pacing",
    "text": "A note on pacing\nLooking at the post-class survey for this lecture:\n\n77.8% felt the pace was about right\n14.8% felt it was slightly too fast\n7.4% felt it was slightly too slow\n\nThis is excellent feedback overall. The strong central tendency around ‚Äúabout right‚Äù suggests the material was well-calibrated for the class level. For those who found the pace slightly too fast, remember that:\n\nThe lectures are recorded and you can rewatch sections\nThe .qmd files are available for you to work through at your own pace\nThe homework gives you extended practice time with these concepts\nThe in-class examples directly mirror the homework structure ‚Äî if you can follow the class examples, you have the scaffolding you need"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#connection-between-class-examples-and-homework",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#connection-between-class-examples-and-homework",
    "title": "Muddy Points",
    "section": "Connection between class examples and homework",
    "text": "Connection between class examples and homework\nSeveral of you mentioned wanting examples that follow exactly what you‚Äôll need for homework. Good news: that‚Äôs exactly what the in-class examples are designed to do.\nThe in-class .qmd file is a template for the homework. When you‚Äôre working through homework problems, refer back to the class examples ‚Äî you‚Äôll see the same patterns (filter ‚Üí select ‚Üí summarize, building ggplots step-by-step, using pipes to chain operations).\nGoing forward, I‚Äôll be more explicit about this connection:\n\n‚ÄúThis pattern of piping filter ‚Üí select ‚Üí summarize? You‚Äôll use this exact structure in homework problem X.‚Äù\n‚ÄúNotice how we‚Äôre building this ggplot layer by layer ‚Äî you‚Äôll follow this same approach for your visualizations.‚Äù"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#packages-what-you-need-and-when",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#packages-what-you-need-and-when",
    "title": "Muddy Points",
    "section": "Packages: what you need and when",
    "text": "Packages: what you need and when\nSeveral questions came up about R packages. Let me clarify:\n\nWhat are packages?\nPackages are collections of functions that extend R‚Äôs capabilities. Think of base R as a smartphone, and packages as apps you install to do specific tasks.\n\n\nThe packages we‚Äôre using in this course\nFor this course, you need these packages installed:\n\ntidyverse (this actually installs several packages including dplyr, ggplot2, and others)\njanitor (for the adorn_ functions)\n\nThat‚Äôs it for now. I‚Äôll let you know when we need additional packages.\n\n\nInstall once, load each session\nThis is a common source of confusion:\nInstallation (do this once per computer):\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"janitor\")\n\nLoading (do this once per R session):\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nThink of it like this:\n\nInstalling is like downloading an app to your phone (do once)\nLoading with library() is like opening that app (do every time you restart R)\n\n\n\nWhy do we need library() every session?\nYes, you need to run library(package_name) at the start of every R session (or at the top of every script/Quarto document). This tells R which packages you want to use for this particular analysis.\nIt might seem redundant, but it‚Äôs actually helpful because:\n\nIt makes your code more reproducible (others know exactly which packages you‚Äôre using)\nIt avoids conflicts when different packages have functions with the same name\nIt keeps R‚Äôs memory usage lower by only loading what you need"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#r-syntax-commas-quotes-and-spacing",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#r-syntax-commas-quotes-and-spacing",
    "title": "Muddy Points",
    "section": "R syntax: commas, quotes, and spacing",
    "text": "R syntax: commas, quotes, and spacing\nSeveral of you mentioned confusion with R syntax, especially around commas and quotes. This is completely normal ‚Äî these small details take practice.\n\nCommon syntax patterns\nFunction arguments are separated by commas:\n\n# Correct\nsummarize(data, mean_value = mean(x), median_value = median(x))\n\n# Incorrect - missing comma between arguments\nsummarize(data, mean_value = mean(x) median_value = median(x))\n\nColumn names usually don‚Äôt need quotes in tidyverse:\n\n# Both work in tidyverse functions\nselect(data, Species, Sepal.Length)\nselect(data, \"Species\", \"Sepal.Length\")\n\n# But unquoted is more common and easier to type\n\nSpacing doesn‚Äôt usually matter:\n\n# These are equivalent\nx &lt;- mean(y)\nx&lt;-mean(y)\nx  &lt;-  mean(  y  )\n\n\n\nWhen you get an ‚Äúunexpected‚Äù error\nIf you get an error like ‚Äúunexpected ‚Äò,‚Äô in‚Ä¶‚Äù or ‚Äúunexpected ‚Äò)‚Äô in‚Ä¶‚Äù, it usually means:\n\nMissing or extra comma\nMissing or extra parenthesis\nUnmatched quotes\n\nDebugging tip: Look at the line number in the error message, then carefully check that line for:\n\nEqual number of opening ( and closing )\nCommas between function arguments\nMatching quotes (every \" has a closing \")\n\n\n\nCode that was missing from class notes\nOne comment noted that some code pieces were missing from the class notes (like needing to reload packages). You‚Äôre absolutely right ‚Äî for people new to R, it‚Äôs confusing when code doesn‚Äôt run because a package wasn‚Äôt loaded.\nGoing forward, I‚Äôll make sure the .qmd files are complete and runnable from top to bottom, including all necessary library() calls at the beginning."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#understanding-pipes-more-than-just-readability",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#understanding-pipes-more-than-just-readability",
    "title": "Muddy Points",
    "section": "Understanding pipes: more than just readability",
    "text": "Understanding pipes: more than just readability\nOne question was: ‚ÄúPipes. Do they just help the readability and flow of your code?‚Äù\nGreat question! The short answer is: primarily yes, but they also help you avoid creating intermediate objects.\n\nWhat pipes do\nThe pipe operator %&gt;% takes the output from one function and passes it as the first argument to the next function.\nWithout pipes (nested functions, read inside-out):\n\nsummarize(\n  filter(\n    select(iris, Species, Sepal.Length),\n    Sepal.Length &gt; 5\n  ),\n  mean_length = mean(Sepal.Length)\n)\n\nWith pipes (read top to bottom):\n\niris %&gt;%\n  select(Species, Sepal.Length) %&gt;%\n  filter(Sepal.Length &gt; 5) %&gt;%\n  summarize(mean_length = mean(Sepal.Length))\n\n\n\nWhy pipes matter\n\nReadability: You can read the code in the order operations happen (like reading a recipe)\nAvoid intermediate objects: You don‚Äôt need to save temporary results\nEasier to modify: You can add or remove steps without restructuring everything\n\nWithout pipes, you‚Äôd need intermediate objects:\n\nstep1 &lt;- select(iris, Species, Sepal.Length)\nstep2 &lt;- filter(step1, Sepal.Length &gt; 5)\nstep3 &lt;- summarize(step2, mean_length = mean(Sepal.Length))\n\nWith pipes, it‚Äôs one continuous flow:\n\nresult &lt;- iris %&gt;%\n  select(Species, Sepal.Length) %&gt;%\n  filter(Sepal.Length &gt; 5) %&gt;%\n  summarize(mean_length = mean(Sepal.Length))\n\nSo while readability is the main benefit, pipes also make your code more concise and easier to maintain."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#chaining-dplyr-verbs-when-and-how",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#chaining-dplyr-verbs-when-and-how",
    "title": "Muddy Points",
    "section": "Chaining dplyr verbs: when and how",
    "text": "Chaining dplyr verbs: when and how\nOne comment: ‚ÄúI‚Äôm a little confused on how to correctly chain dplyr verbs and when it is necessary to chain something‚Äù\n\nWhen to chain\nYou chain dplyr verbs (using pipes) when you want to perform multiple operations in sequence on the same dataset.\nChain when operations are related:\n\n# Good use of chaining - logical sequence\niris %&gt;%\n  filter(Species == \"setosa\") %&gt;%        # First, filter to one species\n  select(Sepal.Length, Sepal.Width) %&gt;%  # Then, select specific columns\n  summarize(mean_length = mean(Sepal.Length))  # Finally, calculate summary\n\nDon‚Äôt chain when operations are independent:\n\n# These are separate analyses, don't chain them\nsetosa_summary &lt;- iris %&gt;%\n  filter(Species == \"setosa\") %&gt;%\n  summarize(mean_length = mean(Sepal.Length))\n\nversicolor_summary &lt;- iris %&gt;%\n  filter(Species == \"versicolor\") %&gt;%\n  summarize(mean_length = mean(Sepal.Length))\n\n\n\nHow to chain correctly\nEach verb in the chain:\n\nTakes the result from the previous step as its first argument (automatically via %&gt;%)\nReturns a modified data frame\nPasses that data frame to the next verb\n\nThe pattern:\n\ndata %&gt;%\n  verb1(arguments) %&gt;%\n  verb2(arguments) %&gt;%\n  verb3(arguments)\n\n\n\nCommon chaining patterns you‚Äôll use\nFilter ‚Üí Select ‚Üí Summarize:\n\ndata %&gt;%\n  filter(condition) %&gt;%      # Reduce rows\n  select(columns) %&gt;%        # Reduce columns\n  summarize(statistic)       # Calculate summary\n\nGroup ‚Üí Summarize:\n\ndata %&gt;%\n  group_by(category) %&gt;%     # Define groups\n  summarize(mean = mean(x))  # Calculate within each group\n\nFilter ‚Üí Mutate:\n\ndata %&gt;%\n  filter(condition) %&gt;%      # Subset the data\n  mutate(new_col = x + y)    # Add a new column\n\nYou‚Äôll practice these patterns extensively in the homework."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#understanding-adorn-functions",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#understanding-adorn-functions",
    "title": "Muddy Points",
    "section": "Understanding adorn functions",
    "text": "Understanding adorn functions\nOne comment: ‚ÄúI got a little lost with how Adorn works but I think I figured out my issue after reviewing the notes.‚Äù\nI‚Äôm glad you figured it out! For others who might still be unclear:\n\nWhat adorn functions do\nThe adorn_ functions from the janitor package add nice formatting to tables, especially frequency tables created with tabyl() or count().\nCommon adorn functions:\n\nadorn_totals() ‚Äî adds row/column totals\nadorn_percentages() ‚Äî converts counts to proportions\nadorn_pct_formatting() ‚Äî formats proportions as percentages (e.g., ‚Äú25.0%‚Äù instead of 0.25)\nadorn_ns() ‚Äî adds counts alongside percentages\n\n\n\nHow to use them\nAdorn functions are meant to be chained (using pipes) after you create a table:\n\niris %&gt;%\n  count(Species) %&gt;%               # Create frequency table\n  adorn_totals(\"row\") %&gt;%          # Add total row\n  adorn_percentages(\"col\") %&gt;%     # Convert to proportions\n  adorn_pct_formatting(digits = 1) # Format as percentages\n\n\n\nThe order matters\nApply adorn functions in this sequence:\n\nadorn_totals() ‚Äî add totals first\nadorn_percentages() ‚Äî then convert to proportions\nadorn_pct_formatting() ‚Äî then format the display\nadorn_ns() ‚Äî optionally add counts in parentheses\n\nIf you do them out of order (like formatting before calculating percentages), you‚Äôll get errors or unexpected results."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#too-many-options-vs.-one-clear-path",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#too-many-options-vs.-one-clear-path",
    "title": "Muddy Points",
    "section": "Too many options vs.¬†one clear path",
    "text": "Too many options vs.¬†one clear path\nOne insightful comment: ‚ÄúIt is confusing for people who are starting out to hear multiple options of how to do something. It may be more helpful to have examples that we work through that follow exactly what we will need to be able to do to complete the homework and master tasks.‚Äù\nThis is excellent feedback. I want to address this directly:\n\nMy teaching approach and why\nI tend to mention alternative approaches because:\n\nI want you to recognize different coding styles when you see them online or in others‚Äô code\nSome of you have prior R experience and benefit from seeing connections\nIt helps build conceptual understanding of why we do things a certain way\n\n\n\nBut I hear you\nFor those new to R, multiple options can be overwhelming when you‚Äôre just trying to learn one way that works.\n\n\nWhat I‚Äôll do differently\nGoing forward, I‚Äôll use a core path + alternatives approach:\n\nTeach one clear method first ‚Äî this is the ‚Äúhomework way‚Äù\nPractice that method with multiple examples\nBriefly mention alternatives only after the core method is solid, clearly labeling them as ‚Äúyou might also see‚Ä¶‚Äù rather than ‚Äúyou could also do‚Ä¶‚Äù\n\nFor example:\n\n‚ÄúFor this course, we‚Äôll use library(tidyverse) at the start of our scripts. You might also see people use require() or load packages individually like library(dplyr), but we‚Äôll stick with library(tidyverse) for consistency.‚Äù\n\nThis way, you have a clear, reliable approach for homework while still being aware that other methods exist."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#live-coding-pace-and-practical-adjustments",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#live-coding-pace-and-practical-adjustments",
    "title": "Muddy Points",
    "section": "Live coding pace and practical adjustments",
    "text": "Live coding pace and practical adjustments\nSeveral comments mentioned the pace of live coding:\n\n‚ÄúThe class just felt fast and if there were any errors in my code, we had already moved on before I could see what the issue was.‚Äù\n‚ÄúThe R stuff is still a little fast for me, especially with how small the screen is‚Äù\n‚ÄúWe just moved very quickly through everything but still didn‚Äôt finish the entire lecture‚Äù\n\nThese are all valid concerns. Here‚Äôs what I‚Äôll adjust for our next R-heavy session:\n\nPacing changes\n\nBuilt-in debug time: After complex examples, I‚Äôll pause for 1-2 minutes and ask ‚ÄúAnyone getting an error? Let me know in chat or raise your hand‚Äù\nSlower typing: I‚Äôll be more deliberate about typing speed, especially for syntax-heavy sections\nFinish or cut strategically: Rather than rushing to finish all slides, I‚Äôll plan to end at a logical stopping point, even if we don‚Äôt cover everything\n\n\n\nVisual improvements\n\nLarger font in RStudio: I‚Äôll increase the font size for better visibility\nClear transitions: I‚Äôll announce when switching between slides and RStudio (e.g., ‚ÄúNow I‚Äôm opening RStudio‚Ä¶‚Äù)\nZoom on key areas: When typing complex syntax, I‚Äôll zoom in on the code\n\n\n\nManaging package installation delays\nOne comment: ‚ÄúInstalling data packages always takes a few minutes or longer if there‚Äôs an error. It seems instantaneous on your screen, and I‚Äôd hate to fall behind while waiting for something to load.‚Äù\nYou‚Äôre absolutely right. Here‚Äôs what we‚Äôll do:\n\nPre-class package list: I‚Äôll post which packages to install before class\nBuffer time in class: When we do install packages during class, I‚Äôll build in 3-5 minutes of buffer time\nAcknowledge the wait: I‚Äôll explain that package installation takes time and that it‚Äôs normal"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#practice-makes-perfect-the-role-of-homework",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#practice-makes-perfect-the-role-of-homework",
    "title": "Muddy Points",
    "section": "Practice makes perfect: the role of homework",
    "text": "Practice makes perfect: the role of homework\nOne comment really captured the learning process well: ‚ÄúI think I just need some practice with all of the R code that we went over in class, it all feels pretty muddy at this point but I think working with it and doing more examples and making mistakes will help me make sense of it.‚Äù\nThis is exactly right! Another comment echoed this: ‚ÄúThe lecture material is helpful but I have trouble following the in class coding examples. I have to work through the homework in order to fully grasp concepts.‚Äù\n\nThis is normal and expected\nLive coding in class is designed to:\n\nShow you what‚Äôs possible\nDemonstrate the workflow\nGive you examples to reference\nProvide scaffolding for homework\n\nIt is not expected that you‚Äôll master everything during the live demo. Real learning happens when you:\n\nWork through homework problems at your own pace\nMake mistakes and debug them\nApply concepts to different datasets\nRewatch recorded sections when needed\n\n\n\nThe class-homework connection\nThe in-class examples are templates for the homework. When you‚Äôre stuck on homework, go back to the .qmd file from class and look for a similar pattern.\nFor example:\n\nHomework asks: Calculate mean Sepal.Length by Species\nClass example showed: Calculate mean bill_length by species (for penguins data)\nPattern is the same: group_by(category) %&gt;% summarize(mean = mean(variable))\n\n\n\nIf you‚Äôre feeling lost during class\nThat‚Äôs okay! Your strategies should be:\n\nWatch and absorb rather than trying to type everything perfectly in real-time\nUse the .qmd file as your reference when doing homework\nRewatch recordings for sections that went too fast\nCome to office hours with specific questions from homework\n\nOne student noted: ‚Äúdoing the homework was far more informative‚Äù ‚Äî this isn‚Äôt a criticism of lecture, it‚Äôs recognition that doing is how we learn coding. Lecture provides the framework; homework provides the practice."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#whats-working-well",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#whats-working-well",
    "title": "Muddy Points",
    "section": "What‚Äôs working well",
    "text": "What‚Äôs working well\nMany of you identified clear points that I want to acknowledge and continue:\n\nThe .qmd file for following along\nMultiple comments mentioned how helpful it was to have the Quarto document to code along with. I‚Äôll continue providing complete, runnable .qmd files for every R session.\n\n\nReal-world examples and explanations\nSeveral of you appreciated:\n\nThe pipe operator analogy (keys, driving to work)\nLearning the history and context of packages\nUnderstanding how functions answer specific questions\n\nI‚Äôll continue using concrete analogies and providing the ‚Äúwhy‚Äù behind our tools.\n\n\nStep-by-step building\nYou valued seeing how to construct things incrementally (especially ggplots). This scaffolded approach works well, so I‚Äôll maintain this pattern."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#looking-ahead",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_dataviz_muddy_points.html#looking-ahead",
    "title": "Muddy Points",
    "section": "Looking ahead",
    "text": "Looking ahead\nBased on your feedback, I‚Äôll:\n\nStart with a clear list of required packages (posted before class)\nMake the connection between class examples and homework more explicit\nUse the ‚Äúcore path + alternatives‚Äù approach to avoid overwhelming you with options\nBuild in debug/catch-up time during live coding\nFocus on finishing a coherent chunk of material rather than rushing through all slides\n\nThank you again for the thoughtful feedback. These muddy points help me teach more effectively, and your willingness to identify what‚Äôs confusing is exactly what makes this process work."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#roadmap-for-today",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#roadmap-for-today",
    "title": "Normal and Poisson Distributions",
    "section": "Roadmap for Today",
    "text": "Roadmap for Today\n\n\nPart 1: Normal Distribution Basics\n\nContinuous distributions\nNormal parameters (Œº, œÉ)\nStandard Normal distribution\n\nPart 2: Z-scores & The Empirical Rule\n\nStandardization\n68-95-99.7 rule\nIdentifying unusual observations\n\nPart 3: Calculating with R\n\npnorm() for probabilities\nqnorm() for percentiles\nReal-world examples\n\n\nPart 4: Normal Approximation\n\nWhen Binomial ‚Üí Normal\nConditions: \\(np \\geq 10\\), \\(n(1-p) \\geq 10\\)\nContinuity correction\n\nPart 5: Poisson Distribution\n\nModeling rare events\nRate √ó time = Œª\nPoisson approximation to Binomial\n\nPart 6: Wrap-up\n\nSummary\nNext steps"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#last-time-discrete-vs.-continuous-random-variables",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#last-time-discrete-vs.-continuous-random-variables",
    "title": "Normal and Poisson Distributions",
    "section": "Last time: Discrete vs.¬†Continuous Random Variables",
    "text": "Last time: Discrete vs.¬†Continuous Random Variables\n\n\n\n\n\nDiscrete Random Variable\n\n\nA discrete r.v. takes on:\n\nA finite number of values, OR\nA countably infinite number of values\n\nExamples:\n\nNumber of heads in 10 coin flips\nNumber of students in a class\nNumber of COVID cases per day\n\n\n\n\n\n\n\n\nContinuous Random Variable\n\n\nA continuous r.v. can take:\n\nAny real value in an interval\nAny value in a union of intervals\n\nExamples:\n\nHeight\nBlood pressure\nTime until an event occurs\n\n\n\n\n\n\nToday‚Äôs focus: Continuous random variables"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#continuous-rv-in-general",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#continuous-rv-in-general",
    "title": "Normal and Poisson Distributions",
    "section": "Continuous rv in general",
    "text": "Continuous rv in general\n\nThe distribution of a continuous rv is governed by a density function/curve.\nProbabilities are calculated as area under the curve over an interval.\nTotal area beneath the density function/curve is 1."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#probability-between-a-and-b",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#probability-between-a-and-b",
    "title": "Normal and Poisson Distributions",
    "section": "Probability between a and b",
    "text": "Probability between a and b\nThe area beneath the density curve/function between two points a and b represents the probability that the random variable (\\(X\\), say) will assume some value between a and b\nWhen working with continuous random variables, probability is found for intervals of values rather than individual values.\n\nThe probability that a continuous r.v. \\(X\\) takes on any single individual value is 0\nThat is, \\(P(X = x) = 0\\).\nThus, \\(P(a &lt; X &lt; b)\\) is equivalent to \\(P(a \\leq X \\leq b)\\)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#probability-at-exactly-a",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#probability-at-exactly-a",
    "title": "Normal and Poisson Distributions",
    "section": "Probability at exactly a",
    "text": "Probability at exactly a\nFor a continuous random variable X:\n\nProbability comes from areas under the curve\nAreas require width\nA single point has no width\n\n\n\nSo:\n\n\\(P(X = a) = 0\\)\nOnly intervals have non-zero probability (for example, \\(P(a ‚â§ X ‚â§ b)\\))\n\n\nIntuition: you can shade an interval, but you can‚Äôt shade a point."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#all-the-following-are-equivalent",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#all-the-following-are-equivalent",
    "title": "Normal and Poisson Distributions",
    "section": "All the following are equivalent",
    "text": "All the following are equivalent\nFor a continuous r.v. \\(X\\), all of the following are equivalent:\n\\[P(a \\leq X \\leq b) = P(a &lt; X \\leq b)\\] \\[= P(a \\leq X &lt; b) = P(a &lt; X &lt; b)\\]\nThat is, we can safely ignore equality when defining the endpoints of a given interval. [This is certainly not true for discrete rv]"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#normal-distribution-1",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#normal-distribution-1",
    "title": "Normal and Poisson Distributions",
    "section": "Normal distribution",
    "text": "Normal distribution\n\n\n\nA random variable X is modeled with a normal distribution:\nShape: symmetric, unimodal bell curve\nCenter: mean \\(\\mu\\)\nSpread (variability): standard deviation \\(\\sigma\\)\nShorthand for a random variable, \\(X\\), that has a Normal distribution: \\[X \\sim \\text{Normal}(\\mu, \\sigma)\\]\n\n\n\n\nExample: We recorded the high temperature in the past 100 years for today. The mean high is 19¬∞C (66.2¬∞F)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#anatomy-of-the-normal-curve",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#anatomy-of-the-normal-curve",
    "title": "Normal and Poisson Distributions",
    "section": "Anatomy of the Normal curve",
    "text": "Anatomy of the Normal curve\n\n\n\n\n\n\n\n\n\n\nThe Normal distribution has a closed-form equation, but for this course:\n\nYou do not need to memorize it\nYou do not need to compute it by hand\nWhat matters is how \\(\\mu\\) and \\(\\sigma\\) shape the curve"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#different-means-same-sd",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#different-means-same-sd",
    "title": "Normal and Poisson Distributions",
    "section": "Different means, Same SD",
    "text": "Different means, Same SD\n\n\n\nOrange curve: \\(\\mu = 15\\), \\(\\sigma = 3\\)\nBlue curve: \\(\\mu = 20\\), \\(\\sigma = 3\\)\nSame spread (width), different centers\nThe mean determines where the bell curve is centered on the x-axis"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#same-mean-different-sd",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#same-mean-different-sd",
    "title": "Normal and Poisson Distributions",
    "section": "Same mean, Different SD",
    "text": "Same mean, Different SD\n\n\n\nOrange curve: \\(\\mu = 20\\), \\(\\sigma = 2\\)\nBlue curve: \\(\\mu = 20\\), \\(\\sigma = 5\\)\nSame center, different spreads\nSmaller SD = taller, narrower curve (less variability)\nLarger SD = shorter, wider curve (more variability)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#different-means-different-sd",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#different-means-different-sd",
    "title": "Normal and Poisson Distributions",
    "section": "Different means, different SD",
    "text": "Different means, different SD\n\n\n\nOrange curve: mu = 15, sigma = 2 (centered left, narrow/tall)\nBlue curve: mu = 24, sigma = 5 (centered right, wide/short)\nThe mean controls the horizontal location (center)\nThe standard deviation controls the spread (width/height)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#why-standardize",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#why-standardize",
    "title": "Normal and Poisson Distributions",
    "section": "Why standardize?",
    "text": "Why standardize?\nDifferent normal distributions have different scales:\n\nHeights measured in centimeters: \\(X \\sim N(170, 10)\\)\nTest scores: \\(Y \\sim N(75, 8)\\)\nBlood pressure: \\(Z \\sim N(120, 15)\\)\n\nProblem: How do we compare observations across different distributions?\nSolution: Convert to a common scale using Z-scores"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#what-is-a-z-score",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#what-is-a-z-score",
    "title": "Normal and Poisson Distributions",
    "section": "What is a Z-score?",
    "text": "What is a Z-score?\nThe Z-score tells you how many standard deviations an observation is from the mean:\nSuppose \\(X\\) is an arbitrary random variable that follows a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), i.e.¬†\\(X \\sim N(\\mu, \\sigma)\\)\n\\[Z = \\dfrac{X - \\mu}{\\sigma} \\Longleftrightarrow X = \\mu + Z\\sigma\\]\nNotation:\n\n\\(X\\) = original observation\n\\(\\mu\\) = mean of the distribution\n\\(\\sigma\\) = standard deviation of the distribution\n\\(Z\\) = standardized score"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#interpreting-z-scores",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#interpreting-z-scores",
    "title": "Normal and Poisson Distributions",
    "section": "Interpreting Z-scores",
    "text": "Interpreting Z-scores\n\n\n\nZ-score\nInterpretation\n\n\n\n\n\\(Z = 0\\)\nExactly at the mean\n\n\n\\(Z = 1\\)\nOne SD above the mean\n\n\n\\(Z = -1\\)\nOne SD below the mean\n\n\n\\(Z = 2.5\\)\n2.5 SDs above the mean\n\n\n\\(Z = -1.8\\)\n1.8 SDs below the mean\n\n\n\n\nRule of thumb:\n\nZ-scores between -2 and 2 are common\nZ-scores beyond ¬±3 are rare (unusual observations)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-height-standardization",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-height-standardization",
    "title": "Normal and Poisson Distributions",
    "section": "Example: Height standardization",
    "text": "Example: Height standardization\nSuppose adult male heights follow \\(N(\\mu = 175, \\sigma = 7)\\) cm.\nQuestion: What is the Z-score for a man who is 189 cm tall?\n\n\\[Z = \\frac{X - \\mu}{\\sigma} = \\frac{189 - 175}{7} = \\frac{14}{7} = 2\\]\nInterpretation: This man is 2 standard deviations above the mean height."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#standard-normal-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#standard-normal-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\nWhen we standardize a normal random variable, we get the Standard Normal distribution:\n\\[Z \\sim N(\\mu = 0, \\sigma = 1)\\]\nProperties:\n\nMean = 0\nStandard deviation = 1\nDenoted by \\(Z\\)\nAll normal distributions can be converted to this standard form"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#the-68-95-99.7-rule",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#the-68-95-99.7-rule",
    "title": "Normal and Poisson Distributions",
    "section": "The 68-95-99.7 Rule",
    "text": "The 68-95-99.7 Rule\nFor any normal distribution:\n\n68% of observations fall within 1 SD of the mean\n95% of observations fall within 2 SDs of the mean\n99.7% of observations fall within 3 SDs of the mean\n\n\nEmpirical rule (68‚Äì95‚Äì99.7).Source: OpenIntro Biostatistics."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#using-the-empirical-rule",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#using-the-empirical-rule",
    "title": "Normal and Poisson Distributions",
    "section": "Using the Empirical Rule",
    "text": "Using the Empirical Rule\nExample: IQ scores follow \\(N(\\mu = 100, \\sigma = 15)\\)\nQuestions:\n\nWhat percentage of people have IQ between 85 and 115?\n\n\n\n85 = 100 - 15 = Œº - œÉ\n115 = 100 + 15 = Œº + œÉ\nAnswer: About 68%. So about 2/3 of people fall within 15 points of 100.\n\n\n\n\nWhat percentage have IQ between 70 and 130?\n\n\n\n\n70 = 100 - 30 = Œº - 2œÉ\n130 = 100 + 30 = Œº + 2œÉ\nAnswer: About 95%"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#why-is-the-empirical-rule-useful",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#why-is-the-empirical-rule-useful",
    "title": "Normal and Poisson Distributions",
    "section": "Why is the Empirical Rule useful?",
    "text": "Why is the Empirical Rule useful?\n\n\nQuick estimates without calculations\nIdentify unusual observations\n\nValues beyond 2 SDs are uncommon (&lt;5%)\nValues beyond 3 SDs are very rare (&lt;0.3%)\n\nCheck data quality\n\nIf your data doesn‚Äôt follow this pattern, it may not be normally distributed"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#calculating-probabilities-from-a-normal-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#calculating-probabilities-from-a-normal-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "Calculating probabilities from a Normal distribution",
    "text": "Calculating probabilities from a Normal distribution\nThere are several ways to calculate probabilities from a normal distribution:\n\nCalculus\n(not for us!)\nNormal probability tables\n\nIncluded in the textbook (Appendix B.1)\nHelpful historically, but not required for this course\n\nR commands (what we will use)\n\n\\(P(Z \\leq q) =\\) pnorm(q, mean = 0, sd = 1)\n\\(P(Z &gt; q) =\\) pnorm(q, mean = 0, sd = 1, lower.tail = FALSE)\n\n\n\nIn this course, we will calculate normal probabilities using R."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#r-functions-for-the-normal-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#r-functions-for-the-normal-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "R functions for the Normal distribution",
    "text": "R functions for the Normal distribution\n\n\n\nFour key functions\n\n\n\n\n\nFunction\nPurpose\nExample\n\n\n\n\ndnorm()\nDensity at a point\nHeight of curve at x\n\n\npnorm()\nCumulative probability\nP(X ‚â§ x)\n\n\nqnorm()\nQuantile/percentile\nWhat x gives P(X ‚â§ x) = p?\n\n\nrnorm()\nRandom samples\nGenerate random normal data\n\n\n\nMost common: pnorm() and qnorm()"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#pnorm-cumulative-probabilities",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#pnorm-cumulative-probabilities",
    "title": "Normal and Poisson Distributions",
    "section": "pnorm(): Cumulative probabilities",
    "text": "pnorm(): Cumulative probabilities\n\n\npnorm(q, mean, sd, lower.tail = TRUE)\nCumulative probability is the total area under the curve to the left of a value, i.e.¬†the probability that a random variable is less than or equal to a value: \\(P(X \\le q)\\).\n\nq = the value you‚Äôre interested in\nmean \\(= \\mu\\)\nsd \\(= \\sigma\\)\nlower.tail = TRUE \\(\\longrightarrow P(X \\le q)\\)\nlower.tail = FALSE \\(\\longrightarrow P(X \\gt q)\\)\n\n\n\n\nExample: For standard normal \\(Z \\sim N(0, 1)\\):\n\n# P(Z ‚â§ 1.96)\npnorm(1.96, mean = 0, sd = 1)\n\n[1] 0.9750021\n\n\n\n\nInterpretation: About 97.5% of observations fall below Z = 1.96"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-standard-normal-probabilities",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-standard-normal-probabilities",
    "title": "Normal and Poisson Distributions",
    "section": "Example: Standard normal probabilities",
    "text": "Example: Standard normal probabilities\n\n\nLet \\(Z \\sim N(0, 1)\\). Calculate:\n\n\n1. \\(P(Z &lt; 2.67)\\)\n\npnorm(2.67)  # mean=0, sd=1 is the default\n\n[1] 0.9962074\n\n\n\n\n\n2. \\(P(Z &gt; -0.37)\\)\n\npnorm(-0.37, lower.tail = FALSE)\n\n[1] 0.6443088\n\n\n\n\nOr\n\n1 - pnorm(-0.37)\n\n[1] 0.6443088"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-standard-normal-probabilities-continued",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-standard-normal-probabilities-continued",
    "title": "Normal and Poisson Distributions",
    "section": "Example: Standard normal probabilities (continued)",
    "text": "Example: Standard normal probabilities (continued)\n\n\n3. \\(P(-2.18 &lt; Z &lt; 2.46)\\)\n\npnorm(2.46) - pnorm(-2.18)\n\n[1] 0.9784244\n\n\n\n\n\n4. \\(P(Z = 1.53)\\)\n\n# For continuous distributions, P(X = x) = 0\n0\n\n[1] 0\n\n\n\nRemember: For continuous random variables, the probability of any single exact value is 0!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-general-normal-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-general-normal-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "Example: General normal distribution",
    "text": "Example: General normal distribution\n\n\nSuppose the distribution of diastolic blood pressure (DBP) in 35- to 44-year old men is normally distributed with mean 80 mm Hg and variance 144 mm Hg.\n\n\n\\[X \\sim N(\\mu = 80, \\sigma = 12)\\]\n(Note: \\(variance = 144\\), so \\(SD = \\sqrt{144} = 12\\))\n\n\nQuestion 1: What proportion has mild hypertension (DBP between 90 and 99)?\n\n\n# P(90 ‚â§ X ‚â§ 99)\npnorm(99, mean = 80, sd = 12) - pnorm(90, mean = 80, sd = 12)\n\n[1] 0.1456556\n\n\nAbout 14.6% have mild hypertension."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#visualizing-the-probability",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#visualizing-the-probability",
    "title": "Normal and Poisson Distributions",
    "section": "Visualizing the probability",
    "text": "Visualizing the probability"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#same-probability-different-scale",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#same-probability-different-scale",
    "title": "Normal and Poisson Distributions",
    "section": "Same probability, different scale",
    "text": "Same probability, different scale\n\n\nRecall the Z-score transformation:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\nThis means any probability from a normal distribution can be computed in two equivalent ways:\n\n\nOriginal scale\n\npnorm(99, mean = 80, sd = 12)\n\n[1] 0.9433272\n\n\n\nStandardized scale\n\npnorm((99 - 80) / 12, mean = 0, sd = 1)\n\n[1] 0.9433272\n\n\n\n¬†\n\nThese two probabilities are identical.\nStandardization changes the scale, not the probability."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#qnorm-finding-percentiles",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#qnorm-finding-percentiles",
    "title": "Normal and Poisson Distributions",
    "section": "qnorm(): Finding percentiles",
    "text": "qnorm(): Finding percentiles\n\n\nqnorm(p, mean, sd, lower.tail = TRUE)\n\n\nA percentile is the value below which a given percentage of observations fall;\nqnorm() returns the value on the x-axis corresponding to a cumulative probability.\n\np = the probability/percentile (as a decimal)\nmean = Œº\nsd = œÉ\nReturns the value where \\(P(X ‚â§ value) = p\\)\n\n\n\n\nExample: What Z-score has 97.5% of data below it?\n\nqnorm(0.975, mean = 0, sd = 1)\n\n[1] 1.959964\n\n\nThis is the famous 1.96 critical value!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-blood-pressure-percentiles",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-blood-pressure-percentiles",
    "title": "Normal and Poisson Distributions",
    "section": "Example: Blood pressure percentiles",
    "text": "Example: Blood pressure percentiles\n\n\nDBP: \\(X \\sim N(80, 12)\\)\n\n\nQuestion 2: What is the 10th percentile?\n\nqnorm(0.10, mean = 80, sd = 12)\n\n[1] 64.62138\n\n\n10% of men have DBP below about 64.6 mm Hg.\n\n\n\nQuestion 3: What is the 95th percentile?\n\nqnorm(0.95, mean = 80, sd = 12)\n\n[1] 99.73824\n\n\n95% of men have DBP below about 99.7 mm Hg."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#connecting-percentiles-to-z-scores",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#connecting-percentiles-to-z-scores",
    "title": "Normal and Poisson Distributions",
    "section": "Connecting percentiles to Z-scores",
    "text": "Connecting percentiles to Z-scores\nAny percentile question can be solved with Z-scores:\nWhat is the 10th percentile of N(80, 12)?\n\n\nStep 1: Find Z-score for 10th percentile\n\nz &lt;- qnorm(0.10)\nz\n\n[1] -1.281552\n\n\n\n\nStep 2: Convert back to original scale\n\nx &lt;- 80 + z * 12\nx\n\n[1] 64.62138\n\n\n\n\nFormula: \\(X = \\mu + Z \\cdot \\sigma\\)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#when-is-a-binomial-approximately-normal",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#when-is-a-binomial-approximately-normal",
    "title": "Normal and Poisson Distributions",
    "section": "When is a binomial approximately normal?",
    "text": "When is a binomial approximately normal?\nRecall that a binomial random variable \\(X\\) counts the total number of successes in \\(n\\) independent trials, each with probability \\(p\\) of a success.\nProbability function for \\(k = 0, 1, ..., n\\) : \\[P(X = k) = {n\\choose k}p^k(1-p)^{n-k}\\]\nAs n gets larger, the binomial distribution becomes more symmetric and can be approximated by a normal distribution.\n\n\n\nNote\n\n\nRule of thumb: Normal approximation works well when:\n\\[np \\geq 10 \\quad \\text{and} \\quad n(1-p) \\geq 10\\]\n\nEnsures sample size (\\(n\\)) is moderately large and the \\(p\\) is not too close to 0 or 1\nOther resources use other criteria (like \\(npq&gt;5\\) or \\(np&gt;5\\))"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#visual-binomial-approaching-normal",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#visual-binomial-approaching-normal",
    "title": "Normal and Poisson Distributions",
    "section": "Visual: Binomial approaching Normal",
    "text": "Visual: Binomial approaching Normal\nBinomial distributions for different \\(n\\) (columns) and \\(p\\) (rows)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#normal-approximation-parameters",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#normal-approximation-parameters",
    "title": "Normal and Poisson Distributions",
    "section": "Normal approximation parameters",
    "text": "Normal approximation parameters\n\n\nIf \\(X \\sim \\text{Binomial}(n, p)\\) and the conditions are met:\n\\[X \\approx N(\\mu, \\sigma)\\]\nwhere:\n\\[\\mu = np \\quad \\text{and} \\quad \\sigma = \\sqrt{np(1-p)}\\]\n\nThese are the same formulas for the mean and SD of a binomial distribution!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#continuity-correction",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#continuity-correction",
    "title": "Normal and Poisson Distributions",
    "section": "Continuity correction",
    "text": "Continuity correction\nThe binomial is discrete (0, 1, 2, ‚Ä¶), but the Normal is continuous.\n\n\nSo we ‚Äúnudge‚Äù the cutoff by 0.5 when using the Normal approximation.\n\nFor left-tail probabilities (\\(&lt;\\) or \\(\\le\\)): add 0.5\n\n\\(P(X \\le k)\\) becomes \\(P(Y \\le k + 0.5)\\)\n\\(P(X &lt; k)\\) becomes \\(P(Y \\le k - 0.5)\\) (since \\(X &lt; k\\) means \\(X \\le k-1\\))\n\nFor right-tail probabilities (\\(&gt;\\) or \\(\\ge\\)): subtract 0.5\n\n\\(P(X \\ge k)\\) becomes \\(P(Y \\ge k - 0.5)\\)\n\\(P(X &gt; k)\\) becomes \\(P(Y \\ge k + 0.5)\\) (since \\(X &gt; k\\) means \\(X \\ge k+1\\))\n\n\n\nWhere \\(X\\) is binomial, and \\(Y\\) is the Normal approximation."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-covid-vaccination-status",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-covid-vaccination-status",
    "title": "Normal and Poisson Distributions",
    "section": "Example: COVID vaccination status",
    "text": "Example: COVID vaccination status\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for it. Suppose 100 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 100 that tested positive. What is the probability that fewer than 20 of the people that tested positive are vaccinated?\nLet \\(X\\) = number vaccinated among the 100.\n\n\nQuestion: What is \\(P(X &lt; 20)\\)?\n\nCheck conditions:\n\nn &lt;- 100\np &lt;- 0.25\n\nn * p  # Should be ‚â• 10\n\n[1] 25\n\nn * (1 - p)  # Should be ‚â• 10\n\n[1] 75\n\n\n‚úì Conditions met!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#exact-vs.-approximate-probability-12",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#exact-vs.-approximate-probability-12",
    "title": "Normal and Poisson Distributions",
    "section": "Exact vs.¬†Approximate probability (1/2)",
    "text": "Exact vs.¬†Approximate probability (1/2)\nMethod 1: Exact (Binomial)\n\\[P(X &lt; 20) = P(X \\leq 19) = P(X=0) + P(X=1) + \\cdots + P(X=19)\\]\n\npbinom(19, size = 100, prob = 0.25)\n\n[1] 0.09953041\n\n\n\n\n\nMethod 2: Normal Approximation\n\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))\n\npnorm(19, mean = mu, sd = sigma)\n\n[1] 0.08292833\n\n\n\n\n\n\nVery close! The normal approximation is 0.083 vs.¬†exact 0.100."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#exact-vs.-approximate-probability-22",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#exact-vs.-approximate-probability-22",
    "title": "Normal and Poisson Distributions",
    "section": "Exact vs.¬†Approximate probability (2/2)",
    "text": "Exact vs.¬†Approximate probability (2/2)\n\n\nMethod 3: Normal Approximation with continuity correction\nBecause we want \\(P(X &lt; 20) = P(X \\le 19)\\), we use 19.5 in the normal approximation.\n\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))\n\npnorm(19 + 0.5, mean = mu, sd = sigma)\n\n[1] 0.1020119\n\n\n\n\nWith continuity correction: 0.102"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#whats-really-happening",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#whats-really-happening",
    "title": "Normal and Poisson Distributions",
    "section": "What‚Äôs really happening?",
    "text": "What‚Äôs really happening?\n\nA binomial counts the number of successes\nWhen n is large, this count behaves like a normal variable\nThe normal approximation lets us:\n\nUse Z-scores\nUse pnorm()\nReuse everything we just learned"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#when-to-use-each-method",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#when-to-use-each-method",
    "title": "Normal and Poisson Distributions",
    "section": "When to use each method?",
    "text": "When to use each method?\nUse Binomial (exact):\n\nWhen n is small or moderate\nWhen you need exact probabilities\nR handles this easily with pbinom()\n\nUse Normal approximation:\n\nWhen n is very large (computing binomial probabilities becomes slow)\nFor theoretical understanding\nHistorically important (before computers!)\n\n\n\nIn practice: With modern computers, we usually just use the exact binomial."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#checking-whether-normal-is-reasonable-12",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#checking-whether-normal-is-reasonable-12",
    "title": "Normal and Poisson Distributions",
    "section": "Checking whether Normal is reasonable (1/2)",
    "text": "Checking whether Normal is reasonable (1/2)\nIn practice, we check normality visually:\n\nHistogram or density plot (shape: roughly symmetric, unimodal)\nQ-Q plot (points close to a straight line)\nIf using a normal model: check residuals, not raw outcomes\n\nWe usually avoid hypothesis tests (e.g., Shapiro-Wilk) because:\n\nWith large n, tiny deviations look ‚Äúsignificant‚Äù\nWith small n, tests have low power\nVisuals + context are more informative\n\nQuantile-quantile plots in ggplot2\n\n# Example code\nggplot(data, \n       aes(sample = x)) +\n  stat_qq() +\n  stat_qq_line()"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#checking-whether-normal-is-reasonable-22",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#checking-whether-normal-is-reasonable-22",
    "title": "Normal and Poisson Distributions",
    "section": "Checking whether Normal is reasonable (2/2)",
    "text": "Checking whether Normal is reasonable (2/2)\nA Q-Q plot compares your sample quantiles to theoretical Normal quantiles; straight-line agreement means the distributional shape matches Normal (especially in the tails)."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-distribution-counts",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-distribution-counts",
    "title": "Normal and Poisson Distributions",
    "section": "Poisson distribution (counts)",
    "text": "Poisson distribution (counts)\nUse a Poisson model for the number of events in a fixed interval when:\n\nEvents occur independently\nThe event rate is roughly constant over the interval\nWe are counting events (0, 1, 2, ‚Ä¶)\n\n\n\nNotation:\n\\[X \\sim \\text{Pois}(\\lambda)\\]\nInterpretation:\n\n\\(\\lambda\\) = expected number of events per interval (rate √ó time)\nMean = \\(\\lambda\\)\nSD = \\(\\sqrt{\\lambda}\\)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-distribution-when-you-see-it-think-poisson",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-distribution-when-you-see-it-think-poisson",
    "title": "Normal and Poisson Distributions",
    "section": "Poisson distribution: when you see it, think Poisson",
    "text": "Poisson distribution: when you see it, think Poisson\n\n\n\nNote\n\n\nPoisson models counts of events in a fixed interval.\nAsk yourself:\n‚ÄúHow many times does something happen in a given amount of time or space?‚Äù\n\n\n\nCommon examples:\n\nNumber of ER arrivals per hour\nNumber of emails received per day\nNumber of mutations per gene\nNumber of accidents per mile of highway per year\n\n\nKey clues:\n\nCounting events: 0, 1, 2, 3, ‚Ä¶\nFixed interval (time, distance, area)\nEvents are relatively rare and independent"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#r-functions-for-poisson",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#r-functions-for-poisson",
    "title": "Normal and Poisson Distributions",
    "section": "R functions for Poisson",
    "text": "R functions for Poisson\n\n\n\nFour key functions\n\n\n\n\n\nFunction\nPurpose\nExample\n\n\n\n\ndpois()\nProbability at a value\nP(X = x)\n\n\nppois()\nCumulative probability\nP(X ‚â§ x)\n\n\nqpois()\nQuantile\nWhat x gives P(X ‚â§ x) = p?\n\n\nrpois()\nRandom samples\nSimulate counts\n\n\n\nMost common: dpois() and ppois()"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#shape-depends-on-Œª",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#shape-depends-on-Œª",
    "title": "Normal and Poisson Distributions",
    "section": "Shape depends on Œª",
    "text": "Shape depends on Œª\n\nAs Œª increases:\n\nThe distribution shifts to the right (larger expected counts)\nThe distribution becomes more symmetric\nFor large Œª, it starts to look approximately Normal"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#example-typhoid-deaths-Œª-scaling",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#example-typhoid-deaths-Œª-scaling",
    "title": "Normal and Poisson Distributions",
    "section": "Example: Typhoid deaths (Œª scaling)",
    "text": "Example: Typhoid deaths (Œª scaling)\nSuppose there are on average 5 deaths per year.\n1. Probability of exactly 3 deaths in 1 year:\n\ndpois(x = 3, lambda = 5)\n\n[1] 0.1403739\n\n\n\n\n2. Probability of exactly 2 deaths in 0.5 years:\nRate scales with time, so \\(\\lambda_{0.5} = 5 \\times 0.5 = 2.5\\)\n\ndpois(x = 2, lambda = 2.5)\n\n[1] 0.2565156\n\n\n\n\n3. Probability of more than 12 deaths in 2 years:\n\\(\\lambda_{2} = 5 \\times 2 = 10\\)\n\nppois(q = 12, lambda = 10, lower.tail = FALSE)\n\n[1] 0.2084435\n\n# or: 1 - ppois(12, lambda = 10)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-approximation-to-binomial-rare-events",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#poisson-approximation-to-binomial-rare-events",
    "title": "Normal and Poisson Distributions",
    "section": "Poisson approximation to Binomial (rare events)",
    "text": "Poisson approximation to Binomial (rare events)\nWhen \\(n\\) is large and \\(p\\) is small, a Binomial can be approximated by a Poisson:\nIf \\(X \\sim \\text{Binomial}(n, p)\\) and \\(p\\) is small, then \\[X \\approx \\text{Pois}(\\lambda = np)\\]\nThis is most useful when the Normal approximation is not appropriate (because \\(p\\) is too close to 0).\n\n\nQuick example:\n\nn &lt;- 1000\np &lt;- 0.002\nlambda &lt;- n * p\n\n# Approx P(X &lt;= 3)\npbinom(3, size = n, prob = p)\n\n[1] 0.8573042\n\nppois(3, lambda = lambda)\n\n[1] 0.8571235\n\n\nVery close! (0.857 vs 0.857)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#summary-poisson-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#summary-poisson-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "Summary: Poisson distribution",
    "text": "Summary: Poisson distribution\nKey characteristics:\n\nModels count data for rare events\nParameter: \\(\\lambda\\) = rate √ó time\nMean = \\(\\lambda\\), SD = \\(\\sqrt{\\lambda}\\)\n\nR functions:\n\ndpois(x, lambda) ‚Üí P(X = x)\nppois(q, lambda) ‚Üí P(X ‚â§ q)\n\nImportant: Remember to adjust Œª when changing the time interval!\nApproximation: Can approximate Binomial when n is large and p is small."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#what-you-need-to-know-normal-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#what-you-need-to-know-normal-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "What you need to know: Normal distribution",
    "text": "What you need to know: Normal distribution\nConceptual understanding:\n\nNormal distributions are symmetric, bell-shaped, continuous\nFully characterized by mean (Œº) and standard deviation (œÉ)\nZ-scores standardize to N(0, 1): \\(Z = \\frac{X - \\mu}{\\sigma}\\)\n\n\n\nEmpirical Rule (68-95-99.7):\n\n68% of data within 1 SD, 95% within 2 SDs, 99.7% within 3 SDs\nValues beyond ¬±3 SDs are very rare\n\n\n\nR skills:\n\npnorm(q, mean, sd) ‚Üí P(X ‚â§ q)\nqnorm(p, mean, sd) ‚Üí value at pth percentile\nNormal approximation when \\(np \\geq 10\\) AND \\(n(1-p) \\geq 10\\)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#what-you-need-to-know-poisson-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#what-you-need-to-know-poisson-distribution",
    "title": "Normal and Poisson Distributions",
    "section": "What you need to know: Poisson distribution",
    "text": "What you need to know: Poisson distribution\nWhen to use Poisson:\n\nCounting rare events in a fixed interval\nEvents occur independently at rate Œª\n\n\n\nKey concepts:\n\nParameter: Œª = rate √ó time\nMean = Œª, SD = \\(\\sqrt{\\lambda}\\)\nAdjust Œª when changing time intervals\n\n\n\nR skills:\n\ndpois(x, lambda) ‚Üí P(X = x)\nppois(q, lambda) ‚Üí P(X ‚â§ q)\nPoisson approximates Binomial when n is large and p is small"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson.html#key-formulas-for-reference",
    "href": "lessons/10_normal_poisson/10_normal_poisson.html#key-formulas-for-reference",
    "title": "Normal and Poisson Distributions",
    "section": "Key formulas (for reference)",
    "text": "Key formulas (for reference)\nYou don‚Äôt need to memorize these, but understand what they represent:\n\n\nZ-score transformation: \\[Z = \\frac{X - \\mu}{\\sigma} \\quad \\text{or} \\quad X = \\mu + Z\\sigma\\]\n\n\nNormal approximation to Binomial:\nWhen \\(np \\geq 10\\) and \\(n(1-p) \\geq 10\\): \\[X \\sim \\text{Binomial}(n, p) \\approx N\\left(\\mu = np, \\sigma = \\sqrt{np(1-p)}\\right)\\]\n\n\nPoisson approximation to Binomial:\nWhen \\(n\\) is large and \\(p\\) is small: \\[X \\sim \\text{Binomial}(n, p) \\approx \\text{Pois}(\\lambda = np)\\]\n\n\n\nBMSC 620 | Normal + Poisson"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. Below I address the main points that came up as muddy or unclear after our first lecture."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#thanks-for-the-feedback",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#thanks-for-the-feedback",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. Below I address the main points that came up as muddy or unclear after our first lecture."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#stratified-sampling-vs.-cluster-sampling-vs.-multistage-sampling",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#stratified-sampling-vs.-cluster-sampling-vs.-multistage-sampling",
    "title": "Muddy Points",
    "section": "1. Stratified sampling vs.¬†cluster sampling vs.¬†multistage sampling",
    "text": "1. Stratified sampling vs.¬†cluster sampling vs.¬†multistage sampling\nThis was the most common point of confusion, which is very normal. These ideas are closely related, and the differences are mostly about how groups are formed and who gets sampled.\nA helpful way to think about this is to ask two questions:\n\nWhy are the groups defined?\nWho do we actually sample?\n\nStratified sampling\n\nGroups (called strata) are formed based on shared characteristics that matter to the research question.\nIndividuals within each stratum are relatively similar.\nWe then randomly sample some individuals from every stratum.\n\nGoal: Ensure representation from all important subgroups.\nExample (animal study):\nYou are studying hormone levels in mice and know sex affects the outcome.\n\nCreate strata by sex (male, female).\nRandomly sample mice from each sex group.\n\nCluster sampling\n\nGroups (called clusters) are formed based on natural or logistical groupings.\nIndividuals within a cluster are often diverse.\nWe randomly select entire clusters, then include all individuals within them.\n\nGoal: Reduce cost or effort when sampling individuals directly is difficult.\nExample (animal study):\nYou are studying lab mice housed in cages.\n\nTreat each cage as a cluster.\nRandomly select some cages.\nMeasure all mice in the selected cages.\n\nMultistage sampling\n\nSampling happens in steps.\nFirst, clusters are randomly selected.\nThen, individuals are randomly sampled within those selected clusters.\n\nGoal: Combine logistical convenience with random sampling.\nExample (animal study):\n\nStage 1: Randomly select cages.\nStage 2: Randomly select mice within each selected cage.\n\nYou can think of multistage sampling as layering familiar sampling ideas together."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#why-would-some-clusters-be-more-likely-to-be-selected",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#why-would-some-clusters-be-more-likely-to-be-selected",
    "title": "Muddy Points",
    "section": "2. Why would some clusters be more likely to be selected?",
    "text": "2. Why would some clusters be more likely to be selected?\nOne question that came up was why certain clusters might have a higher chance of selection in multistage sampling.\nThis was a place where I misspoke in class (around the 57 mimute mark of the recording), so I want to clarify.\nFor the types of sampling designs we focus on in this course (and in the textbook), clusters are usually selected at random, with each cluster having the same probability of being chosen. You should generally think of cluster sampling as treating each cluster equally at the selection stage.\nMore complex designs where clusters have different selection probabilities do exist, but we will not be focusing on those, and we will not be getting into weighting in this course.\nTo help reinforce the distinction, here is a contrast between stratified sampling and cluster sampling.\nStratified sampling\n\nThe population is divided into strata such that units within each stratum are similar with respect to the variable(s) of interest.\nA random sample is then taken within each stratum.\nGoal: reduce variability within strata and ensure representation of important subgroups.\nResult:\n\nLow variability within strata\nHigher variability between strata\n\n\nCluster sampling\n\nThe population is divided into clusters such that:\n\nunits within a cluster are diverse, and\n\nclusters themselves are similar to one another.\n\n\nA random sample of clusters is selected, and then all units (or many units) within the selected clusters are included.\nGoal: improve practicality or reduce cost when sampling individuals directly is difficult.\nAs described in the textbook:\n\nHigh case-to-case variability within clusters\nClusters are similar to each other\n\n\nIn short:\n\nStratified sampling: simple random sample of units within every group\nCluster sampling: simple random sample of entire groups\n\nThank you for raising this! It was a good catch, and this clarification will help going forward."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#nominal-vs.-ordinal-variables",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#nominal-vs.-ordinal-variables",
    "title": "Muddy Points",
    "section": "3. Nominal vs.¬†ordinal variables",
    "text": "3. Nominal vs.¬†ordinal variables\nA few people mentioned that variable types felt rushed near the end.\nA quick reminder:\n\nNominal variables: categories with no natural order (e.g., species, blood type).\nOrdinal variables: categories with a meaningful order, but unclear spacing (e.g., mild / moderate / severe).\n\nWe will return to variable types repeatedly throughout the course, especially when we start visualizing data and choosing analyses."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#r-quarto-and-.qmd-files",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#r-quarto-and-.qmd-files",
    "title": "Muddy Points",
    "section": "4. R, Quarto, and .qmd files",
    "text": "4. R, Quarto, and .qmd files\nSeveral people noted that the introduction to R and .qmd files felt intimidating, especially for those new to R.\nThat reaction is expected.\nFor now, the key idea is:\n\nA .qmd file is a document that mixes text and code.\nRendering turns it into something readable (like an HTML file).\n\nHomework 0 is designed to be:\n\nlow-stakes,\nguided,\nand focused on setup rather than programming.\n\nYou are not expected to understand R deeply yet."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#homework-submission-and-course-logistics",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#homework-submission-and-course-logistics",
    "title": "Muddy Points",
    "section": "5. Homework submission and course logistics",
    "text": "5. Homework submission and course logistics\nA few people asked how homework is submitted and how lecture material connects to the textbook.\n\nThe course website is your main hub for slides, recordings, and instructions.\nSakai is used for submitting assignments and checking grades.\nLectures and the textbook are meant to complement each other; sometimes lecture will preview ideas, other times it will reinforce them.\n\nThis will feel clearer once you‚Äôve completed your first homework."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#final-note",
    "href": "lessons/01_intro_to_data/01_intro_to_data_muddy_points.html#final-note",
    "title": "Muddy Points",
    "section": "Final note",
    "text": "Final note\nIf something still feels muddy after this clarification, that‚Äôs okay. Many concepts in statistics become clearer only after you see them used multiple times.\nPlease keep using the post-class check-ins. They are genuinely helpful for guiding what we slow down on or revisit."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#roadmap-for-todays-r-content",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#roadmap-for-todays-r-content",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Roadmap for Today‚Äôs R Content",
    "text": "Roadmap for Today‚Äôs R Content\nBuilding on last class: File paths and reproducibility\n\n\nToday‚Äôs goals:\n\nR Projects - Your solution to file path headaches\nThe here package - Robust file referencing\nReading data - Getting your data into R\n\nCSV files with readr\nExcel files with readxl\n\n\n\n\nBy the end, you‚Äôll be able to load the body temperature dataset we‚Äôll use for hypothesis testing!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#recall-why-do-file-paths-break",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#recall-why-do-file-paths-break",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Recall: Why do file paths break?",
    "text": "Recall: Why do file paths break?\nLast class we talked about how this breaks:\n\n# This works on MY computer\ndata &lt;- read_csv(\"C:/Users/Emile/Documents/BMSC620/data/BodyTemps.csv\")\n\n\n\nProblems:\n\nHard-coded path specific to one computer\nWon‚Äôt work if you move the folder\nWon‚Äôt work on collaborator‚Äôs computer\nWon‚Äôt work if you rename folders\nMakes your code not reproducible"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#reproducibility",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#reproducibility",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nResearch data and code (and documentation) can reach the same results regardless of who is running the code\n\nThis can also refer to future or past you!\n\nWe want to set up our work so the entire folder can be moved around and work in its new location"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-we-want-portable-reproducible-code",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-we-want-portable-reproducible-code",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "What we want: Portable, reproducible code",
    "text": "What we want: Portable, reproducible code\nIdeal scenario:\n\nYour entire project folder can be moved anywhere\nCode still works without editing paths\nCollaborators can run your code immediately\nFuture you can run it on a new computer\n\n\n\nThe solution: R Projects + here package"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-is-an-r-project",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-is-an-r-project",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "What is an R Project?",
    "text": "What is an R Project?\nAn R Project is a way to designate a working directory for your analysis.\n\n\nWhen you create an R Project:\n\nRStudio creates a .Rproj file in your folder\nThat folder becomes the ‚Äúroot‚Äù of your working directory\nRStudio knows where you are and where to find files\nEach project has its own independent environment\n\n\n\n\n\n\nBest practice\n\n\nCreate a separate R Project for every analysis (and every class!)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#why-use-r-projects",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#why-use-r-projects",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Why use R Projects?",
    "text": "Why use R Projects?\nOrganization:\n\nKeeps all files for one project together\nEasy to see what belongs to what analysis\n\n\n\nReproducibility:\n\nPaths are relative to the project folder\nProject can be moved anywhere and still work\nEasy to share with collaborators\n\n\n\nWorkflow:\n\nCan have multiple RStudio sessions open (different projects)\nEach session is independent\nEasy to switch between projects"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#the-nice-thing-about-r-projects",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#the-nice-thing-about-r-projects",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "The nice thing about R projects",
    "text": "The nice thing about R projects\n\n5 minute video explaining some of the nice features of R projects\n\nhttps://rfortherestofus.com/2022/10/rstudio-projects"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#recommended-folder-structure",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#recommended-folder-structure",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Recommended folder structure",
    "text": "Recommended folder structure\nWhen you create a project, organize your files:\nMy typical folder structure\nMyProject/\n‚îú‚îÄ‚îÄ MyProject.Rproj      # R Project file\n‚îú‚îÄ‚îÄ data/                # data files (never edited by hand)\n‚îú‚îÄ‚îÄ code/                # R, qmd, html\n‚îú‚îÄ‚îÄ docs/                # notes, instructions, PDFs, references\n‚îú‚îÄ‚îÄ figures/             # saved figures\n‚îú‚îÄ‚îÄ deliverables/        # sent to collaborators, by date\n‚îî‚îÄ‚îÄ admin/               # budgets, admin\n\n\nFor this class, I recommend:\nBMSC620/\n‚îú‚îÄ‚îÄ BMSC620.Rproj        # R Project file\n‚îú‚îÄ‚îÄ data/                # Datasets I provide\n‚îú‚îÄ‚îÄ homework/            # Your homework files, one folder for each HW\n‚îú‚îÄ‚îÄ notes/               # Your class notes (hmtl, pdf, etc.)\n‚îú‚îÄ‚îÄ practice/            # Practice exercises\n‚îî‚îÄ‚îÄ misc/                # And other folders if you want"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#how-to-create-an-r-project",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#how-to-create-an-r-project",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "How to create an R Project",
    "text": "How to create an R Project\n\n\nOption 1: New project in existing folder\n(recommended if you already organized folders)\n\nFile ‚Üí New Project...\nChoose Existing Directory\nNavigate to your class folder\nCheck ‚ÄúOpen in new session‚Äù\nClick Create Project\n\n\nOption 2: New project in new folder\n\nFile ‚Üí New Project...\nChoose New Directory\nChoose New Project\nName your project and choose where to save it\nCheck ‚ÄúOpen in new session‚Äù\nClick Create Project\n\n\n\n\n\n\n\nAlways check ‚ÄúOpen in new session‚Äù\n\n\nThis keeps your current work separate from the new project. Good habit for managing multiple projects!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#live-demonstration",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#live-demonstration",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Live demonstration",
    "text": "Live demonstration\nLet me show you how to:\n\nCreate an R Project for our class\nSet up the folder structure\nOpen the project\nNote: Watch for the ‚ÄúOpen in new session‚Äù checkbox\n\n\n\n\n\n\nNote\n\n\nWe‚Äôre creating a ‚Äúregular‚Äù R Project, not a ‚ÄúQuarto Project‚Äù\n\nRegular projects are simpler and work perfectly for our needs\nOnce you‚Äôre comfortable, you can explore Quarto Projects later"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#your-turn-create-your-class-project",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#your-turn-create-your-class-project",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Your turn: Create your class project",
    "text": "Your turn: Create your class project\nTask: Create an R Project for BMSC 620\n\n\nSteps:\n\nDecide where on your computer you want your class folder\nCreate folders: data, homework, notes, practice\nIn RStudio: File ‚Üí New Project... ‚Üí Existing Directory\nNavigate to your class folder\n‚úì Check ‚ÄúOpen in new session‚Äù\nClick Create Project\n\n\n\nYou should now see a .Rproj file in your folder!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#opening-a-project",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#opening-a-project",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Opening a project",
    "text": "Opening a project\nTo work on your project in the future:\n\n\nOption 1: Double-click the .Rproj file\n\nOpens RStudio with that project loaded\nWorking directory is automatically set\n\n\n\nOption 2: In RStudio, click the project dropdown (top right)\n\nShows recent projects\nEasy to switch between projects\n\n\n\n\n\n\nWorkflow tip\n\n\nAlways open RStudio by opening your project file, not just opening RStudio directly!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#the-problem-here-solves",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#the-problem-here-solves",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "The problem here solves",
    "text": "The problem here solves\nEven with an R Project, you still need to reference files:\n\n# These might work differently depending on file type\ndata &lt;- read_csv(\"data/BodyTemps.csv\")\n\n\n\nThe issue:\n\n.qmd files and .R files handle working directories differently\nCan lead to confusion about where files are\nhere package makes this consistent and reliable"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-does-here-do",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#what-does-here-do",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "What does here do?",
    "text": "What does here do?\nThe here package always starts at your project root (where the .Rproj file is)\n\nlibrary(here)\nhere()  # Shows your project root directory\n\n[1] \"/Users/latour/Library/CloudStorage/Dropbox/teaching/BMSC_620_W26\"\n\n\n\n\nBenefits:\n\nWorks the same in .qmd and .R files\nPaths are relative to project root\nVery clear where files are located\nEssential for reproducibility!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#using-here-to-reference-files",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#using-here-to-reference-files",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Using here() to reference files",
    "text": "Using here() to reference files\nBasic syntax:\n\nhere(\"folder_name\", \"filename\")\n\n\n\nExamples:\n\n# Data file in the data folder\nhere(\"data\", \"BodyTemps.csv\")\n\n# Output file\nhere(\"output\", \"my_plot.png\")\n\n# Nested folders\nhere(\"data\", \"raw\", \"survey_data.xlsx\")\n\n\n\nThe here() function builds the full file path for you!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#here-readr-reading-csv-files",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#here-readr-reading-csv-files",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "here + readr: Reading CSV files",
    "text": "here + readr: Reading CSV files\nTo load a CSV file:\n\nlibrary(tidyverse)  # includes readr package\nlibrary(here)\n\n# Read CSV file from data folder\nbody_temps &lt;- read_csv(here(\"data\", \"BodyTemperatures.csv\"))\n\n\n\nWhat‚Äôs happening:\n\nhere(\"data\", \"BodyTemperatures.csv\") creates the full path\nread_csv() reads the CSV file into R\nData is stored in body_temps object"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#here-readxl-reading-excel-files",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#here-readxl-reading-excel-files",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "here + readxl: Reading Excel files",
    "text": "here + readxl: Reading Excel files\nTo load an Excel file:\n\nlibrary(readxl)\nlibrary(here)\n\n# Read Excel file from data folder\nbody_temps &lt;- read_excel(here(\"data\", \"BodyTemperatures.xlsx\"))\n\n\n\nNote: readxl is not part of the tidyverse, so install separately:\n\ninstall.packages(\"readxl\")"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#common-data-reading-functions",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#common-data-reading-functions",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Common data reading functions",
    "text": "Common data reading functions\n\n\n\n\n\n\n\n\n\nFunction\nFile type\nPackage\nNotes\n\n\n\n\nread_csv()\n.csv\nreadr (tidyverse)\nRecommended for CSV files\n\n\nread_excel()\n.xlsx, .xls\nreadxl\nFor Excel files\n\n\nread.csv()\n.csv\nbase R\nOlder base R function\n\n\nread_delim()\ntab, other delimiters\nreadr\nFor other delimited files\n\n\nread_sas()\n.sas7bdat\nhaven\nFor SAS files\n\n\n\n\n\nFor this class: You‚Äôll mostly use read_csv() and occasionally read_excel()"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#putting-it-all-together",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#putting-it-all-together",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Putting it all together",
    "text": "Putting it all together\nComplete workflow for loading data:\n\n# 1. Load packages\nlibrary(tidyverse)  # includes read_csv()\nlibrary(here)\n\n# 2. Load data using here\nbody_temps &lt;- read_csv(here(\"data\", \"BodyTemperatures.csv\"))\n\n# 3. Check the data\nglimpse(body_temps)\n\n\n\nThis code will work:\n\nOn any computer\nAfter moving your project folder\nFor your collaborators\nYears from now"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#key-resources",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#key-resources",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Key resources",
    "text": "Key resources\nR Projects:\n\nRStudio Projects and Working Directories: A Beginner‚Äôs Guide\nUsing RStudio Projects\nVideo: The Basics of Projects in RStudio\n\n\n\nhere package:\n\nhere package\nOde to the here package (Jenny Bryan)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#best-practices-summary",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#best-practices-summary",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Best practices summary",
    "text": "Best practices summary\n\n\n\nAlways do these three things\n\n\n\nUse R Projects for every analysis\nUse here() for all file paths\nOrganize your files in a clear folder structure\n\n\n\n\n\n\nThis makes your code:\n\nReproducible\nPortable\nShareable\nFuture-proof\n\n\n\nYour future self (and collaborators) will thank you!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#practice-load-the-body-temperature-data",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#practice-load-the-body-temperature-data",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Practice: Load the body temperature data",
    "text": "Practice: Load the body temperature data\nYour task:\n\nMake sure your R Project is open\nDownload BodyTemperatures.csv from OneDrive\nSave it in your data folder\nCreate a new .qmd file\nLoad the data using here()\n\n\n\nCode to try:\n\nlibrary(tidyverse)\nlibrary(here)\n\nbody_temps &lt;- read_csv(here(\"data\", \"BodyTemperatures.csv\"))\nglimpse(body_temps)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#questions",
    "href": "lessons/12_hypothesis_testing/12_r_workflow_slides.html#questions",
    "title": "R Workflow: Projects, File Paths, and Reading Data",
    "section": "Questions?",
    "text": "Questions?\nWe‚Äôll use this workflow throughout the course!\n\n\nComing up: We‚Äôll use this body temperature dataset for hypothesis testing examples.\n\n\n\n\nArtwork by @allison_horst\n\nBMSC 620 | R Workflow"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html",
    "title": "Response to Muddy Points",
    "section": "",
    "text": "Code chunk options: You‚Äôre right to notice this - in the homework file I distributed, the global chunk options were set to eval = FALSE. For your own work, you should change this to eval = TRUE so that your code runs and produces output in the rendered HTML. I‚Äôll make sure this is set correctly in future homework files. Thanks for catching this."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#administrative-note",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#administrative-note",
    "title": "Response to Muddy Points",
    "section": "",
    "text": "Code chunk options: You‚Äôre right to notice this - in the homework file I distributed, the global chunk options were set to eval = FALSE. For your own work, you should change this to eval = TRUE so that your code runs and produces output in the rendered HTML. I‚Äôll make sure this is set correctly in future homework files. Thanks for catching this."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#conceptual-clarifications",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#conceptual-clarifications",
    "title": "Response to Muddy Points",
    "section": "Conceptual Clarifications",
    "text": "Conceptual Clarifications\n\nAlternative vs ‚ÄúTrue‚Äù Hypothesis\nThe alternative hypothesis (\\(H_0\\) or \\(H_A\\)) is what we specify before collecting data. It‚Äôs our research hypothesis stating what we think might be true. There isn‚Äôt really a separate ‚Äútrue hypothesis‚Äù in the formal testing framework. In reality, either the null hypothesis is true or it isn‚Äôt, but we never observe that directly. We use our data to decide whether we have enough evidence to reject \\(H_0\\) in favor of \\(H_A\\).\n\n\nOne-Sample vs Two-Sample t-tests\n‚ÄúIs a one-variable t-test comparing a sample mean?‚Äù - Yes! A one-sample t-test compares one sample mean to a hypothesized population value (often \\(\\mu_0 = 0\\)). It‚Äôs ‚Äúone variable‚Äù because you have one group of measurements.\n‚ÄúAre t-tests always comparing a mean to a mean?‚Äù - Almost, but not quite:\n\nOne-sample t-test: Compares a sample mean to a fixed value (like \\(\\mu = 0\\))\nTwo-sample t-test: Compares two sample means to each other (we‚Äôll cover this next week)\n\n\n\nOne-Sided vs Two-Sided Tests\nWhen to use one-sided: You need a strong scientific reason established before seeing your data. Examples where one-sided might be justified:\n\nTesting whether a new drug lowers blood pressure (can‚Äôt raise it by mechanism)\nTesting whether an educational intervention improves test scores (ethically, we wouldn‚Äôt use an intervention we think makes things worse)\nTesting whether a treatment is non-inferior to standard care\n\nDefault should be two-sided because:\n\nWe‚Äôre usually genuinely unsure which direction an effect might go\nTwo-sided tests are more conservative\nJournal reviewers/regulatory agencies often require two-sided tests\n\nIf you‚Äôre asking yourself ‚Äúshould I use one-sided?‚Äù, the answer is probably no.\n\n\nP-values and Confidence Intervals\n‚ÄúIs \\(p \\gt \\alpha\\) inside the CI or not?‚Äù - Let me clarify this relationship:\n\nIf \\(p \\lt \\alpha\\): The null hypothesis value (like \\(\\mu = 0\\) is outside the confidence interval ‚Üí we reject H‚ÇÄ\nIf \\(p \\ge \\alpha\\): The null hypothesis value is inside the confidence interval ‚Üí we fail to reject \\(H_0\\)\n\nSo \\(p \\ge \\alpha\\) means the hypothesized value IS inside the CI (not outside). This relationship holds when the confidence level matches \\(\\alpha\\) (e.g., a 95% CI and \\(\\alpha = 0.05\\))\n\n\n‚ÄúLow p-value was worse‚Äù\n\nSome of you may be thinking of situations where a ‚Äúlow score is bad‚Äù (e.g., exam scores, health indices). A p-value isn‚Äôt a score in that sense.\nA low p-value means the observed data would be unlikely if the null hypothesis were true. That‚Äôs all it measures. Not goodness, quality, or success.\n\n\nStatistical vs Practical Significance\n‚ÄúHow you can tell if p is actually relevant to real world data‚Äù - Great question! This is the difference between statistical and practical significance:\n\nStatistical significance (\\(p \\lt 0.05\\)): We have evidence of a difference\nPractical significance: The difference is large enough to matter\n\nExample: In a study of 10,000 people, we might find that a drug lowers blood pressure by 0.5 mmHg (\\(p = 0.001\\)). This is statistically significant but clinically meaningless. That small a change doesn‚Äôt affect patient outcomes.\nAlways interpret results in context: What is the effect size? Does the confidence interval include clinically important values?"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#practical-questions",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#practical-questions",
    "title": "Response to Muddy Points",
    "section": "Practical Questions",
    "text": "Practical Questions\n\nRandom Sampling in Clinical Trials\n‚ÄúDoes random sampling correspond to treatment group assignment or enrollment?‚Äù\nThese are two different types of randomization:\n\nRandom sampling refers to how we select participants from the population\nRandom assignment refers to how we assign participants to treatment groups\n\nIn clinical trials:\n\nEnrollment is usually not random (we recruit volunteers who meet criteria)\nTreatment assignment is randomized (patients randomly assigned to treatment vs control)\n\nThis is why clinical trials can establish causation (through random assignment) but may have limited generalizability (because enrollment isn‚Äôt a random sample of the population).\n\n\nDegrees of Freedom\n‚ÄúWhy is it n-1?‚Äù - Here‚Äôs the intuition: If you know the sample mean and \\(n-1\\) of the data points, the last data point is determined. It‚Äôs no longer ‚Äúfree‚Äù to vary.\nExample: If mean = 5 from 3 numbers, and you know two are 4 and 5, the third must be 6.\nThe \\(n-1\\) degrees of freedom accounts for this loss of freedom when we estimate the mean from the data. You‚Äôre right that you don‚Äôt need to fully understand this to use it correctly. Just know that df = \\(n-1\\) for one-sample tests.\n\n\nWorking Across Multiple Computers\n‚ÄúI work on laptop at work and desktop at home - does this create problems?‚Äù\nThis is exactly why R Projects and the here package are so valuable! As long as you:\n\nStore your project folder in Dropbox/OneDrive\nOpen the .Rproj file on each computer\nUse here() for file paths\n\n‚Ä¶everything will work seamlessly. The here() function builds paths relative to your project root, so it doesn‚Äôt matter what your username is or whether you‚Äôre on Mac/PC. Your file structure within the project stays the same.\nJust make sure cloud sync completes before switching computers!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#r-project-setup",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing_and_r_worflow_muddy_points.html#r-project-setup",
    "title": "Response to Muddy Points",
    "section": "R Project Setup",
    "text": "R Project Setup\nSeveral of you mentioned finding the R project and here() discussion helpful. Going forward, all homework and activities should be organized within R projects using relative paths. This will save you headaches and make your work more reproducible.\n\nWe‚Äôll revisit several of these ideas as we move forward, especially when we look at two-sample tests and confidence intervals in more detail."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#todays-plan",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#todays-plan",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Today‚Äôs plan",
    "text": "Today‚Äôs plan\n\nSummarizing categorical data (tables + bar plots)\nR basics: writing and running code in Quarto"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#summarizing-categorical-data",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#summarizing-categorical-data",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Summarizing categorical data",
    "text": "Summarizing categorical data\n\nLast week we looked at:\n\nVariable types\nSummarizing numerical variables\n\nToday, we focus on summarizing and describing categorical variables."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#what-do-we-mean-by-categorical",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#what-do-we-mean-by-categorical",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "What do we mean by categorical?",
    "text": "What do we mean by categorical?\n\nValues are labels or categories\nCounts and proportions matter more than averages\nExamples from biomedicine:\n\nTreatment group\nDiagnosis\nSex\nResponse category (e.g., improved / unchanged / worsened)\n\n\n\n\n\nNominal ‚Äì labels, no order\nOrdinal ‚Äì labels, with order"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#example-dataset-famuss",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#example-dataset-famuss",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Example dataset: FAMuSS",
    "text": "Example dataset: FAMuSS\nFunctional SNPs Associated with Muscle Size and Strength (FAMuSS)\n\nStudy goal: examine how demographic, physiological, and genetic factors are associated with muscle strength\nStrength measured in:\n\nDominant arm\nNon-dominant arm\nBefore and after resistance training\n\nKey gene of interest:\n\nACTN3 (‚Äúthe sports gene‚Äù)\n\nData frame with 595 participants\n\nVariables we will focus on today:\n\nsex (Female, Male)\nrace (African Am, Asian, Caucasian, Hispanic, Other)\nactn3.r577x (CC, CT, TT genotype)\n\n(We will use other variables later in the course.)"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#one-categorical-variable-section-1.5",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#one-categorical-variable-section-1.5",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "One categorical variable (Section 1.5)",
    "text": "One categorical variable (Section 1.5)\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#frequency-tables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#frequency-tables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Frequency tables",
    "text": "Frequency tables\n\nA frequency table shows the count in each category\nOften the first summary we compute for categorical data\n\n\n\n\nQuestions it helps answer:\n\nHow many observations are in each category?\nAre some categories rare?"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#relative-frequency-tables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#relative-frequency-tables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Relative frequency tables",
    "text": "Relative frequency tables\n\nA relative frequency table shows proportions instead of counts\nProportions often make comparisons easier\nEspecially useful when:\n\nGroup sizes differ\nWe want to compare across studies or samples"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#famuss-example",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#famuss-example",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "FAMuSS example",
    "text": "FAMuSS example\n\n\n\n\nCounts\n\n\n\n\n\n\n\n\n\nactn3.r577x\nn\n\n\n\n\nCC\n173\n\n\nCT\n261\n\n\nTT\n161\n\n\nTotal\n595\n\n\n\n\n\n\n\n\n\nProportions\n\n\n\n\n\n\n\n\n\nactn3.r577x\nn\npercent\n\n\n\n\nCC\n173\n29.1%\n\n\nCT\n261\n43.9%\n\n\nTT\n161\n27.1%\n\n\nTotal\n595\n100.0%"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-for-categorical-data",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-for-categorical-data",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Bar plots for categorical data",
    "text": "Bar plots for categorical data\n\nBar plots visualize counts or proportions\nEach bar represents a category\nBar height reflects frequency or proportion\n\nBar plots are used for categorical data\nHistograms are used for numerical data"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-categorical-variable-bar-plots",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-categorical-variable-bar-plots",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Visualizing a categorical variable: bar plots",
    "text": "Visualizing a categorical variable: bar plots\n\n\nHeight = count or proportion\n\n\nCounts\n\n\n\n\n\n\n\n\n\n\nProportions"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#two-categorical-variables-section-1.6.2",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#two-categorical-variables-section-1.6.2",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Two categorical variables (Section 1.6.2)",
    "text": "Two categorical variables (Section 1.6.2)\n\nSo far, we have summarized one categorical variable at a time\n\nCounts\nProportions\nBar plots\n\nOften, we want to understand the relationship between two categorical variables\n\n\n\n\nExamples:\n\nGenotype and sex\nTreatment group and response\nExposure and disease status"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#contingency-tables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#contingency-tables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Contingency tables",
    "text": "Contingency tables\n\nWhen we have two categorical variables, we summarize them with a contingency table (also called a two-way table)\n\n\n\n\nEach cell shows the count for a combination of categories\n\n\n\n\nRows represent one variable\n\nColumns represent the other variable"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#contingency-table-example-counts",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#contingency-table-example-counts",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Contingency table example (counts)",
    "text": "Contingency table example (counts)\n\nExample question:\n\nDoes the distribution of genotypes differ by sex?\n\n\n\n\n\nThese are counts, not proportions\nTotals appear along the margins\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n106\n149\n98\n353\n\n\nMale\n67\n112\n63\n242\n\n\nTotal\n173\n261\n161\n595"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#marginal-totals-vs-conditional-distributions",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#marginal-totals-vs-conditional-distributions",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Marginal totals vs conditional distributions",
    "text": "Marginal totals vs conditional distributions\n\n\n\nMarginal totals\n\nSummarize one variable at a time\nIgnore the other variable\nFound in the row totals or column totals\n\n\n\n\n\nConditional distributions\n\nDescribe one variable within levels of the other\nRequire computing proportions\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n106\n149\n98\n353\n\n\nMale\n67\n112\n63\n242\n\n\nTotal\n173\n261\n161\n595"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#row-proportions-vs-column-proportions-12",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#row-proportions-vs-column-proportions-12",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Row proportions vs column proportions (1/2)",
    "text": "Row proportions vs column proportions (1/2)\n\nWhich one you use depends on the question\nRow proportions\n\nCondition on the row variable\nEach row sums to 1 (or 100%)\n\nExample question: Among females, what proportion have genotype CC?\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n106\n149\n98\n353\n\n\nMale\n67\n112\n63\n242\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n0.30\n0.42\n0.28\n1.00\n\n\nMale\n0.28\n0.46\n0.26\n1.00"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#row-proportions-vs-column-proportions-22",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#row-proportions-vs-column-proportions-22",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Row proportions vs column proportions (2/2)",
    "text": "Row proportions vs column proportions (2/2)\n\nColumn proportions\n\nCondition on the column variable\nEach column sums to 1 (or 100%)\n\nExample question: Among those with genotype CC, what proportion are female?\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\n\n\n\n\nFemale\n106\n149\n98\n\n\nMale\n67\n112\n63\n\n\nTotal\n173\n261\n161\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\n\n\n\n\nFemale\n0.61\n0.57\n0.61\n\n\nMale\n0.39\n0.43\n0.39\n\n\nTotal\n1.00\n1.00\n1.00"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#interpreting-contingency-tables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#interpreting-contingency-tables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Interpreting contingency tables",
    "text": "Interpreting contingency tables\n\nAlways ask:\n\nWhat are the rows?\nWhat are the columns?\nWhat is being held fixed?\n\n\n\n\n\nInterpretation depends on:\n\nThe research question\nWhich variable you condition on"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#common-interpretation-pitfalls",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#common-interpretation-pitfalls",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Common interpretation pitfalls",
    "text": "Common interpretation pitfalls\n\nConfusing marginal totals with conditional distributions\n\nMarginal totals describe the sample overall\nConditional distributions describe relationships (what happens within groups)\n\nComparing counts when group sizes differ\nForgetting which variable is being conditioned on"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-two-categorical-variables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-two-categorical-variables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Visualizing two categorical variables",
    "text": "Visualizing two categorical variables\n\nContingency tables show the numbers\nPlots help reveal patterns"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-example-sex-by-genotype",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-example-sex-by-genotype",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Bar plots example: Sex by genotype",
    "text": "Bar plots example: Sex by genotype\n\n\n\n\nGrouped bar plot\n\n\n\n\n\n\n\n\n\n\nStacked bar plot\n\n\n\n\n\n\n\n\n\n\nPercent stacked bar plot"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-example-genotype-by-sex",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#bar-plots-example-genotype-by-sex",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Bar plots example: Genotype by sex",
    "text": "Bar plots example: Genotype by sex\n\n\n\n\nGrouped bar plot\n\n\n\n\n\n\n\n\n\n\nStacked bar plot\n\n\n\n\n\n\n\n\n\n\nPercent stacked bar plot"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#special-case-two-by-two-tables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#special-case-two-by-two-tables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Special case: two-by-two tables",
    "text": "Special case: two-by-two tables\n\nA two-by-two table is a contingency table with:\n\nTwo levels of one variable\nTwo levels of another variable\n\n\n\n\n\nVery common in biomedical research:\n\nExposure (Yes / No) √ó Outcome (Yes / No)\nTreatment (Drug / Control) √ó Response (Improved / Not improved)\nTest result (Positive / Negative) √ó Disease status (Present / Absent)\n\n\n\n\n\nToday:\n\nFocus on structure and interpretation\n\nLater:\n\nRisk, odds, probability, and inference"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#a-quick-note-on-numeric-variables",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#a-quick-note-on-numeric-variables",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "A quick note on numeric variables",
    "text": "A quick note on numeric variables\nLast week, we summarized numeric variables using:\n\nmean and standard deviation\nmedian and IQR\n\n\n\nWe can also summarize numeric variables visually, just like we did for categorical data."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-numeric-variable-histogram",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-numeric-variable-histogram",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Visualizing a numeric variable: histogram",
    "text": "Visualizing a numeric variable: histogram\n\nHistograms show the distribution of a numeric variable\nUseful for seeing:\n\nshape (symmetric vs skewed)\noutliers\nclusters"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-numeric-variable-box-plot",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#visualizing-a-numeric-variable-box-plot",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Visualizing a numeric variable: box plot",
    "text": "Visualizing a numeric variable: box plot\n\nBox plots summarize a numeric variable using:\n\nmedian\nIQR\npotential outliers\n\n\n\n\n\n\nBox plot\n\n\n\n\n\n\n\n\n\n\nBox plot by groups"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#box-plot-legend",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#box-plot-legend",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Box plot legend",
    "text": "Box plot legend"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#wrap-up",
    "href": "lessons/04_categorical_data_and_tables/04_categorical_data_and_tables.html#wrap-up",
    "title": "Summarizing Categorical Data: Tables and Plots",
    "section": "Wrap-up",
    "text": "Wrap-up\nToday you learned how to:\n\nSummarize categorical variables (counts + proportions)\nCompare two categorical variables (contingency tables)\nInterpret row vs column percentages\nUse bar plots, histograms, and box plots as quick visual summaries\n\n\n\n\nBMSC 620 | Summarizing Categorical Data"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#learning-objectives-today",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#learning-objectives-today",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Learning objectives (today)",
    "text": "Learning objectives (today)\nBy the end of class, you should be able to:\n\nIdentify observations and variables in a dataset\nDistinguish numerical and categorical variables (discrete/continuous; nominal/ordinal)\nDescribe the center of numerical data using the mean and median\nDescribe the spread of numerical data using the SD and IQR\nExplain why skewness and outliers affect some summaries more than others"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#intro-to-data-1.2",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#intro-to-data-1.2",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Intro to Data (1.2)",
    "text": "Intro to Data (1.2)\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#a-motivating-example-frog-reproduction-data1",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#a-motivating-example-frog-reproduction-data1",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "A motivating example: frog reproduction data1",
    "text": "A motivating example: frog reproduction data1\nTo make ideas about data more concrete, we will work with a dataset from an evolutionary biology study on frog reproduction.\nFemale frogs invest energy into reproduction by producing eggs. Because energy is limited, there are natural trade-offs:\n\nproducing many small eggs versus\nproducing fewer larger eggs\n\nResearchers collected data from frog egg clutches found at breeding ponds across multiple locations that differed in altitude.\nThe goal was to understand how reproductive investment varies across environments.\nDataset adapted from an example in Introductory Statistics for the Life and Biomedical Sciences."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-data-12",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-data-12",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "The frog study data (1/2)",
    "text": "The frog study data (1/2)\n\n\n\nrow\naltitude\negg.size\nclutch.size\nclutch.volume\nbody.size\n\n\n\n\n1\n3,462.00\n1.95\n181.97\n177.83\n3.63\n\n\n2\n3,462.00\n1.95\n269.15\n257.04\n3.63\n\n\n3\n3,462.00\n1.95\n158.49\n151.36\n3.72\n\n\n150\n2,597.00\n2.24\n537.03\n776.25\nNA"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-data-22",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-data-22",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "The frog study data (2/2)",
    "text": "The frog study data (2/2)\n\n\n\nrow\naltitude\negg.size\nclutch.size\nclutch.volume\nbody.size\n\n\n\n\n1\n3,462.00\n1.95\n181.97\n177.83\n3.63\n\n\n2\n3,462.00\n1.95\n269.15\n257.04\n3.63\n\n\n3\n3,462.00\n1.95\n158.49\n151.36\n3.72\n\n\n150\n2,597.00\n2.24\n537.03\n776.25\nNA\n\n\n\n\n\n\nEach observation is a row.\nEach variable is a column.\nEach cell contains a single value.\nAll the observations and variables together make a data frame. The textbook will sometimes call it a data matrix.\n\n¬†\n\nMissing values: NA here means ‚Äúmissing‚Äù. The clutch #150 is missing body.size."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-variables-and-descriptions",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#the-frog-study-variables-and-descriptions",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "The frog study variables and descriptions",
    "text": "The frog study variables and descriptions\n\n\n\n\n\nvariable\ndescription\n\n\n\n\naltitude\nAltitude of the study site (meters above sea level)\n\n\nlatitude\nLatitude of the study site (degrees)\n\n\negg.size\nAverage diameter of an individual egg (mm)\n\n\nclutch.size\nEstimated number of eggs in a clutch\n\n\nclutch.volume\nTotal volume of the egg clutch (mm^3)\n\n\nbody.size\nBody length of the egg-laying female frog (cm)"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#types-of-variables",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#types-of-variables",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Types of variables",
    "text": "Types of variables\n\nISLBS"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#numerical-variables",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#numerical-variables",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Numerical variables",
    "text": "Numerical variables\nNumerical variables take on values for which mathematical operations (addition, subtraction, averaging) are meaningful.\n\n\nThere are two common types:\n\n\nDiscrete\n\nTake on separate, countable values\nUsually whole numbers\nArise from counting\n\nExamples:\n\nNumber of eggs in a clutch\nNumber of clinic visits\nNumber of children in a family\n\n\nContinuous\n\nCan take on any value within a range\nOften measured rather than counted\nDecimals are possible\n\nExamples:\n\nEgg size (mm)\nHeight or weight\nBlood pressure"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#categorical-variables",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#categorical-variables",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Categorical variables",
    "text": "Categorical variables\nCategorical variables describe qualities or group membership rather than numerical magnitude. The values are called levels.\n\n\n\n\nNominal\n\nCategories have no natural ordering\nDifferences are labels, not amounts\n\nExamples:\n\nSpecies\nBlood type\nGender identity\n\n\nOrdinal\n\nCategories have a meaningful order\nThe spacing between categories is not necessarily equal\n\nExamples:\n\nDisease severity (mild, moderate, severe)\nLikert-scale responses (strongly disagree -&gt; strongly agree)\nEducation level"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#how-are-data-stored-how-do-we-use-them",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#how-are-data-stored-how-do-we-use-them",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "How are data stored, how do we use them?",
    "text": "How are data stored, how do we use them?\n\nOften, data are in an Excel sheet, or a plain text file (.csv, .txt)\n.csv files open in Excel automatically, but actually are plain text\nUsually, columns are variables/measures and rows are observations (i.e.¬†a person‚Äôs measurements)\n\nData in R\n\nWe can import data from many file types, including .csv, .txt., and .xlsx\n\nWe will cover this on a later date\n\nOnce imported, R typically stores data as data frames, or tibbles if using the tidyverse package (more on this later).\n\nFor our purposes, these are essentially the same, and I will tend to use the terms interchangeably.\nThese are examples of what we call object types in R."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#which-type-is-each-frog-variable",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#which-type-is-each-frog-variable",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Which type is each frog variable?",
    "text": "Which type is each frog variable?\n\n\n\n\n\n\n\n\n\n\nvariable\ndescription\ntype\n\n\n\n\naltitude\nAltitude of the study site (meters above sea level)\nNumerical (continuous)\n\n\nlatitude\nLatitude of the study site (degrees)\nNumerical (continuous)\n\n\negg.size\nAverage diameter of an individual egg (mm)\nNumerical (continuous)\n\n\nclutch.size\nEstimated number of eggs in a clutch\nNumerical (discrete)\n\n\nclutch.volume\nTotal volume of the egg clutch (mm^3)\nNumerical (continuous)\n\n\nbody.size\nBody length of the egg-laying female frog (cm)\nNumerical (continuous)"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#how-variable-types-appear-in-r-preview",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#how-variable-types-appear-in-r-preview",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "How variable types appear in R (preview)",
    "text": "How variable types appear in R (preview)\nWe are not using R in depth yet.\nThis slide is here to help you later connect:\n\nthe variable types we talk about conceptually, and\nhow R stores those variables internally.\n\nYou do not need to memorize this now.\n\n\n\n\n\n\n\n\nR type\nVariable type\nWhat it represents\n\n\n\n\ninteger\nNumerical (discrete)\nWhole-number counts\n\n\ndouble / numeric\nNumerical (continuous)\nMeasured values with decimals\n\n\nfactor\nCategorical\nCategories stored with defined levels\n\n\ncharacter\nCategorical\nText labels\n\n\nlogical\nCategorical\nTRUE / FALSE values"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#summarizing-numerical-data-1.4",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#summarizing-numerical-data-1.4",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Summarizing numerical data (1.4)",
    "text": "Summarizing numerical data (1.4)\nOnce data have been collected, a first step is to describe what we see.\n\n\nFor numerical variables, we often want to understand:\n\nwhat values are typical, and\nhow much the values vary across observations.\n\n\n\nNumerical summaries help us:\n\nquickly describe large datasets,\ncompare groups,\nand communicate patterns clearly.\n\nIn this section, we focus on summaries for numerical variables. We will return to categorical variables later."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#two-questions-we-often-ask",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#two-questions-we-often-ask",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Two questions we often ask",
    "text": "Two questions we often ask\nFor a numerical variable, two questions come up repeatedly:\n\nWhere are the values centered?\n\nWhat is a ‚Äútypical‚Äù value?\n\nHow spread out are the values?\n\nAre observations tightly clustered or widely dispersed?\n\n\nThe summaries we introduce next are designed to answer these two questions.\n\n\n\nNote\n\n\nSome examples will show R output as a reference. You do not need to understand the R code yet ‚Äî focus on the ideas."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-center-the-mean",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-center-the-mean",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of center: the mean",
    "text": "Measures of center: the mean\nThe mean (or average) describes the center of a numerical variable.\nIt is calculated by:\n\nadding all observed values, and\ndividing by the number of observations.\n\n\\[\n\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n} = \\sum_{i=1}^{n} \\frac{x_i}{n}\n\\]\nwhere:\n\n\\(x_1, x_2, \\ldots, x_n\\) are the observed values, and\n\\(n\\) is the number of observations.\n\nThe mean uses all observed values and is sensitive to unusually large or small values. All data values contribute equally, even ‚Äúoutliers.‚Äù"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#example-mean-clutch-volume",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#example-mean-clutch-volume",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Example: mean clutch volume",
    "text": "Example: mean clutch volume\nUsing the frog data, we can ask:\nWhat is a typical clutch volume?\n\n\nFor this dataset:\n\neach observation is one egg clutch\nclutch volume is measured in mm\\(^3\\)\n\n\\[\n\\bar{x} = \\frac{177.8 + 257.0 + \\cdots + 933.3}{431} = \\frac{380346.3}{431} \\approx 882.5\n\\]\n\nmean(frog$clutch.volume, na.rm = TRUE)\n\n[1] 882.474\n\n\nThe mean clutch volume is 882.5 mm\\(^3\\).\n\n\n\nThe mean tells us where the data balance, but it doesn‚Äôt tell us how spread out they are."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#things-to-note",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#things-to-note",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Things to note",
    "text": "Things to note\n\n\n\nThe mean of a binary variable with 0/1 coding gives the proportion (relative frequency) of ones in the sample.\nThe mean can be heavily influenced by ‚Äúoutliers.‚Äù\n\n\\({2, 7, 9} \\rightarrow \\bar{x} = \\frac{2 + 7 + 9}{3} = 6\\)\n\\({2, 7, 29} \\rightarrow \\bar{x} = \\frac{2 + 7 + 29}{3} \\approx 12.7\\)"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#distributions-of-frog-variables",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#distributions-of-frog-variables",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Distributions of frog variables",
    "text": "Distributions of frog variables"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-center-the-median",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-center-the-median",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of center: the median",
    "text": "Measures of center: the median\nThe median describes the center of a numerical variable based on order, not magnitude.\n\nThe median is the middle value once observations are ordered from smallest to largest.\nHalf of the observations lie below the median\nHalf of the observations lie above the median\n\nIf there are:\n\nan odd number of observations, the median is the middle value\nan even number of observations, the median is the average of the two middle values\n\nUnlike the mean, the median is not affected by extreme values."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#example-mean-vs.-median",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#example-mean-vs.-median",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Example: mean vs.¬†median",
    "text": "Example: mean vs.¬†median\nConsider these two datasets:\n\n\\(2, 7, 9\\)\n\nMean = 6\n\nMedian = 7\n\n\\(2, 7, 29\\)\n\nMean = 12.7\n\nMedian = 7\n\n\nOnly one value changed, but the mean changed a lot. The median did not."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#distributions-of-frog-variables-1",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#distributions-of-frog-variables-1",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Distributions of frog variables",
    "text": "Distributions of frog variables\n\n\nWhen distributions are skewed, the mean is pulled toward the tail.\nThe median stays closer to where most observations lie."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#a-note-on-the-mode",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#a-note-on-the-mode",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "A note on the mode",
    "text": "A note on the mode\nThe mode is the most frequent value in a dataset.\n\nFor numerical data, the mode is often unstable or uninformative\nIt depends on how values are measured or grouped\nAs a result, it is rarely reported for continuous variables\n\nThe mode is more useful for categorical data, which we will revisit later."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-standard-deviation-sd-13",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-standard-deviation-sd-13",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: standard deviation (SD) (1/3)",
    "text": "Measures of spread: standard deviation (SD) (1/3)\nstandard deviation is (approximately) the average distance between an observation and the mean\n\nAn observation‚Äôs deviation is the distance between its value \\(x\\) and the sample mean \\(\\bar{x}\\): deviation = \\(x - \\bar{x}\\)."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-sd-23",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-sd-23",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: SD (2/3)",
    "text": "Measures of spread: SD (2/3)\n\nThe sample variance \\(s^2\\) is the sum of squared deviations divided by the number of observations minus 1.\n\n\\[\ns^2 =\n\\frac{(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 + \\cdots + (x_n - \\bar{x})^2}{n - 1}\n=\n\\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})^2}{n - 1}\n\\] where \\(x_1, x_2, \\dots, x_n\\) represent the \\(n\\) observed values.\n¬†\n\nThe standard deviation \\(s\\) (or \\(sd\\)) is the square root of the variance.\n\n\\[\ns\n= \\sqrt{s^2}\n= \\sqrt{\\frac{1}{n - 1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\]"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-sd-33",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-sd-33",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: SD (3/3)",
    "text": "Measures of spread: SD (3/3)\nLet‚Äôs calculate the sample standard deviation for the clutch.volume from the frog dataset.\n\nDoing this by hand can be really time consuming!\nR does this easily for us.\n\n\nsd(frog$clutch.volume, na.rm = TRUE)\n\n[1] 379.0527\n\n\nSo the standard deviation is 379.1 mm\\(^3\\).\n\n\nFor the sample of 431 frog clutches, the mean clutch volume was 882.5 mm\\(^3\\) (SD = 379.1 mm\\(^3\\))."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#empirical-rule-one-way-to-think-about-the-sd",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#empirical-rule-one-way-to-think-about-the-sd",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Empirical Rule: one way to think about the SD",
    "text": "Empirical Rule: one way to think about the SD\n\n\n\nFor symmetric bell-shaped data, about\n\n68% of the data are within 1 SD of the mean\n95% of the data are within 2 SD‚Äôs of the mean\n99.7% of the data are within 3 SD‚Äôs of the mean\n\nThese percentages are based off of percentages of a true normal distribution.\n\n\n\n\nhttps://statistics-made-easy.com/empirical-rule/"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-interquartile-range-iqr-12",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-interquartile-range-iqr-12",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: interquartile range (IQR) (1/2)",
    "text": "Measures of spread: interquartile range (IQR) (1/2)\nThe \\(p^{th}\\) percentile is the observation such that \\(p\\%\\) of the remaining observations fall below this observation.\n\nThe first quartile \\(Q_1\\) is the \\(25^{th}\\) percentile.\nThe second quartile \\(Q_2\\), i.e., the median, is the \\(50^{th}\\) percentile.\nThe third quartile \\(Q_3\\) is the \\(75^{th}\\) percentile.\n\nThe interquartile range (IQR) is the distance between the third and first quartiles. \\[IQR = Q_3 - Q_1\\]\n\nIQR focuses on the middle 50% of the data.\nRobust against outliers."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-interquartile-range-iqr-22",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-interquartile-range-iqr-22",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: interquartile range (IQR) (2/2)",
    "text": "Measures of spread: interquartile range (IQR) (2/2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(frog$clutch.volume)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  151.4   609.6   831.8   882.5  1096.5  2630.3 \n\n\n\\[IQR = Q_3 - Q_1 = 1096.5 - 609.6 = 486.9\\]\n\n\n\nIQR(frog$clutch.volume)\n\n[1] 486.9009"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-range",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#measures-of-spread-range",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Measures of spread: range",
    "text": "Measures of spread: range\nThe range describes spread using only the smallest and largest values.\n\\[\n\\text{Range} = \\max(x) - \\min(x)\n\\]\n\nEasy to compute and easy to interpret\nNot robust: it depends only on two observations\nA single unusually large or small value can dramatically change the range\n\n\n\n\nNote\n\n\nBecause it is so sensitive to extreme values, the range is usually less informative than the SD or IQR."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#range-and-outliers-example",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#range-and-outliers-example",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Range and outliers (example)",
    "text": "Range and outliers (example)\n\n\\(2, 7, 9\\)\n\n\\(min = 2, max = 9\\)\n\\(Range = 9 - 2 = 7\\)\n\n\\(2, 7, 29\\)\n\n\\(min = 2, max = 29\\)\n\\(Range = 29 - 2 = 27\\)\n\n\nOnly one value changed, but the range changed a lot."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#robust-estimates",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont.html#robust-estimates",
    "title": "Introduction to Data & Numerical Summaries (continued)",
    "section": "Robust estimates",
    "text": "Robust estimates\nSummary statistics are called robust estimates if extreme observations (outliers) have little effect on their values\n\n\n\nEstimate\nRobust?\n\n\n\n\nSample mean\n‚ùå\n\n\nMedian\n‚úÖ\n\n\nStandard deviation\n‚ùå\n\n\nIQR\n‚úÖ\n\n\nRange\n‚ùå\n\n\n\n\nFor samples with extreme values or skewed distributions, the median and IQR often provide a more stable summary of center and spread than the mean, standard deviation, or range.\n\n\n\n\nBMSC 620 | Intro to Data & Numerical Summaries (continued)"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#coding-in-r",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#coding-in-r",
    "title": "R basics and data summaries",
    "section": "Coding in R",
    "text": "Coding in R\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#we-have-options-where-to-code-in-r",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#we-have-options-where-to-code-in-r",
    "title": "R basics and data summaries",
    "section": "We have options where to code in R",
    "text": "We have options where to code in R\nConsole\n\nFor quick experiments\nTemporary (not saved)\n\nR scripts (.R files)\n\nOften used for data cleaning, functions, or prep\nCommon in real analysis workflows\nCode only\n\nCode chunks in a .qmd file\n\nUsed for analysis and reporting\nCombine code and written explanation\nSaved and reproducible\n\nRunning code\n\nRun the current line or selection with Cmd/Ctrl + Enter"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#coding-along-optional",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#coding-along-optional",
    "title": "R basics and data summaries",
    "section": "Coding along (optional)",
    "text": "Coding along (optional)\nIf you want to follow along during class:\n\nOpen a new Quarto document (.qmd)\nThis is how homework and exams will be completed\n\nInsert a code chunk:\n\nMac: Cmd + Option + I\nWindows: Ctrl + Alt + I\n\nYou can run code with Cmd/Ctrl + Enter."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-as-a-calculator",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-as-a-calculator",
    "title": "R basics and data summaries",
    "section": "R as a calculator",
    "text": "R as a calculator\n\nRules for order of operations are followed\nSpaces between numbers and characters are ignored\n\n\n\n\n\n\n10^2\n\n[1] 100\n\n3 ^ 7\n\n[1] 2187\n\n6/9\n\n[1] 0.6666667\n\n9-43\n\n[1] -34\n\n\n\n\n4^3-2* 7+9 /2\n\n[1] 54.5\n\n\nThe equation above is computed as \\[4^3 ‚àí (2 \\cdot 7) + \\frac{9}{2}\\]"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#variables-objects-in-r",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#variables-objects-in-r",
    "title": "R basics and data summaries",
    "section": "Variables (objects) in R",
    "text": "Variables (objects) in R\nVariables let us store results so we can reuse them later\n(e.g., data, summaries, plots, model output).\n\n\n\n\nAssigning a single value\n\nUse &lt;- to assign a value to a name\nRead as ‚Äúgets‚Äù, ‚Äúbecomes‚Äù, or ‚Äúassigns‚Äù\n\n\nx &lt;- 5\nx\n\n[1] 5\n\n\nYou‚Äôll mostly see &lt;- in examples and documentation, so that‚Äôs what we‚Äôll use in this course. But sometimes people use =.\n\nx = 5\nx\n\n[1] 5\n\n\n\nAssigning multiple values (vectors)\nSequences\n\na &lt;- 3:10\na\n\n[1]  3  4  5  6  7  8  9 10\n\n\nCombining values with c()\n\nb &lt;- c(5, 12, 2, 100, 8)\nb\n\n[1]   5  12   2 100   8"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#overwriting-objects",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#overwriting-objects",
    "title": "R basics and data summaries",
    "section": "Overwriting objects",
    "text": "Overwriting objects\nIn R, you can overwrite an object by assigning a new value to the same name.\n\nx &lt;- 5\nx\n\n[1] 5\n\n\n\nx &lt;- 10\nx\n\n[1] 10\n\n\n\nR does not warn you when this happens.\nThe old value is replaced.\nThis is normal and common in R."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#comments-in-r",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#comments-in-r",
    "title": "R basics and data summaries",
    "section": "Comments in R",
    "text": "Comments in R\nComments are notes to yourself (and others).\nR ignores anything after #.\n\n# This is a comment\nx &lt;- 5   # assign 5 to x\nx\n\n[1] 5\n\n\n\nComments can explain what your code is doing.\nEven better, comments can explain why you chose to do something.\n\n\n# Example: WHAT the code is doing\n# Adding two numbers and storing the result\nsum_result &lt;- 2 + 3\n\n# Example: WHY\n# Creating a constant that will be reused later in the analysis\ntotal_score &lt;- 2 + 3\n\n\nFor this class, comments can be helpful in homework and exams\nThey let us see your thought process or where you might have been unsure"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-practice-30-60-seconds",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-practice-30-60-seconds",
    "title": "R basics and data summaries",
    "section": "Quick practice (30-60 seconds)",
    "text": "Quick practice (30-60 seconds)\nIn your .qmd, create:\n\ny &lt;- 8\nc_vec &lt;- 15:20\nd_vec &lt;- c(16:19, 22)\n\n(Do not overthink it - just try it.)"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-practice-solution",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-practice-solution",
    "title": "R basics and data summaries",
    "section": "Quick practice: solution",
    "text": "Quick practice: solution\n\ny &lt;- 8\ny\n\n[1] 8\n\n\n\nc_vec &lt;- 15:20\nc_vec\n\n[1] 15 16 17 18 19 20\n\n\n\nd_vec &lt;- c(16:19, 22)\nd_vec\n\n[1] 16 17 18 19 22"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-functions",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-functions",
    "title": "R basics and data summaries",
    "section": "Using functions",
    "text": "Using functions\n\nA function performs a task (e.g., calculate a mean)\nFunctions use parentheses: function_name()\nInputs to a function are called arguments\nUse ?function_name to see the help file\n\n\n\n\n\nArguments specified by name\n\nmean(x = 1:4)\n\n[1] 2.5\n\nseq(from = 1, to = 12, by = 3)\n\n[1]  1  4  7 10\n\nseq(by = 3, to = 12, from = 1)\n\n[1]  1  4  7 10\n\n\n\nArguments specified by position\n\nmean(1:4)\n\n[1] 2.5\n\nseq(1, 12, 3)\n\n[1]  1  4  7 10"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-functions-for-summary-statistics",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-functions-for-summary-statistics",
    "title": "R basics and data summaries",
    "section": "Using functions for summary statistics",
    "text": "Using functions for summary statistics\nNow let‚Äôs apply functions to the vectors you just created.\n\nCalculate the mean of c_vec\nCalculate the standard deviation of c_vec\nUse ?sd to see what arguments sd() takes\n\n\n\n\nmean(c_vec)\n\n[1] 17.5\n\nsd(c_vec)\n\n[1] 1.870829\n\n\n¬†\nIf you have time, also try:\n\nmedian(c_vec)\n\n[1] 17.5\n\nIQR(c_vec)\n\n[1] 2.5"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-check",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-check",
    "title": "R basics and data summaries",
    "section": "Quick check",
    "text": "Quick check\n\nDo these functions return one number or many?\nDoes that match what you expect a ‚Äúsummary‚Äù to do?"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#working-with-a-real-dataset",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#working-with-a-real-dataset",
    "title": "R basics and data summaries",
    "section": "Working with a real dataset",
    "text": "Working with a real dataset\n¬†\n\nR comes with several built-in datasets that we can use to practice.\nWe‚Äôll start with the iris dataset.\n\nThis dataset is useful because it includes both numeric and categorical variables."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#fishers-or-andersons-iris-data-set",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#fishers-or-andersons-iris-data-set",
    "title": "R basics and data summaries",
    "section": "Fisher‚Äôs (or Anderson‚Äôs) Iris data set",
    "text": "Fisher‚Äôs (or Anderson‚Äôs) Iris data set\nData description:\n\nn = 150\n3 species of Iris flowers (Setosa, Virginica, and Versicolour)\n\n50 measurements of each type of Iris\n\nVariables:\n\nsepal length, sepal width, petal length, petal width, and species\n\n\n\n\n\nGareth Duffy"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#load-and-view-the-data",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#load-and-view-the-data",
    "title": "R basics and data summaries",
    "section": "Load and view the data",
    "text": "Load and view the data\nThe iris dataset is already available in base R.\n\ndata(iris)\n\n\n\n\n\nViewing in the console\nYou can display the dataset by typing its name:\n\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\nInteractive view\nYou can open an interactive view of the dataset like this:\n\nView(iris)\n\n(Note: View() works interactively in RStudio, but does not display in slides.)"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#inspecting-the-dataset",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#inspecting-the-dataset",
    "title": "R basics and data summaries",
    "section": "Inspecting the dataset",
    "text": "Inspecting the dataset\nBefore summarizing or plotting, it helps to understand what‚Äôs in the dataset.\n\ndim(iris)\nnames(iris)\nstr(iris)\nhead(iris)\ntail(iris)\n\nThese functions help answer questions like:\n\nHow many rows and columns are there?\nWhat are the variable names?\nWhich variables are numeric vs categorical?"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#inspecting-the-dataset-key-questions",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#inspecting-the-dataset-key-questions",
    "title": "R basics and data summaries",
    "section": "Inspecting the dataset: key questions",
    "text": "Inspecting the dataset: key questions\nHow many rows and columns are there?\n\ndim(iris)\n\n[1] 150   5\n\n\nWhat are the variable names?\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nWhich variables are numeric vs categorical?\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#viewing-rows-of-a-dataset",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#viewing-rows-of-a-dataset",
    "title": "R basics and data summaries",
    "section": "Viewing rows of a dataset",
    "text": "Viewing rows of a dataset\n\n\nWhen a dataset has many rows, it helps to look at just a few.\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\nYou can also specify how many rows to view:\n\nhead(iris, 3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\ntail(iris, 2)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#accessing-a-single-variable-with",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#accessing-a-single-variable-with",
    "title": "R basics and data summaries",
    "section": "Accessing a single variable with $",
    "text": "Accessing a single variable with $\nTo work with one column at a time, use the $ operator.\n\niris$Petal.Length\n\n  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n[109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n[127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n[145] 5.7 5.2 5.0 5.2 5.4 5.1\n\n\ndataset$variable pulls out a single column from a data frame."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#summarizing-one-numeric-variable",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#summarizing-one-numeric-variable",
    "title": "R basics and data summaries",
    "section": "Summarizing one numeric variable",
    "text": "Summarizing one numeric variable\nOnce you‚Äôve selected a single numeric variable, you can apply summary functions to it.\n\nmean(iris$Petal.Length)\n\n[1] 3.758\n\nsd(iris$Petal.Length)\n\n[1] 1.765298\n\nmedian(iris$Petal.Length)\n\n[1] 4.35\n\nIQR(iris$Petal.Length)\n\n[1] 3.5\n\n\n\nMean / SD describe center and spread\n\nMedian / IQR are more robust to outliers"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-summaries-for-all-variables",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#quick-summaries-for-all-variables",
    "title": "R basics and data summaries",
    "section": "Quick summaries for all variables",
    "text": "Quick summaries for all variables\nWe can also get a fast overview of the entire dataset at once.\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nsummary() provides basic summaries for every column, based on its type."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#missing-values-na-in-r",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#missing-values-na-in-r",
    "title": "R basics and data summaries",
    "section": "Missing values (NA) in R",
    "text": "Missing values (NA) in R\nSometimes datasets contain missing values, represented as NA.\nBy default, summary functions return NA if any values are missing.\n\nx &lt;- c(2, 5, NA, 7)\nmean(x)\n\n[1] NA\n\n\nTo ignore missing values, use na.rm = TRUE.\n\nmean(x, na.rm = TRUE)\n\n[1] 4.666667\n\nsd(x, na.rm = TRUE)\n\n[1] 2.516611\n\nmedian(x, na.rm = TRUE)\n\n[1] 5\n\nIQR(x, na.rm = TRUE)\n\n[1] 2.5\n\n\n\nna.rm = TRUE tells R to remove missing values before calculating"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#summarizing-a-categorical-variable-counts",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#summarizing-a-categorical-variable-counts",
    "title": "R basics and data summaries",
    "section": "Summarizing a categorical variable (counts)",
    "text": "Summarizing a categorical variable (counts)\nFor categorical variables, we often start by counting how many observations fall in each category.\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#categorical-proportions",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#categorical-proportions",
    "title": "R basics and data summaries",
    "section": "Categorical proportions",
    "text": "Categorical proportions\nWe can convert counts into proportions using prop.table().\n\nprop.table(table(iris$Species))\n\n\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\n\nTo express proportions as percentages:\n\n100 * prop.table(table(iris$Species))\n\n\n    setosa versicolor  virginica \n  33.33333   33.33333   33.33333"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#plotting-a-numeric-variable",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#plotting-a-numeric-variable",
    "title": "R basics and data summaries",
    "section": "Plotting a numeric variable",
    "text": "Plotting a numeric variable\nA histogram shows the distribution of a single numeric variable.\n\nhist(iris$Petal.Length)"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#plotting-a-categorical-variable",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#plotting-a-categorical-variable",
    "title": "R basics and data summaries",
    "section": "Plotting a categorical variable",
    "text": "Plotting a categorical variable\nA bar chart shows counts for each category.\n\nbarplot(table(iris$Species))\n\n\nbarplot(table()) is a quick way to visualize categorical data."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-packages",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-packages",
    "title": "R basics and data summaries",
    "section": "R Packages",
    "text": "R Packages"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-packages-1",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#r-packages-1",
    "title": "R basics and data summaries",
    "section": "R Packages",
    "text": "R Packages\nA good analogy for R packages is that they are like apps you can download onto a mobile phone:\n\nModernDive Figure 1.4\nPackages contain additional functions and data"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#installing-vs-loading-packages",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#installing-vs-loading-packages",
    "title": "R basics and data summaries",
    "section": "Installing vs loading packages",
    "text": "Installing vs loading packages\nThere are two separate steps:\nInstall (only once per computer, example):\n\ninstall.packages(\"dplyr\")\n\nLoad (every time you start R):\n\nlibrary(dplyr)\n\nInstalling puts the package on your computer.\nLoading makes it available in your R session.\n\nIn practice, install.packages() and library() calls should go near the top of a script or in an early code chunk of a .qmd file"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-to-access-package-functions",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#using-to-access-package-functions",
    "title": "R basics and data summaries",
    "section": "Using :: to access package functions",
    "text": "Using :: to access package functions\nThere are two ways to use functions from a package.\n\n\nOption 1: Load the package\n\nlibrary(dplyr)\narrange(iris, Petal.Length)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            4.6         3.6          1.0         0.2     setosa\n2            4.3         3.0          1.1         0.1     setosa\n3            5.8         4.0          1.2         0.2     setosa\n4            5.0         3.2          1.2         0.2     setosa\n5            4.7         3.2          1.3         0.2     setosa\n6            5.4         3.9          1.3         0.4     setosa\n7            5.5         3.5          1.3         0.2     setosa\n8            4.4         3.0          1.3         0.2     setosa\n9            5.0         3.5          1.3         0.3     setosa\n10           4.5         2.3          1.3         0.3     setosa\n11           4.4         3.2          1.3         0.2     setosa\n12           5.1         3.5          1.4         0.2     setosa\n13           4.9         3.0          1.4         0.2     setosa\n14           5.0         3.6          1.4         0.2     setosa\n15           4.6         3.4          1.4         0.3     setosa\n16           4.4         2.9          1.4         0.2     setosa\n17           4.8         3.0          1.4         0.1     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.2         3.4          1.4         0.2     setosa\n20           5.5         4.2          1.4         0.2     setosa\n21           4.9         3.6          1.4         0.1     setosa\n22           4.8         3.0          1.4         0.3     setosa\n23           4.6         3.2          1.4         0.2     setosa\n24           5.0         3.3          1.4         0.2     setosa\n25           4.6         3.1          1.5         0.2     setosa\n26           5.0         3.4          1.5         0.2     setosa\n27           4.9         3.1          1.5         0.1     setosa\n28           5.4         3.7          1.5         0.2     setosa\n29           5.7         4.4          1.5         0.4     setosa\n30           5.1         3.8          1.5         0.3     setosa\n31           5.1         3.7          1.5         0.4     setosa\n32           5.2         3.5          1.5         0.2     setosa\n33           5.4         3.4          1.5         0.4     setosa\n34           5.2         4.1          1.5         0.1     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.1         3.4          1.5         0.2     setosa\n37           5.3         3.7          1.5         0.2     setosa\n38           4.8         3.4          1.6         0.2     setosa\n39           5.0         3.0          1.6         0.2     setosa\n40           5.0         3.4          1.6         0.4     setosa\n41           4.7         3.2          1.6         0.2     setosa\n42           4.8         3.1          1.6         0.2     setosa\n43           5.0         3.5          1.6         0.6     setosa\n44           5.1         3.8          1.6         0.2     setosa\n45           5.4         3.9          1.7         0.4     setosa\n46           5.7         3.8          1.7         0.3     setosa\n47           5.4         3.4          1.7         0.2     setosa\n48           5.1         3.3          1.7         0.5     setosa\n49           4.8         3.4          1.9         0.2     setosa\n50           5.1         3.8          1.9         0.4     setosa\n51           5.1         2.5          3.0         1.1 versicolor\n52           4.9         2.4          3.3         1.0 versicolor\n53           5.0         2.3          3.3         1.0 versicolor\n54           5.0         2.0          3.5         1.0 versicolor\n55           5.7         2.6          3.5         1.0 versicolor\n56           5.6         2.9          3.6         1.3 versicolor\n57           5.5         2.4          3.7         1.0 versicolor\n58           5.5         2.4          3.8         1.1 versicolor\n59           5.2         2.7          3.9         1.4 versicolor\n60           5.6         2.5          3.9         1.1 versicolor\n61           5.8         2.7          3.9         1.2 versicolor\n62           5.5         2.3          4.0         1.3 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.8          4.0         1.3 versicolor\n65           5.5         2.5          4.0         1.3 versicolor\n66           5.8         2.6          4.0         1.2 versicolor\n67           5.8         2.7          4.1         1.0 versicolor\n68           5.6         3.0          4.1         1.3 versicolor\n69           5.7         2.8          4.1         1.3 versicolor\n70           5.9         3.0          4.2         1.5 versicolor\n71           5.6         2.7          4.2         1.3 versicolor\n72           5.7         3.0          4.2         1.2 versicolor\n73           5.7         2.9          4.2         1.3 versicolor\n74           6.4         2.9          4.3         1.3 versicolor\n75           6.2         2.9          4.3         1.3 versicolor\n76           6.7         3.1          4.4         1.4 versicolor\n77           6.6         3.0          4.4         1.4 versicolor\n78           6.3         2.3          4.4         1.3 versicolor\n79           5.5         2.6          4.4         1.2 versicolor\n80           6.4         3.2          4.5         1.5 versicolor\n81           5.7         2.8          4.5         1.3 versicolor\n82           5.6         3.0          4.5         1.5 versicolor\n83           6.2         2.2          4.5         1.5 versicolor\n84           6.0         2.9          4.5         1.5 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           4.9         2.5          4.5         1.7  virginica\n88           6.5         2.8          4.6         1.5 versicolor\n89           6.6         2.9          4.6         1.3 versicolor\n90           6.1         3.0          4.6         1.4 versicolor\n91           7.0         3.2          4.7         1.4 versicolor\n92           6.3         3.3          4.7         1.6 versicolor\n93           6.1         2.9          4.7         1.4 versicolor\n94           6.1         2.8          4.7         1.2 versicolor\n95           6.7         3.1          4.7         1.5 versicolor\n96           5.9         3.2          4.8         1.8 versicolor\n97           6.8         2.8          4.8         1.4 versicolor\n98           6.2         2.8          4.8         1.8  virginica\n99           6.0         3.0          4.8         1.8  virginica\n100          6.9         3.1          4.9         1.5 versicolor\n101          6.3         2.5          4.9         1.5 versicolor\n102          5.6         2.8          4.9         2.0  virginica\n103          6.3         2.7          4.9         1.8  virginica\n104          6.1         3.0          4.9         1.8  virginica\n105          6.7         3.0          5.0         1.7 versicolor\n106          5.7         2.5          5.0         2.0  virginica\n107          6.0         2.2          5.0         1.5  virginica\n108          6.3         2.5          5.0         1.9  virginica\n109          6.0         2.7          5.1         1.6 versicolor\n110          5.8         2.7          5.1         1.9  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          5.8         2.8          5.1         2.4  virginica\n113          6.3         2.8          5.1         1.5  virginica\n114          6.9         3.1          5.1         2.3  virginica\n115          5.8         2.7          5.1         1.9  virginica\n116          5.9         3.0          5.1         1.8  virginica\n117          6.7         3.0          5.2         2.3  virginica\n118          6.5         3.0          5.2         2.0  virginica\n119          6.4         2.7          5.3         1.9  virginica\n120          6.4         3.2          5.3         2.3  virginica\n121          6.9         3.1          5.4         2.1  virginica\n122          6.2         3.4          5.4         2.3  virginica\n123          6.8         3.0          5.5         2.1  virginica\n124          6.5         3.0          5.5         1.8  virginica\n125          6.4         3.1          5.5         1.8  virginica\n126          6.3         2.9          5.6         1.8  virginica\n127          6.4         2.8          5.6         2.1  virginica\n128          6.4         2.8          5.6         2.2  virginica\n129          6.1         2.6          5.6         1.4  virginica\n130          6.3         3.4          5.6         2.4  virginica\n131          6.7         3.1          5.6         2.4  virginica\n132          6.9         3.2          5.7         2.3  virginica\n133          6.7         3.3          5.7         2.1  virginica\n134          6.7         3.3          5.7         2.5  virginica\n135          6.5         3.0          5.8         2.2  virginica\n136          6.7         2.5          5.8         1.8  virginica\n137          7.2         3.0          5.8         1.6  virginica\n138          7.1         3.0          5.9         2.1  virginica\n139          6.8         3.2          5.9         2.3  virginica\n140          6.3         3.3          6.0         2.5  virginica\n141          7.2         3.2          6.0         1.8  virginica\n142          7.2         3.6          6.1         2.5  virginica\n143          7.4         2.8          6.1         1.9  virginica\n144          7.7         3.0          6.1         2.3  virginica\n145          7.3         2.9          6.3         1.8  virginica\n146          7.9         3.8          6.4         2.0  virginica\n147          7.6         3.0          6.6         2.1  virginica\n148          7.7         3.8          6.7         2.2  virginica\n149          7.7         2.8          6.7         2.0  virginica\n150          7.7         2.6          6.9         2.3  virginica\n\n\n\nOption 2: Use :: without loading the package\n\ndplyr::arrange(iris, Petal.Length)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            4.6         3.6          1.0         0.2     setosa\n2            4.3         3.0          1.1         0.1     setosa\n3            5.8         4.0          1.2         0.2     setosa\n4            5.0         3.2          1.2         0.2     setosa\n5            4.7         3.2          1.3         0.2     setosa\n6            5.4         3.9          1.3         0.4     setosa\n7            5.5         3.5          1.3         0.2     setosa\n8            4.4         3.0          1.3         0.2     setosa\n9            5.0         3.5          1.3         0.3     setosa\n10           4.5         2.3          1.3         0.3     setosa\n11           4.4         3.2          1.3         0.2     setosa\n12           5.1         3.5          1.4         0.2     setosa\n13           4.9         3.0          1.4         0.2     setosa\n14           5.0         3.6          1.4         0.2     setosa\n15           4.6         3.4          1.4         0.3     setosa\n16           4.4         2.9          1.4         0.2     setosa\n17           4.8         3.0          1.4         0.1     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.2         3.4          1.4         0.2     setosa\n20           5.5         4.2          1.4         0.2     setosa\n21           4.9         3.6          1.4         0.1     setosa\n22           4.8         3.0          1.4         0.3     setosa\n23           4.6         3.2          1.4         0.2     setosa\n24           5.0         3.3          1.4         0.2     setosa\n25           4.6         3.1          1.5         0.2     setosa\n26           5.0         3.4          1.5         0.2     setosa\n27           4.9         3.1          1.5         0.1     setosa\n28           5.4         3.7          1.5         0.2     setosa\n29           5.7         4.4          1.5         0.4     setosa\n30           5.1         3.8          1.5         0.3     setosa\n31           5.1         3.7          1.5         0.4     setosa\n32           5.2         3.5          1.5         0.2     setosa\n33           5.4         3.4          1.5         0.4     setosa\n34           5.2         4.1          1.5         0.1     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.1         3.4          1.5         0.2     setosa\n37           5.3         3.7          1.5         0.2     setosa\n38           4.8         3.4          1.6         0.2     setosa\n39           5.0         3.0          1.6         0.2     setosa\n40           5.0         3.4          1.6         0.4     setosa\n41           4.7         3.2          1.6         0.2     setosa\n42           4.8         3.1          1.6         0.2     setosa\n43           5.0         3.5          1.6         0.6     setosa\n44           5.1         3.8          1.6         0.2     setosa\n45           5.4         3.9          1.7         0.4     setosa\n46           5.7         3.8          1.7         0.3     setosa\n47           5.4         3.4          1.7         0.2     setosa\n48           5.1         3.3          1.7         0.5     setosa\n49           4.8         3.4          1.9         0.2     setosa\n50           5.1         3.8          1.9         0.4     setosa\n51           5.1         2.5          3.0         1.1 versicolor\n52           4.9         2.4          3.3         1.0 versicolor\n53           5.0         2.3          3.3         1.0 versicolor\n54           5.0         2.0          3.5         1.0 versicolor\n55           5.7         2.6          3.5         1.0 versicolor\n56           5.6         2.9          3.6         1.3 versicolor\n57           5.5         2.4          3.7         1.0 versicolor\n58           5.5         2.4          3.8         1.1 versicolor\n59           5.2         2.7          3.9         1.4 versicolor\n60           5.6         2.5          3.9         1.1 versicolor\n61           5.8         2.7          3.9         1.2 versicolor\n62           5.5         2.3          4.0         1.3 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.8          4.0         1.3 versicolor\n65           5.5         2.5          4.0         1.3 versicolor\n66           5.8         2.6          4.0         1.2 versicolor\n67           5.8         2.7          4.1         1.0 versicolor\n68           5.6         3.0          4.1         1.3 versicolor\n69           5.7         2.8          4.1         1.3 versicolor\n70           5.9         3.0          4.2         1.5 versicolor\n71           5.6         2.7          4.2         1.3 versicolor\n72           5.7         3.0          4.2         1.2 versicolor\n73           5.7         2.9          4.2         1.3 versicolor\n74           6.4         2.9          4.3         1.3 versicolor\n75           6.2         2.9          4.3         1.3 versicolor\n76           6.7         3.1          4.4         1.4 versicolor\n77           6.6         3.0          4.4         1.4 versicolor\n78           6.3         2.3          4.4         1.3 versicolor\n79           5.5         2.6          4.4         1.2 versicolor\n80           6.4         3.2          4.5         1.5 versicolor\n81           5.7         2.8          4.5         1.3 versicolor\n82           5.6         3.0          4.5         1.5 versicolor\n83           6.2         2.2          4.5         1.5 versicolor\n84           6.0         2.9          4.5         1.5 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           4.9         2.5          4.5         1.7  virginica\n88           6.5         2.8          4.6         1.5 versicolor\n89           6.6         2.9          4.6         1.3 versicolor\n90           6.1         3.0          4.6         1.4 versicolor\n91           7.0         3.2          4.7         1.4 versicolor\n92           6.3         3.3          4.7         1.6 versicolor\n93           6.1         2.9          4.7         1.4 versicolor\n94           6.1         2.8          4.7         1.2 versicolor\n95           6.7         3.1          4.7         1.5 versicolor\n96           5.9         3.2          4.8         1.8 versicolor\n97           6.8         2.8          4.8         1.4 versicolor\n98           6.2         2.8          4.8         1.8  virginica\n99           6.0         3.0          4.8         1.8  virginica\n100          6.9         3.1          4.9         1.5 versicolor\n101          6.3         2.5          4.9         1.5 versicolor\n102          5.6         2.8          4.9         2.0  virginica\n103          6.3         2.7          4.9         1.8  virginica\n104          6.1         3.0          4.9         1.8  virginica\n105          6.7         3.0          5.0         1.7 versicolor\n106          5.7         2.5          5.0         2.0  virginica\n107          6.0         2.2          5.0         1.5  virginica\n108          6.3         2.5          5.0         1.9  virginica\n109          6.0         2.7          5.1         1.6 versicolor\n110          5.8         2.7          5.1         1.9  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          5.8         2.8          5.1         2.4  virginica\n113          6.3         2.8          5.1         1.5  virginica\n114          6.9         3.1          5.1         2.3  virginica\n115          5.8         2.7          5.1         1.9  virginica\n116          5.9         3.0          5.1         1.8  virginica\n117          6.7         3.0          5.2         2.3  virginica\n118          6.5         3.0          5.2         2.0  virginica\n119          6.4         2.7          5.3         1.9  virginica\n120          6.4         3.2          5.3         2.3  virginica\n121          6.9         3.1          5.4         2.1  virginica\n122          6.2         3.4          5.4         2.3  virginica\n123          6.8         3.0          5.5         2.1  virginica\n124          6.5         3.0          5.5         1.8  virginica\n125          6.4         3.1          5.5         1.8  virginica\n126          6.3         2.9          5.6         1.8  virginica\n127          6.4         2.8          5.6         2.1  virginica\n128          6.4         2.8          5.6         2.2  virginica\n129          6.1         2.6          5.6         1.4  virginica\n130          6.3         3.4          5.6         2.4  virginica\n131          6.7         3.1          5.6         2.4  virginica\n132          6.9         3.2          5.7         2.3  virginica\n133          6.7         3.3          5.7         2.1  virginica\n134          6.7         3.3          5.7         2.5  virginica\n135          6.5         3.0          5.8         2.2  virginica\n136          6.7         2.5          5.8         1.8  virginica\n137          7.2         3.0          5.8         1.6  virginica\n138          7.1         3.0          5.9         2.1  virginica\n139          6.8         3.2          5.9         2.3  virginica\n140          6.3         3.3          6.0         2.5  virginica\n141          7.2         3.2          6.0         1.8  virginica\n142          7.2         3.6          6.1         2.5  virginica\n143          7.4         2.8          6.1         1.9  virginica\n144          7.7         3.0          6.1         2.3  virginica\n145          7.3         2.9          6.3         1.8  virginica\n146          7.9         3.8          6.4         2.0  virginica\n147          7.6         3.0          6.6         2.1  virginica\n148          7.7         3.8          6.7         2.2  virginica\n149          7.7         2.8          6.7         2.0  virginica\n150          7.7         2.6          6.9         2.3  virginica\n\n\n\nBoth are valid.\n\nlibrary() loads all functions from a package\npackage::function() uses just one function\nEither approach is fine.\nI recommend including library() calls at the top of a file as a cue to yourself (and others) which packages are being used."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#learn-more-optional",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#learn-more-optional",
    "title": "R basics and data summaries",
    "section": "Learn more (optional)",
    "text": "Learn more (optional)\n\n\nIf you want a short, clear walkthrough on R packages:\n\n\n\nInstalling and loading R packages Danielle Navarro (YouTube) https://www.youtube.com/watch?v=kpHZVyDvEhQ"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#textbook-datasets-important",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#textbook-datasets-important",
    "title": "R basics and data summaries",
    "section": "Textbook datasets (important)",
    "text": "Textbook datasets (important)\n\n\nThe textbook datasets live in an R package called oibiostat.\n¬†\nIt is not on CRAN, so we install it from GitHub, per the book authors‚Äô instructions.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"OI-Biostat/oi_biostat_data\", force = TRUE)\n\n(This may take a few minutes the first time.)\n¬†\nAfter installing, load it (this part is done every time you restart R):\n\nlibrary(oibiostat)"
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#check-that-it-worked",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#check-that-it-worked",
    "title": "R basics and data summaries",
    "section": "Check that it worked",
    "text": "Check that it worked\nIf installation worked, you can load the package and access a dataset:\n\nlibrary(oibiostat)\ndata(dds.discr)\nhead(dds.discr)\n\nIf this runs without errors, you‚Äôre set."
  },
  {
    "objectID": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#wrap-up",
    "href": "lessons/05_r_basics_and_summaries/05_r_basics_and_summaries.html#wrap-up",
    "title": "R basics and data summaries",
    "section": "Wrap-up",
    "text": "Wrap-up\nToday you learned how to:\n\nRun basic R code\nInspect a dataset\nSummarize numeric and categorical variables\nMake simple plots\n\nWe‚Äôll build on this foundation to:\n\nWork more efficiently with data\nStart using additional functions and packages\n\n\n\n\nBMSC 620 | R basics + summaries"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#roadmap-for-today",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#roadmap-for-today",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Roadmap for Today",
    "text": "Roadmap for Today\n\n\nPart 1: Paired Data\n\nWhat makes data ‚Äúpaired‚Äù?\nExamples and study designs\nThe vegetarian diet example\nPaired t-tests in R\n\nPart 2: The Math Behind Paired Tests\n\nPopulation parameters vs.¬†sample statistics\nTest statistics and p-values\nConfidence intervals for differences\n\n\nPart 3: Independent Samples\n\nWhat makes samples ‚Äúindependent‚Äù?\nThe caffeine and finger tapping example\nTwo-sample t-tests in R\n\nPart 4: Choosing the Right Test\n\nPaired vs.¬†independent: key differences\nStudy design implications\nCommon mistakes to avoid"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#cis-and-hypothesis-testing-for-different-scenarios",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#cis-and-hypothesis-testing-for-different-scenarios",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "CI‚Äôs and hypothesis testing for different scenarios:",
    "text": "CI‚Äôs and hypothesis testing for different scenarios:\n\n\n\n\n\n\n\n\n\n\n\nDay\nSection\nPopulation parameter\nSymbol\nPoint estimate\nSymbol\n\n\n\n\n9\n5.1\nPopulation mean\n\\(\\mu\\)\nSample mean\n\\(\\bar{x}\\)\n\n\n10\n5.2\nPopulation mean of paired differences\n\\(\\mu_d\\) or \\(\\delta\\)\nSample mean of paired differences\n\\(\\bar{x}_{d}\\)\n\n\n10\n5.3\nDifferences in population means\n\\(\\mu_1-\\mu_2\\)\nDifferences in sample means\n\\(\\bar{x}_1 - \\bar{x}_2\\)\n\n\n13\n8.1\nPopulation proportion\n\\(p\\)\nSample proportions\n\\(\\widehat{p}\\)\n\n\n14\n8.2\nDifferences in population proportions\n\\(p_1-p_2\\)\nDifferences in sample proportions\n\\(\\widehat{p}_1-\\widehat{p}_2\\)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#where-are-we-in-the-course",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#where-are-we-in-the-course",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Where are we in the course?",
    "text": "Where are we in the course?\nWe‚Äôve been building up our inference toolkit:\n\n\nSo far:\n\nSingle-sample mean: \\(\\mu\\)\n\nCI: \\(\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\)\nTest: Compare \\(\\bar{x}\\) to hypothesized \\(\\mu_0\\)\n\n\n\n\nToday:\n\nMean difference from paired samples: \\(\\mu_d\\) or \\(\\delta\\)\nDifference in means from independent samples: \\(\\mu_1 - \\mu_2\\)\n\n\n\nWhy this matters: The study design determines which test we use!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#reminder-the-six-steps-of-hypothesis-testing",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#reminder-the-six-steps-of-hypothesis-testing",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Reminder: The six steps of hypothesis testing",
    "text": "Reminder: The six steps of hypothesis testing\nBefore we dive into examples, let‚Äôs review our standard framework:\n\nState hypotheses (\\(H_0\\) and \\(H_A\\))\nSet significance level (usually \\(\\alpha\\) = 0.05)\nCheck assumptions (independence, normality/large n)\nCalculate test statistic\n\nPaired: \\(t = \\frac{\\bar{x}_d - 0}{s_d/\\sqrt{n}}\\)\nIndependent: \\(t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\)\n\nFind p-value (probability of seeing this or more extreme)\nMake conclusion (reject or fail to reject \\(H_0\\), with context)\n\n\n\nToday we‚Äôll apply this framework to both paired and independent samples!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#what-are-paired-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#what-are-paired-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "What are paired data?",
    "text": "What are paired data?\n\n\n\nDefinition: Paired Data\n\n\nPaired data occur when two sets of observations are uniquely matched so that an observation in one set corresponds to exactly one observation in the other.\n\n\n\n\n\nCommon scenarios:\n\nBefore-and-after studies (longitudinal data)\n\nMeasure the same people at two time points\nExample: Blood pressure before and after medication\n\nMatched pairs\n\nTwin studies: One twin gets treatment, other gets control\nMatched controls: Pair people based on age, sex, etc.\n\nNatural pairs\n\nLeft eye vs.¬†right eye\nParent-child pairs"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#examples-of-paired-designs",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#examples-of-paired-designs",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Examples of paired designs",
    "text": "Examples of paired designs\n\n\nExample 1: Swimmer performance\n\nCompetitive swimmers tested twice\nOnce wearing wetsuit\nOnce wearing regular swimsuit\nCompare maximum speed\n\n\n\nWhy paired?\n\nSame swimmer in both conditions\nControls for individual differences in ability\n\n\nExample 2: Drug effectiveness\n\nPatients tested before treatment\nSame patients tested after treatment\nCompare blood glucose levels\n\n\n\nWhy paired?\n\nSame patient at two time points\nNatural ‚Äúbefore vs.¬†after‚Äù comparison\n\n\n\n\nKey insight: Pairing reduces variability because we‚Äôre comparing each person to themselves!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#todays-example-vegetarian-diet-and-cholesterol",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#todays-example-vegetarian-diet-and-cholesterol",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Today‚Äôs example: Vegetarian diet and cholesterol",
    "text": "Today‚Äôs example: Vegetarian diet and cholesterol\n\n\n\nResearch Question\n\n\nCan a vegetarian diet reduce cholesterol levels?\n\n\n\n\n\nStudy design:\n\n43 non-vegetarian adults enrolled\nInstructed to adopt a vegetarian diet\nCholesterol measured before and after diet\nFollow-up period: 3 months\n\n\n\nWhy is this paired data?\n\nSame individuals measured twice\nEach person serves as their own control\nWe can calculate: \\(\\text{After - Before}\\) for each person"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#loading-and-exploring-the-cholesterol-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#loading-and-exploring-the-cholesterol-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Loading and exploring the cholesterol data",
    "text": "Loading and exploring the cholesterol data\n\nlibrary(dplyr)\nlibrary(here)\nlibrary(readr)\n\n# Load the data\nchol &lt;- read_csv(here(\"data\", \n                      \"chol213_n40.csv\"))\n\n# Take a look at the structure\nglimpse(chol)\n\nRows: 43\nColumns: 2\n$ Before &lt;dbl&gt; 195, 145, 205, 159, 244, 166, 250, 236, 192, 224, 238, 197, 169‚Ä¶\n$ After  &lt;dbl&gt; 146, 155, 178, 146, 208, 147, 202, 215, 184, 208, 206, 169, 182‚Ä¶\n\n\n\n\nWhat do we have?\n\nBefore: Cholesterol level before diet (mg/dL)\nAfter: Cholesterol level after diet (mg/dL)\nEach row is one person"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#calculate-the-paired-differences",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#calculate-the-paired-differences",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Calculate the paired differences",
    "text": "Calculate the paired differences\n\n\n\n\nFor paired data, we create a new variable: the difference\n\n# Calculate difference: After - Before\nchol &lt;- chol %&gt;%\n  mutate(DiffChol = After - Before)\n\n# Look at first few differences\nchol\n\n# A tibble: 43 √ó 3\n   Before After DiffChol\n    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1    195   146      -49\n 2    145   155       10\n 3    205   178      -27\n 4    159   146      -13\n 5    244   208      -36\n 6    166   147      -19\n 7    250   202      -48\n 8    236   215      -21\n 9    192   184       -8\n10    224   208      -16\n# ‚Ñπ 33 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of differences:\n\nNegative values: cholesterol decreased\nPositive values: cholesterol increased\nZero: no change"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#visualizing-the-paired-differences",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#visualizing-the-paired-differences",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Visualizing the paired differences",
    "text": "Visualizing the paired differences\n\n\n\n\n\n\n\n\n\n\n\nEach line represents one person‚Äôs change\n\n\n\n\n\n\n\n\n\n\nMost people decreased (negative values)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#summary-statistics-for-paired-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#summary-statistics-for-paired-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Summary statistics for paired data",
    "text": "Summary statistics for paired data\n\nlibrary(dplyr)\nlibrary(gt)\nlibrary(rstatix)\n\n\n# Summary statistics for differences\nchol %&gt;%\n  get_summary_stats(DiffChol, type = \"common\") %&gt;%\n  gt() %&gt;% \n  tab_options(table.font.size = 40)\n\n\n\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\n\n\nDiffChol\n43\n-49\n13\n-23\n16\n-21.767\n13.89\n2.118\n4.275\n\n\n\n\n\n\n\n\n\nWhat we see:\n\nMean difference: \\(\\bar{x}_d =\\) 21.767 mg/dL\nOn average, cholesterol decreased by about 22 mg/dL\nBut is this difference statistically significant?\n\n\n\nTo answer this, we need a hypothesis test!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#notation-for-paired-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#notation-for-paired-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Notation for paired data",
    "text": "Notation for paired data\n\n\n\nPopulation Parameters vs.¬†Sample Statistics\n\n\n\n\nPopulation (what we want to know)\n\nMean difference: \\(\\delta\\) (delta) or \\(\\mu_d\\)\nStandard deviation: \\(\\sigma_d\\)\nSample size: \\(N\\)\n\n\nSample (what we observe)\n\nSample mean difference: \\(\\bar{x}_d\\)\nSample standard deviation: \\(s_d\\)\nSample size: \\(n\\)\n\n\n\n\n\n\n\nKey insight: Once we calculate the differences, this becomes a one-sample problem!\n\nWe have one number per person (the difference)\nWe test if \\(\\bar{x}_d\\) is significantly different from 0"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-paired-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-paired-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Hypothesis test for paired data",
    "text": "Hypothesis test for paired data\nResearch question: Is there evidence that cholesterol changed after the vegetarian diet?\n\n\nStep 1: State hypotheses\n\\[H_0: \\delta = 0\\] \\[H_A: \\delta \\neq 0\\]\nIn words:\n\n\\(H_0\\): The population mean difference in cholesterol is zero (no change)\n\\(H_A\\): The population mean difference in cholesterol is not zero (there is a change)\n\n\n\nStep 2: Set significance level\n\nUse \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#check-the-assumptions",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#check-the-assumptions",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Check the assumptions",
    "text": "Check the assumptions\nStep 3: Check the assumptions\n\nThe assumptions to run a hypothesis test on a sample are:\n\nIndependent pairs: Each pair is independent from all other pairs,\nApproximately normal sample or big n: the distribution of the sample should be approximately normal, or the sample size should be at least 30\n\n\n\n\n\nIn our example, we would check the assumptions with a statement:\n\nThe pairs of observations are independent from each other and the number of pairs in our sample is 43. Thus, we can use CLT to approximate the sampling distribution."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#the-test-statistic-for-paired-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#the-test-statistic-for-paired-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "The test statistic for paired data",
    "text": "The test statistic for paired data\nStep 4: Calculate test statistic\nThe test statistic for paired data is:\n\\[t = \\frac{\\bar{x}_d - 0}{\\frac{s_d}{\\sqrt{n}}}\\]\n\n\nThis looks familiar! It‚Äôs the same formula as for a one-sample t-test.\n\n\n\n\n\n# Calculate components\nn &lt;- nrow(chol)\nxbar_d &lt;- mean(chol$DiffChol)\ns_d &lt;- sd(chol$DiffChol)\nSE &lt;- s_d / sqrt(n)\n\n# Calculate t-statistic\nt_stat &lt;- (xbar_d - 0) / SE\nt_stat\n\n[1] -10.27603\n\n\n\n\n# Calculate the p-value\n2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)\n\n[1] 4.945625e-13"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-15",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-15",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a paired t-test in R (1/5)",
    "text": "Running a paired t-test in R (1/5)\nStep 5: Find a p-value\n\n\nOption 1: Use the difference variable\n\n# Test the differences directly\nt.test(x = chol$DiffChol, mu = 0)\n\n\n    One Sample t-test\n\ndata:  chol$DiffChol\nt = -10.276, df = 42, p-value = 4.946e-13\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -26.04229 -17.49259\nsample estimates:\nmean of x \n-21.76744"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-25",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-25",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a paired t-test in R (2/5)",
    "text": "Running a paired t-test in R (2/5)\n\n\nOption 2: Use the paired = TRUE argument\n\n# Let R calculate differences for us\nt.test(x = chol$After, y = chol$Before, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  chol$After and chol$Before\nt = -10.276, df = 42, p-value = 4.946e-13\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -26.04229 -17.49259\nsample estimates:\nmean difference \n      -21.76744"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-35",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-35",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a paired t-test in R (3/5)",
    "text": "Running a paired t-test in R (3/5)\n\n\nbroom::tidy(): Use the tidy() function in the broom package with either Option 1 or Option 2\n\nlibrary(broom)\n\n# The argument conf.int = TRUE gives a confidence interval (default is 95%)\n\nt.test(x = chol$After, y = chol$Before, paired = TRUE) %&gt;% \n  broom::tidy(conf.int = TRUE)     \n\n# A tibble: 1 √ó 8\n  estimate statistic  p.value parameter conf.low conf.high method    alternative\n     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      \n1    -21.8     -10.3 4.95e-13        42    -26.0     -17.5 Paired t‚Ä¶ two.sided"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-45",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-45",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a paired t-test in R (4/5)",
    "text": "Running a paired t-test in R (4/5)\nOption 3: Use rstatix package\n\nRequires that the data are in long format which means that\n\nall of the outcome values are in one column and\nanother column indicates which group the values are from\n\n\n\nchol_long\n\n# A tibble: 86 √ó 4\n   DiffChol ID    Time   Cholesterol\n      &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;        &lt;dbl&gt;\n 1      -49 1     Before         195\n 2      -49 1     After          146\n 3       10 2     Before         145\n 4       10 2     After          155\n 5      -27 3     Before         205\n 6      -27 3     After          178\n 7      -13 4     Before         159\n 8      -13 4     After          146\n 9      -36 5     Before         244\n10      -36 5     After          208\n# ‚Ñπ 76 more rows"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-55",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-paired-t-test-in-r-55",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a paired t-test in R (5/5)",
    "text": "Running a paired t-test in R (5/5)\nOption 3: Use rstatix package\n\nlibrary(rstatix)\n\nt_test(data = chol_long, \n       Cholesterol ~ Time, \n       paired = TRUE, \n       detailed = TRUE)\n\n# A tibble: 1 √ó 13\n  estimate .y.       group1 group2    n1    n2 statistic        p    df conf.low\n*    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     21.8 Choleste‚Ä¶ Before After     43    43      10.3 4.95e-13    42     17.5\n# ‚Ñπ 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;, alternative &lt;chr&gt;"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#interpreting-the-paired-t-test-output",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#interpreting-the-paired-t-test-output",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Interpreting the paired t-test output",
    "text": "Interpreting the paired t-test output\n\n# Save and tidy the results\nchol_test &lt;- t.test(x = chol$DiffChol, \n                    mu = 0)\n\nchol_test %&gt;% \n  tidy(conf.int = TRUE) %&gt;% \n  gt() %&gt;% \n  tab_options(table.font.size = 40)\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-21.76744\n-10.27603\n4.945625e-13\n42\n-26.04229\n-17.49259\nOne Sample t-test\ntwo.sided\n\n\n\n\n\n\n\nWhat we see:\n\nt-statistic = -10.28\np-value &lt; 0.001 (very small!)\n95% CI for \\(\\delta\\): (-26.04, -17.49)\n\nStep 6: Make a conclusion\n\nSince p-value &lt; \\(\\alpha = 0.05\\), we reject \\(H_0\\).\nConclusion: There is sufficient evidence that cholesterol levels changed after the vegetarian diet (p &lt; 0.001)."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#writing-a-complete-conclusion",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#writing-a-complete-conclusion",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Writing a complete conclusion",
    "text": "Writing a complete conclusion\n\n\n\nBest Practice: Include Key Numbers\n\n\nA good conclusion includes:\n\nDecision about \\(H_0\\) (reject or fail to reject)\nContext (what was measured)\nEffect size (mean difference)\nConfidence interval\nP-value\n\n\n\n\n\n\nOur conclusion:\nAfter adopting a vegetarian diet, cholesterol levels decreased by an average of 21.77 mg/dL (95% CI: 17.49 to 26.04 mg/dL lower), which is significantly different from zero (t = -10.28, df = 42, p &lt; 0.001, Paired t-test)."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-sided-vs.-two-sided-tests",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-sided-vs.-two-sided-tests",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "One-sided vs.¬†two-sided tests",
    "text": "One-sided vs.¬†two-sided tests\nTwo-sided test (what we just did):\n\n\\(H_A: \\delta \\neq 0\\) (different from zero)\nAppropriate when we don‚Äôt know direction\n\n\n\nOne-sided test (if we have directional prediction):\n\n\\(H_A: \\delta &lt; 0\\) (decrease)\n\\(H_A: \\delta &gt; 0\\) (increase)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#visual-one-sided-vs.-two-sided",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#visual-one-sided-vs.-two-sided",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Visual: One-sided vs.¬†two-sided",
    "text": "Visual: One-sided vs.¬†two-sided"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-sided-example",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-sided-example",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "One-sided example",
    "text": "One-sided example\nExample: If we specifically want to test if diet decreased cholesterol:\n\\[H_0: \\delta \\ge 0\\] \\[H_A: \\delta \\lt 0\\]\nIn words:\n\n\\(H_0\\): The population mean difference in cholesterol greater than or equal to zero\n\\(H_A\\): The population mean difference in cholesterol is less zero (there is a change)\n\n\n\n\nt.test(x = chol$DiffChol, mu = 0, alternative = \"less\") %&gt;% \n  broom::tidy(conf.int = TRUE) %&gt;% \n  gt() %&gt;% \n  tab_options(table.font.size = 40)\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-21.76744\n-10.27603\n2.472813e-13\n42\n-Inf\n-18.20461\nOne Sample t-test\nless\n\n\n\n\n\n\n\nNotice: For a one-sided test, the p-value changes and the confidence interval is one-sided."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#what-are-independent-samples",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#what-are-independent-samples",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "What are independent samples?",
    "text": "What are independent samples?\n\n\n\nDefinition: Independent Samples\n\n\nIndependent samples occur when individuals in one group are completely unrelated to individuals in the other group. There is no natural pairing or matching.\n\n\n\n\n\n\n\nKey characteristics:\n\nDifferent people in each group\nNo before/after measurements\nNo natural matching\nTypically: different sample sizes are possible\n\n\nCommon scenarios:\n\nTreatment vs.¬†control groups (randomized trials)\nCase vs.¬†control studies\nMen vs.¬†women\nExposed vs.¬†unexposed"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#paired-vs.-independent-the-key-difference",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#paired-vs.-independent-the-key-difference",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Paired vs.¬†Independent: The key difference",
    "text": "Paired vs.¬†Independent: The key difference\n\n\n\n\n\nPaired Data\n\n\nStructure:\n\nSame people measured twice\nOR matched pairs\nSame sample size for both conditions\n\n\n\nAnalysis:\n\nCalculate differences\nOne number per person/pair\nOne-sample t-test on differences\n\n\n\nExample:\nWeight before and after diet program (same 50 people)\n\n\n\n\n\n\n\nIndependent Samples\n\n\nStructure:\n\nDifferent people in each group\nNo natural pairing\nCan have different sample sizes\n\n\n\nAnalysis:\n\nCompare two separate means\nTwo numbers: \\(\\bar{x}_1\\) and \\(\\bar{x}_2\\)\nTwo-sample t-test\n\n\n\nExample:\nWeight of 50 men vs.¬†50 women (different people)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#todays-example-caffeine-and-finger-tapping",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#todays-example-caffeine-and-finger-tapping",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Today‚Äôs example: Caffeine and finger tapping",
    "text": "Today‚Äôs example: Caffeine and finger tapping\n\n\n\nResearch Question\n\n\nDoes caffeine increase finger tapping speed?\n\n\n\n\n\n:: columns ::: {.column width=‚Äú50%‚Äù} Study design:\n\n70 college students trained to tap fingers rapidly\nRandomly assigned to two groups:\n\nControl: Decaffeinated coffee\nCaffeine: Coffee with ~200mg caffeine\n\nDouble-blind design\nAfter 2 hours, tested finger taps per minute :::\n\n\nWhy independent samples?\n\nDifferent students in each group\nEach person tested only once\nNo pairing or matching\n\n:::"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#loading-the-caffeine-data",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#loading-the-caffeine-data",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Loading the caffeine data",
    "text": "Loading the caffeine data\n\n# Load the data\nCaffTaps &lt;- read_csv(here(\"data\", \n                          \"CaffeineTaps_n35.csv\"))\n\n# Check structure\nglimpse(CaffTaps)\n\nRows: 70\nColumns: 2\n$ Taps  &lt;dbl&gt; 246, 248, 250, 252, 248, 250, 246, 248, 245, 250, 242, 245, 244,‚Ä¶\n$ Group &lt;chr&gt; \"Caffeine\", \"Caffeine\", \"Caffeine\", \"Caffeine\", \"Caffeine\", \"Caf‚Ä¶\n\n\n\n\nWhat we have:\n\nTaps: Finger taps per minute\nGroup: Caffeine or NoCaffeine\nEach row is one person\n35 people per group"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#exploring-the-data-by-group",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#exploring-the-data-by-group",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Exploring the data by group",
    "text": "Exploring the data by group\n\n# Summary statistics by group\nCaffTaps %&gt;%\n  group_by(Group) %&gt;%\n  get_summary_stats(Taps, type = \"mean_sd\") %&gt;%\n  gt() %&gt;% \n  tab_options(table.font.size = 40)\n\n\n\n\n\n\n\nGroup\nvariable\nn\nmean\nsd\n\n\n\n\nCaffeine\nTaps\n35\n248.114\n2.621\n\n\nNoCaffeine\nTaps\n35\n244.514\n2.318\n\n\n\n\n\n\n\n\n\nWhat we see:\n\nCaffeine group: mean = 248.1 taps/min\nControl group: mean = 244.5 taps/min\nDifference = 3.6 taps/min\n\n\n\nQuestion: Is this difference statistically significant?"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#visualizing-independent-samples",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#visualizing-independent-samples",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Visualizing independent samples",
    "text": "Visualizing independent samples\n\n\n\n\n\n\n\n\n\n\n\nBox plots with individual points\n\n\n\n\n\n\n\n\n\n\nOverlapping histograms\n\n\n\nNote: We cannot calculate 35 paired differences - these are different people!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#notation-for-two-independent-samples",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#notation-for-two-independent-samples",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Notation for two independent samples",
    "text": "Notation for two independent samples\n\n\n\nPopulation Parameters vs.¬†Sample Statistics\n\n\n\n\nPopulation\n\nGroup 1 mean: \\(\\mu_1\\)\nGroup 2 mean: \\(\\mu_2\\)\nDifference: \\(\\mu_1 - \\mu_2\\)\nGroup 1 SD: \\(\\sigma_1\\)\nGroup 2 SD: \\(\\sigma_2\\)\n\n\nSample\n\nGroup 1 mean: \\(\\bar{x}_1\\)\nGroup 2 mean: \\(\\bar{x}_2\\)\nDifference: \\(\\bar{x}_1 - \\bar{x}_2\\)\nGroup 1 SD: \\(s_1\\)\nGroup 2 SD: \\(s_2\\)\n\n\n\n\n\n\n\nKey difference from paired data:\n\nTwo separate groups with potentially different SDs\nCannot reduce to a single set of differences\nNeed a different standard error formula!"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-two-independent-samples-12",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-two-independent-samples-12",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Hypothesis test for two independent samples (1/2)",
    "text": "Hypothesis test for two independent samples (1/2)\n\n\nCaffeine example: Does caffeine increase finger tapping speed?\n\n\nNull hypothesis (no effect): \\[H_0: \\mu_{caffeine} = \\mu_{control} \\quad \\Longleftrightarrow \\quad \\mu_{caffeine} - \\mu_{control} = 0\\]\n\n\nAlternative hypothesis (caffeine increases tapping): \\[H_A: \\mu_{caffeine} &gt; \\mu_{control} \\quad \\Longleftrightarrow \\quad \\mu_{caffeine} - \\mu_{control} &gt; 0\\]\n\n\nWhy one-sided? We specifically predicted caffeine would increase tapping, not just ‚Äúmake it different‚Äù"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-two-independent-samples-22",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#hypothesis-test-for-two-independent-samples-22",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Hypothesis test for two independent samples (2/2)",
    "text": "Hypothesis test for two independent samples (2/2)\n\n\n\n\n\nGeneral form\n\n\nFor two independent samples, we always test \\(H_0: \\mu_1 - \\mu_2 = 0\\) against ONE of:\n\n\\(H_A: \\mu_1 - \\mu_2 \\neq 0\\) (two-sided)\n\\(H_A: \\mu_1 - \\mu_2 &gt; 0\\) (one-sided upper)\n\n\\(H_A: \\mu_1 - \\mu_2 &lt; 0\\) (one-sided lower)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#example-does-caffeine-increase-finger-tapping-speed",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#example-does-caffeine-increase-finger-tapping-speed",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Example: Does caffeine increase finger tapping speed?",
    "text": "Example: Does caffeine increase finger tapping speed?\n\n\nStep 1: State hypotheses\n\\[H_0: \\mu_1 - \\mu_2 = 0\\] \\[H_A: \\mu_1 - \\mu_2 &gt; 0\\]\nWhere: \\(\\mu_1\\) = mean for Caffeine group, \\(\\mu_2\\) = mean for Control group\n\n\nStep 2: Set significance level\n\nUse \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#example-does-caffeine-increase-finger-tapping-speed-1",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#example-does-caffeine-increase-finger-tapping-speed-1",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Example: Does caffeine increase finger tapping speed?",
    "text": "Example: Does caffeine increase finger tapping speed?\n\n\nStep 3: Calculate test statistic\nThe test statistic for two independent samples:\n\\[t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\]\n\n\nNotice the different SE formula!\n\nFor paired: \\(SE = \\frac{s_d}{\\sqrt{n}}\\)\nFor independent: \\(SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\)\n\n\n\nDegrees of freedom: By default, t.test() uses the Welch two-sample t-test (does not assume equal variances), so df is computed with the Welch‚ÄìSatterthwaite formula and can be non-integer."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#check-the-assumptions-1",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#check-the-assumptions-1",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Check the assumptions",
    "text": "Check the assumptions\nStep 3: Check the assumptions\n\nThe assumptions to run a hypothesis test on a sample are:\n\nIndependent observations: Each observation from both samples is independent from all other observations\nApproximately normal sample or big n: the distribution of each sample should be approximately normal, or the sample size of each sample should be at least 30\n\n\n\n\n\nIn our example, we would check the assumptions with a statement:\n\nThe observations are independent from each other. Each caffeine group (aka sample) has 35 individuals. Thus, we can use CLT to approximate the sampling distribution for each sample."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-two-sample-t-test-in-r",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#running-a-two-sample-t-test-in-r",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Running a two-sample t-test in R",
    "text": "Running a two-sample t-test in R\nSteps 4 and 5: Calculate test statistic and p-value\n¬†\nUsing formula notation:\n\n# Test using formula: outcome ~ group\nt.test(Taps ~ Group, \n       data = CaffTaps, \n       alternative = \"greater\")\n\n\n    Welch Two Sample t-test\n\ndata:  Taps by Group\nt = 6.0867, df = 67.002, p-value = 3.133e-08\nalternative hypothesis: true difference in means between group Caffeine and group NoCaffeine is greater than 0\n95 percent confidence interval:\n 2.613502      Inf\nsample estimates:\n  mean in group Caffeine mean in group NoCaffeine \n                248.1143                 244.5143 \n\n\n\n\nNote: R automatically determines which group is ‚Äúgroup 1‚Äù alphabetically (Caffeine comes before NoCaffeine)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#using-rstatix",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#using-rstatix",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Using rstatix",
    "text": "Using rstatix\n\nlibrary(rstatix) \n\nt_test(data = CaffTaps, \n       Taps ~ Group, \n       detailed = TRUE)\n\n# A tibble: 1 √ó 15\n  estimate estimate1 estimate2 .y.   group1 group2    n1    n2 statistic       p\n*    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     3.60      248.      245. Taps  Caffe‚Ä¶ NoCaf‚Ä¶    35    35      6.09 6.27e-8\n# ‚Ñπ 5 more variables: df &lt;dbl&gt;, conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;,\n#   alternative &lt;chr&gt;"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#interpreting-the-two-sample-t-test",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#interpreting-the-two-sample-t-test",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Interpreting the two-sample t-test",
    "text": "Interpreting the two-sample t-test\nSteps 6: make a conclusion\n\n# Save and tidy results\ncaff_test &lt;- t.test(Taps ~ Group, \n                    data = CaffTaps, \n                    alternative = \"greater\")\n\ntidy(caff_test, \n     conf.int = TRUE) %&gt;% \n  gt() %&gt;% \n  tab_options(table.font.size = 30)\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n3.6\n248.1143\n244.5143\n6.086677\n3.132816e-08\n67.00222\n2.613502\nInf\nWelch Two Sample t-test\ngreater\n\n\n\n\n\n\n\nWhat we see:\n\nMean difference: \\(\\bar{x}_1 - \\bar{x}_2 =\\) 3.6 taps/min\nt-statistic = 6.09\np-value = &lt; 0.001\nOne-sided 95% CI: (2.6, Inf)\n\nConclusion: There is strong evidence that caffeine increases finger tapping speed (p &lt; 0.001)."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#complete-conclusion-for-two-sample-test",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#complete-conclusion-for-two-sample-test",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Complete conclusion for two-sample test",
    "text": "Complete conclusion for two-sample test\n\n\n\nBest Practice: Report Both Groups\n\n\nFor two-sample tests, report:\n\nMeans and SDs for both groups\nDifference in means\nTest statistic and df\nP-value\nConfidence interval for difference\n\n\n\n\n\n\nOur conclusion:\nMean (SD) tapping speed among students who consumed caffeine was 248.1 taps/min compared to 244.5 taps/min among the control group. Taps/min was significantly higher in the caffeine group (t = 6.09, df = 67.00, p &lt; 0.001, one-sided two-sample t-test). On average, students who consumed caffeine tapped 3.6 taps/min faster than those in the control group (95% CI: at least 2.6 taps/min faster)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-rule-to-remember",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#one-rule-to-remember",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "One rule to remember",
    "text": "One rule to remember\n\n\n\nThe decision rule\n\n\nAsk one question:\n\nCan I calculate a meaningful difference for each individual (or pair)?\n\n\nYes ‚Üí Paired t-test\nNo ‚Üí Two-sample t-test\n\nThis is determined by study design, not by the values in the data.\n\n\n\n\n\nKey idea:\nPairing is about how the data were collected, not how they are stored or analyzed."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#examples-paired-vs.-independent",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#examples-paired-vs.-independent",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Examples: Paired vs.¬†Independent",
    "text": "Examples: Paired vs.¬†Independent\n\n\n\n\n\n\n\n\nScenario\nData Structure\nTest\n\n\n\n\nBlood pressure before and after medication\nSame people, two measurements\nPaired t-test\n\n\nWeight loss: Diet A vs.¬†Diet B\nDifferent people in each group\nTwo-sample t-test\n\n\nLeft eye vs.¬†right eye vision\nSame people\nPaired t-test\n\n\nTest scores: Men vs.¬†Women\nDifferent people\nTwo-sample t-test\n\n\nCholesterol: Twin 1 vs.¬†Twin 2\nMatched pairs\nPaired t-test\n\n\nPain score: Treatment vs.¬†Placebo (RCT)\nDifferent people\nTwo-sample t-test\n\n\n\n\n\nShortcut:\nIf you can draw a line connecting two measurements, it‚Äôs paired."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#common-mistakes-to-avoid",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#common-mistakes-to-avoid",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Common mistakes to avoid",
    "text": "Common mistakes to avoid\n\n\n\nMistakes we see all the time\n\n\n1. Using a paired test for independent data\n\nExample: Testing men vs.¬†women with paired = TRUE\nWhy it‚Äôs wrong: R pairs observations by row order, not by any real relationship\nResult: Meaningless inference\n\n\n\n2. Treating paired data as independent\n\nExample: Analyzing before/after as two separate groups\nWhy it‚Äôs wrong: Ignores within-person comparison\nResult: Larger SE and reduced power\n\n\n\n\n\n\nBottom line:\nYou don‚Äôt get to choose the test based on convenience ‚Äî the design chooses it for you."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#checking-your-work-does-it-make-sense",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#checking-your-work-does-it-make-sense",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Checking your work: Does it make sense?",
    "text": "Checking your work: Does it make sense?\nAfter running your test, ask:\n\n\n\nDoes the sample size match my study design?\n\nPaired: Should see n = number of pairs\nIndependent: Should see n1 + n2 = total people\n\nDo the means make sense?\n\nCheck that group means match your data summaries\n\nIs the SE reasonable?\n\nPaired tests usually have smaller SE (less variability)\nIndependent tests have larger SE (more variability)\n\nDoes the conclusion answer the research question?\n\nMake sure you‚Äôre interpreting the right comparison"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#summary-paired-vs.-independent",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#summary-paired-vs.-independent",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Summary: Paired vs.¬†Independent",
    "text": "Summary: Paired vs.¬†Independent\nPaired Data:\n\nSame people or matched pairs\nCalculate differences first\nUse: t.test(differences, mu = 0) or t.test(x, y, paired = TRUE)\nSE: \\(\\frac{s_d}{\\sqrt{n}}\\)\ndf: \\(n - 1\\)\n\n\n\nIndependent Samples:\n\nDifferent people in each group\nCompare two means directly\nUse: t.test(outcome ~ group, data = ...)\nSE: \\(\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\)\ndf: varies (Welch formula; see R output)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#key-takeaways",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#key-takeaways",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nStudy design determines analysis\n\nPaired or independent is about how data were collected\nCannot change after the fact!\n\nPaired tests are more powerful\n\nWhen appropriate, pairing reduces variability\nSmaller SE ‚Üí easier to detect true effects\n\nBoth tests follow same logic\n\nState hypotheses\nCalculate test statistic\nFind p-value\nMake conclusion\n\nAlways check assumptions\n\nIndependence (within or between pairs)\nApproximate normality (or large n)"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means.html#looking-ahead",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means.html#looking-ahead",
    "title": "Comparing Two Means: Paired and Independent Samples",
    "section": "Looking ahead",
    "text": "Looking ahead\n\n\nNext time:\n\nMidterm review\n\n\n\n\nBMSC 620 | Comparing Two Means"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#where-we-are",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#where-we-are",
    "title": "Probability and Conditional Probability",
    "section": "Where we are",
    "text": "Where we are\nOn Monday we worked with:\n\nfrequency tables\nrow and column percentages\ncontingency tables\n\nToday we formalize those ideas using probability notation."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#learning-goals",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#learning-goals",
    "title": "Probability and Conditional Probability",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of class, you should be able to:\n\nInterpret probabilities using notation\nDistinguish joint, marginal, and conditional probabilities\nCompute conditional probabilities from tables\nUnderstand when events are independent"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-is-probability",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-is-probability",
    "title": "Probability and Conditional Probability",
    "section": "What is probability?",
    "text": "What is probability?\nA probability is a number between 0 and 1 that describes how likely an event is.\n\n0 = impossible\n1 = certain\n\nA more technical definition:\n\nprobability of an outcome is the proportion of times the outcome would occur if the random phenomenon could be observed an infinite number of times."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#probability-notation",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#probability-notation",
    "title": "Probability and Conditional Probability",
    "section": "Probability notation",
    "text": "Probability notation\n\n\nWe write probabilities using:\n\\[\nP(A)\n\\]\nwhich means: the probability that event \\(A\\) occurs\n\n\nExamples:\n\n\\(P(\\text{Heads})\\)\n\\(P(\\text{Rolling a 6})\\)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#probability-notation-continued",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#probability-notation-continued",
    "title": "Probability and Conditional Probability",
    "section": "Probability notation (continued)",
    "text": "Probability notation (continued)\n¬†\nIf an event A occurs m times out of a total of n identical trials, then\n\\[\nP(A) = \\frac{m}{n}\n     = \\frac{\\text{number of times } A \\text{ occurs}}{\\text{number of trials}}\n\\]\nExamples:\n\nFlip a fair coin 10 times and record the proportion of heads.\nRolling a six-sided die lots of times, and recording proportion of times a 6 appears."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#is-the-coin-fair",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#is-the-coin-fair",
    "title": "Probability and Conditional Probability",
    "section": "Is the coin fair?",
    "text": "Is the coin fair?\n\n\n\nWe can think of flipping a coin.\n\nThere are two possible outcomes (heads or tails).\nThe probability of getting heads is 0.5.\n\n\n\n\n\nIf we flip the coin 10 times, it is not certain that we will get 5 heads.\nHowever, if we flip it enough times, we will get heads 50% of the flips.\n\n\n\n\nFun ‚ÄúSeeing Theory‚Äù demonstration!"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#law-of-large-numbers-intuition",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#law-of-large-numbers-intuition",
    "title": "Probability and Conditional Probability",
    "section": "Law of Large Numbers (intuition)",
    "text": "Law of Large Numbers (intuition)\n\nImpractical to conduct ‚Äúinfinitely‚Äù many trials to determined probabilities\nInstead estimate probabilities using the proportion (of times an event occurs) from ‚Äúlarge‚Äù samples\n\nLaw of large numbers If we repeat a random experiment many times:\n\nthe long-run proportion of times an event occurs\napproaches the true probability\n\nThis is why we interpret probability as a long-run relative frequency."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#complement-rule",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#complement-rule",
    "title": "Probability and Conditional Probability",
    "section": "Complement rule",
    "text": "Complement rule\nIf \\(A\\) is an event, then:\n\\[\nP(A^c) = 1 - P(A)\n\\]\nExample:\n\nIf \\(P(\\text{Rain}) = 0.3\\)\nthen \\(P(\\text{No rain}) = 0.7\\)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#disjoint-events",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#disjoint-events",
    "title": "Probability and Conditional Probability",
    "section": "Disjoint events",
    "text": "Disjoint events\nTwo events are disjoint if they cannot occur at the same time.\nIf \\(A\\) and \\(B\\) are disjoint:\n\\[\nP(A \\text{ or } B) = P(A) + P(B)\n\\]\n\nAlso use the term mutually exclusive to mean disjoint.\nCan see ‚Äúor‚Äù represented by the \\(\\cup\\) symbol. So \\(P(A \\cup B)\\)."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-rolling-a-die",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-rolling-a-die",
    "title": "Probability and Conditional Probability",
    "section": "Example: rolling a die",
    "text": "Example: rolling a die\nLet:\n\n\\(A\\) = rolling a 1\n\\(B\\) = rolling a 6\n\nThese are disjoint.\n\\[\nP(A \\text{ or } B) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#k-disjoint-outcomes",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#k-disjoint-outcomes",
    "title": "Probability and Conditional Probability",
    "section": "\\(k\\) disjoint outcomes",
    "text": "\\(k\\) disjoint outcomes\nIf there are \\(k\\) disjoint outcomes \\(A_1\\), ‚Ä¶, \\(A_k\\), then the probability that either one of these outcomes will occur is \\[P(A_1) + P(A_2) + \\cdots + P(A_k)\\] Example: probability of rolling a 1, 2, 3, 4, 5, or 6.\n\\[\n\\begin{aligned}\nP(1 \\text{ or } 2\\text{ or } 3\\text{ or } 4\\text{ or } 5\\text{ or } 6) &= P(1) + P(2) + P(3) + P(4) + P(5) + P(6) \\\\\n&= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} \\\\\n&= 1\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#textbooks-die-rolling-example",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#textbooks-die-rolling-example",
    "title": "Probability and Conditional Probability",
    "section": "Textbook‚Äôs die rolling example",
    "text": "Textbook‚Äôs die rolling example\n\n\nLet:\n\n\\(A\\) = rolling a 1 or 2\n\\(B\\) = rolling a 4 or 6\n\n\n\n\\[\nP(A \\text{ or } B) = P(A) + P(B) = \\frac{2}{6} + \\frac{2}{6} = \\frac{2}{6} = \\frac{2}{3}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#non-disjoint-events",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#non-disjoint-events",
    "title": "Probability and Conditional Probability",
    "section": "Non-disjoint events",
    "text": "Non-disjoint events\n\n\nWhat if events CAN occur at the same time?\n\n\nExample:\n\nDrawing a card that is a diamond\nDrawing a card that is a face card (Jack, Queen, King)\n\n\n\nThese events overlap - a card can be both!"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-addition-rule",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-addition-rule",
    "title": "Probability and Conditional Probability",
    "section": "General Addition Rule",
    "text": "General Addition Rule\n\n\nIf \\(A\\) and \\(B\\) are any two events (disjoint or not):\n\\[\nP(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\n\\]\nWe subtract \\(P(A \\text{ and } B)\\) because those outcomes were counted twice.\n¬†\nThis formula is sometimes written:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-cards",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-cards",
    "title": "Probability and Conditional Probability",
    "section": "Example: Cards",
    "text": "Example: Cards\n\n\\(P(\\text{diamond}) = \\frac{13}{52}\\)\n\\(P(\\text{face card}) = \\frac{12}{52}\\)\n\\(P(\\text{diamond and face card}) = \\frac{3}{52}\\) (J‚ô¶, Q‚ô¶, K‚ô¶)\n\n\\[\n\\begin{aligned}\nP(\\text{diamond or face card}) &= \\frac{13}{52} + \\frac{12}{52} - \\frac{3}{52} \\\\\n&= \\frac{22}{52}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#dice-again",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#dice-again",
    "title": "Probability and Conditional Probability",
    "section": "Dice again",
    "text": "Dice again\n\n\nLet:\n\n\\(A\\) = rolling a 1 or 2\n\\(D\\) = rolling a 2 or 3\n\n\\[\n\\begin{aligned}\nP(\\text{A or D}) &= \\frac{2}{6} + \\frac{2}{6} - \\frac{1}{6} \\\\\n&= \\frac{3}{6} \\\\\n&= \\frac{1}{2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-addition-rule-when-events-are-disjoint",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-addition-rule-when-events-are-disjoint",
    "title": "Probability and Conditional Probability",
    "section": "General Addition Rule when events are disjoint",
    "text": "General Addition Rule when events are disjoint\n\n\nGeneral Addition Rule again\n\\[\nP(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\n\\]\nIf events are disjoint, then \\(P(A \\text{ and } B) = 0\\), and we get the same result we saw before for disjoint events.\n\\[\nP(A \\text{ or } B) = P(A) + P(B)\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#connecting-back-to-monday",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#connecting-back-to-monday",
    "title": "Probability and Conditional Probability",
    "section": "Connecting back to Monday",
    "text": "Connecting back to Monday\nRemember the contingency tables from Monday?\n\nWe calculated row proportions and column proportions\nToday we‚Äôre going to give these formal names using probability notation\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n106\n149\n98\n353\n\n\nMale\n67\n112\n63\n242\n\n\nTotal\n173\n261\n161\n595"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#a-simpler-example-for-today",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#a-simpler-example-for-today",
    "title": "Probability and Conditional Probability",
    "section": "A simpler example for today",
    "text": "A simpler example for today\nFor teaching purposes, let‚Äôs work with a simpler 2√ó2 table:\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n180\n270\n\n\nTest -\n10\n720\n730\n\n\nTotal\n100\n900\n1000\n\n\n\nThis represents 1,000 patients who were tested for a disease."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#joint-probabilities",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#joint-probabilities",
    "title": "Probability and Conditional Probability",
    "section": "Joint probabilities",
    "text": "Joint probabilities\n\n\nJoint probabilities involve two events happening together.\n\n\n\n\nExamples:\n\n\\(P(\\text{Disease and Test +}) = \\textcolor{red}{90} / 1000\\)\n\\(P(\\text{No Disease and Test -}) = \\textcolor{blue}{720} / 1000\\)\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n180\n270\n\n\nTest -\n10\n720\n730\n\n\nTotal\n100\n900\n1000"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-probabilities",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-probabilities",
    "title": "Probability and Conditional Probability",
    "section": "Marginal probabilities",
    "text": "Marginal probabilities\n\n\nMarginal probabilities ignore the other variable.\n\n\nExamples:\n\n\\(P(\\text{Disease}) = \\textcolor{red}{100} / 1000\\)\n\\(P(\\text{Test +}) = \\textcolor{blue}{270} / 1000\\)\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n180\n270\n\n\nTest -\n10\n720\n730\n\n\nTotal\n100\n900\n1000"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-vs-joint",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-vs-joint",
    "title": "Probability and Conditional Probability",
    "section": "Marginal vs Joint",
    "text": "Marginal vs Joint\nIt can help to remember when looking at a table that:\n\nJoint probability: intersection of row and column\nMarginal probability: row or column total"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-vs-joint-vs-conditional",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#marginal-vs-joint-vs-conditional",
    "title": "Probability and Conditional Probability",
    "section": "Marginal vs Joint vs Conditional",
    "text": "Marginal vs Joint vs Conditional\nFrom the table:\n\nMarginal: \\(P(\\text{Disease}) = 100 / 1000\\) (ignore test results)\nJoint: \\(P(\\text{Disease and Test +}) = 90 / 1000\\) (both happening)\nConditional: \\(P(\\text{Disease} \\mid \\text{Test +}) = ?\\) (we‚Äôll calculate next)\n\nKey difference: Marginal ignores other variables, conditional focuses within a subgroup."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#conditional-probabilities",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#conditional-probabilities",
    "title": "Probability and Conditional Probability",
    "section": "Conditional probabilities",
    "text": "Conditional probabilities\n\n\nConditional probability answers:\nGiven that \\(B\\) occurred, how likely is \\(A\\)?\n\n\nNotation:\n\\[\nP(A \\mid B)\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#definition-of-conditional-probability",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#definition-of-conditional-probability",
    "title": "Probability and Conditional Probability",
    "section": "Definition of conditional probability",
    "text": "Definition of conditional probability\n\\[\nP(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)}\n\\]\n\n\nThis is just a restricted proportion.\n\nWe‚Äôre only looking at cases where \\(B\\) occurred (the denominator)\nThen asking: of those cases, how many also have \\(A\\)?\nWe‚Äôve ‚Äúrestricted‚Äù our view to just the \\(B\\) group\n\n\n\n\nExample: \\(P(\\text{Disease} \\mid \\text{Test +})\\)\n\nDenominator: only people who tested positive\nNumerator: of those, how many have disease?\nWe‚Äôve restricted to the ‚ÄúTest+‚Äù subgroup"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-from-the-table",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-from-the-table",
    "title": "Probability and Conditional Probability",
    "section": "Example from the table",
    "text": "Example from the table\n\n\nWhat is \\(P(\\text{Disease} \\mid \\text{Test +})\\)?\n\n\n\n\n\\[\n\\begin{aligned}\nP(\\text{Disease} \\mid \\text{Test +}) &= \\frac{P(Disease \\text{ and } Test +)}{P(Test +)} \\\\\n&= \\frac{\\textcolor{red}{90} / 1000}{\\textcolor{blue}{270} / 1000} \\\\\n&= \\frac{\\textcolor{red}{90}}{\\textcolor{blue}{270}} \\\\\n&\\approx 0.333\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n180\n270\n\n\nTest -\n10\n720\n730\n\n\nTotal\n100\n900\n1000\n\n\n\n\n\n\nInterpretation: Among those who tested positive, about 33% have the disease."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#this-is-what-you-did-monday",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#this-is-what-you-did-monday",
    "title": "Probability and Conditional Probability",
    "section": "This is what you did Monday!",
    "text": "This is what you did Monday!\n\n\nWhen you calculated row proportions:\n\nYou were computing \\(P(\\text{genotype} \\mid \\text{sex})\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n106\n149\n98\n353\n\n\nMale\n67\n112\n63\n242\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\nTotal\n\n\n\n\nFemale\n0.30\n0.42\n0.28\n1.00\n\n\nMale\n0.28\n0.46\n0.26\n1.00"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#this-is-what-you-did-monday-1",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#this-is-what-you-did-monday-1",
    "title": "Probability and Conditional Probability",
    "section": "This is what you did Monday!",
    "text": "This is what you did Monday!\n\n\nWhen you calculated column proportions:\n\nYou were computing \\(P(\\text{sex} \\mid \\text{genotype})\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\n\n\n\n\nFemale\n106\n149\n98\n\n\nMale\n67\n112\n63\n\n\nTotal\n173\n261\n161\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsex/actn3.r577x\nCC\nCT\nTT\n\n\n\n\nFemale\n0.61\n0.57\n0.61\n\n\nMale\n0.39\n0.43\n0.39\n\n\nTotal\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe formula just formalizes what you already know how to do."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-is-independence",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-is-independence",
    "title": "Probability and Conditional Probability",
    "section": "What is independence?",
    "text": "What is independence?\n\n\nTwo events are independent if knowing one provides no information about the other.\n\n\nExamples:\n\nFlipping a coin and rolling a die (independent)\nYour height and the weather tomorrow (independent)\nHaving a disease and testing positive (NOT independent!)\nSmoking and lung cancer (NOT independent!)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#checking-for-independence",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#checking-for-independence",
    "title": "Probability and Conditional Probability",
    "section": "Checking for independence",
    "text": "Checking for independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if:\n\\[P(A \\text{ and } B) = P(A) \\times P(B)\\]\nOR equivalently:\n\\[P(A \\mid B) = P(A)\\]\n\n\nWhy are these equivalent? Starting with the conditional probability formula:\n\\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A) \\times P(B)}{P(B)} = P(A)\\]\n\n\nKey idea: ‚ÄúKnowing \\(B\\) doesn‚Äôt change the probability of \\(A\\)‚Äù"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-independence",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-independence",
    "title": "Probability and Conditional Probability",
    "section": "Example: Independence",
    "text": "Example: Independence\n\n\nRoll two dice. Are the outcomes independent?\n\n\n\n\\(P(\\text{first die} = 1) = \\frac{1}{6}\\)\n\\(P(\\text{second die} = 1) = \\frac{1}{6}\\)\n\\(P(\\text{both} = 1) = \\frac{1}{36}\\)\n\n\n\nCheck: \\(\\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\\) ‚úì\n\n\nThe events are independent."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-not-independent",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-not-independent",
    "title": "Probability and Conditional Probability",
    "section": "Example: NOT independent",
    "text": "Example: NOT independent\n\n\nFrom our medical test example:\n\n\\(P(\\text{Disease}) = \\frac{100}{1000} = 0.10\\)\n\\(P(\\text{Disease} \\mid \\text{Test +}) = \\frac{90}{270} \\approx 0.33\\)\n\n\n\nSince \\(0.33 \\neq 0.10\\), the events are NOT independent.\n\n\nTesting positive changes the probability of disease! This is why tests are useful."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-multiplication-rule",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#general-multiplication-rule",
    "title": "Probability and Conditional Probability",
    "section": "General multiplication rule",
    "text": "General multiplication rule\nThe General multiplication rule\n\n\n\\[\nP(A \\text{ and } B) = P(A \\mid B) \\times P(B)\n\\]\nwhich follows from rearranging the definition of conditional probability:\n\\[\nP(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)} \\rightarrow P(A|B)P(B) = P(A \\text{ and } B)\n\\]\n\n\nThis connects joint and conditional probabilities."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-multiplication-rule",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#example-multiplication-rule",
    "title": "Probability and Conditional Probability",
    "section": "Example: Multiplication rule",
    "text": "Example: Multiplication rule\n\n\nWhat is the probability of randomly selecting a person who is male AND has hypertension?\n\n\nGiven:\n\n\\(P(\\text{male}) = 0.50\\)\n\\(P(\\text{hypertension} \\mid \\text{male}) = 0.18\\)\n\n\n\n\\[\n\\begin{aligned}\nP(\\text{male and hypertension}) &= P(\\text{hypertension} \\mid \\text{male}) \\times P(\\text{male}) \\\\\n&= 0.18 \\times 0.50 \\\\\n&= 0.09\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#multiplication-rule-for-independent-events",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#multiplication-rule-for-independent-events",
    "title": "Probability and Conditional Probability",
    "section": "Multiplication rule for independent events",
    "text": "Multiplication rule for independent events\n\n\nWhen events are independent, the multiplication rule simplifies:\n\\[\nP(A \\text{ and } B) = P(A) \\times P(B)\n\\]\n\n\nWhy? Because when events are independent, \\(P(A \\mid B) = P(A)\\).\n\n\nExample: Rolling two dice\n\\[\nP(\\text{both are 6}) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\n\\]"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#a-medical-testing-scenario",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#a-medical-testing-scenario",
    "title": "Probability and Conditional Probability",
    "section": "A medical testing scenario",
    "text": "A medical testing scenario\n\n\nGiven information:\n\nPrevalence (disease rate in population) = 1%\nSensitivity (correct positive test result when disease present) = 90%\nSpecificity (correct negative test result when disease absent) = 90%\n\n\n\nQuestion: If someone tests positive, what‚Äôs the probability they actually have the disease?\n\n\nThis is asking for: \\(P(\\text{Disease} \\mid \\text{Test +})\\)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#build-a-contingency-table",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#build-a-contingency-table",
    "title": "Probability and Conditional Probability",
    "section": "Build a contingency table",
    "text": "Build a contingency table\n\n\nLet‚Äôs think about 10,000 people:\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n?\n?\n?\n\n\nTest -\n?\n?\n?\n\n\nTotal\n?\n?\n10,000\n\n\n\n\n\nLet‚Äôs fill this in step by step‚Ä¶"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#building-the-table-using-what-we-learned",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#building-the-table-using-what-we-learned",
    "title": "Probability and Conditional Probability",
    "section": "Building the table using what we learned",
    "text": "Building the table using what we learned\n\n\nWe‚Äôll use:\n\nMarginal probabilities (prevalence)\nConditional probabilities (sensitivity, specificity)\n\nMultiplication rule: \\(P(A \\text{ and } B) = P(A \\mid B) \\times P(B)\\)\n\n\n\nThis shows how all the concepts work together!"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-1-how-many-have-the-disease",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-1-how-many-have-the-disease",
    "title": "Probability and Conditional Probability",
    "section": "Step 1: How many have the disease?",
    "text": "Step 1: How many have the disease?\n\n\nPrevalence = 1%, so out of 10,000 people:\n\n\n\n\n\n\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n?\n?\n?\n\n\nTest -\n?\n?\n?\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\n1% of 10,000 = 100 people have disease\n99% of 10,000 = 9,900 people don‚Äôt have disease"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-2-among-those-with-disease-how-many-test-positive",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-2-among-those-with-disease-how-many-test-positive",
    "title": "Probability and Conditional Probability",
    "section": "Step 2: Among those WITH disease, how many test positive?",
    "text": "Step 2: Among those WITH disease, how many test positive?\n\n\nSensitivity = 90%, so of the 100 with disease:\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n?\n?\n\n\nTest -\n10\n?\n?\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\n90% of 100 = 90 test positive (true positives)\n\nUsing multiplication rule: \\(P(\\text{Test +} \\mid \\text{Disease}) \\times 100\\)\n\n10% of 100 = 10 test negative (false negatives)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-3-among-those-without-disease-how-many-test-positive",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-3-among-those-without-disease-how-many-test-positive",
    "title": "Probability and Conditional Probability",
    "section": "Step 3: Among those WITHOUT disease, how many test positive?",
    "text": "Step 3: Among those WITHOUT disease, how many test positive?\n\n\nSpecificity = 90% (so 10% test positive when they don‚Äôt have disease):\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n990\n?\n\n\nTest -\n10\n8,910\n?\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\n10% of 9,900 = 990 test positive (false positives)\n\nUsing multiplication rule: \\(P(\\text{Test +} \\mid \\text{No Disease}) \\times 9,900\\)\n\n90% of 9,900 = 8,910 test negative (true negatives)"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-4-fill-in-the-row-totals",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#step-4-fill-in-the-row-totals",
    "title": "Probability and Conditional Probability",
    "section": "Step 4: Fill in the row totals",
    "text": "Step 4: Fill in the row totals\n\n\nNow we can complete the table:\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n990\n1,080\n\n\nTest -\n10\n8,910\n8,920\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\nTotal positive tests: 90 + 990 = 1,080\nTotal negative tests: 10 + 8,910 = 8,920"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#calculate-the-ppv",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#calculate-the-ppv",
    "title": "Probability and Conditional Probability",
    "section": "Calculate the PPV",
    "text": "Calculate the PPV\n\n\n\\[\n\\begin{aligned}\nP(\\text{Disease} \\mid \\text{Test +}) &= \\frac{\\textcolor{red}{90}}{\\textcolor{purple}{1,080}} \\\\\n&\\approx 0.083 \\\\\n&= 8.3\\%\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n990\n1,080\n\n\nTest -\n10\n8,910\n8,920\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\nOnly about 8% of positive tests indicate disease!"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#key-takeaway",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#key-takeaway",
    "title": "Probability and Conditional Probability",
    "section": "Key takeaway",
    "text": "Key takeaway\n\n\nEven a good test (90% sensitivity, 90% specificity) can have a low PPV when the condition is rare.\n\n\nWhy?\n\nOnly 100 people have the disease\nBut 990 people test positive incorrectly\nThe false positives outnumber the true positives!\n\n\n\nBase rates matter.\n\n\nNext class: We‚Äôll see how Bayes‚Äô theorem formalizes this calculation."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-to-remember",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_and_conditional_probability.html#what-to-remember",
    "title": "Probability and Conditional Probability",
    "section": "What to remember",
    "text": "What to remember\n\n\n\nProbability is a long-run relative frequency (between 0 and 1)\nAddition rules: disjoint vs non-disjoint events\nContingency tables show joint and marginal probabilities\nConditional probability: \\(P(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)}\\)\n\nThis formalizes the row/column proportions you did Monday!\n\nIndependence: \\(P(A \\mid B) = P(A)\\) (knowing \\(B\\) doesn‚Äôt change \\(A\\))\nMultiplication rule: \\(P(A \\text{ and } B) = P(A \\mid B) \\times P(B)\\)\nBase rates matter for interpreting test results\n\n\n\nNext class (after MLK Day): Bayes‚Äô theorem and doing this in R with tidyverse!\n\n\n\nBMSC 620 | Probability"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#welcome-to-bmsc-620",
    "href": "lessons/00_welcome/00_welcome.html#welcome-to-bmsc-620",
    "title": "Welcome to BMSC 620",
    "section": "Welcome to BMSC 620",
    "text": "Welcome to BMSC 620\n\nEmile Latour, MS\nBiostatistician, OHSU Knight Cancer Institute\n¬†\nThis course builds on prior versions developed by\nMeike Niederhausen and Nicky Wakim, with updates and revisions for Winter 2026."
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#some-important-tasks",
    "href": "lessons/00_welcome/00_welcome.html#some-important-tasks",
    "title": "Welcome to BMSC 620",
    "section": "Some important tasks",
    "text": "Some important tasks\n\n\nBookmark the course website\nhttps://emilelatour.github.io/BMSC_620_W26/\n\n¬†\n\nComplete Homework 0 by Sunday at 11:00 pm\n\nGet comfortable with RStudio and Quarto\nMake sure you can render a document successfully\nThis assignment is graded for completion only\n\n\n¬†\n\nMake sure you have access to the textbook\n\nDetails are posted on the course website"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-homepage",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-homepage",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Homepage",
    "text": "Let‚Äôs visit the website: Homepage"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#course-information-on-the-website",
    "href": "lessons/00_welcome/00_welcome.html#course-information-on-the-website",
    "title": "Welcome to BMSC 620",
    "section": "Course information on the website",
    "text": "Course information on the website\n\nSyllabus\n\nWhat this course is about\nHow grading and homework work\nExams, attendance, and course policies\n\nInstructors\n\nContact information\nOffice hours\nHow to get help\n\nResources\n\nR and RStudio installation instructions\nCourse materials and datasets\nAdditional support resources"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-syllabus",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-syllabus",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Syllabus",
    "text": "Let‚Äôs visit the website: Syllabus"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-instructors",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-instructors",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Instructors",
    "text": "Let‚Äôs visit the website: Instructors"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-resources",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-resources",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Resources",
    "text": "Let‚Äôs visit the website: Resources"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#how-this-course-runs-on-the-website",
    "href": "lessons/00_welcome/00_welcome.html#how-this-course-runs-on-the-website",
    "title": "Welcome to BMSC 620",
    "section": "How this course runs on the website",
    "text": "How this course runs on the website\n\nSchedule\n\nBig-picture view of topics and due dates\nUpdated if anything changes\n\nWeekly materials\n\nWhat to read or review\nSlides, code, and links for each class\n\nHomework\n\nAssignment templates\nDue dates and grading expectations\n\nExams\n\nMidterm and final format\nTiming, coverage, and policies"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-schedule",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-schedule",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Schedule",
    "text": "Let‚Äôs visit the website: Schedule"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-weekly-materials",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-weekly-materials",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Weekly materials",
    "text": "Let‚Äôs visit the website: Weekly materials"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-homework",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-homework",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Homework",
    "text": "Let‚Äôs visit the website: Homework"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-exams",
    "href": "lessons/00_welcome/00_welcome.html#lets-visit-the-website-exams",
    "title": "Welcome to BMSC 620",
    "section": "Let‚Äôs visit the website: Exams",
    "text": "Let‚Äôs visit the website: Exams"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#structure-for-this-course",
    "href": "lessons/00_welcome/00_welcome.html#structure-for-this-course",
    "title": "Welcome to BMSC 620",
    "section": "Structure for this course",
    "text": "Structure for this course\n\nLearning the core tools to understand and interpret statistics\n\n¬†\n\nSome pieces may feel abstract or disconnected at first ‚Äî that‚Äôs normal\n\n¬†\n\nThe goal is to build a toolbox that lets you analyze data and explain what the results mean"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#let-me-know-if-you-have-questions",
    "href": "lessons/00_welcome/00_welcome.html#let-me-know-if-you-have-questions",
    "title": "Welcome to BMSC 620",
    "section": "Let me know if you have questions",
    "text": "Let me know if you have questions\nOr if you notice:\n\nsomething unclear\nsomething confusing\nor something that contradicts the course site"
  },
  {
    "objectID": "lessons/00_welcome/00_welcome.html#thats-it-for-logistics",
    "href": "lessons/00_welcome/00_welcome.html#thats-it-for-logistics",
    "title": "Welcome to BMSC 620",
    "section": "That‚Äôs it for logistics",
    "text": "That‚Äôs it for logistics\n\nThe course website is your home base\nHomework 0 is due Sunday at 11:00 pm\nReach out early if something is confusing\n\nLet‚Äôs shift gears and start the course.\n\n\n\nBMSC 620"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "",
    "text": "Note\n\n\n\nYou do not need to read every section below. Each heading addresses a specific muddy point raised in class. Feel free to focus on the ones most relevant to you.\nThank you for the thoughtful feedback. Most of you found the pace about right, and I‚Äôm glad the Z vs T distinction, distribution visualizations, and common-mistake callouts were helpful. Below I address the most common muddy points."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#critical-values-and-margin-of-error",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#critical-values-and-margin-of-error",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Critical Values and Margin of Error",
    "text": "Critical Values and Margin of Error\nQ: ‚ÄúI still don‚Äôt understand what a critical value is‚Äù\nQ: ‚ÄúWhen we got to confidence intervals, especially when critical values were introduced I got lost. Specifically I‚Äôm having a hard time understanding logically how the margin of error contributes to confidence intervals.‚Äù\nA critical value (like \\(z^*\\) or \\(t^*\\)) is just a multiplier that determines how wide your confidence interval needs to be to achieve your desired confidence level.\nIt comes from the sampling distribution, not from your raw data.\nThink of it this way:\n\nWe start with a point estimate: \\(\\bar{x}\\) = 65 inches (our best guess for average height)\nWe know there‚Äôs uncertainty: SE = 0.5 inches\nQuestion: How many SEs should we go above and below our estimate to be 95% confident we‚Äôve captured the true mean?\nAnswer: About 2 SEs (more precisely, 1.96 or ~2 for large samples)\n\nThat multiplier (1.96) is the critical value - it tells you ‚Äúgo this many standard errors in each direction.‚Äù\nThe margin of error is: critical value √ó SE\nSo if \\(t^* = 2.0\\) and \\(SE = 0.5\\), then \\(\\text{margin of error} = 2.0 √ó 0.5 = 1.0 inch\\).\nWhy does this work? Because of how the normal/t-distribution works:\n\n95% of the probability sits within ¬±1.96 standard deviations of the mean\nSo if we go ¬±1.96 SEs from our sample mean, we‚Äôll capture Œº about 95% of the time across repeated samples\n\nIn R:\n\n# For a 95% CI with df = 30\nqt(0.975, df = 30)  # Returns ~2.04 (the critical value)\n\n[1] 2.042272\n\n# We use 0.975 because we want 2.5% in each tail (95% in middle)\n\nThe critical value gets smaller as your sample size increases (because you have more certainty)."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#confidence-interval-interpretation",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#confidence-interval-interpretation",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Confidence Interval Interpretation",
    "text": "Confidence Interval Interpretation\nQ: ‚ÄúInterpreting CI was not too clear to me‚Äù\nThe key insight: The parameter is fixed, the interval is random.\nCORRECT interpretation: ‚ÄúWe are 95% confident that the true population mean Œº is between 64.5 and 65.5 inches.‚Äù\nWhat this really means: If we repeated this study 100 times and calculated 100 different CIs, about 95 of them would contain the true Œº.\nINCORRECT interpretation: ‚ÄúThere‚Äôs a 95% probability that Œº is in this interval.‚Äù\nWhy this is wrong: Œº is a fixed (but unknown) value. Once you‚Äôve calculated your CI, it either contains Œº or it doesn‚Äôt - there‚Äôs no probability about it. The randomness is in the sampling process, not in Œº.\nHelpful analogy: Imagine Œº is a bullseye on a target that‚Äôs hidden behind a curtain. Each sample is like throwing a net at the target. The net has a specific size (your CI). If you throw 100 nets, about 95 of them will catch the bullseye. But once you‚Äôve thrown your net, it either caught the target or it didn‚Äôt - you just don‚Äôt know which.\nThe ‚Äú95% confidence‚Äù refers to the long-run success rate of the procedure, not the probability for one specific interval."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#sample-distribution-vs.-sampling-distribution",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#sample-distribution-vs.-sampling-distribution",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Sample Distribution vs.¬†Sampling Distribution",
    "text": "Sample Distribution vs.¬†Sampling Distribution\nQ: ‚ÄúI‚Äôm still a little confused about the difference between the sample and sampling distribution. Which one comes up more often/is more relevant?‚Äù\nGreat question! The sampling distribution is way more important and comes up constantly.\nSample distribution:\n\nThe distribution of values in YOUR specific sample\nExample: Heights of the 50 people you actually measured\nWhat you see when you do hist(sample_data$height)\nYou see this once per study\n\nSampling distribution:\n\nThe distribution of sample means if you repeated the study infinitely\nThis is theoretical - you never actually see it\nBut it‚Äôs what lets you do inference!\nThe CLT tells you its shape (approximately normal for large n)\n\nWhich is more relevant? The sampling distribution!\nWhy? Because when you calculate a CI or do a hypothesis test, you‚Äôre asking: ‚ÄúIf I repeated this study many times, how much would my sample mean vary?‚Äù That‚Äôs the sampling distribution.\nYou use your one sample to estimate properties of the sampling distribution:\n\n\\(SE = \\frac{s}{\\sqrt{n}}\\) estimates the standard deviation of the sampling distribution\nThen you use that to build your CI\n\nIn practice:\n\nYou collect one sample ‚Üí calculate one \\(\\bar{x}\\) and one \\(s\\)\nYou use those to estimate properties of the sampling distribution (via SE)\nYou use the sampling distribution to make inferences about \\(\\mu\\)\n\nThe sample distribution tells you about your sample. The sampling distribution tells you how reliable your estimate is.\nIf you remember only one thing for this course: all confidence intervals and hypothesis tests live on the sampling distribution."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#degrees-of-freedom",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#degrees-of-freedom",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nQ: ‚ÄúI am slightly unclear on degrees of freedom. If you start with sample # -1 how would you run out of degrees of freedom especially if it is a large dataset‚Äù\nQ: ‚ÄúI‚Äôm still a bit confused what you mean that the mean uses up a degree of freedom. I don‚Äôt really understand what degrees of freedom are.‚Äù\nDegrees of freedom (df) = the number of independent pieces of information you have left after estimating something.\nWhy n-1 instead of n?\nImagine you have 3 numbers and I tell you:\n\nTheir mean is 10\nTwo of the numbers are 8 and 12\nWhat‚Äôs the third number?\n\nYou can figure it out! It MUST be 10 (because (8 + 12 + 10)/3 = 10).\nOnce you know the mean and n-1 values, the last value is completely determined. So you only have n-1 ‚Äúfree‚Äù values that contain independent information.\nHow does the mean ‚Äúuse up‚Äù a degree of freedom?\nWhen you calculate the sample standard deviation (s), you use the formula:\n\\[s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\]\nYou‚Äôre calculating deviations from \\(\\bar{x}\\) (not from Œº). Since you had to estimate \\(\\bar{x}\\) from the same data, you ‚Äúused up‚Äù one piece of information. That leaves you with n-1 independent deviations. That‚Äôs why the t-distribution depends on df ‚Äî it reflects how much uncertainty remains.\nLarge datasets: You never ‚Äúrun out‚Äù of df. Larger samples simply have larger df. As n gets large, df gets large too, and the t-distribution looks almost identical to the normal distribution.\nPractical impact:\n\nSmall samples (n = 5, df = 4): t-distribution has heavy tails, wider CIs\nLarge samples (n = 100, df = 99): t-distribution ‚âà normal distribution, narrower CIs\n\nIn R:\n\n# t-distribution with df = 4 (small sample)\nqt(0.975, df = 4)  # Returns ~2.78\n\n[1] 2.776445\n\n# t-distribution with df = 99 (large sample)  \nqt(0.975, df = 99)  # Returns ~1.98 (very close to z* = 1.96)\n\n[1] 1.984217"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#why-95-for-confidence-intervals",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#why-95-for-confidence-intervals",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Why 95% for Confidence Intervals?",
    "text": "Why 95% for Confidence Intervals?\nQ: ‚ÄúWhy is 95% the most commonly used for confidence interval for biomedical research? Does it have to do with balancing size of the interval with confidence level? Am I thinking correctly that the intervals will be bigger at 99% than at 95%?‚Äù\nYes, you‚Äôre thinking correctly! 99% CIs are wider than 95% CIs.\nThe tradeoff:\n\nHigher confidence (99%) ‚Üí wider interval (less precise)\nLower confidence (90%) ‚Üí narrower interval (more precise)\n\nWhy 95%? It‚Äôs mostly convention, established early in the history of statistics:\n\nHistorical precedent: R.A. Fisher and other early statisticians popularized 0.05 as the significance level, which corresponds to 95% confidence\nReasonable balance: 95% gives you high confidence without making intervals so wide they‚Äôre useless\nField standard: Everyone uses it, so it‚Äôs easier to compare across studies\n\nIs 95% ‚Äúspecial‚Äù? Not really. In some fields:\n\nParticle physics uses 99.9999% (5-sigma rule) because errors are very costly\nSome exploratory research uses 90% to be less conservative\nClinical trials might use 99% for safety endpoints\n\nYour intuition is correct: There‚Äôs a balance between confidence and precision.\nExample:\n\n# For the same data (xÃÑ = 65, s = 3, n = 50)\n# 90% CI\n65 + qt(c(0.05, 0.95), df = 49) * (3/sqrt(50))\n\n[1] 64.2887 65.7113\n\n# Narrower interval\n\n# 95% CI  \n65 + qt(c(0.025, 0.975), df = 49) * (3/sqrt(50))\n\n[1] 64.14741 65.85259\n\n# Medium interval\n\n# 99% CI\n65 + qt(c(0.005, 0.995), df = 49) * (3/sqrt(50))\n\n[1] 63.86299 66.13701\n\n# Wider interval\n\nIn biomedical research: 95% is standard, but you might see 99% for safety-critical decisions or 90% for preliminary/exploratory analyses."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#three-distributions-keeping-them-straight",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#three-distributions-keeping-them-straight",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Three Distributions: Keeping Them Straight",
    "text": "Three Distributions: Keeping Them Straight\nQ: ‚ÄúThe 3 distributions were the least clear and when to use what‚Äù\nHere‚Äôs a comparison table to keep them straight:\n\n\n\n\n\n\n\n\n\nDistribution\nWhat it shows\nWhen you see it\nExample\n\n\n\n\nPopulation distribution\nAll values in the entire population\nAlmost never (you don‚Äôt measure everyone!)\nHeights of ALL adults in the US: Œº = 65‚Äù, œÉ = 3‚Äù\n\n\nSample distribution\nValues in your specific sample\nEvery time you collect data\nHeights of the 50 people YOU measured: \\(\\bar{x}\\) = 64.8‚Äù, s = 2.9‚Äù\n\n\nSampling distribution\nWhat sample means would look like if you repeated the study infinitely\nTheoretical (you never actually see this)\nDistribution of all possible \\(\\bar{x}\\) values from samples of size 50: mean = Œº, SD = œÉ/‚àön\n\n\n\nWhich one do you USE for inference? The sampling distribution!\nKey insight:\n\nYou have ONE sample (sample distribution)\nYou want to learn about the population (population distribution)\n\nYou use the sampling distribution to connect them (via CLT and CIs)\n\nIn practice:\n\nCollect your sample ‚Üí look at sample distribution (histogram of your data)\nCalculate \\(\\bar{x}\\) and s from your sample\nUse CLT to know the sampling distribution is approximately normal with mean \\(\\mu\\) and \\(SE = \\frac{s}{\\sqrt{n}}\\)\nUse the sampling distribution to build your CI\n\nCommon mistake to avoid: Don‚Äôt confuse the sample distribution (spread of your data) with the sampling distribution (spread of possible sample means). The sampling distribution is MUCH narrower because means are less variable than individual values."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-to-use-z-vs.-t-in-practice",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-to-use-z-vs.-t-in-practice",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "When to Use Z vs.¬†T in Practice",
    "text": "When to Use Z vs.¬†T in Practice\nQ: ‚Äúz and t distributions‚Äù\nQ: ‚ÄúI am unclear when z values are actually used with real life data.‚Äù\nSimple rule: In real research, you almost always use t.\nWhy? Because you almost never know œÉ (the true population standard deviation). If you truly knew œÉ exactly for your population, inference would be much less common, which is why this situation is rare in practice.\nWhen to use Z (rare):\n\nYou know the population SD (\\(\\sigma\\)) from extensive prior research\nExample: IQ scores (\\(\\sigma\\) = 15 is well established)\nExample: Standardized test scores where \\(\\sigma\\) is published\n\nWhen to use t (almost always):\n\nYou estimate the SD from your sample (use \\(s\\) instead of \\(\\sigma\\))\nThis is the typical situation in biomedical research\n\nExample scenarios:\n‚úÖ Use t: You measure blood pressure in 30 patients with a new treatment. You calculate \\(\\bar{x}\\) = 125 and s = 15 from your data.\n‚ùå Don‚Äôt use z: You don‚Äôt know œÉ for blood pressure in this population (you only have s from your sample)\n‚úÖ Could use z (but probably still use t): You measure IQ in 30 patients. You know from decades of research that œÉ = 15 for IQ in the general population.\nPractical advice: Just use t-based CIs for everything. As sample size increases, the t-distribution converges to the normal distribution anyway, so you‚Äôre not losing anything by using t.\nIn R:\n\n# t-based CI (standard approach)\nt.test(data$variable)$conf.int\n\n# You rarely need to manually use z"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#population-parameters-in-labbasic-science-research",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#population-parameters-in-labbasic-science-research",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Population Parameters in Lab/Basic Science Research",
    "text": "Population Parameters in Lab/Basic Science Research\nQ: ‚ÄúT-distributions makes sense to me when you have a clearly defined population (like humans) that can be sampled (height of n=50). What about lab work? I run n = 5 experiments and looking at stimulation of cells (for example). Would you ever know the population parameters for something like this? Would you theoretically have to test ALL the cells to get this?‚Äù\nQ: ‚ÄúMore of how this all applies to scenarios we may see in our work: I am unsure when the goal of a research question is to describe the data or estimate a population. I work in cell biology and do lots of quantitative microscopy, and when reporting results I am describing what I see in the sample of cells I imaged, is the goal then to extrapolate this to the general population of cells?‚Äù\nExcellent questions! The concept of ‚Äúpopulation‚Äù in lab research is more abstract but still applies.\nFor cell biology/microscopy:\nYour population is not all cells that exist in the universe, but rather:\n\nAll cells that COULD be generated under the same experimental conditions\nThe ‚Äúinfinite hypothetical‚Äù cells you could culture/image under identical protocols\nAll cells of this type under these specific conditions\n\nExample:\n\nYou image 50 cells in a microscopy experiment\nThose 50 cells are a SAMPLE\nThe POPULATION is ‚Äúall cells of this type cultured under these conditions‚Äù\nŒº = the true mean fluorescence intensity for this cell line under these conditions\nYou‚Äôll never measure ALL possible cells, but Œº exists conceptually\n\nDo you ever know Œº? No, basically never. You always estimate it from your sample.\nThe statistical framework still applies:\n\nYou have 5 independent experimental replicates (n = 5)\nYou calculate \\(\\bar{x}\\) (mean cell stimulation) and s (SD of your replicates)\nYou use df = 4, and the t-distribution to build a CI for Œº\nThis tells you about the ‚Äútrue‚Äù mean response of cells under these conditions\n\nWhen to use t-tests in lab work:\n‚úÖ Comparing treatment vs.¬†control in cell stimulation (n = 5 replicates per group) ‚úÖ Comparing fluorescence intensity across conditions (n = 50 cells imaged per condition) ‚úÖ Any situation where you have a sample and want to infer about the broader biological phenomenon\nKey insight: The ‚Äúpopulation‚Äù in basic science is often conceptual/theoretical rather than an actual enumerable group. But that‚Äôs okay! The statistics still work because you‚Äôre making inferences about what would happen if you repeated the experiment infinitely."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-to-report-se-vs.-sd-in-your-work",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-to-report-se-vs.-sd-in-your-work",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "When to Report SE vs.¬†SD in Your Work",
    "text": "When to Report SE vs.¬†SD in Your Work\nQ: ‚ÄúWould it then be appropriate to report SE over SD or would I still report SD?‚Äù\nQ: ‚ÄúThe semantics of standard error vs standard deviation have left me a little confused. The interpretation part for SE isn‚Äôt clicking to me for some reason.‚Äù\nDifferent purposes, both useful:\nRule of thumb: Use SD to describe variability in your data and SE (or a CI) to describe uncertainty in the mean.\nReport SD when:\n\nDescribing the variability in your sample/population\nShowing ‚Äúhow spread out are the individual values?‚Äù\nExample: ‚ÄúCell diameter was 12.3 Œºm (SD = 2.1 Œºm)‚Äù ‚Üí tells reader that individual cells vary by ~2 Œºm\n\nReport SE when:\n\nDescribing uncertainty in your ESTIMATE of the mean\nShowing ‚Äúhow confident are we in our estimate of the population mean?‚Äù\nExample: ‚ÄúMean cell diameter was 12.3 Œºm (SE = 0.3 Œºm)‚Äù ‚Üí tells reader that the true mean is probably very close to 12.3\n\nIn practice for cell biology/microscopy:\nYou often report both or use error bars to show uncertainty:\n\nBar plots with error bars = SE (shows precision of your mean estimate)\nText description = SD (shows biological variability)\n\nExample reporting:\n\n‚ÄúMean fluorescence intensity was 1250 AU (SD = 300 AU, n = 50 cells). This represents a statistically significant increase compared to control (mean = 900 AU, SE = 45 AU, p &lt; 0.001).‚Äù\n\nWhy both?\n\nSD (300) tells you: individual cells vary quite a bit\nSE (45) tells you: but we‚Äôre quite confident in the mean difference\n\nRemember:\n\nSD describes your data (larger is more variable)\nSE describes your uncertainty (larger is less certain)\nSE = SD/‚àön (so SE is always smaller than SD)\n\nCommon in papers:\n\nError bars in figures are often SEM or CIs (check journal conventions)\nText descriptions include both SD and n\n\nGoal:\n\nAre you describing the phenomenon? ‚Üí SD\nAre you making an inference about the population mean? ‚Üí SE\n\nFor your microscopy work: you‚Äôre doing both! You‚Äôre describing what you see (SD) AND extrapolating to the general population of cells (SE for uncertainty in your mean estimate)."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-and-why-to-use-clt",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#when-and-why-to-use-clt",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "When and Why to Use CLT",
    "text": "When and Why to Use CLT\nQ: ‚ÄúStill a little unclear on why you would want to use CLT and in what context it would be useful by itself? Also, how do you determine the degree of skew is too much skew and you need to increase n? How is that defined, other than eye-balling a histogram?‚Äù\nWhy CLT is useful:\nThe CLT allows you to do statistical inference even when your data are NOT normally distributed!\nExample:\n\nYou measure hospital length of stay (very right-skewed: most stays are short, few are very long)\nYour sample distribution looks nothing like a normal distribution\nBut: Because of CLT, you know that the sampling distribution of \\(\\bar{x}\\) IS approximately normal (if n is large enough)\nThis lets you use t-tests and CIs even though your raw data are skewed\n\nWhen is n ‚Äúlarge enough‚Äù?\nRules of thumb: These are heuristics, not strict rules. They‚Äôre meant to guide judgment, not replace it.\n\nn ‚â• 30 is the classic rule (works for most distributions)\nn &lt; 30 can still work if your data are not too skewed\nn &gt; 15 usually fine for symmetric distributions\nHighly skewed data might need n &gt; 50\n\nHow to assess skewness:\nBeyond eyeballing histograms‚Ä¶\n\nSkewness &lt; 1 and n ‚â• 15: probably fine\nSkewness between 1-2 and n ‚â• 30: should be okay\nSkewness &gt; 2: might need n &gt; 50, or consider transformations/non-parametric methods\n\nWhen CLT ‚Äúby itself‚Äù is useful:\nYou use CLT implicitly every time you:\n\nCalculate a CI for a mean (you assume the sampling distribution is normal)\nDo a t-test (same assumption)\nMake probability statements about sample means\n\nExample: ‚ÄúIf we sample 50 patients, what‚Äôs the probability our sample mean is within 2 units of the true mean?‚Äù CLT lets you answer this even if individual patient values are skewed."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#understanding-t-beyond-the-r-code",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#understanding-t-beyond-the-r-code",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Understanding t* Beyond the R Code",
    "text": "Understanding t* Beyond the R Code\nQ: ‚ÄúI‚Äôm also kind of confused on what the calculations for t* actually is beyond plugging it into the R code.‚Äù\nWhat t* actually represents:\nThe t* value tells you: ‚ÄúHow many standard errors away from the mean do I need to go to capture the middle X% of the t-distribution?‚Äù\nExample with 95% CI:\n\nqt(0.975, df = 20)  # Returns ~2.086\n\n[1] 2.085963\n\n\nThis means: ‚ÄúIn a t-distribution with 20 degrees of freedom, if I go ¬±2.086 standard errors from the mean, I‚Äôll capture 95% of the distribution.‚Äù\nWhy 0.975 instead of 0.95?\nThe t-distribution (like the normal distribution) is symmetric. For a 95% CI:\n\nYou want 95% in the middle\nThat leaves 5% in the tails\nSplit evenly: 2.5% in each tail\nSo you want the value that has 2.5% to its right (97.5% to its left)\nThat‚Äôs why we use qt(0.975, df) not qt(0.95, df)\n\nWhat‚Äôs happening inside qt()?\nWithout going into the math details:\n\nR has the mathematical formula for the t-distribution\nIt‚Äôs solving: ‚ÄúWhat value of t has exactly 97.5% of the distribution to its left?‚Äù\nIt uses numerical methods to find this value\n\nVisual intuition:\nImagine the t-distribution as a hill:\n\nThe peak is at 0\nqt(0.975, df) finds the point where 97.5% of the area under the curve is to the left\nThis point gets closer to 1.96 (the z value) as df increases\n\nYou don‚Äôt need to calculate it by hand - that‚Äôs why we use R! But understanding that it‚Äôs a percentile of the t-distribution (like how 1.96 is the 97.5th percentile of the normal distribution) helps build intuition.\nPractical use:\n\nSmall df (5) ‚Üí t* is large (2.57) ‚Üí wider CIs (less certainty)\nLarge df (100) ‚Üí t* is small (1.98) ‚Üí narrower CIs (more certainty)\nInfinite df ‚Üí t* = z* (1.96) ‚Üí t-distribution becomes normal"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#homework-and-exam-preparation",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#homework-and-exam-preparation",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Homework and Exam Preparation",
    "text": "Homework and Exam Preparation\nQ: ‚ÄúNot for class, but on the homework, sometimes the wording is confusing and it is unclear what we need to do. This is true when there is some of the code already given, just adding a ‚Äògiven‚Äô comment and then saying more explicitly what is needed would be helpful. Also the homework is taking me approximately 3-4 hours to complete, I am concerned with how long this is that the exam will be extremely long. Also, I know we will have an exam review, but maybe letting us know what kind of tasks we will need to be able to perform would help direct us.‚Äù\nThank you - this is helpful feedback.\nHomework clarity:\n\nI will add clearer labels in the homework templates (e.g., GIVEN vs YOUR TASK) and make the prompt for each part more explicit.\nIf something feels ambiguous while you are working, please reach out right away (office hours or email). Often a 2-minute clarification can save you a lot of time.\n\nHomework time:\nHomework is meant to be the main place you practice and build fluency, so it may take a few hours. If you find that a particular question is confusing or taking disproportionately long, let us know - that is useful information for improving the assignment.\nMidterm expectations:\nThe midterm is not designed to be a short, in-class exam. It will be a longer, take-home style assessment that is intended to take roughly 3‚Äì5 hours.\n\nYou will not need to memorize formulas.\nThe focus will be on applying ideas correctly and communicating your reasoning.\nYou should expect tasks similar in style to the homework, but more focused.\n\nBefore the midterm, I will provide guidance on:\n\nthe core concepts to prioritize,\nthe types of questions to expect,\nand a small set of practice problems."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#summary",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals_muddy_points.html#summary",
    "title": "Muddy Points Responses: Sampling Distributions & Confidence Intervals",
    "section": "Summary",
    "text": "Summary\nKey takeaways:\n\nCritical values are just multipliers that tell you how wide your CI needs to be\nCI interpretation: ‚Äú95% confident‚Äù means the procedure works 95% of the time, not that there‚Äôs a 95% probability for this specific interval\nSampling distribution is more important than sample distribution - it‚Äôs what lets you do inference\nDegrees of freedom = independent pieces of information left after estimation\n95% CIs are convention, not magic - balance confidence with precision\nUse t almost always in real research (you rarely know œÉ)\nPopulation in lab work is conceptual - ‚Äúall cells under these conditions‚Äù\nReport SD for variability, SE for uncertainty in your estimate\nCLT lets you use normal theory even when data aren‚Äôt normal\nt* is a percentile of the t-distribution - R finds it for you\n\nKeep the questions coming! This is complex material and it‚Äôs normal to need multiple exposures to fully understand it."
  },
  {
    "objectID": "homework/HW03/HW03.html",
    "href": "homework/HW03/HW03.html",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "",
    "text": "Note\n\n\n\nFile naming and submission\nPlease use the following file naming convention:\nLastname_FirstInitial_HW##\nExamples:\n\nSmith_J_HW03.qmd\nSmith_J_HW03.html\n\nWhen submitting Homework 3, upload both:\n\nthe .qmd file\nthe rendered .html file"
  },
  {
    "objectID": "homework/HW03/HW03.html#homework-3",
    "href": "homework/HW03/HW03.html#homework-3",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Homework 3",
    "text": "Homework 3\nThis assignment reviews:\n\nBayes‚Äô Theorem and medical testing\nRandom variables: expected value and variance\nBinomial distribution and probability calculations\nContinued practice with dplyr, janitor, rstatix, and ggplot2\n\nUnless stated otherwise, show your work using R code chunks."
  },
  {
    "objectID": "homework/HW03/HW03.html#part-0-setup",
    "href": "homework/HW03/HW03.html#part-0-setup",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 0: Setup",
    "text": "Part 0: Setup\n\nIn the chunk below, load the packages you need for this homework.\nRun the chunk to confirm there are no errors.\n\n\nlibrary(oibiostat)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(janitor)\nlibrary(rstatix)"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-1-bayes-theorem",
    "href": "homework/HW03/HW03.html#part-1-bayes-theorem",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 1: Bayes‚Äô Theorem",
    "text": "Part 1: Bayes‚Äô Theorem\n\nBackground\nA new rapid test for influenza has been developed. Clinical trials show:\n\nSensitivity: 85% (probability of testing positive given you have flu)\nSpecificity: 92% (probability of testing negative given you don‚Äôt have flu)\n\nDuring flu season, approximately 5% of people who visit their doctor with flu-like symptoms actually have influenza.\n\n\n1A. Set up the problem\nWrite out the given information using probability notation:\n\n\\(P(\\text{Test +} \\mid \\text{Flu}) =\\) ___________\n\\(P(\\text{Test -} \\mid \\text{No Flu}) =\\) ___________\n\\(P(\\text{Test +} \\mid \\text{No Flu}) =\\) ___________ (Calculate this from specificity)\n\\(P(\\text{Flu}) =\\) ___________\n\\(P(\\text{No Flu}) =\\) ___________\n\nFill in your answers above, then verify them in the code chunk below:\n\n# Given information\nsensitivity &lt;- \nspecificity &lt;- \nprevalence &lt;- \n\n# Calculate derived values\np_test_pos_given_no_flu &lt;- \np_no_flu &lt;- \n\n# Display\nsensitivity\np_test_pos_given_no_flu\nprevalence\np_no_flu\n\n\n\n1B. Calculate PPV using Bayes‚Äô Theorem\nUse Bayes‚Äô Theorem to calculate the Positive Predictive Value (PPV): What is the probability someone has flu given they tested positive?\n\\[\nP(\\text{Flu} \\mid \\text{Test +}) = \\frac{P(\\text{Test +} \\mid \\text{Flu}) \\times P(\\text{Flu})}{P(\\text{Test +} \\mid \\text{Flu}) \\times P(\\text{Flu}) + P(\\text{Test +} \\mid \\text{No Flu}) \\times P(\\text{No Flu})}\n\\]\nStep 1: Calculate the numerator (true positives)\n\nnumerator &lt;- \n\nnumerator\n\nStep 2: Calculate the denominator (all positive tests)\n\ndenominator &lt;- \n\ndenominator\n\nStep 3: Calculate PPV\n\nppv &lt;- \n\nppv\n\n# As a percentage\nppv * 100\n\n\n\n1C. Interpretation\nAnswer in 2-3 sentences:\n\nIf someone tests positive, what is the probability they actually have the flu?\nWhy is the PPV lower than the sensitivity (85%)?\n\nAnswers:\n\n\n\n\n\n\n1D. Calculate NPV\nNow calculate the Negative Predictive Value (NPV): What is the probability someone does NOT have flu given they tested negative?\n\\[\nP(\\text{No Flu} \\mid \\text{Test -}) = \\frac{P(\\text{Test -} \\mid \\text{No Flu}) \\times P(\\text{No Flu})}{P(\\text{Test -} \\mid \\text{No Flu}) \\times P(\\text{No Flu}) + P(\\text{Test -} \\mid \\text{Flu}) \\times P(\\text{Flu})}\n\\]\nHint: \\(P(\\text{Test -} \\mid \\text{Flu}) = 1 - \\text{sensitivity}\\)\n\n# Calculate NPV\n\nWhat is the NPV? Is it higher or lower than the PPV? Why?\nAnswer:"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-2-random-variables",
    "href": "homework/HW03/HW03.html#part-2-random-variables",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 2: Random Variables",
    "text": "Part 2: Random Variables\n\n2A. Discrete probability distribution\nA hospital emergency department tracks the number of patients arriving per hour during overnight shifts. The probability distribution is:\n\n\n\nNumber of patients (\\(x\\))\n0\n1\n2\n3\n4\n5\n\n\n\n\n\\(P(X = x)\\)\n0.05\n0.15\n0.30\n0.25\n0.15\n0.10\n\n\n\nQuestion 1: Verify this is a valid probability distribution. What must be true?\n\n# Create the probability distribution\nx &lt;- c(0, 1, 2, 3, 4, 5)\nprob &lt;- c(0.05, 0.15, 0.30, 0.25, 0.15, 0.10)\n\n# Check if probabilities sum to 1\nsum(prob)\n\n# Hint: probabilities in a valid distribution must sum to 1\n# You may find sum() helpful here (see ?sum)\n\nAnswer:\nQuestion 2: Calculate the expected value (mean). On average, how many patients arrive per hour?\n\\[E(X) = \\sum x_i \\cdot P(X = x_i)\\]\n\n# Calculate expected value\n# Hint: expected value is a weighted average\n# In R, this can be computed as sum(x * prob)\n\nAnswer: The expected number of patients per hour is ________.\nQuestion 3: Calculate the variance and standard deviation.\n\\[\\text{Var}(X) = \\sum (x_i - \\mu)^2 \\cdot P(X = x_i)\\]\n\n# Calculate variance\n# Hint: first compute the mean (mu), then use\n# sum((x - mu)^2 * prob)\n\n\n\n# Calculate standard deviation\n# Hint: SD is the square root of the variance (see sqrt())\n\nAnswer:\n\nVariance = ________\nStandard deviation = ________\n\n\n\n2B. Linear combinations\nSuppose the hospital emergency department operates for 3 hours during an overnight shift. Let \\(X_1\\), \\(X_2\\), and \\(X_3\\) be the number of patients arriving in hours 1, 2, and 3, respectively. Assume each has the same distribution as above and arrivals are independent across hours.\nQuestion 1: What is the expected total number of patients arriving during the 3-hour shift?\nUse: \\(E(X_1 + X_2 + X_3) = E(X_1) + E(X_2) + E(X_3)\\)\n\n# Calculate expected total\n\nAnswer:\nQuestion 2: What is the variance and standard deviation of the total number of patients?\nUse: \\(\\text{Var}(X_1 + X_2 + X_3) = \\text{Var}(X_1) + \\text{Var}(X_2) + \\text{Var}(X_3)\\) (for independent random variables)\n\n# Calculate variance of total\n\n\n# Calculate standard deviation of total\n\nAnswer:\n\nVariance = ________\nStandard deviation = ________"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-3-binomial-distribution",
    "href": "homework/HW03/HW03.html#part-3-binomial-distribution",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 3: Binomial Distribution",
    "text": "Part 3: Binomial Distribution\n\n3A. Identifying binomial scenarios\nFor each scenario below, state whether it follows a binomial distribution. If yes, identify \\(n\\) (number of trials) and \\(p\\) (probability of success). If no, explain why not.\nScenario 1: A researcher tests 20 patients for a genetic mutation. Each patient has a 15% chance of having the mutation. We count how many patients have the mutation.\nAnswer:\nScenario 2: A doctor sees patients until they find 5 patients with high blood pressure. We count how many patients the doctor had to see.\nAnswer:\nScenario 3: A clinical trial enrolls 50 patients. Each patient is randomly assigned to treatment (probability 0.5) or control (probability 0.5). We count how many patients receive treatment.\nAnswer:\n\n\n3B. Binomial calculations\nAccording to recent data, approximately 20.3% of US adults aged 65-74 have diabetes. Suppose we randomly sample 15 adults from this age group.\nLet \\(X\\) = the number of adults with diabetes in our sample.\nQuestion 1: What distribution does \\(X\\) follow? Write this using notation.\nAnswer: \\(X \\sim\\) ________________\nQuestion 2: What is the expected number of adults with diabetes in the sample?\n\\[E(X) = np\\]\n\n# Calculate expected value\nn &lt;- \np &lt;- \n\nexpected_value &lt;- \n\nexpected_value\n\nAnswer:\nQuestion 3: What is the standard deviation?\n\\[SD(X) = \\sqrt{np(1-p)}\\]\n\n# Calculate standard deviation\n\nAnswer:\nQuestion 4: What is the probability that exactly 4 adults have diabetes?\nUse the formula: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nOr use R: dbinom(x = k, size = n, prob = p)\n\n# Calculate P(X = 4)\n\nAnswer:\nQuestion 5: What is the probability that at most 2 adults have diabetes?\n\\[P(X \\leq 2) = P(X=0) + P(X=1) + P(X=2)\\]\nUse R: pbinom(q = k, size = n, prob = p)\n\n# Calculate P(X &lt;= 2)\n\nAnswer:\nQuestion 6: What is the probability that at least 5 adults have diabetes?\n\\[P(X \\geq 5) = 1 - P(X \\leq 4)\\]\nOr use: pbinom(q = 4, size = n, prob = p, lower.tail = FALSE)\n\n# Calculate P(X &gt;= 5) using both methods\n\n# Method 1: complement rule\n\n\n# Method 2: lower.tail = FALSE\n\nAnswer:\n\n\n3C. Visualizing the binomial distribution\nCreate a bar plot showing the binomial probability distribution for \\(n = 15\\) and \\(p = 0.203\\).\n\n# Create probability distribution data\nx_values &lt;- 0:15\nprobabilities &lt;- dbinom(x_values, size = 15, prob = 0.203)\n\n# Create a data frame\nbinom_data &lt;- data.frame(\n  x = x_values,\n  probability = probabilities\n)\n\n# Create bar plot\nggplot(binom_data, aes(x = x, y = probability)) +\n  geom_col(fill = \"steelblue\", color = \"black\") +\n  labs(\n    title = \"Binomial Distribution: n = 15, p = 0.203\",\n    x = \"Number of Adults with Diabetes\",\n    y = \"Probability\"\n  ) +\n  scale_x_continuous(breaks = 0:15) # controls x-axis tick marks (we'll learn more about scale_* later; see ?scale_x_continuous)\n\nLooking at the plot, what is the most likely number of adults with diabetes in a sample of 15? Does this match the expected value you calculated?\nAnswer:"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-4-data-analysis-with-tidyverse-continued-practice",
    "href": "homework/HW03/HW03.html#part-4-data-analysis-with-tidyverse-continued-practice",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 4: Data analysis with tidyverse (continued practice)",
    "text": "Part 4: Data analysis with tidyverse (continued practice)\nFor this section, we‚Äôll continue working with the nhanes.samp dataset. You may use either the formula or R, but show the code you use.\n\ndata(\"nhanes.samp\")\n\n\n4A. Data wrangling\nCreate a new dataset called diabetes_subset that:\n\nFilters to people aged 40 or older\nRemoves rows with missing Diabetes values (use filter(!is.na(Diabetes)))\nSelects the columns: ID, Age, Gender, Race1, BMI, Diabetes\n\nHow many people are in this subset? (Use nrow())\nAnswer:\n\n\n4B. Summary statistics by group\nUsing your diabetes_subset, calculate the mean and standard deviation of BMI grouped by Diabetes status. [Hint: use group_by and get_summary_stats from the rstatix pacakge]\nDo people with diabetes have higher or lower BMI on average? Does this match what you‚Äôd expect?\nAnswer:\n\n\n4C. Two-way frequency table\nCreate a two-way table showing the relationship between Diabetes and Gender using tabyl(). Add row percentages.\nAmong people aged 40+, what percentage of females have diabetes? What about males?\nAnswer:\n\n\n4D. Visualization\nCreate a boxplot comparing BMI across Diabetes groups. Color the boxes by Diabetes status.\nDescribe what you see in 1-2 sentences.\nAnswer:"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-5-connecting-concepts-integration",
    "href": "homework/HW03/HW03.html#part-5-connecting-concepts-integration",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 5: Connecting concepts (Integration)",
    "text": "Part 5: Connecting concepts (Integration)\n\n5A. Binomial to data\nIn Part 3, we calculated that with \\(n=15\\) and \\(p=0.203\\), the expected number of adults with diabetes is approximately 3.\nNow let‚Äôs check this against real data. Using the full nhanes.samp dataset:\n\nFilter to adults aged 65-74 (use filter(Age &gt;= 65 & Age &lt;= 74))\nCalculate the proportion who have diabetes (use tabyl(Diabetes))\n\nQuestions:\n\nWhat proportion of adults aged 65-74 in this sample have diabetes?\nHow does this compare to the 20.3% we used in our binomial calculations?\nIf you randomly selected 15 people from this sample, would you expect about 3 to have diabetes?\n\nAnswers:\n\n\n\n\n\n\n\n5B. Bayes‚Äô Theorem with data\nSuppose we use BMI &gt;= 30 as a ‚Äútest‚Äù for diabetes (obese BMI as a predictor).\nCalculate the following using the diabetes_subset you created in Part 4A:\n\n# Create BMI test variable\ndiabetes_subset &lt;- diabetes_subset %&gt;%\n  mutate(BMI_test = if_else(BMI &gt;= 30, \"Positive\", \"Negative\"))\n\n# Create contingency table\ntable_diabetes_bmi &lt;- diabetes_subset %&gt;%\n  tabyl(Diabetes, BMI_test)\n\ntable_diabetes_bmi\n\nTreat BMI_test as the test result and Diabetes as the true condition.\n\n‚ÄúPositive‚Äù = BMI ‚â• 30\n‚ÄúNegative‚Äù = BMI &lt; 30\n\nQuestion 1: What is the sensitivity? (Among people with diabetes, what proportion have BMI &gt;= 30?)\nHint: Look at the ‚ÄúYes‚Äù row of the Diabetes column\nAnswer:\nQuestion 2: What is the specificity? (Among people without diabetes, what proportion have BMI &lt; 30?)\nAnswer:\nQuestion 3: Using the table, calculate the PPV: Among people with BMI &gt;= 30, what proportion have diabetes?\nAnswer:"
  },
  {
    "objectID": "homework/HW03/HW03.html#part-6-reflection-optional-but-encouraged",
    "href": "homework/HW03/HW03.html#part-6-reflection-optional-but-encouraged",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Part 6: Reflection (Optional but encouraged)",
    "text": "Part 6: Reflection (Optional but encouraged)\nIn 3-4 sentences, reflect on the connection between:\n\nBayes‚Äô Theorem (flipping conditional probabilities)\nBinomial distribution (modeling repeated trials)\nReal data analysis (testing these concepts)\n\nHow do these topics relate to biomedical research?\nAnswer:"
  },
  {
    "objectID": "homework/HW03/HW03.html#final-check",
    "href": "homework/HW03/HW03.html#final-check",
    "title": "BMSC 620 ‚Äî Homework 3",
    "section": "Final check",
    "text": "Final check\nBefore submitting, confirm that:\n\nThe document renders to HTML without errors\nAll code chunks run successfully\nYour name appears at the top\nYou‚Äôve answered all required questions\nYou uploaded both the .qmd and .html files"
  },
  {
    "objectID": "homework/HW01/HW01.html",
    "href": "homework/HW01/HW01.html",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "",
    "text": "Note\n\n\n\nFile naming and submission\nPlease use the following file naming convention:\nLastname_FirstInitial_HW##\nExamples:\n\nSmith_J_HW01.qmd\nSmith_J_HW01.html\n\nWhen submitting Homework 1, upload both:\n\nthe .qmd file\nthe rendered .html file"
  },
  {
    "objectID": "homework/HW01/HW01.html#homework-1",
    "href": "homework/HW01/HW01.html#homework-1",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Homework 1",
    "text": "Homework 1\nThis assignment reviews:\n\nwriting and running code in Quarto\nsummarizing numeric and categorical variables\nfrequency tables and contingency tables\nbar plots, histograms, and box plots\n\nUnless stated otherwise, show your work using R code chunks."
  },
  {
    "objectID": "homework/HW01/HW01.html#part-0-setup",
    "href": "homework/HW01/HW01.html#part-0-setup",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 0: Setup",
    "text": "Part 0: Setup\n\nIn the chunk below, load the packages you need for this homework.\nRun the chunk to confirm there are no errors.\n\n\n# NOTE: If you don't already have the oibiostat package installed, then uncomment and run the two lines below. Then re-comment them and check installation with `library(oibiostat)`.\n# install.packages(\"devtools\")\n# devtools::install_github(\"OI-Biostat/oi_biostat_data\", force = TRUE)\n\nlibrary(oibiostat)"
  },
  {
    "objectID": "homework/HW01/HW01.html#part-1-r-objects-and-vectors",
    "href": "homework/HW01/HW01.html#part-1-r-objects-and-vectors",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 1: R objects and vectors",
    "text": "Part 1: R objects and vectors\n\n1A. Calculator practice\nCreate code that computes each of the following (one line each):\n\n12 / 5\n3^4\nsqrt(81)\n4^3 - 2 * 7 + 9 / 2\n\n\n# Your code here\n\n\n\n1B. Create vectors and summarize\n\nCreate a vector named x containing the numbers: 4, 9, 2, 10, 7, 7\nCompute the mean and standard deviation of x\nCompute the median and IQR of x\n\n\n\n1C. Missing values\n\nCreate a vector named y containing: 2, 5, NA, 7, 9\nCompute mean(y). What happens?\nCompute the mean again ignoring missing values\n\nWrite 1 to 2 sentences explaining what na.rm = TRUE does.\nYour explanation:"
  },
  {
    "objectID": "homework/HW01/HW01.html#part-2-inspecting-a-dataset-nhanes.samp",
    "href": "homework/HW01/HW01.html#part-2-inspecting-a-dataset-nhanes.samp",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 2: Inspecting a dataset (nhanes.samp)",
    "text": "Part 2: Inspecting a dataset (nhanes.samp)\nIn this homework, you will work with the dataset nhanes.samp, which is included in the oibiostat package.\nThe National Health and Nutrition Examination Survey (NHANES) is a large, ongoing study conducted in the United States to assess the health and nutritional status of adults and children. The dataset used here is a sample of 200 individuals from NHANES, provided for instructional purposes.\nTo load the dataset, run:\n\nlibrary(oibiostat)\ndata(\"nhanes.samp\")\n\n\n2A. Basic inspection\nRun the following functions:\n\ndim(nhanes.samp)\nnames(nhanes.samp)\nstr(nhanes.samp)\nhead(nhanes.samp)\n\nAnswer the questions below in plain text.\n\nHow many rows and columns does nhanes.samp have?\nName two categorical variables? (i.e.¬†Factor variable type)\nGive one example of a numeric variable. (int or num)\n\nAnswers: 1. 2. 3.\n\n\n2B. Accessing a single variable with $\n\nUse $ to pull out Age\nCompute the mean, sd, median, and IQR of Age\n\n\n\n2C. Working with NA values.\nWe can see that some variables in the dataset have missing values (NA) like the variable Height.\n\nsummary(nhanes.samp$Height)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   90.6   156.6   166.2   162.6   175.7   191.3      10 \n\n\n\nUse $ to pull out Height\nCompute the mean, sd, median, and IQR of Height. Hint: you will need to remove the NA values by adding the argument na.rm = TRUE to the function calls."
  },
  {
    "objectID": "homework/HW01/HW01.html#part-3-summarizing-one-categorical-variable",
    "href": "homework/HW01/HW01.html#part-3-summarizing-one-categorical-variable",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 3: Summarizing one categorical variable",
    "text": "Part 3: Summarizing one categorical variable\nWe will summarize Gender\n\n3A. Counts and proportions\n\nUse table() to get counts of Gender\nUse prop.table() to get proportions of Gender\nConvert proportions to percentages\n\nHint: table(nhanes.samp$Gender) and prop.table(...)\n\n\n3B. Bar plot\nMake a bar plot of Gender using the barplot function."
  },
  {
    "objectID": "homework/HW01/HW01.html#part-4-two-categorical-variables-contingency-tables",
    "href": "homework/HW01/HW01.html#part-4-two-categorical-variables-contingency-tables",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 4: Two categorical variables (contingency tables)",
    "text": "Part 4: Two categorical variables (contingency tables)\nWe can use the table() function to examine the relationships between two categorical variables. Here is an example using Gender and Race1:\n\ntable(nhanes.samp$Gender, nhanes.samp$Race1)   # counts\n\n        \n         Black Hispanic Mexican White Other\n  female     7        8       9    65    13\n  male      16        6      13    57     6\n\nprop.table(table(nhanes.samp$Gender, nhanes.samp$Race1), margin = 1)  # row proportions\n\n        \n              Black   Hispanic    Mexican      White      Other\n  female 0.06862745 0.07843137 0.08823529 0.63725490 0.12745098\n  male   0.16326531 0.06122449 0.13265306 0.58163265 0.06122449\n\nprop.table(table(nhanes.samp$Gender, nhanes.samp$Race1), margin = 2)  # column proportions\n\n        \n             Black  Hispanic   Mexican     White     Other\n  female 0.3043478 0.5714286 0.4090909 0.5327869 0.6842105\n  male   0.6956522 0.4285714 0.5909091 0.4672131 0.3157895\n\n\nUsing row percentages (margin = 1), where each row sums to 100% and Gender is held fixed, we see that among females in the data set, 7 (6.8%) are Black, 8 (7.8%) Hispanic, 9 (8.8%) Mexican, 65 (63.7%) White, and 13 (12.7%) Other.\nUsing column percentages (margin = 2), where each column sums to 100% and Race is held fixed, we see that among the largest racial group, White, 53.3% are female and 46.7% are male.\n\n4A. Contingency table (counts)\nChoose either the Diabetes or SmokeNow variable in the data set. Create a contingency table similar to above with Gender and the variable that you choose.\n\n\n4B. Row proportions vs column proportions\n\nCreate a row proportion table (each row sums to 1)\nCreate a column proportion table (each column sums to 1)\n\nHint:\n\nprop.table(table(nhanes.samp$Gender, YOUR VARIABLE), margin = 1)\nprop.table(table(nhanes.samp$Gender, YOUR VARIABLE), margin = 2)\n\n\n\n4C. Interpretation\nAnswer each question in 1 to 2 sentences.\n\nProvide 1 or 2 short sentences describing the row percentages.\nProvide 1 or 2 short sentences describing the column percentages.\n\nAnswers: 1. 2."
  },
  {
    "objectID": "homework/HW01/HW01.html#part-5-visual-summaries-for-numeric-variables",
    "href": "homework/HW01/HW01.html#part-5-visual-summaries-for-numeric-variables",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Part 5: Visual summaries for numeric variables",
    "text": "Part 5: Visual summaries for numeric variables\n\n5A. Histogram\nMake a histogram of BMI.\nUsing the hist() function, you can add:\n\na title by adding an argument main = \"Histogram of BMI\"\nand a label for the x-axis using xlab = \"BMI\"\nWhen in doubt about arguments to functions, use the ? then the function name to get help. i.e.¬†type in the console ?hist to get help for the hist() function.\n\nIf you get an error due to missing values, use na.omit() or remove NA values before calling hist().\n\n\n5B. Box plot (overall)\nMake a single box plot of Height using boxplot(). Include a title ‚ÄúBox plot of Height‚Äù and a label for the y-axis (ylab = \"Height\"). Get help using ?boxplot if you need it.\nNOTE: We saw earlier that Height contained NA values. boxplot() will ignore NA values automatically.\n\n\n5C. Box plot by group\nMake a box plot of Height by Gender.\nIf you look at the first example in the help for the boxplot function ?boxplot, they give an example of a box plot of count by spray using the InsectSprays dataset.\n\nboxplot(count ~ spray, data = InsectSprays, col = \"lightgray\")\n\nFollow their example to make your Height by Gender box plot with the nhanes.samp data.\nWhich group has a higher median height? How can you tell from the figure? Are there any outliers?\nAnswer:"
  },
  {
    "objectID": "homework/HW01/HW01.html#final-check",
    "href": "homework/HW01/HW01.html#final-check",
    "title": "BMSC 620 ‚Äî Homework 1",
    "section": "Final check",
    "text": "Final check\nBefore submitting, confirm that:\n\nThe document renders to HTML without errors\nAll code chunks run successfully\nYour name appears at the top\nYou uploaded both the .qmd and .html files"
  },
  {
    "objectID": "exams.html",
    "href": "exams.html",
    "title": "Exams",
    "section": "",
    "text": "See Sakai",
    "crumbs": [
      "Home",
      "Exams"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BMSC 620: Introduction to Biostatistics",
    "section": "",
    "text": "Welcome to BMSC 620: Introduction to Biostatistics. This course introduces fundamental statistical methods commonly used in the biomedical and health sciences, with an emphasis on understanding, interpretation, and clear communication rather than mathematical derivations.\nWe will begin with descriptive statistics and graphical methods for summarizing data, followed by an introduction to basic probability concepts that motivate statistical inference. Key probability and sampling distributions, including the binomial, Poisson, and normal distributions, will be introduced as tools for understanding variability and uncertainty in data.\nThe course will then cover confidence intervals and hypothesis testing for one- and two-sample problems, using both parametric and nonparametric approaches. Additional topics include inference for proportions, analysis of two-way tables, one-way analysis of variance (ANOVA), correlation, and simple linear regression.\nThroughout the course, emphasis will be placed on selecting appropriate statistical methods, interpreting results, and communicating conclusions in a way that is accessible to audiences without formal statistical training. Students will gain hands-on experience using statistical software (R) for basic data management, visualization, and interpretation of output generated by statistical analyses, as well as for building reproducible analytical workflows.\nCourse materials and structure for BMSC 620 were developed by Emile Latour and informed by prior offerings taught by Meike Niederhausen and Nicky Wakim. Portions of the syllabus, resources, and instructional approach were adapted from their courses, with permission, and modified for this offering.\n\n\n\n\n Emile Latour, MS\n\n KCRB\n latour@ohsu.edu\n\n\n\nEmile  Thursday, 1:00‚Äì2:00 PM\nJoseph  Friday, 10:00-11:00 AM\nNick  Wednesday, 1:00‚Äì2:00 PM\n\n\n\n Mondays, Wednesdays\n January 5‚ÄìMarch 20\n 9:00 AM‚Äì10:30 AM\n In-person, RJH 4320\nNote: Class will meet in MAC 3198 on January 21 only.\n\n\n\nE-mail is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#bmsc-620-introduction-to-biostatistics",
    "href": "index.html#bmsc-620-introduction-to-biostatistics",
    "title": "BMSC 620: Introduction to Biostatistics",
    "section": "",
    "text": "Welcome to BMSC 620: Introduction to Biostatistics. This course introduces fundamental statistical methods commonly used in the biomedical and health sciences, with an emphasis on understanding, interpretation, and clear communication rather than mathematical derivations.\nWe will begin with descriptive statistics and graphical methods for summarizing data, followed by an introduction to basic probability concepts that motivate statistical inference. Key probability and sampling distributions, including the binomial, Poisson, and normal distributions, will be introduced as tools for understanding variability and uncertainty in data.\nThe course will then cover confidence intervals and hypothesis testing for one- and two-sample problems, using both parametric and nonparametric approaches. Additional topics include inference for proportions, analysis of two-way tables, one-way analysis of variance (ANOVA), correlation, and simple linear regression.\nThroughout the course, emphasis will be placed on selecting appropriate statistical methods, interpreting results, and communicating conclusions in a way that is accessible to audiences without formal statistical training. Students will gain hands-on experience using statistical software (R) for basic data management, visualization, and interpretation of output generated by statistical analyses, as well as for building reproducible analytical workflows.\nCourse materials and structure for BMSC 620 were developed by Emile Latour and informed by prior offerings taught by Meike Niederhausen and Nicky Wakim. Portions of the syllabus, resources, and instructional approach were adapted from their courses, with permission, and modified for this offering.\n\n\n\n\n Emile Latour, MS\n\n KCRB\n latour@ohsu.edu\n\n\n\nEmile  Thursday, 1:00‚Äì2:00 PM\nJoseph  Friday, 10:00-11:00 AM\nNick  Wednesday, 1:00‚Äì2:00 PM\n\n\n\n Mondays, Wednesdays\n January 5‚ÄìMarch 20\n 9:00 AM‚Äì10:30 AM\n In-person, RJH 4320\nNote: Class will meet in MAC 3198 on January 21 only.\n\n\n\nE-mail is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "resources/keyboard_shortcuts.html",
    "href": "resources/keyboard_shortcuts.html",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "",
    "text": "These are the keyboard shortcuts you‚Äôll use most frequently in RStudio. Learning even a few of these will make your workflow much faster!"
  },
  {
    "objectID": "resources/keyboard_shortcuts.html#most-essential-shortcuts",
    "href": "resources/keyboard_shortcuts.html#most-essential-shortcuts",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "Most Essential Shortcuts",
    "text": "Most Essential Shortcuts\n\n\n\n\n\n\n\n\nAction\nMac\nWindows/Linux\n\n\n\n\nInsert pipe %&gt;%\nCmd + Shift + M\nCtrl + Shift + M\n\n\nInsert code chunk\nCmd + Option + I\nCtrl + Alt + I\n\n\nRun current line/selection\nCmd + Enter\nCtrl + Enter\n\n\nRun current chunk\nCmd + Shift + Enter\nCtrl + Shift + Enter\n\n\nRun all chunks above\nCmd + Option + P\nCtrl + Alt + P\n\n\nComment/uncomment line(s)\nCmd + Shift + C\nCtrl + Shift + C\n\n\nInsert assignment &lt;-\nOption + - (minus)\nAlt + - (minus)"
  },
  {
    "objectID": "resources/keyboard_shortcuts.html#additional-helpful-shortcuts",
    "href": "resources/keyboard_shortcuts.html#additional-helpful-shortcuts",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "Additional Helpful Shortcuts",
    "text": "Additional Helpful Shortcuts\n\n\n\n\n\n\n\n\nAction\nMac\nWindows/Linux\n\n\n\n\nMove cursor to source editor\nCtrl + 1\nCtrl + 1\n\n\nMove cursor to console\nCtrl + 2\nCtrl + 2\n\n\nClear console\nCtrl + L\nCtrl + L\n\n\nRestart R session\nCmd + Shift + 0\nCtrl + Shift + F10\n\n\nShow keyboard shortcut reference\nOption + Shift + K\nAlt + Shift + K\n\n\nFind in files\nCmd + Shift + F\nCtrl + Shift + F\n\n\nAuto-complete\nTab\nTab\n\n\nGet help for function\nF1 (cursor on function)\nF1 (cursor on function)"
  },
  {
    "objectID": "resources/keyboard_shortcuts.html#tips-for-learning-shortcuts",
    "href": "resources/keyboard_shortcuts.html#tips-for-learning-shortcuts",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "Tips for Learning Shortcuts",
    "text": "Tips for Learning Shortcuts\n\nStart with 2-3: Don‚Äôt try to memorize all of these at once. Start with the pipe operator and running code.\nUse them consistently: The more you use a shortcut, the more automatic it becomes.\nView all shortcuts: In RStudio, go to Tools ‚Üí Keyboard Shortcuts Help or press Option/Alt + Shift + K to see the complete list.\nCustomize shortcuts: You can customize shortcuts in Tools ‚Üí Modify Keyboard Shortcuts."
  },
  {
    "objectID": "resources/keyboard_shortcuts.html#the-shortcuts-youll-use-every-class",
    "href": "resources/keyboard_shortcuts.html#the-shortcuts-youll-use-every-class",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "The Shortcuts You‚Äôll Use Every Class",
    "text": "The Shortcuts You‚Äôll Use Every Class\nIf you only remember three shortcuts, make them these:\n\nCmd/Ctrl + Shift + M - Insert pipe %&gt;%\nCmd/Ctrl + Enter - Run current line\nCmd/Ctrl + Shift + C - Comment/uncomment\n\nThese three will save you countless hours of typing!"
  },
  {
    "objectID": "resources/keyboard_shortcuts.html#rstudio-cheatsheets",
    "href": "resources/keyboard_shortcuts.html#rstudio-cheatsheets",
    "title": "Essential RStudio Keyboard Shortcuts",
    "section": "RStudio Cheatsheets",
    "text": "RStudio Cheatsheets\nRStudio provides official cheatsheets for many packages and topics. Access them in RStudio:\nHelp ‚Üí Cheatsheets\nOr download them directly from: https://posit.co/resources/cheatsheets/\n\nMost relevant cheatsheets for this course:\n\nRStudio IDE Cheat Sheet - Overview of RStudio interface and shortcuts\nData Transformation with dplyr - The dplyr verbs we use constantly\nData Visualization with ggplot2 - Creating plots\nR Markdown - Works for Quarto documents too\n\n\nTip: Print out the dplyr and ggplot2 cheatsheets and keep them handy while coding!"
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Email: latour@ohsu.edu\nCampus location: KCRB\nPronouns: he/him/his\nName: Please feel free to call me Emile (pronounced ‚Äúeh-MEEL‚Äù or ‚Äúah-MEEL‚Äù).\nLast name: Latour (pronounced ‚Äúluh-TOOR‚Äù).\nBest way to contact me: Email is best for course logistics. Office hours are best for homework, R help, and concepts.\n\n\n\n\n\n\n\n\nEmail: hwangjo@ohsu.edu\n\n\n\n\n\nEmail: chaiyach@ohsu.edu\n\n\nNote: If you are unsure who to contact, email Emile and I will route your question.",
    "crumbs": [
      "Home",
      "Course info",
      "Instructors"
    ]
  },
  {
    "objectID": "instructors.html#teaching-team",
    "href": "instructors.html#teaching-team",
    "title": "Instructors",
    "section": "",
    "text": "Email: latour@ohsu.edu\nCampus location: KCRB\nPronouns: he/him/his\nName: Please feel free to call me Emile (pronounced ‚Äúeh-MEEL‚Äù or ‚Äúah-MEEL‚Äù).\nLast name: Latour (pronounced ‚Äúluh-TOOR‚Äù).\nBest way to contact me: Email is best for course logistics. Office hours are best for homework, R help, and concepts.\n\n\n\n\n\n\n\n\nEmail: hwangjo@ohsu.edu\n\n\n\n\n\nEmail: chaiyach@ohsu.edu\n\n\nNote: If you are unsure who to contact, email Emile and I will route your question.",
    "crumbs": [
      "Home",
      "Course info",
      "Instructors"
    ]
  },
  {
    "objectID": "instructors.html#office-hours",
    "href": "instructors.html#office-hours",
    "title": "Instructors",
    "section": "Office hours",
    "text": "Office hours\nAll office hours will be held via Webex unless otherwise noted.\n\nEmile (Instructor)\n\nTime: Thursday, 1:00-2:00 PM\nWebex: https://ohsu.webex.com/meet/latour\n\n\n\nTeaching assistant(s)\n\n\nJoseph (TA)\n\nTime: Friday, 10:00-11:00 AM\nWebex: https://ohsu.webex.com/meet/hwangjo\n\n\n\nNick (TA)\n\nTime: Wednesday, 1:00‚Äì2:00 PM\nWebex: https://ohsu.webex.com/meet/chaiyach",
    "crumbs": [
      "Home",
      "Course info",
      "Instructors"
    ]
  },
  {
    "objectID": "instructors.html#what-to-contact-us-about",
    "href": "instructors.html#what-to-contact-us-about",
    "title": "Instructors",
    "section": "What to contact us about",
    "text": "What to contact us about\n\nEmile (Instructor): course policies, grading questions, accommodations, schedule issues, and anything sensitive or private.\nTAs: homework questions, practice problems, and R troubleshooting.",
    "crumbs": [
      "Home",
      "Course info",
      "Instructors"
    ]
  },
  {
    "objectID": "weeks/week_04.html",
    "href": "weeks/week_04.html",
    "title": "Week 4",
    "section": "",
    "text": "HW 2 due Tuesday, January 27 at 11:00 pm\nHW 3 released Monday, January 26",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#announcements",
    "href": "weeks/week_04.html#announcements",
    "title": "Week 4",
    "section": "",
    "text": "HW 2 due Tuesday, January 27 at 11:00 pm\nHW 3 released Monday, January 26",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#overview",
    "href": "weeks/week_04.html#overview",
    "title": "Week 4",
    "section": "Overview",
    "text": "Overview\nThis week focuses on random variables and probability distributions.\nWe will learn about discrete and continuous random variables, calculate expected values and variances, and work with two fundamental probability distributions: the Binomial distribution and the Normal distribution.\nBy the end of the week, you should be able to:\n\ndefine random variables and distinguish between discrete and continuous types,\ncalculate expected values and variances of random variables,\nwork with linear combinations of random variables,\nidentify when the Binomial distribution applies and calculate probabilities,\nunderstand properties of the Normal distribution and calculate probabilities using R,\nidentify when the Poisson distribution applies and calculate probabilities using R.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#readings-before-class",
    "href": "weeks/week_04.html#readings-before-class",
    "title": "Week 4",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook section 3.1 (Random variables)\nTextbook section 3.2 (Binomial distribution)\nTextbook section 3.3 (Normal distribution)\nTextbook section 3.4 (Poisson distribution)\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#materials",
    "href": "weeks/week_04.html#materials",
    "title": "Week 4",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî Random Variables and Binomial Distribution\n\nTopics\n\nWhat are random variables?\nExpected value and variance\nLinear combinations of random variables\nBernoulli distribution\nBinomial distribution\nCalculating probabilities with R\n\nSlides\n\nRandom Variables and Binomial Distribution (HTML | PDF | OneDrive)\n\nRecording\n\nRandom Variables and Binomial Distribution\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 6\n\n\n\n\n\nWednesday ‚Äî Normal and Poisson Distributions\n\nTopics\n\nThe Normal distribution\nStandard Normal (Z) distribution\nNormal probability calculations (pnorm(), qnorm())\nNormal approximation to the Binomial (with continuity correction)\nThe Poisson distribution\nPoisson probability calculations (dpois(), ppois())\nPoisson approximation to the Binomial (rare events)\n\nSlides\n\nNormal and Poisson Distributions (HTML | PDF | OneDrive)\n\nRecording\n\nNormal and Poisson Distributions\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 7",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#homework",
    "href": "weeks/week_04.html#homework",
    "title": "Week 4",
    "section": "Homework",
    "text": "Homework\n\nHW 2\n\nDue Tuesday, January 27 at 11:00 pm\nCovers:\n\ndata wrangling with dplyr\nsummary statistics with rstatix\nfrequency tables with janitor\ndata visualization with ggplot2\nprobability concepts (marginal, joint, and conditional probabilities)\n\nView HW 2 instructions\n\nHW 3\n\nReleased Monday, January 26\nDue Sunday, February 1 at 11:00 pm\nCovers:\n\nBayes‚Äô Theorem\nRandom variables and expected value\nBinomial distribution\nContinued practice with tidyverse tools\n\nView HW 3 instructions\n\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#post-class-check-in-attendance",
    "href": "weeks/week_04.html#post-class-check-in-attendance",
    "title": "Week 4",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#looking-ahead",
    "href": "weeks/week_04.html#looking-ahead",
    "title": "Week 4",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext week we will begin statistical inference:\n\nMonday: Confidence intervals\nWednesday: Hypothesis testing introduction\n\nThese concepts are the foundation for drawing conclusions from data and making decisions based on evidence.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_03.html",
    "href": "weeks/week_03.html",
    "title": "Week 3",
    "section": "",
    "text": "No class Monday, January 19 (MLK Day)\nHW 2 due Tuesday, January 27 at 11:00 pm",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#announcements",
    "href": "weeks/week_03.html#announcements",
    "title": "Week 3",
    "section": "",
    "text": "No class Monday, January 19 (MLK Day)\nHW 2 due Tuesday, January 27 at 11:00 pm",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#overview",
    "href": "weeks/week_03.html#overview",
    "title": "Week 3",
    "section": "Overview",
    "text": "Overview\nThis week focuses on exploratory data analysis (EDA) and data visualization.\nWe will learn how to explore and visualize data using histograms, box plots, and scatterplots. We‚Äôll also introduce data frames and tibbles, practice subsetting and filtering data, and begin working with ggplot2 for creating publication-quality graphics.\nBy the end of the week, you should be able to:\n\ncreate and interpret histograms and box plots for numeric data,\nuse scatterplots to explore relationships between variables,\nunderstand the difference between data frames and tibbles,\nsubset and filter data effectively,\ncreate basic plots using ggplot2.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#readings-before-class",
    "href": "weeks/week_03.html#readings-before-class",
    "title": "Week 3",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook section 2.2 (Bayes‚Äô Theorem)\nTextbook section 1.7 (exploratory data analysis (EDA) and data visualization)\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#materials",
    "href": "weeks/week_03.html#materials",
    "title": "Week 3",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî No class (MLK Day)\nPlease review on your own:\n\nBayes‚Äô Theorem recording (HTML | PDF | OneDrive)\n\nLink to recording\n\n\nAdditional Bayes‚Äô Theorem resources:\n\nAn Intuitive (and Short) Explanation of Bayes‚Äô Theorem ‚Äî A clear, accessible introduction\nBayes‚Äô Theorem (3Blue1Brown video) ‚Äî Excellent visual explanation\nBayes‚Äô Theorem: A Primer ‚Äî Another helpful walkthrough\n\n\n\n\nWednesday ‚Äî Exploratory Data Analysis and Data Visualization\n\nTopics\n\nHistograms and distribution shapes\nBox plots and identifying outliers\nScatterplots and relationships\nData frames vs tibbles\nSubsetting and filtering data\nIntroduction to ggplot2\n\nSlides\n\nExploratory Data Analysis and Data Visualization (HTML | PDF | OneDrive)\n\nCode along\n\nDownload EDA and Data Viz code along (.qmd)\n\nRecording\n\nExploratory Data Analysis and Data Visualization - part 1\nExploratory Data Analysis and Data Visualization - part 2\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 5",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#homework",
    "href": "weeks/week_03.html#homework",
    "title": "Week 3",
    "section": "Homework",
    "text": "Homework\n\nHW 2\n\nDue Monday, Tuesday 27 at 11:00 pm\nCovers:\n\ndata wrangling with dplyr (filter(), select(), mutate())\nsummary statistics with rstatix\nfrequency tables with janitor\ndata visualization with ggplot2 (histograms, boxplots, scatterplots, bar charts)\nprobability concepts (marginal, joint, and conditional probabilities)\n\nView HW 2 instructions\n\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#post-class-check-in-attendance",
    "href": "weeks/week_03.html#post-class-check-in-attendance",
    "title": "Week 3",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#looking-ahead",
    "href": "weeks/week_03.html#looking-ahead",
    "title": "Week 3",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext week we will introduce random variables and probability distributions:\n\nMonday: Random variables and the binomial distribution\nWednesday: Normal distribution and sampling distributions\n\nThese concepts form the foundation for statistical inference and hypothesis testing later in the course.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_01.html",
    "href": "weeks/week_01.html",
    "title": "Week 1",
    "section": "",
    "text": "This week introduces the course structure, expectations, and the role of data as the foundation of biostatistics. We will focus on how data are collected and how to summarize numerical variables.\nBy the end of the week, you should be able to:\n\ndescribe different types of data,\ncompute and interpret basic numerical summaries,\nfeel comfortable navigating R and RStudio.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#overview",
    "href": "weeks/week_01.html#overview",
    "title": "Week 1",
    "section": "",
    "text": "This week introduces the course structure, expectations, and the role of data as the foundation of biostatistics. We will focus on how data are collected and how to summarize numerical variables.\nBy the end of the week, you should be able to:\n\ndescribe different types of data,\ncompute and interpret basic numerical summaries,\nfeel comfortable navigating R and RStudio.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#readings-before-class",
    "href": "weeks/week_01.html#readings-before-class",
    "title": "Week 1",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook sections 1.1‚Äì1.4\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#materials",
    "href": "weeks/week_01.html#materials",
    "title": "Week 1",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî Welcome & Introduction to Data\n\nTopics\n\nWelcome and course overview\nIntroduction to data\nSummarizing numerical data\n\nSlides\n\nWelcome & course logistics (HTML | PDF | OneDrive)\nIntroduction to data & numerical summaries (HTML | PDF | OneDrive)\n\nRecording\n\nLecture 01 ‚Äì Course Introduction + Intro to Data (Slides 1‚Äì22)\n\nMuddy points\nI reviewed your post-class feedback and wrote short clarifications here:\n\nMuddy Points - Lesson 1\n\n\n\n\nWednesday ‚Äî Introduction to R and RStudio\n\nTopics\n\nIntroduction to data (continued)\nIntroduction to R, RStudio, and Quarto\n\nSlides\n\nIntroduction to data & numerical summaries (Continued) (HTML | PDF | OneDrive)\nIntroduction to R, RStudio, and Quarto (HTML | PDF | OneDrive)\n\nSoftware\n\nInstall R and RStudio (see the Resources page)\n\nRecording\n\nLecture 02 ‚Äì Intro to Data (Cont.) + Intro to R & RStudio, Quarto\n\nMuddy points\nI reviewed your post-class feedback and wrote short clarifications here:\n\nMuddy Points - Lesson 2",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#day-1-course-background-survey",
    "href": "weeks/week_01.html#day-1-course-background-survey",
    "title": "Week 1",
    "section": "Day 1 course background survey",
    "text": "Day 1 course background survey\nPlease complete the Course Background Survey after Monday‚Äôs class:\n\nCourse Background Survey\n\nThis short survey helps me learn about your prior experience with statistics, programming, and what you hope to get out of the course.\nYour responses will be used only to help tailor examples, pacing, and support for this class.\nThere are no right or wrong answers, and it is not graded for correctness.\nPlease complete this survey by Wednesday before class.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#post-class-check-in-attendance",
    "href": "weeks/week_01.html#post-class-check-in-attendance",
    "title": "Week 1",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#homework",
    "href": "weeks/week_01.html#homework",
    "title": "Week 1",
    "section": "Homework",
    "text": "Homework\n\nHW 0: Course setup\n\nDue Sunday at 11:00 pm\nFocuses on course setup and basic concepts from Week 1\nView HW 0 instructions\n\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#looking-ahead",
    "href": "weeks/week_01.html#looking-ahead",
    "title": "Week 1",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext week we will introduce probability and begin exploratory data analysis and visualization.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_02.html",
    "href": "weeks/week_02.html",
    "title": "Week 2",
    "section": "",
    "text": "New TA: Nick Chaiyachakorn\nHW 0 Solutions released, and homework grading policy\nReminder: No class next Monday, January 19",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#announcements",
    "href": "weeks/week_02.html#announcements",
    "title": "Week 2",
    "section": "",
    "text": "New TA: Nick Chaiyachakorn\nHW 0 Solutions released, and homework grading policy\nReminder: No class next Monday, January 19",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#overview",
    "href": "weeks/week_02.html#overview",
    "title": "Week 2",
    "section": "Overview",
    "text": "Overview\nThis week focuses on categorical data and probability.\nWe will learn how to summarize and compare categorical variables using tables and plots, and then introduce the basic ideas of probability, conditional probability, and Bayes‚Äô theorem. These concepts form the foundation for statistical inference later in the course.\nBy the end of the week, you should be able to:\n\nsummarize categorical variables using counts and proportions,\ninterpret contingency tables using row and column percentages,\nunderstand probability as a long-run proportion,\ncompute conditional probabilities from tables,\nuse Bayes‚Äô theorem to reverse conditioning in applied examples.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#readings-before-class",
    "href": "weeks/week_02.html#readings-before-class",
    "title": "Week 2",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook sections 1.5‚Äì1.7 (categorical data and relationships)\nTextbook sections 2.1‚Äì2.2 (probability and conditional probability)\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#materials",
    "href": "weeks/week_02.html#materials",
    "title": "Week 2",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî Categorical data and relationships\n\nTopics\n\nCategorical variables\nFrequency tables and proportions\nBar plots\nContingency tables\nRow vs column percentages\nInterpreting conditional distributions\n\nSlides\n\nCategorical data and tables (HTML | PDF | OneDrive)\nR basics and data summaries (HTML | PDF | OneDrive)\n\nRecording\n\nLecture 03, Part 1 ‚Äì Categorical Data and Contingency Tables, R basics and data summaries\nLecture 03, Part 2 ‚Äì Categorical Data and Contingency Tables, R basics and data\n\n\nI was trying out new recording software today, and there was a glitch about 1 hour and 20 minutes into class. You are not missing any required material; the full lecture is covered across the two recordings.\nPart 1 (the first ~1 hour and 20 minutes) is available on OneDrive in MP4 format.\nPart 2 (the final ~10 minutes of class) is available via Loom.\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 3\n\n\n\n\n\nWednesday ‚Äî Probability and conditional probability\n\nTopics\n\nWhat probability means (long-run interpretation)\nSample space and events\nComplements and probability rules\nConditional probability\nBayes‚Äô theorem\nDiagnostic testing example (PPV)\n\nSlides\n\nProbability and conditional probability (HTML | PDF | OneDrive)\n\nRecording\n\nLecture 04 ‚Äì Probability and conditional probability (loom.com)\nLecture 04 ‚Äì Probability and conditional probability (OneDrive folder)\nMuddy points\n\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 4",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#homework",
    "href": "weeks/week_02.html#homework",
    "title": "Week 2",
    "section": "Homework",
    "text": "Homework\n\nHW 1\n\nDue Sunday at 11:00 pm\nCovers:\n\nvectors and missing values\nnumeric and categorical summaries\ncontingency tables\nhistograms and box plots\n\nView HW 1 instructions\n\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#post-class-check-in-attendance",
    "href": "weeks/week_02.html#post-class-check-in-attendance",
    "title": "Week 2",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#looking-ahead",
    "href": "weeks/week_02.html#looking-ahead",
    "title": "Week 2",
    "section": "Looking ahead",
    "text": "Looking ahead\nThere is no class next Monday.\nNext Wednesday we will begin data visualization and exploratory data analysis (EDA), including:\n\nhistograms, box plots, and scatterplots,\ndata frames vs tibbles,\nsubsetting and filtering data,\nan introduction to ggplot2.\n\nThese tools will help us move from summaries to storytelling with data.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_06.html",
    "href": "weeks/week_06.html",
    "title": "Week 6",
    "section": "",
    "text": "Midterm Exam opens Wednesday, February 11 at 3:00 PM and closes Monday, February 16 at 11:00 PM",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#announcements",
    "href": "weeks/week_06.html#announcements",
    "title": "Week 6",
    "section": "",
    "text": "Midterm Exam opens Wednesday, February 11 at 3:00 PM and closes Monday, February 16 at 11:00 PM",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#overview",
    "href": "weeks/week_06.html#overview",
    "title": "Week 6",
    "section": "Overview",
    "text": "Overview\nThis week focuses on comparing two groups and preparing for the midterm.\nOn Monday, we will extend our hypothesis testing framework to scenarios with two groups, distinguishing between paired (dependent) data and independent samples. On Wednesday, we will review all material covered so far and prepare for the midterm exam.\nBy the end of the week, you should be able to:\n\ndistinguish between paired and independent samples based on study design,\nperform paired t-tests for dependent data,\nconduct two-sample t-tests for independent groups,\nchoose the appropriate test based on how data were collected,\nsynthesize and apply all concepts from Weeks 1-5 (Lessons 1-9).",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#readings-before-class",
    "href": "weeks/week_06.html#readings-before-class",
    "title": "Week 6",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook section 5.2 (Paired data)\nTextbook section 5.3 (Difference of two means)\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#materials",
    "href": "weeks/week_06.html#materials",
    "title": "Week 6",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî Comparing Two Means: Paired and Independent Samples\n\nTopics\n\nFinish up R topics from last week.\nDistinguishing paired vs.¬†independent samples\nStudy design implications\nPaired t-tests: before-and-after studies\nTwo-sample t-tests: comparing independent groups\nConfidence intervals for paired differences\nConfidence intervals for differences in means\nConducting paired and two-sample tests in R\nChoosing the right test\n\nSlides\n\nR Workflow: Projects, File Paths, and Reading Data (start with slide 16) (HTML | PDF | OneDrive)\nComparing Two Means (HTML | PDF | OneDrive)\n\nRecording\n\nComparing two means\n\nMuddy points\n\nMuddy Points - Lesson 10\n\n\n\n\n\nWednesday ‚Äî Midterm Review\n\nTopics\n\nExam logistics and format\nStudy design fundamentals\nProbability and Bayes‚Äô Theorem\nProbability distributions (Binomial, Poisson, Normal)\nR functions for distributions\nSampling distributions and Central Limit Theorem\nConfidence intervals\nHypothesis testing framework\nCommon pitfalls and tips\n\nSlides\n\nMidterm Review (HTML | PDF | OneDrive)\n\nRecording\n\nComing soon\n\nMuddy points\n\nComing soon",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#homework",
    "href": "weeks/week_06.html#homework",
    "title": "Week 6",
    "section": "Homework",
    "text": "Homework\n\nNone this week. See Midterm Exam details below\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#midterm-exam",
    "href": "weeks/week_06.html#midterm-exam",
    "title": "Week 6",
    "section": "Midterm Exam",
    "text": "Midterm Exam\n\nOpens: Wednesday, February 11 at 3:00 PM\nCloses: Monday, February 16 at 11:00 PM\nFormat: 8 parts, 120 points total, designed for 3-5 hours completion\nCoverage: Lessons 1-9 (through hypothesis testing and one-sample t-tests)\nResources allowed: Course materials, R documentation, your notes\nNOT allowed: Collaboration with others, AI assistants, online help forums\nSubmit: Both .qmd and .html files",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#post-class-check-in-attendance",
    "href": "weeks/week_06.html#post-class-check-in-attendance",
    "title": "Week 6",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#looking-ahead",
    "href": "weeks/week_06.html#looking-ahead",
    "title": "Week 6",
    "section": "Looking ahead",
    "text": "Looking ahead\nAfter the midterm, we will continue building our statistical inference toolkit:\n\nWeek 7:\n\nPower\n\nWeek 8:\n\nInference for proportions (single and two-sample)\nChi-squared tests and categorical data analysis\n\n\nThese concepts extend our hypothesis testing framework to categorical outcomes and proportions.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_05.html",
    "href": "weeks/week_05.html",
    "title": "Week 5",
    "section": "",
    "text": "HW 4 released Monday, February 2",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#announcements",
    "href": "weeks/week_05.html#announcements",
    "title": "Week 5",
    "section": "",
    "text": "HW 4 released Monday, February 2",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#overview",
    "href": "weeks/week_05.html#overview",
    "title": "Week 5",
    "section": "Overview",
    "text": "Overview\nThis week focuses on statistical inference: making conclusions about populations based on sample data.\nWe will learn how to estimate population parameters using confidence intervals and how to test hypotheses about population parameters using hypothesis tests.\nBy the end of the week, you should be able to:\n\nunderstand the concept of a sampling distribution and standard error,\nconstruct and interpret confidence intervals for a population mean,\nexplain what a confidence level means,\nstate null and alternative hypotheses,\nconduct and interpret one-sample t-tests,\nunderstand p-values and statistical significance,\nrecognize the connection between confidence intervals and hypothesis tests.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#readings-before-class",
    "href": "weeks/week_05.html#readings-before-class",
    "title": "Week 5",
    "section": "Readings (before class)",
    "text": "Readings (before class)\n\nTextbook section 4.1 (Variability in estimates)\nTextbook section 4.2 (Confidence intervals)\nTextbook section 4.3 (Hypothesis testing)\nTextbook section 5.1 (Single-sample inference with the t-distribution)\n\n(Additional resources will be posted if helpful.)",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#materials",
    "href": "weeks/week_05.html#materials",
    "title": "Week 5",
    "section": "Materials",
    "text": "Materials\n\nMonday ‚Äî Estimation and Confidence Intervals\n\nTopics\n\nSampling distributions and standard error\nPoint estimates vs.¬†interval estimates\nConfidence intervals for population means\nInterpreting confidence levels (e.g., 95% CI)\nUsing the t-distribution when œÉ is unknown\nCalculating confidence intervals in R\n\nSlides\n\nEstimation and Confidence Intervals (HTML | PDF | OneDrive)\n\nRecording\n\nEstimation and Confidence Intervals\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 8\n\n\n\n\n\nWednesday ‚Äî Hypothesis Testing and One-Sample t-Tests\n\nTopics\n\nThe logic of hypothesis testing\nNull and alternative hypotheses\nTest statistics and p-values\nStatistical significance and decision rules\nOne-sample t-tests\nConducting t-tests in R\nConnection between confidence intervals and hypothesis tests\n\nSlides\n\nHypothesis Testing and One-Sample t-Tests (HTML | PDF | OneDrive)\nR Workflow: Projects, File Paths, and Reading Data (HTML | PDF | OneDrive)\n\nResource\n\nHypothesis Testing: One-Page Reference\nLink to class OneDrive folder ‚Äì see data folder\n\nRecording\n\nHypothesis testing, one-sample t-tests, and R workflow\n\nMuddy points\nI reviewed your post-class feedback and wrote clarifications here:\n\nMuddy Points - Lesson 9",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#homework",
    "href": "weeks/week_05.html#homework",
    "title": "Week 5",
    "section": "Homework",
    "text": "Homework\n\nHW 4\n\nReleased Monday, February 2\nDue Sunday, February 8 at 11:00 pm\nCovers:\n\nNormal distribution and properties\nZ-scores and standardization\nCalculating probabilities with pnorm() and qnorm()\nNormal approximation to the Binomial\nPoisson distribution\n\nView HW 4 instructions\n\nSee the full list of assignments on the Homework page.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#post-class-check-in-attendance",
    "href": "weeks/week_05.html#post-class-check-in-attendance",
    "title": "Week 5",
    "section": "Post-class check-in (attendance)",
    "text": "Post-class check-in (attendance)\n\nPlease complete the post-class check-in after each class meeting.\nUsed for attendance credit and to identify topics that need clarification.\nLink: Post-class check-in",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#looking-ahead",
    "href": "weeks/week_05.html#looking-ahead",
    "title": "Week 5",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext week we will continue with statistical inference:\n\nMonday: Paired data and paired t-tests; Two-sample independent t-tests\nWednesday: Midterm review\n\nThese concepts extend our hypothesis testing framework to compare two groups and handle related measurements.",
    "crumbs": [
      "Home",
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework",
    "section": "",
    "text": "File naming and submission\n\n\n\nFile naming: Lastname_FirstInitial_HW## (example: Latour_E_HW01)\nSubmit both files on Sakai:\n\nLastname_FirstInitial_HW##.qmd\nLastname_FirstInitial_HW##.html\nHomework assignments are due on Sundays at 11:00 pm unless otherwise noted.\nStart from the provided .qmd template for each assignment.",
    "crumbs": [
      "Home",
      "Homework"
    ]
  },
  {
    "objectID": "homework.html#homework-schedule",
    "href": "homework.html#homework-schedule",
    "title": "Homework",
    "section": "Homework schedule",
    "text": "Homework schedule\nAll homework files are distributed through OneDrive. Each homework link contains everything you need for that assignment.\nHomework solutions will be posted in Sakai after the submission deadline. These are provided for review and learning purposes.\n\n\n\nHW\nDue (@11pm)\nFiles\nPreview\n\n\n\n\n0\n01/11\nHW 00 files (OneDrive)\nView HW 00\n\n\n1\n01/18\nHW 01 files (OneDrive)\nView HW 01\n\n\n2\n01/27\nHW 02 files (OneDrive)\nView HW 02\n\n\n3\n02/01\nHW 03 files (OneDrive)\nView HW 03\n\n\n4\n02/08\nHW 04 files (OneDrive)\nView HW 04\n\n\n5\n02/22\n(to be posted)\n(to be posted)\n\n\n6\n03/01\n(to be posted)\n(to be posted)\n\n\n7\n03/08\n(to be posted)\n(to be posted)\n\n\n8\n03/15\n(to be posted)\n(to be posted)",
    "crumbs": [
      "Home",
      "Homework"
    ]
  },
  {
    "objectID": "homework.html#grading-rubric-10-points",
    "href": "homework.html#grading-rubric-10-points",
    "title": "Homework",
    "section": "Grading rubric (10 points)",
    "text": "Grading rubric (10 points)\nEach homework is graded on a 10-point scale:\n\nSubstantial completion (6 points): ~75-80% of parts attempted with a genuine effort\nDemonstrated process (2 points): relevant work shown; R code included when used\nInterpretation and communication (2 points): brief written interpretation in context when appropriate\n\nHomework is graded primarily for effort, reasoning, and clarity, not strict correctness.\n\nLate homework\nLate homework is accepted for partial credit (up to 80% of total points).\nFeedback is provided only for homework submitted on time.",
    "crumbs": [
      "Home",
      "Homework"
    ]
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html",
    "href": "resources/hypothesis_testing_handout.html",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "",
    "text": "Goal: Use sample data to evaluate evidence against a specific claim about a population parameter.\n\nThe claim we test is the null hypothesis\nWe assume the null is true and ask: How surprising is our data under that assumption?"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#what-is-hypothesis-testing",
    "href": "resources/hypothesis_testing_handout.html#what-is-hypothesis-testing",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "",
    "text": "Goal: Use sample data to evaluate evidence against a specific claim about a population parameter.\n\nThe claim we test is the null hypothesis\nWe assume the null is true and ask: How surprising is our data under that assumption?"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#key-hypotheses",
    "href": "resources/hypothesis_testing_handout.html#key-hypotheses",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Key hypotheses",
    "text": "Key hypotheses\nNull hypothesis (\\(H_0\\))\n\nRepresents the status quo or specific claim\nUses an equals sign\n\n\\[H_0: \\mu = \\mu_0\\]\nAlternative hypothesis (\\(H_A\\))\n\nRepresents what we‚Äôre looking for evidence in favor of\nUses \\(\\neq\\), \\(&lt;\\), or \\(&gt;\\)\n\n\\[H_A: \\mu \\neq \\mu_0 \\quad \\text{(two-sided)}\\] \\[H_A: \\mu &lt; \\mu_0 \\quad \\text{or} \\quad H_A: \\mu &gt; \\mu_0 \\quad \\text{(one-sided)}\\]"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#significance-level-alpha",
    "href": "resources/hypothesis_testing_handout.html#significance-level-alpha",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Significance level (\\(\\alpha\\))",
    "text": "Significance level (\\(\\alpha\\))\n\n\\(\\alpha\\) is the threshold for ‚Äústrong evidence‚Äù\nChosen before seeing the data\nMost common: \\(\\alpha = 0.05\\)\n\nInterpretation: If \\(H_0\\) is true, we are willing to reject it incorrectly at most \\(\\alpha \\times 100\\)% of the time."
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#assumptions-for-a-one-sample-t-test",
    "href": "resources/hypothesis_testing_handout.html#assumptions-for-a-one-sample-t-test",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Assumptions for a one-sample t-test",
    "text": "Assumptions for a one-sample t-test\n\nObservations are independent\nData are approximately normal OR sample size is large (\\(n \\geq 30\\), CLT applies)"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#test-statistic-what-comes-from-the-data",
    "href": "resources/hypothesis_testing_handout.html#test-statistic-what-comes-from-the-data",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Test statistic (what comes from the data)",
    "text": "Test statistic (what comes from the data)\nThe t-statistic measures how far the sample mean is from the null value, in standard error units:\n\\[t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\]\n\nComes from the sample\nRandom (varies from study to study)\nUnder \\(H_0\\), follows a t-distribution with \\(df = n - 1\\)"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#critical-value-what-defines-too-extreme",
    "href": "resources/hypothesis_testing_handout.html#critical-value-what-defines-too-extreme",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Critical value (what defines ‚Äútoo extreme‚Äù)",
    "text": "Critical value (what defines ‚Äútoo extreme‚Äù)\n\nComes from the t-distribution\nDepends on \\(\\alpha\\) and degrees of freedom\nFixed before seeing the data\n\n\\[t^* = t_{1-\\alpha/2,\\; df} \\quad \\text{(two-sided)}\\]"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#decision-rules-three-equivalent-ways",
    "href": "resources/hypothesis_testing_handout.html#decision-rules-three-equivalent-ways",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Decision rules (three equivalent ways)",
    "text": "Decision rules (three equivalent ways)\n\n1. Test-statistic approach\nReject \\(H_0\\) if: \\(|t_{\\text{obs}}| &gt; t^*\\)\n\n\n2. P-value approach\nP-value: Probability of observing a test statistic as extreme as (or more extreme than) what we saw, assuming \\(H_0\\) is true.\nReject \\(H_0\\) if: \\(\\text{p-value} &lt; \\alpha\\)\n\n\n3. Confidence interval approach (two-sided tests)\nReject \\(H_0\\) if: the \\((1 - \\alpha) \\times 100\\)% confidence interval does not contain \\(\\mu_0\\)"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#what-p-values-mean-and-dont-mean",
    "href": "resources/hypothesis_testing_handout.html#what-p-values-mean-and-dont-mean",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "What p-values mean (and don‚Äôt mean)",
    "text": "What p-values mean (and don‚Äôt mean)\n\n\nP-value IS:\n\nA measure of how surprising the data are if \\(H_0\\) were true\n\n\nP-value is NOT:\n\nThe probability that \\(H_0\\) is true\nThe probability you made a mistake\nA measure of effect size or importance"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#common-language-to-use",
    "href": "resources/hypothesis_testing_handout.html#common-language-to-use",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Common language to use",
    "text": "Common language to use\n‚úîÔ∏è ‚ÄúWe reject the null hypothesis‚Äù\n‚úîÔ∏è ‚ÄúWe fail to reject the null hypothesis‚Äù\n‚ùå ‚ÄúWe accept the null hypothesis‚Äù"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#one-sample-t-test-in-r",
    "href": "resources/hypothesis_testing_handout.html#one-sample-t-test-in-r",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "One-sample t-test in R",
    "text": "One-sample t-test in R\n\nt.test(x, mu = mu0, alternative = \"two.sided\", conf.level = 0.95)\n\nKey output:\n\nt-statistic\ndegrees of freedom\np-value\nconfidence interval\nsample mean"
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#reporting-results-example",
    "href": "resources/hypothesis_testing_handout.html#reporting-results-example",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Reporting results (example)",
    "text": "Reporting results (example)\n\nA one-sample t-test was conducted to assess whether mean body temperature differs from 98.6¬∞F. The sample (\\(n = 130\\)) had a mean of 98.25¬∞F (SD = 0.733). The test was statistically significant, \\(t(129) = -5.45\\), \\(p &lt; 0.001\\), with a 95% confidence interval of [98.12, 98.38], indicating that the population mean body temperature is lower than 98.6¬∞F."
  },
  {
    "objectID": "resources/hypothesis_testing_handout.html#big-picture-reminder",
    "href": "resources/hypothesis_testing_handout.html#big-picture-reminder",
    "title": "Hypothesis Testing: One-Page Reference",
    "section": "Big picture reminder",
    "text": "Big picture reminder\n\nHypothesis tests and confidence intervals use the same information\nA small p-value does not imply practical importance\nAlways interpret results in context ```"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "homework/HW00/HW00.html",
    "href": "homework/HW00/HW00.html",
    "title": "BMSC 620 ‚Äî Homework 0",
    "section": "",
    "text": "Note\n\n\n\nFile naming and submission\nPlease use the following file naming convention:\nLastname_FirstInitial_HW##\nExamples:\n\nSmith_J_HW01.qmd\nSmith_J_HW01.html\n\nWhen submitting Homework 0, upload both:\n\nthe .qmd file\nthe rendered .html file"
  },
  {
    "objectID": "homework/HW00/HW00.html#homework-0",
    "href": "homework/HW00/HW00.html#homework-0",
    "title": "BMSC 620 ‚Äî Homework 0",
    "section": "Homework 0",
    "text": "Homework 0\nThis assignment is intended to help you get comfortable working in RStudio and using Quarto documents.\nThis assignment is graded for completion and effort, not correctness."
  },
  {
    "objectID": "homework/HW00/HW00.html#part-1-markdown-practice",
    "href": "homework/HW00/HW00.html#part-1-markdown-practice",
    "title": "BMSC 620 ‚Äî Homework 0",
    "section": "Part 1: Markdown practice",
    "text": "Part 1: Markdown practice\nEdit this section to demonstrate the following:\n\nBold text\nItalic text\nA bulleted list\nA numbered list\n\nYou may replace the text below with your own examples.\n\nExample bullet\nAnother bullet\n\n\nExample item\nAnother item"
  },
  {
    "objectID": "homework/HW00/HW00.html#part-2-r-code-chunks",
    "href": "homework/HW00/HW00.html#part-2-r-code-chunks",
    "title": "BMSC 620 ‚Äî Homework 0",
    "section": "Part 2: R code chunks",
    "text": "Part 2: R code chunks\nBelow is an example R code chunk.\n\n# This is a comment\n\n2 + 2\n\n[1] 4\n\n\n\nTasks\n\nModify the code chunk above so that it:\n\n\nIncludes at least one additional comment\nRuns without errors\n\n\nAdd a second R code chunk below that:\n\n\nCreates a numeric vector with at least 5 numbers\nComputes the mean of that vector using mean()\nI‚Äôve included an example below as one possible solution for reference. The submitted code should be your own.\n\n\n\nExample (for reference only)\n\n# Example\n\n# Create a numeric vector\nx &lt;- c(3, 7, 10, 4, 6)\n\n# Compute the mean\nmean(x)\n\n[1] 6\n\n\n\n# Your code here"
  },
  {
    "objectID": "homework/HW00/HW00.html#part-3-final-check",
    "href": "homework/HW00/HW00.html#part-3-final-check",
    "title": "BMSC 620 ‚Äî Homework 0",
    "section": "Part 3: Final check",
    "text": "Part 3: Final check\nBefore you are finished, confirm that:\n\nThe document renders to HTML without errors\nAll R code chunks run successfully\nYour name appears at the top of the document"
  },
  {
    "objectID": "homework/HW04/HW04.html",
    "href": "homework/HW04/HW04.html",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "",
    "text": "Note\n\n\n\nFile naming and submission\nPlease use the following file naming convention:\nLastname_FirstInitial_HW##\nExamples:\n\nSmith_J_HW04.qmd\nSmith_J_HW04.html\n\nWhen submitting Homework 4, upload both:\n\nthe .qmd file\nthe rendered .html file"
  },
  {
    "objectID": "homework/HW04/HW04.html#instructions",
    "href": "homework/HW04/HW04.html#instructions",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Instructions",
    "text": "Instructions\n\nAnswer each question clearly and concisely.\nShow your work when calculations are involved.\nUse R to compute probabilities and quantiles when requested.\nYou may round final answers to 3 decimal places unless otherwise noted.\nDo not use continuity correction for Normal approximations in this assignment.\n\n\n\n\n\n\n\nTip\n\n\n\nSome code chunks are intentionally incomplete. Fill in the missing values so the code runs correctly."
  },
  {
    "objectID": "homework/HW04/HW04.html#part-1-the-normal-distribution",
    "href": "homework/HW04/HW04.html#part-1-the-normal-distribution",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 1: The Normal Distribution",
    "text": "Part 1: The Normal Distribution\n\n1A. Properties of the Normal distribution\nAnswer briefly (1‚Äì2 sentences each).\n\nWhat does it mean for a distribution to be symmetric?\nWhat parameters define a Normal distribution?\nWhy is the Normal distribution important in statistics?\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-2-z-scores-and-standardization",
    "href": "homework/HW04/HW04.html#part-2-z-scores-and-standardization",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 2: Z-scores and Standardization",
    "text": "Part 2: Z-scores and Standardization\nSuppose adult systolic blood pressure (SBP) is Normally distributed with:\n\nMean = 120 mmHg\nStandard deviation = 15 mmHg\n\n\n2A. Calculating z-scores\n\nCompute the z-score for an individual with SBP = 135 mmHg.\nInterpret this z-score in words.\n\n\n# Define parameters\nmu &lt;- 120\nsigma &lt;- 15\nx &lt;- 135\n\n# Compute z-score: z = (x - mu) / sigma\nz &lt;- \n\nz\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-3-probabilities-from-the-normal-distribution",
    "href": "homework/HW04/HW04.html#part-3-probabilities-from-the-normal-distribution",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 3: Probabilities from the Normal Distribution",
    "text": "Part 3: Probabilities from the Normal Distribution\nUsing the same SBP distribution:\n\n3A. Probabilities\n\nWhat proportion of adults have SBP above 140 mmHg?\nWhat proportion have SBP between 110 and 130 mmHg?\n\n\n# Proportion above 140\npnorm(\n  q = ,\n  mean = ,\n  sd = ,\n  lower.tail = \n)\n\n# Proportion between 110 and 130\n# P(110 &lt; X &lt; 130) = P(X &lt; 130) - P(X &lt; 110)\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-4-quantiles-and-cutoffs",
    "href": "homework/HW04/HW04.html#part-4-quantiles-and-cutoffs",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 4: Quantiles and Cutoffs",
    "text": "Part 4: Quantiles and Cutoffs\n\n4A. Percentiles\n\nWhat SBP value corresponds to the 90th percentile?\nHypertension screening flags the top 10% of SBP values. What is the cutoff?\n\n\n# 90th percentile\nqnorm(\n  p = ,\n  mean = ,\n  sd = \n)\n\nAnswers:\n\n\n\n\nInterpret the cutoff in one sentence:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-5-binomial-distribution",
    "href": "homework/HW04/HW04.html#part-5-binomial-distribution",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 5: Binomial Distribution",
    "text": "Part 5: Binomial Distribution\nA new medication has a 30% chance of success for each patient. Suppose 20 patients are treated.\n\n5A. Exact Binomial probabilities\n\nWhat is the probability that exactly 8 patients respond?\nWhat is the probability that at least 5 patients respond?\n\n\n# Exactly 8 successes\ndbinom(\n  x = ,\n  size = ,\n  prob = \n)\n\n# At least 5 successes\n# P(X &gt;= 5) = P(X &gt; 4) = 1 - P(X &lt;= 4)\npbinom(\n  q = ,\n  size = ,\n  prob = ,\n  lower.tail = \n)\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-6-normal-approximation-to-the-binomial",
    "href": "homework/HW04/HW04.html#part-6-normal-approximation-to-the-binomial",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 6: Normal Approximation to the Binomial",
    "text": "Part 6: Normal Approximation to the Binomial\nSuppose a manufacturing process has a defect rate of 10%. Out of 200 items produced:\n\n6A. Check conditions\n\nState the mean and standard deviation of the Binomial distribution.\nVerify whether a Normal approximation is reasonable.\n\n\nn &lt;- 200\np &lt;- 0.10\n\n# Mean of binomial: mu = n * p\nmu_b &lt;- \n\n# SD of binomial: sd = sqrt(n * p * (1 - p))\nsd_b &lt;- \n\nmu_b\nsd_b\n\n# Check conditions: np &gt;= 10 and n(1-p) &gt;= 10\n\nAnswers:\n\n\n\n\n\n\n6B. Approximate probability\nUse a Normal approximation without continuity correction.\nWhat is the approximate probability that more than 30 items are defective?\n\n# P(X &gt; 30) using Normal approximation\npnorm(\n  q = ,\n  mean = ,\n  sd = ,\n  lower.tail = \n)\n\nAnswer:\nBriefly comment on whether this approximation seems reasonable:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-7-poisson-distribution",
    "href": "homework/HW04/HW04.html#part-7-poisson-distribution",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 7: Poisson Distribution",
    "text": "Part 7: Poisson Distribution\nEmergency room arrivals follow a Poisson distribution with an average rate of 3 arrivals per hour.\n\n7A. Probabilities\n\nWhat is the probability of exactly 2 arrivals in an hour?\nWhat is the probability of at least 5 arrivals in an hour?\n\n\n# Exactly 2 arrivals\ndpois(\n  x = ,\n  lambda = \n)\n\n# At least 5 arrivals: P(X &gt;= 5) = 1 - P(X &lt;= 4)\nppois(\n  q = ,\n  lambda = ,\n  lower.tail = \n)\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#part-8-choosing-the-right-distribution",
    "href": "homework/HW04/HW04.html#part-8-choosing-the-right-distribution",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Part 8: Choosing the Right Distribution",
    "text": "Part 8: Choosing the Right Distribution\nFor each scenario, state which distribution (Normal, Binomial, or Poisson) is most appropriate and briefly explain why.\n\nNumber of typos on a randomly selected manuscript page\nProportion of voters in a sample who support a candidate\nAdult heights in a large population\n\nAnswers:"
  },
  {
    "objectID": "homework/HW04/HW04.html#optional-not-graded-reflection",
    "href": "homework/HW04/HW04.html#optional-not-graded-reflection",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Optional (Not Graded): Reflection",
    "text": "Optional (Not Graded): Reflection\nIn 2‚Äì3 sentences, describe one situation where using the wrong distribution could lead to misleading conclusions.\nAnswer:"
  },
  {
    "objectID": "homework/HW04/HW04.html#submission-checklist",
    "href": "homework/HW04/HW04.html#submission-checklist",
    "title": "BMSC 620 ‚Äî Homework 4",
    "section": "Submission checklist",
    "text": "Submission checklist\nBefore submitting, make sure you have:\n\nAnswered all required questions\nIncluded R output where requested\nWritten brief interpretations in words when asked\nRendered your HTML successfully\nUploaded both .qmd and .html files"
  },
  {
    "objectID": "homework/HW02/HW02.html",
    "href": "homework/HW02/HW02.html",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "",
    "text": "Note\n\n\n\nFile naming and submission\nPlease use the following file naming convention:\nLastname_FirstInitial_HW##\nExamples:\n\nSmith_J_HW02.qmd\nSmith_J_HW02.html\n\nWhen submitting Homework 2, upload both:\n\nthe .qmd file\nthe rendered .html file"
  },
  {
    "objectID": "homework/HW02/HW02.html#homework-2",
    "href": "homework/HW02/HW02.html#homework-2",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Homework 2",
    "text": "Homework 2\nThis assignment reviews:\n\ndata wrangling with dplyr\nsummary tables with janitor and rstatix\ndata visualization with ggplot2\nprobability concepts: marginal, joint, and conditional probabilities\n\nUnless stated otherwise, show your work using R code chunks."
  },
  {
    "objectID": "homework/HW02/HW02.html#part-0-setup",
    "href": "homework/HW02/HW02.html#part-0-setup",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 0: Setup",
    "text": "Part 0: Setup\n\nIn the chunk below, load the packages you need for this homework.\nRun the chunk to confirm there are no errors.\n\n\n# NOTE: If you don't already have the oibiostat package installed, then uncomment and run the two lines below. Then re-comment them and check installation with `library(oibiostat)`.\n# install.packages(\"devtools\")\n# devtools::install_github(\"OI-Biostat/oi_biostat_data\", force = TRUE)\n\nlibrary(oibiostat)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(janitor)\nlibrary(rstatix)"
  },
  {
    "objectID": "homework/HW02/HW02.html#part-1-exploring-data-with-tidyverse-tools",
    "href": "homework/HW02/HW02.html#part-1-exploring-data-with-tidyverse-tools",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 1: Exploring data with tidyverse tools",
    "text": "Part 1: Exploring data with tidyverse tools\nIn this homework, you will work with the nhanes.samp dataset (the same dataset from HW1, but now using tidyverse tools!).\nLoad the dataset:\n\ndata(\"nhanes.samp\")\n\n\n1A. Initial data inspection\nUse the following tidyverse functions to explore the data:\n\nglimpse() to see the structure\nUse the pipe %&gt;% with head() to see first 5 rows (e.g., nhanes.samp %&gt;% head(5))\ndim() to get dimensions\n\nAnswer in plain text:\n\nHow many rows and columns does nhanes.samp have?\nWhat type of variable is Race1? What about Age?\nHow is this different from using str() in HW1?\n\nAnswers: 1. 2. 3.\n\n\n1B. Using filter() and select()\n\nUse filter() to keep only people with PhysActive == \"Yes\" (physically active)\nThen use select() to keep only the columns: Age, Gender, Race1, PhysActive, Pulse\nAssign this filtered/selected data to a new object called active_people\n\nHow many physically active people are in the dataset? (Use nrow() on your new object)\nAnswer:\n\n\n1C. Creating new variables with mutate()\nUsing the full nhanes.samp dataset:\n\nUse mutate() to create a new variable called age_group that categorizes age:\n\n‚ÄúChild‚Äù if Age &lt; 18\n‚ÄúAdult‚Äù if Age &lt; 65\n‚ÄúSenior‚Äù if Age &gt;= 65\n\nUse select() to show just ID, Age, and age_group\nUse head() to show the first 10 rows\n\nHint: Use case_when() inside mutate()."
  },
  {
    "objectID": "homework/HW02/HW02.html#part-2-summary-statistics-with-rstatix",
    "href": "homework/HW02/HW02.html#part-2-summary-statistics-with-rstatix",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 2: Summary statistics with rstatix",
    "text": "Part 2: Summary statistics with rstatix\n\n2A. Summary for one variable\nUse get_summary_stats() from the rstatix package to calculate the mean and standard deviation of Pulse. Use type = \"mean_sd\".\n\n\n2B. Summary by groups\nUse group_by() and get_summary_stats() to calculate the mean and standard deviation of Pulse by PhysActive (physically active yes/no).\nDo physically active people have a higher or lower mean pulse rate? What might explain this?\nAnswer:\n\n\n2C. Multiple variables and groups\nCalculate summary statistics for Age, Pulse, and Weight grouped by both Gender AND PhysActive status. Use type = \"mean_sd\"."
  },
  {
    "objectID": "homework/HW02/HW02.html#part-3-frequency-tables-with-janitor",
    "href": "homework/HW02/HW02.html#part-3-frequency-tables-with-janitor",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 3: Frequency tables with janitor",
    "text": "Part 3: Frequency tables with janitor\n\n3A. One-way frequency table\nUse tabyl() to create a frequency table for the Race1 variable.\nWhich racial/ethnic group has the highest percentage in this sample?\nAnswer:\n\n\n3B. Two-way table\nCreate a two-way table showing the relationship between Gender and PhysActive using tabyl().\n\n\n3C. Adorned tables\n\nCreate the same Gender √ó PhysActive table\nAdd row percentages using adorn_percentages(\"row\")\nFormat percentages with one decimal place using adorn_pct_formatting(digits = 1)\nAdd totals for rows and columns using adorn_totals(c(\"row\", \"col\"))\n\nAmong females, what percentage are physically active? Among males? (Look at the row percentages)\nAnswer:"
  },
  {
    "objectID": "homework/HW02/HW02.html#part-4-data-visualization-with-ggplot2",
    "href": "homework/HW02/HW02.html#part-4-data-visualization-with-ggplot2",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 4: Data visualization with ggplot2",
    "text": "Part 4: Data visualization with ggplot2\n\n4A. Histogram\nCreate a histogram of Age using ggplot2. Include:\n\nbins = 20\nA title: ‚ÄúDistribution of Age in NHANES Sample‚Äù\nAn x-axis label: ‚ÄúAge (years)‚Äù\n\nDescribe the distribution in 1-2 sentences (shape, center, spread, any interesting features).\nAnswer:\n\n\n4B. Boxplot by group\nCreate a boxplot comparing Pulse across PhysActive groups. Include:\n\nAppropriate axis labels\nA title\nTry adding fill = PhysActive inside aes() for color\n\nDo physically active people appear to have different pulse rates? Are there any outliers?\nAnswer:\n\n\n4C. Scatterplot\nCreate a scatterplot of Age (x-axis) vs Pulse (y-axis).\n\nColor the points by Gender\nSet alpha = 0.5 for transparency\nAdd appropriate labels and a title\n\nDescribe any relationship between age and pulse rate in 1-2 sentences.\nAnswer:\n\n\n4D. Bar chart\nCreate a bar chart showing counts of the Race1 variable.\n\nAdd a title and axis labels\nUse coord_flip() at the end to make horizontal bars (easier to read the labels)"
  },
  {
    "objectID": "homework/HW02/HW02.html#part-5-combining-dplyr-and-ggplot2-bonus---optional",
    "href": "homework/HW02/HW02.html#part-5-combining-dplyr-and-ggplot2-bonus---optional",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 5: Combining dplyr and ggplot2 (BONUS - Optional)",
    "text": "Part 5: Combining dplyr and ggplot2 (BONUS - Optional)\nThis section is optional but recommended for extra practice combining dplyr and ggplot2.\n\n5A. Filter then visualize\n\nUse pipes to filter to people under age 20 (children/adolescents)\nCreate a histogram of their Pulse\nUse facet_wrap(~Gender) to create separate panels by gender\n\nDo the pulse rate distributions look similar between males and females in this age group?\nAnswer:\n\n\n5B. Complex workflow\nCreate a workflow that:\n\nFilters to people who are physically active (PhysActive == \"Yes\")\nCreates a new variable age_category:\n\n‚ÄúUnder 30‚Äù if Age &lt; 30\n‚Äú30-50‚Äù if Age &lt; 50\n‚Äú50+‚Äù if Age &gt;= 50\n\nCreates a boxplot of Pulse by age_category\nColors the boxes by age_category using fill = age_category in aes()\nFacets by Gender"
  },
  {
    "objectID": "homework/HW02/HW02.html#part-6-probability-concepts",
    "href": "homework/HW02/HW02.html#part-6-probability-concepts",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Part 6: Probability concepts",
    "text": "Part 6: Probability concepts\nFor this section, we‚Äôll work with a medical testing scenario.\nConsider the following contingency table showing disease status and test results for 1,000 patients:\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n180\n270\n\n\nTest -\n10\n720\n730\n\n\nTotal\n100\n900\n1,000\n\n\n\n\n6A. Marginal probabilities\nCalculate the following marginal probabilities:\n\n\\(P(\\text{Disease})\\)\n\\(P(\\text{Test +})\\)\n\\(P(\\text{No Disease})\\)\n\nShow your calculations below (you can do this by hand or in R):\nAnswers: 1. P(Disease) = 2. P(Test +) = 3. P(No Disease) =\n\n\n6B. Joint probabilities\nCalculate the following joint probabilities:\n\n\\(P(\\text{Disease and Test +})\\)\n\\(P(\\text{No Disease and Test -})\\)\n\\(P(\\text{Disease and Test -})\\)\n\nAnswers: 1. P(Disease and Test +) = 2. P(No Disease and Test -) = 3. P(Disease and Test -) =\n\n\n6C. Conditional probabilities\nCalculate the following conditional probabilities. Remember:\n\\[P(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]\n\n\\(P(\\text{Disease} \\mid \\text{Test +})\\) - This is the Positive Predictive Value (PPV)\n\\(P(\\text{No Disease} \\mid \\text{Test -})\\) - This is the Negative Predictive Value (NPV)\n\\(P(\\text{Test +} \\mid \\text{Disease})\\) - This is the sensitivity\n\nShow your work:\nAnswers: 1. P(Disease | Test +) = 2. P(No Disease | Test -) = 3. P(Test + | Disease) =\n\n\n6D. Interpretation\nIn 2-3 sentences, explain what the Positive Predictive Value (PPV) from 6C.1 tells us. Why might this value be lower than the sensitivity?\nAnswer:"
  },
  {
    "objectID": "homework/HW02/HW02.html#final-check",
    "href": "homework/HW02/HW02.html#final-check",
    "title": "BMSC 620 ‚Äî Homework 2",
    "section": "Final check",
    "text": "Final check\nBefore submitting, confirm that:\n\nThe document renders to HTML without errors\nAll code chunks run successfully\nYour name appears at the top\nYou‚Äôve answered all text questions in Parts 1-6\nYou uploaded both the .qmd and .html files\n(Optional) If you completed Part 5, make sure those chunks run too!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#section",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#section",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "",
    "text": "Artwork by @allison_horst"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#roadmap-for-today",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#roadmap-for-today",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Roadmap for Today",
    "text": "Roadmap for Today\n\n\nPart 1: Sampling Fundamentals\n\nPopulation parameters vs.¬†sample statistics\nPoint estimates\nSampling variability\n\nPart 2: Sampling Distributions\n\nWhat is a sampling distribution?\nProperties of the sampling distribution of means\nStandard error\n\nPart 3: Central Limit Theorem\n\nStatement of the CLT\nWhen the CLT applies\nApplications with R\n\n\nPart 4: Introduction to Inference\n\nFrom point estimates to interval estimates\nConfidence intervals: concept and interpretation\n\nPart 5: Confidence Intervals in Practice\n\nCI when œÉ is known (z-based)\nCI when œÉ is unknown (t-based)\nThe t-distribution\n\nPart 6: Wrap-up\n\nSummary\nCommon misconceptions\nNext steps"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-do-we-sample",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-do-we-sample",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why do we sample?",
    "text": "Why do we sample?\n\n\n\nThe fundamental challenge of statistics\n\n\nWe want to learn about a population, but we can only observe a sample.\n\n\n\n\n\nPopulations:\n\nToo large to measure everyone\nToo expensive or time-consuming\nSometimes impossible (would you destroy every lightbulb to test lifespan?)\n\n\n\nSamples:\n\nSmaller, manageable\nIf chosen properly, can tell us about the population\nBut there‚Äôs uncertainty‚Ä¶"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#from-week-1-population-vs.-sample",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#from-week-1-population-vs.-sample",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "From Week 1: Population vs.¬†sample",
    "text": "From Week 1: Population vs.¬†sample\n\n\n\n\n\n(Target) Population\n\n\n\nGroup of interest being studied\nGroup from which the sample is selected\n\nstudies often have inclusion and/or exclusion criteria\n\nAlmost always too expensive or logistically impossible to collect data for every case in a population\n\n\n\n\n\n\n\n\nSample\n\n\n\nGroup on which data are collected\nA subset (of measurements) from the population\n\n\n\n\n\n\nWe use information from a sample to learn about the population from which it was drawn.\nGoal is to get a representative sample of the population: the characteristics of the sample are similar to the characteristics of the population"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#population-vs.-sample-visual",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#population-vs.-sample-visual",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Population vs.¬†Sample: Visual",
    "text": "Population vs.¬†Sample: Visual"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#population-parameters-vs.-sample-statistics",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#population-parameters-vs.-sample-statistics",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Population parameters vs.¬†Sample statistics",
    "text": "Population parameters vs.¬†Sample statistics\nUnderstanding the notation is crucial for clear statistical thinking.\n\n\n\n\n\n\n\nPopulation Parameter\n\n\nFixed (but unknown) values describing the population\nFor the mean:\n\nSymbol: \\(\\mu\\) (mu)\nWe want to know it but usually can‚Äôt measure it\n\nFor standard deviation:\n\nSymbol: \\(\\sigma\\) (sigma)\nAlso fixed and unknown\n\nFor proportion:\n\nSymbol: \\(p\\) or \\(\\pi\\) (pi)\n\n\n\n\n\n\n\n\nSample Statistic\n\n\nCalculated values from our sample data\nFor the mean:\n\nSymbol: \\(\\bar{x}\\) (x-bar)\nOur best guess at \\(\\mu\\)\n\nFor standard deviation:\n\nSymbol: \\(s\\)\nOur estimate of \\(\\sigma\\)\n\nFor proportion:\n\nSymbol: \\(\\hat{p}\\) (p-hat)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-point-estimate",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-point-estimate",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What is a point estimate?",
    "text": "What is a point estimate?\nA point estimate is a single value calculated from sample data used to estimate a population parameter.\n\n\nExamples:\n\nSample mean (\\(\\bar{x}\\)) estimates population mean (\\(\\mu\\))\nSample proportion (\\(\\hat{p}\\)) estimates population proportion (\\(p\\))\nSample standard deviation (\\(s\\)) estimates population SD (\\(\\sigma\\))\n\n\n\n\n\n\nThe problem with point estimates\n\n\nThey‚Äôre just single numbers. They don‚Äôt tell us:\n\nHow much uncertainty there is\nHow close we might be to the true value\nWhether our sample was typical or unusual"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-variability-a-demonstration-in-r-12",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-variability-a-demonstration-in-r-12",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Sampling variability: A demonstration in R (1/2)",
    "text": "Sampling variability: A demonstration in R (1/2)\nLet‚Äôs see what happens when we take multiple samples from the same population.\n\n# Create a population\npopulation &lt;- tibble(\n  height = rnorm(10000, mean = 65, sd = 3)\n)\n\n# Take 5 samples of size 50\nresults &lt;- tibble(\n  sample_num = 1:5,\n  mean_height = NA_real_  # Initialize with missing values\n)\n\n# Calculate mean for each sample\nfor (i in 1:5) {\n  one_sample &lt;- sample(population$height, size = 50)   # Take a random sample\n  results$mean_height[i] &lt;- mean(one_sample)           # Calculate the mean\n}"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-variability-a-demonstration-in-r-22",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-variability-a-demonstration-in-r-22",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Sampling variability: A demonstration in R (2/2)",
    "text": "Sampling variability: A demonstration in R (2/2)\nThe results from taking\n\n5 random samples,\neach size 50,\nfrom our population of 10,000\n\n\nresults\n\n# A tibble: 5 √ó 2\n  sample_num mean_height\n       &lt;int&gt;       &lt;dbl&gt;\n1          1        64.8\n2          2        64.4\n3          3        64.8\n4          4        65.5\n5          5        64.7\n\n\n\n\nNotice: Even from the same population, our sample means vary! This is sampling variability - it‚Äôs not error, it‚Äôs natural variation."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-13",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-13",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visualizing sampling variability (1/3)",
    "text": "Visualizing sampling variability (1/3)\nWhat if we took many, many samples?\n\nFrom the same population size 10,000 with \\(\\mu = 65\\) and \\(\\sigma = 3\\)\n\n\n# Take 1000 samples, each of size 50\nmany_samples &lt;- tibble(\n  sample_num = 1:1000,\n  mean_height = NA_real_  # Initialize with missing values\n)\n\n# Calculate mean for each sample\nfor (i in 1:1000) {\n  one_sample &lt;- sample(population$height, size = 50)   # Take a random sample\n  many_samples$mean_height[i] &lt;- mean(one_sample)      # Calculate the mean\n}"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-23",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-23",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visualizing sampling variability (2/3)",
    "text": "Visualizing sampling variability (2/3)\nWhat if we took many, many samples?\n\nFrom the same population size 10,000 with \\(\\mu = 65\\) and \\(\\sigma = 3\\)\n\n\ndim(many_samples)\n\n[1] 1000    2\n\nhead(many_samples)\n\n# A tibble: 6 √ó 2\n  sample_num mean_height\n       &lt;int&gt;       &lt;dbl&gt;\n1          1        64.3\n2          2        65.0\n3          3        65.1\n4          4        65.0\n5          5        63.9\n6          6        63.7"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-33",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-sampling-variability-33",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visualizing sampling variability (3/3)",
    "text": "Visualizing sampling variability (3/3)\nWhat if we took many, many samples?"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-sampling-distribution",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-sampling-distribution",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What is a sampling distribution?",
    "text": "What is a sampling distribution?\n\n\n\nDefinition\n\n\nThe sampling distribution of a statistic is the distribution of that statistic‚Äôs values across all possible samples of a given size from a population.\n\n\n\n\n\nThink of it this way:\n\nImagine taking a sample of size \\(n\\)\nCalculate a statistic (like the mean)\nWrite it down\nRepeat steps 1-3 for all possible samples\nThe distribution of those statistics is the sampling distribution\n\n\n\nKey insight: The sampling distribution tells us how our estimates behave across different samples."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#three-distributions-to-keep-straight",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#three-distributions-to-keep-straight",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Three distributions to keep straight",
    "text": "Three distributions to keep straight\n\n\n\n\n\nPopulation Distribution\n\n\n\nDistribution of the variable in the population\nMean: \\(\\mu\\), SD: \\(\\sigma\\)\nFixed, but unknown\nWe never observe this directly\n\n\n\n\n\n\n\n\nSample Distribution\n\n\n\nDistribution of the variable in one sample\nMean: \\(\\bar{x}\\), SD: \\(s\\)\nRandom (changes sample to sample)\nWhat we actually observe\n\n\n\n\n\n\n\n\nSampling Distribution\n\n\n\nDistribution of a sample statistic across many samples\nMean: \\(\\mu_{\\bar{X}} = \\mu\\), SD (SE): \\(\\frac{\\sigma}{\\sqrt{n}}\\)\nTheoretical (describes variability of \\(\\bar{x}\\))\nNot the distribution of raw data!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visual-three-distributions",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visual-three-distributions",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visual: Three distributions",
    "text": "Visual: Three distributions"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-does-the-standard-error-exist",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-does-the-standard-error-exist",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why does the standard error exist?",
    "text": "Why does the standard error exist?\nBefore we introduce the formula, let‚Äôs understand the concept:\n\n\n\n\nThe logic:\n\nEach random sample produces a slightly different estimate\nThose estimates vary from sample to sample\nThat variability forms a sampling distribution\n\n\nThe standard error (SE) is:\n\nThe standard deviation of the sampling distribution\nA measure of how much a statistic varies across repeated samples\n\n\n\n\n\n\n\nKey distinction\n\n\nStandard error quantifies sampling variability, not data variability.\n\nStandard deviation (\\(s\\)) ‚Üí spread of data in one sample\nStandard error (\\(SE\\)) ‚Üí spread of statistics across many samples"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#standard-error-a-special-name",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#standard-error-a-special-name",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Standard error: A special name",
    "text": "Standard error: A special name\nThe standard deviation of a sampling distribution has a special name:\n\n\n\nStandard Error (SE)\n\n\nThe standard error is the standard deviation of a sampling distribution.\nFor the sampling distribution of sample means:\n\\[SE = \\frac{\\sigma}{\\sqrt{n}}\\]\nwhere \\(\\sigma\\) = population standard deviation and \\(n\\) = sample size\n\n\n\nWhat does SE tell us?\nThe SE describes how far the sample mean (\\(\\bar{x}\\)) is expected to deviate from the true population mean (\\(\\mu\\)) across many different random samples of size \\(n\\).\nKey properties:\n\nLarger samples ‚Üí smaller SE ‚Üí more precise estimates\nSE decreases as \\(\\sqrt{n}\\) increases, not as \\(n\\) (doubling sample size doesn‚Äôt halve SE.)\nIn practice, we rarely know \\(\\sigma\\), so we use: \\(SE = \\frac{s}{\\sqrt{n}}\\)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-to-report-se-vs.-sd",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-to-report-se-vs.-sd",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "When to report SE vs.¬†SD",
    "text": "When to report SE vs.¬†SD\nWhen presenting results, choose based on your goal:\n\n\n\n\n\nReport SD when‚Ä¶\n\n\nGoal: Describe the data\nUse: \\(\\bar{x} \\pm s\\)\nExample: ‚ÄúHeights were 65.2 ¬± 3.1 inches‚Äù\nInterpretation: Shows the spread of individual observations\n\n\n\n\n\n\n\nReport SE when‚Ä¶\n\n\nGoal: Estimate population parameter\nUse: \\(\\bar{x} \\pm SE\\)\nExample: ‚ÄúMean height was 65.2 ¬± 0.44 inches‚Äù\nInterpretation: Shows precision of the estimate\n\n\n\n\n\n\n\n\n\nCommon mistake\n\n\nDon‚Äôt report SE to make your data look ‚Äúbetter‚Äù (less variable). Use SD to describe variability in your sample, SE to quantify uncertainty about the population mean."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-does-sample-size-matter",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-does-sample-size-matter",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why does sample size matter?",
    "text": "Why does sample size matter?\nLet‚Äôs see the effect of sample size on the sampling distribution:"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-central-limit-theorem-clt",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-central-limit-theorem-clt",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "The Central Limit Theorem (CLT)",
    "text": "The Central Limit Theorem (CLT)\n\n\n\nCentral Limit Theorem\n\n\nFor sufficiently large sample sizes, the sampling distribution of the sample mean is approximately normal, regardless of the shape of the population distribution.\nSpecifically, if we have a random sample of size \\(n\\) from a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\):\n\\[\\bar{X} \\sim N\\left(\\mu_{\\bar{X}} = \\mu, \\quad SE = \\frac{\\sigma}{\\sqrt{n}}\\right)\\]\n\n\n\n\n\nThe key question: What counts as ‚Äúsufficiently large‚Äù?"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-can-we-use-the-clt",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-can-we-use-the-clt",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "When can we use the CLT?",
    "text": "When can we use the CLT?\nThe required sample size depends on the shape of the population distribution:\n\n\nPopulation approximately normal\n\nCLT works for any sample size\nEven \\(n = 5\\) is fine\nThe sampling distribution is exactly normal\n\nPopulation slightly skewed\n\nUsually \\(n \\geq 30\\) is sufficient\nThis is the common ‚Äúrule of thumb‚Äù\n\n\nPopulation highly skewed\n\nMay need \\(n \\geq 50\\) or even larger\nThe ‚Äú30‚Äù rule doesn‚Äôt apply here!\nMore skewness ‚Üí need larger \\(n\\)\n\nPopulation with extreme outliers\n\nMay need \\(n \\geq 100\\) or more\nOutliers slow down convergence to normality\n\n\n\n\n\n\n\nIn practice\n\n\nLook at your sample data:\n\nIs it approximately symmetric with no extreme outliers? ‚Üí \\(n \\geq 30\\) likely okay\nIs it very skewed or has outliers? ‚Üí Consider larger \\(n\\) or non-parametric methods"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#clt-in-action-starting-with-a-skewed-population",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#clt-in-action-starting-with-a-skewed-population",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "CLT in action: Starting with a skewed population",
    "text": "CLT in action: Starting with a skewed population\nLet‚Äôs see what happens when we start with a highly skewed population:"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-distributions-at-different-sample-sizes",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#sampling-distributions-at-different-sample-sizes",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Sampling distributions at different sample sizes",
    "text": "Sampling distributions at different sample sizes\nNow watch what happens to the sampling distribution as we increase \\(n\\):"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-the-clt-is-remarkable",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-the-clt-is-remarkable",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why the CLT is remarkable",
    "text": "Why the CLT is remarkable\nThe CLT works even if the population is:\n\nSlightly or moderately skewed\nUniform\n\nBimodal\nMany other non-normal shapes\n\n\n\nThe key insight: Averages are less variable than individual observations, and with enough averaging (large enough \\(n\\)), the distribution of those averages becomes normal.\n\n\n\n\n\nDon‚Äôt blindly trust n ‚â• 30\n\n\nThe ‚Äú\\(n \\geq 30\\)‚Äù rule is a rough guideline, not a guarantee.\n\nFor symmetric distributions, 30 is usually plenty\nFor highly skewed distributions (like we just saw), you may need 50, 100, or more\nAlways look at your actual data before trusting the CLT"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-is-this-useful",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-is-this-useful",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why is this useful?",
    "text": "Why is this useful?\n\n\n\nRoutine studies involve data from a single sample, not repeated samples.\nIf \\(n\\) is large, then regardless of the distribution of the original population, CLT provides a way of treating our single sample mean as one observation from a normal distribution.\nThe distribution of sample means derived from discrete distributions will also be normal provided \\(n\\) is large."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#applying-the-clt-example",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#applying-the-clt-example",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Applying the CLT: Example",
    "text": "Applying the CLT: Example\n\n\n\nExample: Heights\n\n\nSuppose the heights of adults in a population have mean \\(\\mu = 65\\) inches and standard deviation \\(\\sigma = 3.5\\) inches. We take a random sample of 50 adults.\nWhat is the probability that the sample mean (yet to be determined) is greater than 66 inches?\n\n\n\n\n\nStep 1: Check if we can use CLT\n\n\\(n = 50 \\geq 30\\) ‚úì\nHeights are generally approximately normal (or at least not heavily skewed) ‚úì\nWe can assume the sampling distribution of \\(\\bar{X}\\) is approximately normal\n\nStep 2: Find the distribution of \\(\\bar{X}\\)\n\\[\\bar{X} \\sim N\\left(\\mu = 65, \\quad SE = \\frac{3.5}{\\sqrt{50}} = 0.495\\right)\\]"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-continued-using-r",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-continued-using-r",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Example continued: Using R",
    "text": "Example continued: Using R\nStep 3: Calculate the probability using R\nWe want \\(P(\\bar{X} &gt; 66)\\)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-continued-using-r-1",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-continued-using-r-1",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Example continued: Using R",
    "text": "Example continued: Using R\nStep 3: Calculate the probability using R\nWe want \\(P(\\bar{X} &gt; 66)\\)\n\n# Define parameters\nn &lt;- 50\nmu &lt;- 65\nsigma &lt;- 3.5\n\n# Calculate SE\nSE &lt;- sigma / sqrt(n)\nSE\n\n[1] 0.4949747\n\n\n\n\n\n# Calculate probability\npnorm(q = 66, mean = mu, sd = SE, lower.tail = FALSE)\n\n[1] 0.02167588\n\n\n\n\nInterpretation: There is about a 2.2% chance of observing a sample mean greater than 66 inches if the true population mean is 65 inches."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-the-clt-tells-us-in-plain-language",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-the-clt-tells-us-in-plain-language",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What the CLT tells us in plain language",
    "text": "What the CLT tells us in plain language\nThe Central Limit Theorem means:\n\nSample means tend toward normality (for large enough \\(n\\), even if the data aren‚Äôt normal)\nSample means cluster around the population mean (\\(\\mu\\))\nThe spread depends on sample size (larger \\(n\\) ‚Üí smaller spread)\n\n\n\nWhy this matters:\n\nWe can use normal distribution tools even when our data aren‚Äôt normal\nWe can quantify uncertainty about sample means\nWe can make probability statements (like we just did)\nThis is the foundation for confidence intervals and hypothesis tests\n\n\n\n\n\n\nLooking ahead\n\n\nThe CLT is why we can construct confidence intervals and do hypothesis tests even when our data aren‚Äôt perfectly normal - as long as our sample size is large enough!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#from-estimation-to-inference",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#from-estimation-to-inference",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "From estimation to inference",
    "text": "From estimation to inference\nSo far we‚Äôve learned:\n\nPopulation parameters vs.¬†sample statistics\nSampling distributions\nThe Central Limit Theorem\n\n\n\nNow we ask a bigger question:\n\n\n\nThe inference question\n\n\nGiven a sample statistic (like \\(\\bar{x} = 66.1\\)), what can we say about the population parameter (\\(\\mu\\))?\n\n\n\n\n\nPoint estimates aren‚Äôt enough - they give us one number but no sense of uncertainty.\nSolution: Use interval estimates!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#point-estimates-vs.-interval-estimates",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#point-estimates-vs.-interval-estimates",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Point estimates vs.¬†Interval estimates",
    "text": "Point estimates vs.¬†Interval estimates\n\n\n\n\n\nPoint Estimate\n\n\nA single value used to estimate a parameter\nExample: ‚ÄúThe mean height is 66.1 inches‚Äù\nPros:\n\nSimple\nEasy to communicate\n\nCons:\n\nNo uncertainty quantified\nDoesn‚Äôt acknowledge sampling variability\n\n\n\n\n\n\n\n\nInterval Estimate\n\n\nA range of plausible values for a parameter\nExample: ‚ÄúThe mean height is between 65.1 and 67.1 inches‚Äù\nPros:\n\nQuantifies uncertainty\nMore honest about what we know\n\nCons:\n\nLess precise\nRequires interpretation"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-confidence-interval",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-is-a-confidence-interval",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What is a confidence interval?",
    "text": "What is a confidence interval?\n\n\n\nConfidence Interval\n\n\nA confidence interval is a range of values that is likely to contain the true population parameter with a specified level of confidence.\nGeneral form:\n\\[\\text{point estimate} \\pm \\text{margin of error}\\]\nFor a mean:\n\\[\\bar{x} \\pm \\text{(critical value)} \\times SE\\]\n\n\n\n\n\nThe critical value depends on:\n\nThe confidence level (commonly 95%)\nThe distribution we‚Äôre using (normal or t)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#some-new-notation",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#some-new-notation",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Some new notation",
    "text": "Some new notation\nBefore we construct confidence intervals, we need to understand the notation for critical values:\n\n\n\n\n\\(\\pm z_{1-\\alpha/2}\\) is the value of \\(z\\) such that \\((1 - \\alpha) \\times 100\\%\\) of the standard normal distribution is contained between \\(- z_{1-\\alpha/2}\\) and \\(+ z_{1-\\alpha/2}\\).\nEquivalently, \\(\\alpha \\times 100\\%\\) is greater than \\(+ z_{1-\\alpha/2}\\) and less than \\(- z_{1-\\alpha/2}\\) combined."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-confidence-intervals-12",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-confidence-intervals-12",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visualizing confidence intervals (1/2)",
    "text": "Visualizing confidence intervals (1/2)\nLet‚Äôs look at what confidence intervals represent:\n\n\n\nThe figure shows CIs from 100 samples:\n\n100 samples: Calculate the mean and confidence interval of each sample\nThe true value of \\(\\mu =65\\) is the vertical black line\nThe horizontal lines are 95% CIs from 100 samples\n\nBlue: the CI contains the true value of \\(\\mu\\)\nRed: the CI did not contain the true value of \\(\\mu\\)\n\n\nWhat percent of CIs captured the true value of \\(\\mu\\)?"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-confidence-intervals-22",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#visualizing-confidence-intervals-22",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Visualizing confidence intervals (2/2)",
    "text": "Visualizing confidence intervals (2/2)\nLet‚Äôs look at what confidence intervals represent:\n\n\n\n\nInterpretation \\((1 - \\alpha) \\times 100\\%\\)\n\n\nIf many samples are collected from a population, and a confidence interval is calculated for each one.\n\n\nWe expect that \\((1 - \\alpha) \\times 100\\%\\) of those intervals will contain the true population mean, \\(\\mu\\)."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#how-do-we-interpret-confidence-intervals",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#how-do-we-interpret-confidence-intervals",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "How do we interpret confidence intervals?",
    "text": "How do we interpret confidence intervals?\nActual interpretation:\n\nIf we were to\n\nrepeatedly take random samples from a population and\ncalculate a 95% CI for each random sample,\n\nthen we would expect 95% of our CIs to contain the true population parameter \\(\\mu\\).\n\n\n\n\n\n\nWhat we typically write as ‚Äúshorthand‚Äù:\n\nIn general form: We are 95% confident that (the 95% confidence interval) captures the value of the population parameter.\n\n\n\nWRONG interpretation:\n\nThere is a 95% chance that (the 95% confidence interval) captures the value of the population parameter.\n\nFor one CI on its own, it either does or doesn‚Äôt contain the population parameter with probability 0 or 1. We just don‚Äôt know which!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-when-œÉ-is-known",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-when-œÉ-is-known",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Confidence interval when œÉ is known",
    "text": "Confidence interval when œÉ is known\nWhen we know the population standard deviation \\(\\sigma\\):\n\n\n\nCI for Œº (with known œÉ)\n\n\n\\[\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nwhere:\n\n\\(\\bar{x}\\) = sample mean\n\\(z^*\\) = critical value from standard normal distribution\n\\(\\sigma\\) = population standard deviation (known)\n\\(n\\) = sample size\n\n\n\n\n\n\nFor a 95% confidence interval:\n\nqnorm(0.975)  # 2.5% in each tail\n\n[1] 1.959964\n\n\nSo \\(z^* = 1.96\\)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-makes-a-confidence-interval-wide-or-narrow",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-makes-a-confidence-interval-wide-or-narrow",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What makes a confidence interval wide or narrow?",
    "text": "What makes a confidence interval wide or narrow?\nBefore we calculate CIs, let‚Äôs build intuition about what affects their width:\n\n\n\n\nCI gets narrower when:\n\nSample size increases\n(\\(\\uparrow n\\) ‚Üí \\(\\downarrow SE\\))\nPopulation variability is smaller\n(\\(\\downarrow \\sigma\\) ‚Üí \\(\\downarrow SE\\))\n\n\nCI gets wider when:\n\nSample size is small\n(\\(\\downarrow n\\) ‚Üí \\(\\uparrow SE\\))\nPopulation variability is large\n(\\(\\uparrow \\sigma\\) ‚Üí \\(\\uparrow SE\\))\nConfidence level increases\n(99% vs 95% ‚Üí larger critical value)\n\n\n\n\n\n\n\nNothing else affects CI width\n\n\nYou can only make a CI narrower by:\n\nCollecting more data\nReducing measurement error\n\nAccepting less confidence"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-ci-with-known-œÉ",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-ci-with-known-œÉ",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Example: CI with known œÉ",
    "text": "Example: CI with known œÉ\n\n\n\nExample\n\n\n\nA random sample of 50 adults has mean height \\(\\bar{x} = 66.1\\) inches.\nAssume the population standard deviation is known to be \\(\\sigma = 3\\) inches.\nFind a 95% confidence interval for the population mean height.\n\n\n\n\n\n\nSolution:\n\nxbar &lt;- 66.1\nsigma &lt;- 3\nn &lt;- 50\nz_star &lt;- qnorm(0.975)  # 1.96\n\n\n# Calculate SE\nSE &lt;- sigma / sqrt(n)\nSE\n\n[1] 0.4242641\n\n\n\n\n\n\n# Calculate CI\nlower_ci &lt;- xbar - z_star * SE\nupper_ci &lt;- xbar + z_star * SE\n\nc(lower_ci, upper_ci)\n\n[1] 65.26846 66.93154\n\n\n\n\n\nWe are 95% confident that the population mean height is between 65.27 and 66.93 inches."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#interpreting-confidence-intervals-what-they-mean",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#interpreting-confidence-intervals-what-they-mean",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Interpreting confidence intervals: What they mean",
    "text": "Interpreting confidence intervals: What they mean\n\n\n\nCorrect interpretation\n\n\n‚ÄúWe are 95% confident that the interval (65.27, 66.93) contains the true population mean height.‚Äù\nWhat this really means:\nIf we were to take many samples and construct a 95% CI from each one, about 95% of those intervals would contain the true population mean \\(\\mu\\).\n\n\n\n\n\nHelpful analogy:\nThink of each CI as a ‚Äúnet‚Äù trying to catch the true parameter. With 95% confidence, our net catches the parameter 95% of the time."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#interpreting-confidence-intervals-what-they-dont-mean",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#interpreting-confidence-intervals-what-they-dont-mean",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Interpreting confidence intervals: What they DON‚ÄôT mean",
    "text": "Interpreting confidence intervals: What they DON‚ÄôT mean\n\n\n\nCommon misconceptions\n\n\nWRONG: ‚ÄúThere is a 95% probability that Œº is in this interval.‚Äù\n\nThe parameter Œº is fixed (not random)\nIt either is or isn‚Äôt in the interval\nThe randomness comes from the sampling process\n\nWRONG: ‚Äú95% of the data falls in this interval.‚Äù\n\nThe CI is about the parameter, not the data\nThe data is in the sample, not in the CI\n\nWRONG: ‚ÄúIf we repeat the study, there‚Äôs a 95% chance the new mean will be in this interval.‚Äù\n\nCIs are for parameters, not future statistics"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-a-95-confidence-interval-actually-means",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-a-95-confidence-interval-actually-means",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What a 95% confidence interval actually means",
    "text": "What a 95% confidence interval actually means\nThis is the most important slide about interpretation:\n\n\n\n\n\nThe key to understanding CIs\n\n\nThe method used to create the interval has 95% long-run coverage.\nIf we repeated the study many times:\n\nEach time, we‚Äôd get a different sample\nEach sample would produce a different confidence interval\nAbout 95% of those intervals would contain the true parameter \\(\\mu\\)\n\n\n\n\n\n\n\nThe critical insight\n\n\nThe parameter is fixed. The interval is random.\nThe confidence is about the procedure, not about any single interval.\nYou cannot assess whether a specific CI is ‚Äúcorrect‚Äù using just one dataset. The 95% guarantee comes from the long-run behavior of the method."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#different-confidence-levels",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#different-confidence-levels",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Different confidence levels",
    "text": "Different confidence levels\nWe can construct CIs at different confidence levels:\n\nxbar &lt;- 66.1\nsigma &lt;- 3\nn &lt;- 50\n\n# Calculate SE\nSE &lt;- sigma / sqrt(n)\n\n\n# 90% CI\nz_90 &lt;- qnorm(0.95)  # 5% in each tail\nc(xbar - z_90 * SE, xbar + z_90 * SE)\n\n[1] 65.40215 66.79785\n\n\n\n\n\n# 95% CI\nz_95 &lt;- qnorm(0.975)  # 2.5% in each tail\nc(xbar - z_95 * SE, xbar + z_95 * SE)\n\n[1] 65.26846 66.93154\n\n\n\n\n\n# 99% CI\nz_99 &lt;- qnorm(0.995)  # 0.5% in each tail\nc(xbar - z_99 * SE, xbar + z_99 * SE)\n\n[1] 65.00717 67.19283\n\n\n\n\nTrade-off: Higher confidence ‚Üí wider interval (less precision)\nNotice: - 90% CI: (65.41, 66.79) - narrowest, but least confident - 99% CI: (65.00, 67.20) - widest, but most confident"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#different-confidence-levels-a-different-way",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#different-confidence-levels-a-different-way",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Different confidence levels (a different way)",
    "text": "Different confidence levels (a different way)\nJust showing another way to do with with R\n\nxbar &lt;- 66.1\nsigma &lt;- 3\nn &lt;- 50\nSE &lt;- sigma / sqrt(n)\n\n# Instead of three separate calculations:\nconfidence_levels &lt;- c(0.90, 0.95, 0.99)\nz_values &lt;- qnorm(1 - (1 - confidence_levels)/2)\n\nresults &lt;- tibble(\n  level = confidence_levels,\n  z_star = z_values,\n  lower = xbar - z_values * SE,\n  upper = xbar + z_values * SE\n)\n\nresults\n\n# A tibble: 3 √ó 4\n  level z_star lower upper\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.9    1.64  65.4  66.8\n2  0.95   1.96  65.3  66.9\n3  0.99   2.58  65.0  67.2"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-intervals-are-about-procedures",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-intervals-are-about-procedures",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Confidence intervals are about procedures",
    "text": "Confidence intervals are about procedures\nLet‚Äôs emphasize the key conceptual point before moving on:\n\n\n\n\nOne dataset ‚Üí one confidence interval\n\nYou conduct one study\nYou get one sample\nYou calculate one interval\nThat interval either contains \\(\\mu\\) or it doesn‚Äôt\n\nWe just don‚Äôt know which!\n\nThe guarantee applies to the method, not a single interval\n\nThe 95% comes from the procedure‚Äôs long-run behavior\nIf everyone repeated your study, 95% of their CIs would contain \\(\\mu\\)\nYour specific CI is one realization from that process\n\n\n\n\n\n\n\nCoverage is a long-run property\n\n\nYou cannot assess CI correctness using one dataset.\nConfidence comes from the repetition (in principle), not from the data alone.\nThis is why we say ‚Äúwe are confident‚Äù rather than ‚Äúthere is a probability.‚Äù"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-if-we-dont-know-œÉ",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-if-we-dont-know-œÉ",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What if we don‚Äôt know œÉ?",
    "text": "What if we don‚Äôt know œÉ?\n\n\nReality check: We almost never know the population standard deviation \\(\\sigma\\).\n\n\nProblem: If we replace \\(\\sigma\\) with \\(s\\) in our CI formula:\n\\[\\bar{x} \\pm z^* \\times \\frac{s}{\\sqrt{n}}\\]\nThis adds extra uncertainty - we‚Äôre now estimating both \\(\\mu\\) and \\(\\sigma\\)!\n\n\nSolution: Use a different distribution that accounts for this extra uncertainty - the t-distribution."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-t-distribution-1",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-t-distribution-1",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "The t-distribution",
    "text": "The t-distribution\n\n\n\n\n\n\n\nStudent‚Äôs t-distribution\n\n\n\nIs symmetric and bell-shaped (like the normal)\nHas heavier tails than the normal distribution\n\nt-based intervals will be wider than Z based intervals\n\nDepends on degrees of freedom (which for one sample: \\(df = n - 1\\))\nApproaches the normal distribution as \\(df\\) increases"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-degrees-of-freedom-n---1",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#why-degrees-of-freedom-n---1",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Why degrees of freedom = n - 1?",
    "text": "Why degrees of freedom = n - 1?\n\n\nDegrees of freedom = number of independent pieces of information\n\n\nWhen calculating the sample standard deviation \\(s\\):\n\nWe use \\(n\\) observations\nBut we first calculate \\(\\bar{x}\\) (which uses all \\(n\\) values)\nThis ‚Äúuses up‚Äù one degree of freedom\nWe‚Äôre left with \\(n - 1\\) independent pieces of information\n\n\n\nIntuition: If you know the mean and \\(n-1\\) values, the \\(n\\)th value is determined."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-with-unknown-œÉ",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-with-unknown-œÉ",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Confidence interval with unknown œÉ",
    "text": "Confidence interval with unknown œÉ\nWhen \\(\\sigma\\) is unknown (which is almost always):\n\n\n\nCI for Œº (with unknown œÉ)\n\n\n\\[\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\]\nwhere:\n\n\\(\\bar{x}\\) = sample mean\n\\(t^*\\) = critical value from t-distribution with \\(df = n - 1\\)\n\\(s\\) = sample standard deviation\n\\(n\\) = sample size"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#qt-finding-the-critical-value-in-r",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#qt-finding-the-critical-value-in-r",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "qt(): Finding the critical value in R",
    "text": "qt(): Finding the critical value in R\nThe qt() function finds critical values from the t-distribution:\nqt(p, df, lower.tail = TRUE)\n\n\nParameters:\n\np = cumulative probability (e.g., 0.975 for 95% CI)\ndf = degrees of freedom (\\(n - 1\\))\nlower.tail = TRUE (default) gives left-tail probability\n\n\n\nReturns: The t-value where \\(P(T \\leq \\text{value}) = p\\)\n\n\n\nExample: 95% CI with n = 50\n\n# For 95% CI, we want 2.5% in each tail, so p = 0.975\n# Degrees of freedom: df = n - 1 = 49\nqt(p = 0.975, df = 49)\n\n[1] 2.009575\n\n\nCompare to \\(z^* = 1.96\\) from the normal distribution - the t-value is slightly larger!"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-ci-with-unknown-œÉ",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#example-ci-with-unknown-œÉ",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Example: CI with unknown œÉ",
    "text": "Example: CI with unknown œÉ\n\n\n\nExample\n\n\nA random sample of 50 adults has:\n\nMean height: \\(\\bar{x} = 66.1\\) inches\nSample SD: \\(s = 3.5\\) inches\n\nFind a 95% confidence interval for the population mean height.\n\n\n\n\n\nSolution:\n\n\n\nxbar &lt;- 66.1\ns &lt;- 3.5\nn &lt;- 50\ndf &lt;- n - 1\n\n# Critical value\nt_star &lt;- qt(0.975, df = df)\nt_star\n\n[1] 2.009575\n\n\n\n\n# Calculate SE (using s instead of œÉ)\nSE &lt;- s / sqrt(n)\n\n# Calculate CI\nlower_ci &lt;- xbar - t_star * SE\nupper_ci &lt;- xbar + t_star * SE\n\nc(lower_ci, upper_ci)\n\n[1] 65.10531 67.09469"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-ci-for-the-mean-mu-z-vs.-t",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#confidence-interval-ci-for-the-mean-mu-z-vs.-t",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Confidence interval (CI) for the mean \\(\\mu\\) (\\(z\\) vs.¬†\\(t\\))",
    "text": "Confidence interval (CI) for the mean \\(\\mu\\) (\\(z\\) vs.¬†\\(t\\))\n\nIn summary, we have two cases that lead to different ways to calculate the confidence interval\n\n\n\n\n\n\nCase 1: We know the population standard deviation\n\n\n\\[\\overline{x}\\ \\pm\\ z^*\\times \\text{SE}\\]\n\nwith \\(\\text{SE} = \\frac{\\sigma}{\\sqrt{n}}\\) and \\(\\sigma\\) is the population standard deviation\n\n\n\n\nFor 95% CI, we use:\n\n\\(z^* =\\) qnorm(p = 0.975) \\(=1.96\\)\n\n\n\n\n\n\n\n\n\nCase 2: We do not know the population sd\n\n\n\\[\\overline{x}\\ \\pm\\ t^*\\times \\text{SE}\\]\n\nwith \\(\\text{SE} = \\frac{s}{\\sqrt{n}}\\) and \\(s\\) is the sample standard deviation\n\n\n\n\nFor 95% CI, we use:\n\n\\(t^* =\\) qt(p = 0.975, df = n-1)"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#comparing-z-based-vs.-t-based-cis",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#comparing-z-based-vs.-t-based-cis",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Comparing z-based vs.¬†t-based CIs",
    "text": "Comparing z-based vs.¬†t-based CIs\nFor our example (\\(n = 50\\)):\n\n\n\n\n\nCase 1: We know the population standard deviation\n\n\n\n# If we knew œÉ = 3.5 (z-based CI)\nz_star &lt;- qnorm(0.975)\nSE &lt;- (3.5 / sqrt(n))\n\nci_z &lt;- xbar + c(-1, 1) * z_star * SE\nci_z\n\n[1] 65.12987 67.07013\n\n\n\n\n\n\n\n\n\nCase 2: We do not know the population sd\n\n\n\n# Using s = 3.5 (t-based CI)\nt_star &lt;- qt(0.975, df = 49)\nSE &lt;- (s / sqrt(n))\n\nci_t &lt;- xbar + c(-1, 1) * t_star * SE\nci_t\n\n[1] 65.10531 67.09469\n\n\n\n\n\n\n\n\nNotice: The t-based CI is slightly wider (because \\(t^* &gt; z^*\\)) - this reflects the extra uncertainty from estimating œÉ."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-to-use-t-vs.-z",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#when-to-use-t-vs.-z",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "When to use t vs.¬†z?",
    "text": "When to use t vs.¬†z?\n\n\n\nDecision rule\n\n\nUse t-distribution when:\n\nYou don‚Äôt know the population standard deviation \\(\\sigma\\)\nYou‚Äôre using the sample standard deviation \\(s\\)\n(This is almost always in practice!)\n\nUse normal (z) distribution when:\n\nYou know the population standard deviation \\(\\sigma\\)\n(This is rare in real applications)\n\n\n\n\n\n\nRule of thumb we‚Äôll use in this class:\nAlways use the t-distribution unless explicitly told you know \\(\\sigma\\)."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-you-need-to-know-sampling-distributions",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-you-need-to-know-sampling-distributions",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What you need to know: Sampling distributions",
    "text": "What you need to know: Sampling distributions\nKey concepts:\n\nSampling variability is natural - different samples give different estimates\nThe sampling distribution describes how statistics vary across samples\nStandard error (SE) measures the variability of sample means: \\(SE = \\frac{\\sigma}{\\sqrt{n}}\\)\nThe Central Limit Theorem says that for \\(n \\geq 30\\), sample means follow approximately normal (often for \\(n \\geq 30\\), depending on skew/outliers)\n\n\n\nIn plain language:\nIf we repeatedly sample from a population and calculate the mean each time, those means will form a normal distribution centered at the true population mean, with spread determined by the standard error."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-you-need-to-know-confidence-intervals",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#what-you-need-to-know-confidence-intervals",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "What you need to know: Confidence intervals",
    "text": "What you need to know: Confidence intervals\nKey concepts:\n\nA confidence interval gives a range of plausible values for a parameter\n95% confidence means that 95% of such intervals would contain the true parameter\nUse the t-distribution when \\(\\sigma\\) is unknown (almost always)\nGeneral form: \\(\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\)\n\n\n\nCritical R functions:\n\n# Finding critical values\nqt(0.975, df = n - 1)  # For 95% CI\n\n# Or for different confidence levels\nqt(0.95, df = n - 1)   # For 90% CI\nqt(0.995, df = n - 1)  # For 99% CI"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#common-mistakes-to-avoid",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#common-mistakes-to-avoid",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Common mistakes to avoid",
    "text": "Common mistakes to avoid\n\n\n\nWatch out for these!\n\n\n\nConfusing the three distributions\n\nPopulation distribution ‚â† sample distribution ‚â† sampling distribution\n\nMisinterpreting confidence intervals\n\nNot ‚Äú95% chance Œº is in the interval‚Äù\nRather ‚Äú95% of such intervals contain Œº‚Äù\n\nUsing z when you should use t\n\nIf you calculated \\(s\\) from your data, use t!\n\nForgetting the assumptions\n\nCLT needs \\(n \\geq 30\\) (or normal population)\nOr: smaller \\(n\\) is okay if data is approximately symmetric"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#key-formulas-for-reference",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#key-formulas-for-reference",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Key formulas for reference",
    "text": "Key formulas for reference\nYou don‚Äôt need to memorize these, but understand what they mean:\n\n\nStandard Error: \\[SE = \\frac{\\sigma}{\\sqrt{n}} \\quad \\text{or} \\quad SE = \\frac{s}{\\sqrt{n}}\\]\n\n\nConfidence Interval (t-based): \\[\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\]\nwhere \\(t^*\\) comes from a t-distribution with \\(df = n - 1\\)\n\n\nConfidence Interval (z-based, if œÉ known): \\[\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}\\]"
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-inference-pipeline",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#the-inference-pipeline",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "The inference pipeline",
    "text": "The inference pipeline\nLet‚Äôs tie everything together:\n\n\n\n\n\nFrom population to inference\n\n\nPopulation ‚Üí Sample ‚Üí Statistic ‚Üí Sampling distribution ‚Üí Confidence interval\n\n\n\n\n\nThe process:\n\nPopulation with unknown parameter \\(\\mu\\)\nTake a random sample of size \\(n\\)\nCalculate a statistic (e.g., \\(\\bar{x}\\))\nUse the sampling distribution to understand variability\nConstruct a confidence interval to quantify uncertainty\n\n\n\nKey insights: We never observe the population directly, so we use sampling distributions to quantify uncertainty and construct plausible ranges for parameters."
  },
  {
    "objectID": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#looking-ahead-1",
    "href": "lessons/11_estimation_and_confidence_intervals/11_estimation_and_confidence_intervals.html#looking-ahead-1",
    "title": "Sampling Distributions and Confidence Intervals",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext time:\n\nMore practice with confidence intervals\nIntroduction to hypothesis testing\nThe logic of statistical inference\n\n\n\nFor now:\n\nPractice calculating CIs with different confidence levels\nGet comfortable with the t-distribution in R\nWork on understanding (not just calculating) what CIs mean\n\n\n\n\n\n\nRemember\n\n\nStatistical inference is about quantifying uncertainty. Confidence intervals give us a principled way to say ‚Äúwe don‚Äôt know exactly, but here‚Äôs a plausible range.‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚Äì&gt;\n\n‚Äì&gt;\n\n‚Äì&gt;\n\n‚Äì&gt;\n\n‚Äì&gt; \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMSC 620 | Sampling & Confidence Intervals"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. I‚Äôm glad the probability material resonated with so many of you, and I appreciate the specific questions about R and the suggestions about course structure."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#thanks-for-the-feedback",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#thanks-for-the-feedback",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. I‚Äôm glad the probability material resonated with so many of you, and I appreciate the specific questions about R and the suggestions about course structure."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#a-note-on-pacing",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#a-note-on-pacing",
    "title": "Muddy Points",
    "section": "A note on pacing",
    "text": "A note on pacing\nLooking at the post-class survey for this lecture:\n\n78% felt the pace was about right\n19% felt it was slightly too fast\n3% felt it was slightly too slow\n\nThis is strong feedback overall. For those who found the live R coding portion slightly too fast, remember that the lectures are recorded and you can rewatch those sections. We‚Äôll also be working extensively with R next week, which will give you more practice time."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#a-note-on-muddy-points-timing",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#a-note-on-muddy-points-timing",
    "title": "Muddy Points",
    "section": "A note on muddy points timing",
    "text": "A note on muddy points timing\nA few of you suggested moving muddy points to the end of class or posting them as videos rather than covering them during class time.\nI appreciate this feedback. Here‚Äôs my current thinking:\n\nMany students specifically noted in the ‚Äúclear points‚Äù that they found the muddy points review helpful\nReviewing them at the start helps ensure everyone‚Äôs on the same page before new material\nThat said, I hear that 20 minutes is a significant chunk of class time\n\nGoing forward, I‚Äôll:\n\nPost muddy points to the website before class (as I do now)\nGive you time to read through them on your own first\nQuickly highlight the most common or important points in class rather than going through everything line by line\nEncourage you to come to office hours with specific questions\n\nThis should give us more time for new material while still addressing the most important confusions."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#multiplication-rule-vs.-conditional-probability",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#multiplication-rule-vs.-conditional-probability",
    "title": "Muddy Points",
    "section": "Multiplication rule vs.¬†conditional probability",
    "text": "Multiplication rule vs.¬†conditional probability\nOne excellent question was: ‚ÄúI think I‚Äôm getting confused between the multiplication rule and conditional probability. Conditional probability is more ‚Äòif this, then what about that‚Äô and the multiplication rule is ‚Äòif this and that‚Äô. But what is the difference, for instance between ‚Äòpositive results and has disease‚Äô vs ‚Äòof those who have positive results, how many have disease‚Äô? Is the difference just in the denominator?‚Äù\nThis is a great question because these concepts are closely related.\n\nConditional probability\nConditional probability answers: ‚ÄúGiven that A happened, what‚Äôs the probability of B?‚Äù\n\\[P(B|A) = \\frac{P(A \\text{ and } B)}{P(A)}\\]\nFor example: ‚ÄúOf those who test positive, what proportion actually have the disease?‚Äù\nThe denominator is \\(P(\\text{positive test})\\) ‚Äî we‚Äôre restricting our focus to only those who tested positive.\n\n\nMultiplication rule\nThe multiplication rule calculates the probability that both A and B happen together:\n\\[P(A \\text{ and } B) = P(A) \\times P(B|A)\\]\nFor example: ‚ÄúWhat‚Äôs the probability someone has the disease AND tests positive?‚Äù\nThis gives you the joint probability of both events occurring.\n\n\nThe relationship\nYou‚Äôre absolutely right that the denominator is the key difference:\n\nConditional probability divides by \\(P(A)\\) to find the proportion within a subset\nMultiplication rule multiplies to find the probability of both events together\n\nThey‚Äôre mathematically related ‚Äî in fact, the multiplication rule comes from rearranging the conditional probability formula:\n\\[P(A \\text{ and } B) = P(B|A) \\times P(A)\\]\n\n\nExample with numbers\nSuppose:\n\n1% of people have a disease: \\(P(\\text{disease}) = 0.01\\)\nThe test is 95% accurate for those with disease: \\(P(\\text{positive}|\\text{disease}) = 0.95\\)\n\nConditional probability: Of those with disease, 95% test positive.\nMultiplication rule: The probability of having disease AND testing positive is: \\[P(\\text{disease and positive}) = 0.01 \\times 0.95 = 0.0095\\]\nSo about 0.95% of the entire population has disease and tests positive.\nThe conditional probability focuses on a rate within a subgroup. The multiplication rule gives you the overall joint probability."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#understanding-pipes-in-r",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#understanding-pipes-in-r",
    "title": "Muddy Points",
    "section": "Understanding pipes in R: %>%",
    "text": "Understanding pipes in R: %&gt;%\nSeveral questions came up about pipes, including:\n\n‚ÄúI don‚Äôt fully understand pipes in R and how to utilize them outside of linking data‚Äù\n‚ÄúI was confused when you used the example: dplyr::count(Species) %&gt;% mutate(proportion = n / sum(n))‚Äù\n\nThis is completely understandable since we only briefly introduced pipes at the end of class.\n\nWhat pipes do\nThe pipe operator %&gt;% takes the output from one function and passes it as the first argument to the next function.\nWithout pipes:\n\nmutate(count(iris, Species), proportion = n / sum(n))\n\nWith pipes:\n\niris %&gt;%\n  count(Species) %&gt;%\n  mutate(proportion = n / sum(n))\n\n\n\nWhy pipes are helpful\nPipes let you read code from left to right (or top to bottom), which is more natural than reading nested functions from inside-out.\nThink of it like a recipe:\nNested approach (inside-out):\n\nbake(mix(add(get_flour(), get_eggs()), get_sugar()))\n\nPipe approach (step-by-step):\n\nget_flour() %&gt;%\n  add(get_eggs()) %&gt;%\n  mix(get_sugar()) %&gt;%\n  bake()\n\n\n\nWe‚Äôll spend more time on this\nDon‚Äôt worry if pipes feel unclear right now. We briefly introduced them at the end of class, but we‚Äôll use them extensively next week when we work with data visualization and data manipulation in the tidyverse.\nFor now, just know that %&gt;% means ‚Äútake the thing on the left and pass it to the function on the right.‚Äù"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#how-does-r-know-that-n-is-the-count-column",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#how-does-r-know-that-n-is-the-count-column",
    "title": "Muddy Points",
    "section": "How does R know that ‚Äún‚Äù is the count column?",
    "text": "How does R know that ‚Äún‚Äù is the count column?\nOne question was: ‚ÄúI was also a little confused when you used the example in class: dplyr::count(Species) %&gt;% mutate(proportion = n / sum(n)), how R knew that ‚Äòn‚Äô was the title for the column of counts.‚Äù\nGreat observation! This is specific to how the count() function works in dplyr.\n\nWhat count() does\nWhen you use count(), it automatically:\n\nGroups the data by the variable(s) you specify\nCounts the number of rows in each group\nAlways names the count column ‚Äún‚Äù, unless you name it something else using the name = argument (see ?dplyr::count)\n\nFor example:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\niris %&gt;%\n  count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50\n\n\nThis creates a table with two columns: - Species (the grouping variable) - n (the counts ‚Äî automatically named by count())\n\n\nWhy we can use ‚Äún‚Äù in mutate()\nBecause count() always creates a column called n, we can refer to it by that name in the next step:\n\niris %&gt;%\n  count(Species) %&gt;%\n  mutate(proportion = n / sum(n))\n\n     Species  n proportion\n1     setosa 50  0.3333333\n2 versicolor 50  0.3333333\n3  virginica 50  0.3333333\n\n\nThis works because: - count() created a column named n - mutate() sees that column and can use it in calculations\n\n\nWhat if you want a different name?\nYou can rename the count column if you want:\n\niris %&gt;%\n  count(Species, name = \"total\")\n\n     Species total\n1     setosa    50\n2 versicolor    50\n3  virginica    50\n\n\nNow the count column is called total instead of n.\n\n\nBottom line\nThe name n isn‚Äôt magic ‚Äî it‚Äôs just the default name that count() gives to the count column. Once you know that pattern, you can use n in subsequent operations."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#does-mutate-edit-your-actual-data",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#does-mutate-edit-your-actual-data",
    "title": "Muddy Points",
    "section": "Does mutate() edit your actual data?",
    "text": "Does mutate() edit your actual data?\nOne question was: ‚ÄúI‚Äôm wondering when you use the mutate function, are you editing your actual data table, or just seeing what a new column would look like.‚Äù\nExcellent question! This is important to understand for working safely with data in R.\n\nShort answer: No, it doesn‚Äôt modify your original data\nWhen you use mutate() (or most data manipulation functions in R), it creates a new data frame with the changes. It does not modify the original data frame unless you explicitly overwrite it.\n\n\nExample\n\nlibrary(dplyr)\n\n# Original data\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n# Use mutate to add a column\niris %&gt;%\n  mutate(Sepal.Area = Sepal.Length * Sepal.Width)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species Sepal.Area\n1            5.1         3.5          1.4         0.2     setosa      17.85\n2            4.9         3.0          1.4         0.2     setosa      14.70\n3            4.7         3.2          1.3         0.2     setosa      15.04\n4            4.6         3.1          1.5         0.2     setosa      14.26\n5            5.0         3.6          1.4         0.2     setosa      18.00\n6            5.4         3.9          1.7         0.4     setosa      21.06\n7            4.6         3.4          1.4         0.3     setosa      15.64\n8            5.0         3.4          1.5         0.2     setosa      17.00\n9            4.4         2.9          1.4         0.2     setosa      12.76\n10           4.9         3.1          1.5         0.1     setosa      15.19\n11           5.4         3.7          1.5         0.2     setosa      19.98\n12           4.8         3.4          1.6         0.2     setosa      16.32\n13           4.8         3.0          1.4         0.1     setosa      14.40\n14           4.3         3.0          1.1         0.1     setosa      12.90\n15           5.8         4.0          1.2         0.2     setosa      23.20\n16           5.7         4.4          1.5         0.4     setosa      25.08\n17           5.4         3.9          1.3         0.4     setosa      21.06\n18           5.1         3.5          1.4         0.3     setosa      17.85\n19           5.7         3.8          1.7         0.3     setosa      21.66\n20           5.1         3.8          1.5         0.3     setosa      19.38\n21           5.4         3.4          1.7         0.2     setosa      18.36\n22           5.1         3.7          1.5         0.4     setosa      18.87\n23           4.6         3.6          1.0         0.2     setosa      16.56\n24           5.1         3.3          1.7         0.5     setosa      16.83\n25           4.8         3.4          1.9         0.2     setosa      16.32\n26           5.0         3.0          1.6         0.2     setosa      15.00\n27           5.0         3.4          1.6         0.4     setosa      17.00\n28           5.2         3.5          1.5         0.2     setosa      18.20\n29           5.2         3.4          1.4         0.2     setosa      17.68\n30           4.7         3.2          1.6         0.2     setosa      15.04\n31           4.8         3.1          1.6         0.2     setosa      14.88\n32           5.4         3.4          1.5         0.4     setosa      18.36\n33           5.2         4.1          1.5         0.1     setosa      21.32\n34           5.5         4.2          1.4         0.2     setosa      23.10\n35           4.9         3.1          1.5         0.2     setosa      15.19\n36           5.0         3.2          1.2         0.2     setosa      16.00\n37           5.5         3.5          1.3         0.2     setosa      19.25\n38           4.9         3.6          1.4         0.1     setosa      17.64\n39           4.4         3.0          1.3         0.2     setosa      13.20\n40           5.1         3.4          1.5         0.2     setosa      17.34\n41           5.0         3.5          1.3         0.3     setosa      17.50\n42           4.5         2.3          1.3         0.3     setosa      10.35\n43           4.4         3.2          1.3         0.2     setosa      14.08\n44           5.0         3.5          1.6         0.6     setosa      17.50\n45           5.1         3.8          1.9         0.4     setosa      19.38\n46           4.8         3.0          1.4         0.3     setosa      14.40\n47           5.1         3.8          1.6         0.2     setosa      19.38\n48           4.6         3.2          1.4         0.2     setosa      14.72\n49           5.3         3.7          1.5         0.2     setosa      19.61\n50           5.0         3.3          1.4         0.2     setosa      16.50\n51           7.0         3.2          4.7         1.4 versicolor      22.40\n52           6.4         3.2          4.5         1.5 versicolor      20.48\n53           6.9         3.1          4.9         1.5 versicolor      21.39\n54           5.5         2.3          4.0         1.3 versicolor      12.65\n55           6.5         2.8          4.6         1.5 versicolor      18.20\n56           5.7         2.8          4.5         1.3 versicolor      15.96\n57           6.3         3.3          4.7         1.6 versicolor      20.79\n58           4.9         2.4          3.3         1.0 versicolor      11.76\n59           6.6         2.9          4.6         1.3 versicolor      19.14\n60           5.2         2.7          3.9         1.4 versicolor      14.04\n61           5.0         2.0          3.5         1.0 versicolor      10.00\n62           5.9         3.0          4.2         1.5 versicolor      17.70\n63           6.0         2.2          4.0         1.0 versicolor      13.20\n64           6.1         2.9          4.7         1.4 versicolor      17.69\n65           5.6         2.9          3.6         1.3 versicolor      16.24\n66           6.7         3.1          4.4         1.4 versicolor      20.77\n67           5.6         3.0          4.5         1.5 versicolor      16.80\n68           5.8         2.7          4.1         1.0 versicolor      15.66\n69           6.2         2.2          4.5         1.5 versicolor      13.64\n70           5.6         2.5          3.9         1.1 versicolor      14.00\n71           5.9         3.2          4.8         1.8 versicolor      18.88\n72           6.1         2.8          4.0         1.3 versicolor      17.08\n73           6.3         2.5          4.9         1.5 versicolor      15.75\n74           6.1         2.8          4.7         1.2 versicolor      17.08\n75           6.4         2.9          4.3         1.3 versicolor      18.56\n76           6.6         3.0          4.4         1.4 versicolor      19.80\n77           6.8         2.8          4.8         1.4 versicolor      19.04\n78           6.7         3.0          5.0         1.7 versicolor      20.10\n79           6.0         2.9          4.5         1.5 versicolor      17.40\n80           5.7         2.6          3.5         1.0 versicolor      14.82\n81           5.5         2.4          3.8         1.1 versicolor      13.20\n82           5.5         2.4          3.7         1.0 versicolor      13.20\n83           5.8         2.7          3.9         1.2 versicolor      15.66\n84           6.0         2.7          5.1         1.6 versicolor      16.20\n85           5.4         3.0          4.5         1.5 versicolor      16.20\n86           6.0         3.4          4.5         1.6 versicolor      20.40\n87           6.7         3.1          4.7         1.5 versicolor      20.77\n88           6.3         2.3          4.4         1.3 versicolor      14.49\n89           5.6         3.0          4.1         1.3 versicolor      16.80\n90           5.5         2.5          4.0         1.3 versicolor      13.75\n91           5.5         2.6          4.4         1.2 versicolor      14.30\n92           6.1         3.0          4.6         1.4 versicolor      18.30\n93           5.8         2.6          4.0         1.2 versicolor      15.08\n94           5.0         2.3          3.3         1.0 versicolor      11.50\n95           5.6         2.7          4.2         1.3 versicolor      15.12\n96           5.7         3.0          4.2         1.2 versicolor      17.10\n97           5.7         2.9          4.2         1.3 versicolor      16.53\n98           6.2         2.9          4.3         1.3 versicolor      17.98\n99           5.1         2.5          3.0         1.1 versicolor      12.75\n100          5.7         2.8          4.1         1.3 versicolor      15.96\n101          6.3         3.3          6.0         2.5  virginica      20.79\n102          5.8         2.7          5.1         1.9  virginica      15.66\n103          7.1         3.0          5.9         2.1  virginica      21.30\n104          6.3         2.9          5.6         1.8  virginica      18.27\n105          6.5         3.0          5.8         2.2  virginica      19.50\n106          7.6         3.0          6.6         2.1  virginica      22.80\n107          4.9         2.5          4.5         1.7  virginica      12.25\n108          7.3         2.9          6.3         1.8  virginica      21.17\n109          6.7         2.5          5.8         1.8  virginica      16.75\n110          7.2         3.6          6.1         2.5  virginica      25.92\n111          6.5         3.2          5.1         2.0  virginica      20.80\n112          6.4         2.7          5.3         1.9  virginica      17.28\n113          6.8         3.0          5.5         2.1  virginica      20.40\n114          5.7         2.5          5.0         2.0  virginica      14.25\n115          5.8         2.8          5.1         2.4  virginica      16.24\n116          6.4         3.2          5.3         2.3  virginica      20.48\n117          6.5         3.0          5.5         1.8  virginica      19.50\n118          7.7         3.8          6.7         2.2  virginica      29.26\n119          7.7         2.6          6.9         2.3  virginica      20.02\n120          6.0         2.2          5.0         1.5  virginica      13.20\n121          6.9         3.2          5.7         2.3  virginica      22.08\n122          5.6         2.8          4.9         2.0  virginica      15.68\n123          7.7         2.8          6.7         2.0  virginica      21.56\n124          6.3         2.7          4.9         1.8  virginica      17.01\n125          6.7         3.3          5.7         2.1  virginica      22.11\n126          7.2         3.2          6.0         1.8  virginica      23.04\n127          6.2         2.8          4.8         1.8  virginica      17.36\n128          6.1         3.0          4.9         1.8  virginica      18.30\n129          6.4         2.8          5.6         2.1  virginica      17.92\n130          7.2         3.0          5.8         1.6  virginica      21.60\n131          7.4         2.8          6.1         1.9  virginica      20.72\n132          7.9         3.8          6.4         2.0  virginica      30.02\n133          6.4         2.8          5.6         2.2  virginica      17.92\n134          6.3         2.8          5.1         1.5  virginica      17.64\n135          6.1         2.6          5.6         1.4  virginica      15.86\n136          7.7         3.0          6.1         2.3  virginica      23.10\n137          6.3         3.4          5.6         2.4  virginica      21.42\n138          6.4         3.1          5.5         1.8  virginica      19.84\n139          6.0         3.0          4.8         1.8  virginica      18.00\n140          6.9         3.1          5.4         2.1  virginica      21.39\n141          6.7         3.1          5.6         2.4  virginica      20.77\n142          6.9         3.1          5.1         2.3  virginica      21.39\n143          5.8         2.7          5.1         1.9  virginica      15.66\n144          6.8         3.2          5.9         2.3  virginica      21.76\n145          6.7         3.3          5.7         2.5  virginica      22.11\n146          6.7         3.0          5.2         2.3  virginica      20.10\n147          6.3         2.5          5.0         1.9  virginica      15.75\n148          6.5         3.0          5.2         2.0  virginica      19.50\n149          6.2         3.4          5.4         2.3  virginica      21.08\n150          5.9         3.0          5.1         1.8  virginica      17.70\n\n# Check the original data again\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nNotice that iris still looks the same ‚Äî it doesn‚Äôt have the Sepal.Area column. The mutate() operation created a new data frame that we didn‚Äôt save.\n\n\nTo keep the changes, you need to save them\nIf you want to keep the modified data, you need to assign it:\n\n# Save the modified data to a new object\niris_modified &lt;- iris %&gt;%\n  mutate(Sepal.Area = Sepal.Length * Sepal.Width)\n\n# Now iris_modified has the new column\nhead(iris_modified)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Area\n1          5.1         3.5          1.4         0.2  setosa      17.85\n2          4.9         3.0          1.4         0.2  setosa      14.70\n3          4.7         3.2          1.3         0.2  setosa      15.04\n4          4.6         3.1          1.5         0.2  setosa      14.26\n5          5.0         3.6          1.4         0.2  setosa      18.00\n6          5.4         3.9          1.7         0.4  setosa      21.06\n\n# But iris is still unchanged\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nOr, you can overwrite the original (use with caution):\n\n# This replaces iris with the modified version\niris &lt;- iris %&gt;%\n  mutate(Sepal.Area = Sepal.Length * Sepal.Width)\n\n\n\nThis is a safety feature\nR‚Äôs approach means you can experiment freely without accidentally destroying your data. You can try different transformations and see what they look like, and your original data remains safe unless you explicitly choose to overwrite it."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#define-terms-before-using-them-tibbles-pipes-etc.",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#define-terms-before-using-them-tibbles-pipes-etc.",
    "title": "Muddy Points",
    "section": "Define terms before using them (tibbles, pipes, etc.)",
    "text": "Define terms before using them (tibbles, pipes, etc.)\nOne comment noted: ‚ÄúI think it would be helpful in the future if you tried to define things before we started using them. For instance it would be nice to know a tibble is just a type of table or that a pipe was used to chain codes before we were using and manipulating them.‚Äù\nThis is very fair feedback. I introduced several tidyverse concepts quickly at the end of class without proper definitions.\n\nWhat I‚Äôll do differently\nGoing forward, especially in next week‚Äôs data visualization class:\n\nI‚Äôll define new terms and functions before using them in examples\nI‚Äôll explain the ‚Äúwhy‚Äù along with the ‚Äúhow‚Äù\nI‚Äôll be more explicit about which concepts are ‚Äúnice to know‚Äù vs.¬†‚Äúessential right now‚Äù\n\n\n\nQuick definitions for this week\nFor reference:\n\nTibble: A modern version of a data frame (R‚Äôs name for a data table). It‚Äôs essentially the same thing, just with slightly nicer printing and behavior. When you see tibble, think ‚Äúdata table.‚Äù\nPipe (%&gt;%): An operator that passes the output of one function as input to the next function. Helps you chain operations together in a readable way.\nmutate(): Creates new columns or modifies existing ones in a data frame\ncount(): Counts the number of rows for each group and automatically creates a column called n with the counts\n\nWe‚Äôll use all of these extensively next week, and I‚Äôll make sure to introduce them more carefully."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#r-coding-pace-and-screen-visibility",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#r-coding-pace-and-screen-visibility",
    "title": "Muddy Points",
    "section": "R coding pace and screen visibility",
    "text": "R coding pace and screen visibility\nSeveral comments mentioned:\n\n‚ÄúThe R stuff is still a little fast for me, especially with how small the screen is‚Äù\n‚ÄúIt‚Äôs difficult to see when we transition to working in R Studio. I found that we were moving a bit too quickly here as well‚Äù\n‚ÄúIt would be helpful if we were given why we do things instead of just this does that‚Äù\n\nThese are all related to the live coding portion at the end of class.\n\nWhat I‚Äôll adjust\nFor next week‚Äôs class (which will involve substantial R work):\n\nSlower pace: I‚Äôll be more deliberate about typing slowly and pausing between steps\nLarger font: I‚Äôll increase the font size in RStudio for better visibility\nMore ‚Äúwhy‚Äù: I‚Äôll explain the purpose of each step, not just what it does\nClear transitions: I‚Äôll announce when we‚Äôre switching from slides to RStudio\nBuffer time: I‚Äôll plan for time to let people catch up, especially during package installation\n\n\n\nFor those following along\nIf you‚Äôre typing along and fall behind:\n\nFocus on watching and understanding rather than typing everything in real-time\nYou can always catch up using the recorded lecture and posted code\nThe goal is understanding, not speed-typing\n\n\n\nPackage installation delays\nOne comment noted: ‚ÄúInstalling data packages always takes a few minutes or longer if there‚Äôs an error. It seems instantaneous on your screen, and I‚Äôd hate to fall behind while waiting for something to load.‚Äù\nYou‚Äôre absolutely right. Package installation can take time, especially on slower connections or older computers.\nIn class, I often have packages already installed, which is why it looks instant.\nGoing forward:\n\nI‚Äôll warn you when we‚Äôre about to install packages\nI‚Äôll suggest installing key packages before class when possible\nIf installation takes time during class, I‚Äôll pause and give everyone time to catch up"
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#request-for-keyboard-shortcuts-cheat-sheet",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#request-for-keyboard-shortcuts-cheat-sheet",
    "title": "Muddy Points",
    "section": "Request for keyboard shortcuts cheat sheet",
    "text": "Request for keyboard shortcuts cheat sheet\nOne request was: ‚ÄúCan we have a cheat sheet of keyboard functions we will commonly use?‚Äù\nGreat idea! Here are some essential RStudio keyboard shortcuts:\n\nMost useful shortcuts\nRunning code:\n\nCtrl/Cmd + Enter: Run current line or selection\nCtrl/Cmd + Shift + Enter: Run entire chunk (in Quarto)\n\nNavigation:\n\nCtrl/Cmd + 1: Move cursor to script editor\nCtrl/Cmd + 2: Move cursor to console\nCtrl/Cmd + Shift + M: Insert pipe operator %&gt;%\n\nCode help:\n\nTab: Auto-complete function names or variable names\nF1 (when cursor on function name): Open help documentation\n\nOther useful:\n\nCtrl/Cmd + Shift + C: Comment/uncomment selected lines\nAlt + -: Insert assignment operator &lt;-\n\n\n\nRStudio‚Äôs built-in cheat sheet\nRStudio has this built in! Go to: Help ‚Üí Cheatsheets ‚Üí RStudio IDE Cheat Sheet\nI‚Äôll also post a short list of the most essential shortcuts to the course website."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#some-stats-seemed-too-basic-when-will-i-use-this",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#some-stats-seemed-too-basic-when-will-i-use-this",
    "title": "Muddy Points",
    "section": "Some stats seemed too basic ‚Äî when will I use this?",
    "text": "Some stats seemed too basic ‚Äî when will I use this?\nOne comment noted: ‚ÄúSome of the stats seemed so basic I had a hard time understanding when I would use it in my own work/day to day. But I‚Äôm sure when we get further it‚Äôll all fall into place.‚Äù\nThis is a fair concern, and you‚Äôre right that things will click more as we progress.\n\nWhy we start with fundamentals\nProbability concepts like conditional probability, independence, and joint distributions are foundational to:\n\nUnderstanding statistical tests (coming soon)\nInterpreting confidence intervals and p-values\nBuilding regression models\nMaking sense of diagnostic test results (like we did with sensitivity/specificity)\n\n\n\nMoving toward applications\nOver the next few weeks, we‚Äôll build on these fundamentals to:\n\nAnalyze real datasets\nFit models to data\nTest hypotheses\nMake predictions\n\nThe probability material we covered this week will come up repeatedly. For example:\n\nRegression coefficients are conditional means\nP-values are conditional probabilities\nConfidence intervals rely on probability distributions\n\nSo while it might feel abstract now, these concepts are the building blocks for the applied work we‚Äôll do later in the course."
  },
  {
    "objectID": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#working-through-code-outside-of-class",
    "href": "lessons/06_probability_and_conditional_probability/06_probability_muddy_points.html#working-through-code-outside-of-class",
    "title": "Muddy Points",
    "section": "Working through code outside of class",
    "text": "Working through code outside of class\nOne comment: ‚ÄúThe lecture material is helpful but I have trouble following the in class coding examples. I have to work through the homework in order to fully grasp concepts.‚Äù\nThis is completely normal and actually a healthy learning process!\n\nLive coding is for exposure, not mastery\nThe purpose of live coding in class is to:\n\nShow you what‚Äôs possible\nDemonstrate the workflow\nGive you examples to refer back to\n\nIt‚Äôs not expected that you‚Äôll fully understand everything the first time you see it.\n\n\nLearning happens through practice\nReal understanding comes from:\n\nWorking through homework problems\nExperimenting with the code on your own\nMaking mistakes and debugging them\nApplying the concepts to different datasets\n\nIf you find that you need to work through examples outside of class to really understand them, that‚Äôs exactly how it should work. The in-class demos are the starting point, not the finish line.\n\n\nHow to make the most of this\n\nWatch the recordings when working on homework\nTry modifying the in-class examples with different data\nCome to office hours to work through specific confusions\n\nYou‚Äôre learning in exactly the right way."
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#todays-agenda",
    "href": "lessons/14_midterm_review/14_midterm_review.html#todays-agenda",
    "title": "Midterm Review",
    "section": "Today‚Äôs Agenda",
    "text": "Today‚Äôs Agenda\n\nQuick overview of exam structure\nKey concepts review\n\nStudy design\nProbability and Bayes‚Äô Theorem\nDistributions (focus on R functions!)\nSampling distributions and CLT\nConfidence intervals\nHypothesis testing\n\nYour questions\n\n\n\nThe midterm opens TODAY at 3:00 PM and closes Monday at 11:00 PM"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#exam-details",
    "href": "lessons/14_midterm_review/14_midterm_review.html#exam-details",
    "title": "Midterm Review",
    "section": "Exam Details",
    "text": "Exam Details\nFormat:\n\n8 parts, 120 points total\nDesigned for 3-5 hours completion\nMix of conceptual questions, R code, and interpretation\n\n\n\nResources allowed:\n\n‚úÖ Course materials (slides, homework, textbook)\n‚úÖ R documentation\n‚úÖ Your notes\n‚ùå Other students\n‚ùå AI assistants\n‚ùå Online help forums\n\n\n\nSubmit both .qmd and .html files!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#whats-covered",
    "href": "lessons/14_midterm_review/14_midterm_review.html#whats-covered",
    "title": "Midterm Review",
    "section": "What‚Äôs Covered",
    "text": "What‚Äôs Covered\n\n\nPart 1: Study design (10 pts)\nPart 2: Descriptive stats & viz (15 pts)\nPart 3: Probability (15 pts)\nPart 4: Distributions (20 pts)\n\nPart 5: Sampling distributions & CLT (15 pts)\nPart 6: Confidence intervals (15 pts)\nPart 7: Hypothesis testing (20 pts)\nPart 8: Integration (10 pts)\n\n\n\nKey datasets: nhanes.samp (you‚Äôve used this in HW!)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#general-tips",
    "href": "lessons/14_midterm_review/14_midterm_review.html#general-tips",
    "title": "Midterm Review",
    "section": "General Tips",
    "text": "General Tips\n\n\n\n\nBefore you start:\n\nRead all instructions carefully\nSet up your workspace (load packages, data)\nCheck that code chunks run\n\n\n\nWhile working:\n\nShow your work and reasoning\nProvide interpretations in complete sentences\nUse comments in your R code\nCheck that your document renders frequently\nSave regularly\n\n\nBefore submitting:\n\nRender one final time\nCheck that all answers are complete\nVerify both files are being submitted"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#study-design-the-basics",
    "href": "lessons/14_midterm_review/14_midterm_review.html#study-design-the-basics",
    "title": "Midterm Review",
    "section": "Study Design: The Basics",
    "text": "Study Design: The Basics\n\n\nExperiments vs.¬†Observational Studies\n\n\nExperiment:\n\nResearchers assign treatments\nRandom assignment\nCan establish causation\nExample: Drug trial with treatment vs.¬†placebo\n\n\nObservational Study:\n\nResearchers observe without interfering\nNo random assignment\nCan only show association\nExample: Reviewing medical records\n\n\n\n\nWhy does this matter?\nOnly randomized experiments can establish causal relationships!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#sampling-concepts",
    "href": "lessons/14_midterm_review/14_midterm_review.html#sampling-concepts",
    "title": "Midterm Review",
    "section": "Sampling Concepts",
    "text": "Sampling Concepts\n\n\nKey terms:\n\nPopulation vs.¬†Sample\nSimple random sample (each individual has equal chance)\nConvenience sample (easily accessible - often biased)\n\n\n\nConfounding variables:\n\nAssociated with both explanatory and response variables\nCan make it look like there‚Äôs a causal relationship when there isn‚Äôt\nExample: Exercise and cardiovascular health might both be related to socioeconomic status"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#dplyr-the-grammar-of-data-manipulation",
    "href": "lessons/14_midterm_review/14_midterm_review.html#dplyr-the-grammar-of-data-manipulation",
    "title": "Midterm Review",
    "section": "dplyr: The grammar of data manipulation",
    "text": "dplyr: The grammar of data manipulation\ndplyr provides a consistent set of verbs for data manipulation:\n\n\n\n\n\nFunction\nWhat it does\n\n\n\n\nfilter()\nKeep rows that meet conditions\n\n\nselect()\nKeep or drop columns\n\n\nmutate()\nCreate or modify columns\n\n\narrange()\nSort rows\n\n\ngroup_by()\nGroup data for summaries\n\n\nsummarize()\nCalculate summary statistics\n\n\n\n\n\nThese verbs can be chained together with %&gt;% for powerful data transformations."
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#ggplot2-the-basic-template",
    "href": "lessons/14_midterm_review/14_midterm_review.html#ggplot2-the-basic-template",
    "title": "Midterm Review",
    "section": "ggplot2: The Basic Template",
    "text": "ggplot2: The Basic Template\n\n\n\nThe ggplot2 pattern\n\n\n\nlibrary(ggplot2)\n\nggplot(data = dataset, \n       aes(x = variable, y = variable)) +\n  geom_*() +                    # Choose your geometry\n  labs(title = \"...\",           # Add labels\n       x = \"...\", \n       y = \"...\")\n\n\n\n\n\n\nKey geoms you need to know:\n\n# Histogram (one continuous variable)\ngeom_histogram(bins = 20)\n\n# Boxplot (continuous by categorical)\ngeom_boxplot()\n\n# Scatterplot (two continuous variables)\ngeom_point()"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#ggplot2-example",
    "href": "lessons/14_midterm_review/14_midterm_review.html#ggplot2-example",
    "title": "Midterm Review",
    "section": "ggplot2: Example",
    "text": "ggplot2: Example\n\nlibrary(ggplot2)\nlibrary(oibiostat)\ndata(\"nhanes.samp\")\n\n# Histogram\nggplot(nhanes.samp, aes(x = Height)) +\n  geom_histogram(bins = 20) +\n  labs(title = \"Distribution of Height\",\n       x = \"Height (cm)\",\n       y = \"Count\")\n\n# Boxplot by group\nggplot(nhanes.samp, \n       aes(x = Gender, y = Weight, fill = Gender)) +\n  geom_boxplot() +\n  labs(title = \"Weight by Gender\",\n       x = \"Gender\",\n       y = \"Weight (kg)\")\n\n\n\nRemember: Start with ggplot(), then add layers with +"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#dplyr-rstatix-summary-statistics",
    "href": "lessons/14_midterm_review/14_midterm_review.html#dplyr-rstatix-summary-statistics",
    "title": "Midterm Review",
    "section": "dplyr + rstatix: Summary Statistics",
    "text": "dplyr + rstatix: Summary Statistics\n\n\n\nThe pattern: group_by() then summarize\n\n\n\nlibrary(dplyr)\nlibrary(rstatix)\n\ndataset %&gt;%\n  group_by(grouping_variable) %&gt;%\n  get_summary_stats(numeric_variable, type = \"mean_sd\")\n\n\n\n\n\n\nExample:\n\n# Summary stats by one group\nnhanes.samp %&gt;%\n  group_by(Gender) %&gt;%\n  get_summary_stats(Height, type = \"mean_sd\")\n\n# Summary stats by multiple groups\nnhanes.samp %&gt;%\n  group_by(Gender, SmokeNow) %&gt;%\n  get_summary_stats(Weight, type = \"mean_sd\")"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#dplyr-only-summary-statistics",
    "href": "lessons/14_midterm_review/14_midterm_review.html#dplyr-only-summary-statistics",
    "title": "Midterm Review",
    "section": "dplyr only: Summary Statistics",
    "text": "dplyr only: Summary Statistics\n\n\n\nThe pattern: group_by() then summarize\n\n\n\nlibrary(dplyr)\n\ndataset %&gt;%\n  group_by(grouping_variable) %&gt;%\n  summarise(...)\n\n\n\n\nExample:\n\n# Summary stats by one group\nnhanes.samp %&gt;%\n  group_by(Gender) %&gt;%\n  summarise(n = sum(!is.na(Height)), \n            mean = mean(Height, na.rm = TRUE), \n            sd = sd(Height, na.rm = TRUE))\n\n# Summary stats by multiple groups\nnhanes.samp %&gt;%\n  group_by(Gender, SmokeNow) %&gt;%\n  summarise(n = sum(!is.na(Weight)), \n            mean = mean(Weight, na.rm = TRUE), \n            sd = sd(Weight, na.rm = TRUE))"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#categorical-data-janitortabyl",
    "href": "lessons/14_midterm_review/14_midterm_review.html#categorical-data-janitortabyl",
    "title": "Midterm Review",
    "section": "Categorical Data: janitor::tabyl()",
    "text": "Categorical Data: janitor::tabyl()\n\n\n\nThe pattern for frequency tables\n\n\n\nlibrary(janitor)\n\n# One-way table\ndataset %&gt;%\n  tabyl(variable)\n\n# Two-way table with row percentages\ndataset %&gt;%\n  tabyl(row_variable, column_variable) %&gt;%\n  adorn_totals(where = \"row\") %&gt;% \n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1)\n\n\n\n\nExample:\n\n# Two-way table\nnhanes.samp %&gt;%\n  tabyl(Gender, SmokeNow) %&gt;%\n  adorn_totals(where = \"row\") %&gt;% \n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#probability-notation-quick-reference",
    "href": "lessons/14_midterm_review/14_midterm_review.html#probability-notation-quick-reference",
    "title": "Midterm Review",
    "section": "Probability Notation Quick Reference",
    "text": "Probability Notation Quick Reference\nBasic probabilities:\n\nMarginal: \\(P(A)\\) - probability of \\(A\\) alone\nJoint: \\(P(A \\text{ and } B)\\) - probability of both\nConditional: \\(P(A \\mid B)\\) - probability of \\(A\\) given \\(B\\)\n\n\n\nKey formula:\n\\[P(A \\mid B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]\n\n\nIndependence:\nEvents \\(A\\) and \\(B\\) are independent if: \\(P(A \\text{ and } B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#probability-rules-to-remember",
    "href": "lessons/14_midterm_review/14_midterm_review.html#probability-rules-to-remember",
    "title": "Midterm Review",
    "section": "Probability Rules to Remember",
    "text": "Probability Rules to Remember\nGeneral Addition Rule:\nIf \\(A\\) and \\(B\\) are any two events:\n\\[P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\\]\nWe subtract \\(P(A \\text{ and } B)\\) because those outcomes were counted twice.\n\n\nGeneral Multiplication Rule:\n\\[P(A \\text{ and } B) = P(A \\mid B) \\times P(B)\\]\nThis connects joint and conditional probabilities, and leads directly to Bayes‚Äô Theorem!\n\n\n\n\n\nSpecial case: Independent events\n\n\nIf \\(A\\) and \\(B\\) are independent: \\(P(A \\text{ and } B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#bayes-theorem-the-pattern",
    "href": "lessons/14_midterm_review/14_midterm_review.html#bayes-theorem-the-pattern",
    "title": "Midterm Review",
    "section": "Bayes‚Äô Theorem: The Pattern",
    "text": "Bayes‚Äô Theorem: The Pattern\nYou‚Äôll almost always use it in this form:\n\\[\n\\begin{aligned}\nP(A \\mid B) &= \\frac{P(B \\mid A) \\times P(A)}{P(B)} \\\\\n\\\\\n&= \\frac{P(B \\mid A) \\times P(A)}{P(B \\mid A) \\times P(A) + P(B \\mid A^c) \\times P(A^c)}\n\\end{aligned}\n\\]\n\n\n\nIn medical testing context:\n\\[P(\\text{Disease} \\mid \\text{Test+}) = \\frac{\\text{sensitivity} \\times \\text{prevalence}}{\\text{sensitivity} \\times \\text{prevalence} + (1-\\text{specificity}) \\times (1-\\text{prevalence})}\\]\n\n\nPro tip: Calculate numerator and denominator separately, then divide!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#bayes-theorem-step-by-step",
    "href": "lessons/14_midterm_review/14_midterm_review.html#bayes-theorem-step-by-step",
    "title": "Midterm Review",
    "section": "Bayes‚Äô Theorem: Step-by-Step",
    "text": "Bayes‚Äô Theorem: Step-by-Step\n\n\nGiven: Sensitivity = 0.90, Specificity = 0.85, Prevalence = 0.02\n\n# Step 1: Set up\nsensitivity &lt;- 0.90     # P(Test + | Disease)\nspecificity &lt;- 0.85     # P(Test - | No Disease)\nprevalence &lt;- 0.02      # P(Disease)\n\n# Step 2: Calculate P(Test + | No Disease)\np_pos_given_healthy &lt;- 1 - specificity\np_pos_given_healthy\n\n[1] 0.15\n\n# Step 3: Numerator (true positives)\nnumerator &lt;- sensitivity * prevalence\nnumerator\n\n[1] 0.018\n\n# Step 4: Denominator (all positives)\ndenominator &lt;- sensitivity * prevalence + p_pos_given_healthy * (1 - prevalence)\ndenominator\n\n[1] 0.165\n\n# Step 5: PPV\nppv &lt;- numerator / denominator\nppv\n\n[1] 0.1090909"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#the-four-functions-pattern",
    "href": "lessons/14_midterm_review/14_midterm_review.html#the-four-functions-pattern",
    "title": "Midterm Review",
    "section": "The Four Functions Pattern",
    "text": "The Four Functions Pattern\nEvery distribution in R has 4 functions:\n\n\nd-functions: dbinom(), dnorm(), dpois()\n\n‚Äúdensity‚Äù or ‚Äúprobability mass‚Äù\nExactly x\nReturns: P(X = x)\n\n\n\np-functions: pbinom(), pnorm(), ppois()\n\n‚Äúcumulative probability‚Äù\nAt most x (or at least with lower.tail = FALSE)\nReturns: P(X ‚â§ x) or P(X &gt; x)\n\n\nq-functions: qbinom(), qnorm(), qpois()\n\n‚Äúquantile‚Äù\nWhat value gives this probability?\nReturns: value of x\n\n\n\nr-functions: rbinom(), rnorm(), rpois()\n\n‚Äúrandom‚Äù\nGenerate random samples\nReturns: random values"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#binomial-functions-in-r",
    "href": "lessons/14_midterm_review/14_midterm_review.html#binomial-functions-in-r",
    "title": "Midterm Review",
    "section": "Binomial Functions in R",
    "text": "Binomial Functions in R\nThe four binomial functions:\n\n# d = probability of EXACTLY x successes\ndbinom(x = 3, size = 10, prob = 0.5)\n# \"What's P(X = 3)?\"\n\n# p = cumulative probability (at most x OR at least x)\npbinom(q = 3, size = 10, prob = 0.5)\n# \"What's P(X ‚â§ 3)?\" (default)\n\npbinom(q = 3, size = 10, prob = 0.5, lower.tail = FALSE)\n# \"What's P(X &gt; 3)?\"\n\n# q = quantile (what value gives this probability?)\nqbinom(p = 0.25, size = 10, prob = 0.5)\n# \"What value has 25% of the distribution below it?\"\n\n# r = random samples\nrbinom(n = 100, size = 10, prob = 0.5)\n# \"Give me 100 random draws\""
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#visual-dbinom---exactly",
    "href": "lessons/14_midterm_review/14_midterm_review.html#visual-dbinom---exactly",
    "title": "Midterm Review",
    "section": "Visual: dbinom() - EXACTLY",
    "text": "Visual: dbinom() - EXACTLY"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#visual-pbinom---at-most-default",
    "href": "lessons/14_midterm_review/14_midterm_review.html#visual-pbinom---at-most-default",
    "title": "Midterm Review",
    "section": "Visual: pbinom() - AT MOST (default)",
    "text": "Visual: pbinom() - AT MOST (default)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#visual-pbinom-lower.tail-false---more-than",
    "href": "lessons/14_midterm_review/14_midterm_review.html#visual-pbinom-lower.tail-false---more-than",
    "title": "Midterm Review",
    "section": "Visual: pbinom(‚Ä¶, lower.tail = FALSE) - MORE THAN",
    "text": "Visual: pbinom(‚Ä¶, lower.tail = FALSE) - MORE THAN"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#the-lower.tail-truefalse-concept",
    "href": "lessons/14_midterm_review/14_midterm_review.html#the-lower.tail-truefalse-concept",
    "title": "Midterm Review",
    "section": "The lower.tail = TRUE/FALSE Concept",
    "text": "The lower.tail = TRUE/FALSE Concept\n\n\n\nVisual Guide\n\n\n\n\n       |--------------‚óè-------------|\n       lower tail     x    upper tail\n       (left)                 (right)\n\n\nlower.tail = TRUE ‚Üí gives you \\(P(X \\le x)\\) ‚Äî everything to the LEFT of (and including) x\nlower.tail = FALSE ‚Üí gives you \\(P(X \\gt x)\\) ‚Äî everything to the RIGHT of x\n\n\n\n\n\nQuick decision rule:\n\nQuestion has ‚Äúless than‚Äù or ‚Äúat most‚Äù ‚Üí lower.tail = TRUE (default)\nQuestion has ‚Äúgreater than‚Äù or ‚Äúat least‚Äù ‚Üí lower.tail = FALSE"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#common-confusion-at-least-5-discrete-distributions",
    "href": "lessons/14_midterm_review/14_midterm_review.html#common-confusion-at-least-5-discrete-distributions",
    "title": "Midterm Review",
    "section": "Common Confusion: ‚ÄúAt least 5‚Äù (Discrete Distributions)",
    "text": "Common Confusion: ‚ÄúAt least 5‚Äù (Discrete Distributions)\n\n\nQuestion: What is \\(P(X \\ge 5)\\) for a binomial distribution?\n\n\nStep 1: Translate to something the computer understands\n\n‚ÄúAt least 5‚Äù = ‚Äú5 or more‚Äù = ‚Äúgreater than 4‚Äù\nSo: \\(P(X \\ge 5)\\) = \\(P(X \\gt 4)\\)\n\nStep 2: Code it\n\n# Correct!\npbinom(q = 4, size = 10, prob = 0.5, lower.tail = FALSE)\n\n# Also correct (but slightly more work)\n1 - pbinom(q = 4, size = 10, prob = 0.5)\n\n\n\n\nKey Point\n\n\nFor discrete distributions: ‚Äú\\(X \\ge 5\\)‚Äù is the same as ‚Äú\\(X \\gt 4\\)‚Äù because we can‚Äôt have \\(4.5\\) successes!\nThis slide applies to binomial and Poisson (discrete). For Normal (continuous), \\(P(X \\ge 5) = P(X \\gt 5)\\) - no adjustment needed!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-questions",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-questions",
    "title": "Midterm Review",
    "section": "Practice: Binomial Questions",
    "text": "Practice: Binomial Questions\nA vaccine is 75% effective. You vaccinate 20 people.\nWhich R function do you use?\n\n\nQuestion 1: What‚Äôs the probability that exactly 15 are protected?\n\n# Your answer:\n\n\n\nQuestion 2: What‚Äôs the probability that at most 12 are protected?\n\n# Your answer:\n\n\nQuestion 3: What‚Äôs the probability that at least 18 are protected?\n\n# Your answer:\n\n\n\nQuestion 4: What‚Äôs the expected number protected?\n\n# Your answer:"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-answers-12",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-answers-12",
    "title": "Midterm Review",
    "section": "Practice: Binomial Answers (1/2)",
    "text": "Practice: Binomial Answers (1/2)\nA vaccine is 75% effective. You vaccinate 20 people.\n\n\nQuestion 1: What‚Äôs the probability that exactly 15 are protected?\n\n# Question 1: Exactly 15\ndbinom(x = 15, size = 20, prob = 0.75)\n\n[1] 0.2023312\n\n\n\n\nQuestion 2: What‚Äôs the probability that at most 12 are protected?\n\n# Question 2: At most 12\npbinom(q = 12, size = 20, prob = 0.75)\n\n[1] 0.1018119\n\n# OR: pbinom(q = 12, size = 20, prob = 0.75, lower.tail = TRUE)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-answers-22",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-binomial-answers-22",
    "title": "Midterm Review",
    "section": "Practice: Binomial Answers (2/2)",
    "text": "Practice: Binomial Answers (2/2)\n\n\nQuestion 3: What‚Äôs the probability that at least 18 are protected?\n\n# Question 3: At least 18 (same as &gt; 17)\npbinom(q = 17, size = 20, prob = 0.75, lower.tail = FALSE)\n\n[1] 0.09126043\n\n# OR: 1 - pbinom(q = 17, size = 20, prob = 0.75)\n\n\n\nQuestion 4: What‚Äôs the expected number protected?\n\n# Question 4: Expected value\nn &lt;- 20\np &lt;- 0.75\nexpected &lt;- n * p\nexpected\n\n[1] 15\n\n# Bonus: standard deviation\nvariance &lt;- n * p * (1 - p)\nst_dev &lt;- sqrt(variance)\nst_dev\n\n[1] 1.936492"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#normal-distribution-functions",
    "href": "lessons/14_midterm_review/14_midterm_review.html#normal-distribution-functions",
    "title": "Midterm Review",
    "section": "Normal Distribution Functions",
    "text": "Normal Distribution Functions\nThe same pattern applies!\n\n# d = density (height of curve at x)\ndnorm(x = 120, mean = 100, sd = 15)\n# Rarely used in practice\n\n# p = cumulative probability\npnorm(q = 120, mean = 100, sd = 15)\n# \"What proportion have values ‚â§ 120?\"\n\npnorm(q = 120, mean = 100, sd = 15, lower.tail = FALSE)\n# \"What proportion have values &gt; 120?\"\n\n# q = quantile (most common!)\nqnorm(p = 0.95, mean = 100, sd = 15)\n# \"What value has 95% below it?\" (95th percentile)\n\n# r = random samples\nrnorm(n = 100, mean = 100, sd = 15)\n# \"Give me 100 random values from this distribution\""
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#visual-normal-distribution",
    "href": "lessons/14_midterm_review/14_midterm_review.html#visual-normal-distribution",
    "title": "Midterm Review",
    "section": "Visual: Normal Distribution",
    "text": "Visual: Normal Distribution"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-distribution",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-distribution",
    "title": "Midterm Review",
    "section": "Practice: Normal Distribution",
    "text": "Practice: Normal Distribution\nBlood pressure is Normal with mean = 120 mmHg, sd = 15 mmHg.\nWhich R function?\n\n\nQuestion 1: What proportion have BP above 135?\n\n# Your answer:\n\n\n\nQuestion 2: What proportion have BP between 110 and 130?\n\n# Your answer:\n\n\nQuestion 3: What BP value is the 90th percentile?\n\n# Your answer:\n\n\n\nQuestion 4: If we want the middle 95%, what are the cutoffs?\n\n# Your answer:"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-answers-12",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-answers-12",
    "title": "Midterm Review",
    "section": "Practice: Normal Answers (1/2)",
    "text": "Practice: Normal Answers (1/2)\n\nmu &lt;- 120\nsigma &lt;- 15\n\n# Question 1: Above 135\npnorm(135, mean = mu, sd = sigma, lower.tail = FALSE)\n\n[1] 0.1586553\n\n# OR\n1 - pnorm(135, mean = mu, sd = sigma, lower.tail = TRUE)\n\n[1] 0.1586553\n\n\n\n\n\n# Question 2: Between 110 and 130\npnorm(130, mean = mu, sd = sigma) - pnorm(110, mean = mu, sd = sigma)\n\n[1] 0.4950149"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-answers-22",
    "href": "lessons/14_midterm_review/14_midterm_review.html#practice-normal-answers-22",
    "title": "Midterm Review",
    "section": "Practice: Normal Answers (2/2)",
    "text": "Practice: Normal Answers (2/2)\n\n# Question 3: 90th percentile\nqnorm(0.90, mean = mu, sd = sigma)\n\n[1] 139.2233\n\n\n\n\n\n# Question 4: Middle 95% (2.5th to 97.5th percentiles)\nqnorm(0.025, mean = mu, sd = sigma)  # Lower\n\n[1] 90.60054\n\nqnorm(0.975, mean = mu, sd = sigma)  # Upper\n\n[1] 149.3995"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#central-limit-theorem-what-you-need-to-know",
    "href": "lessons/14_midterm_review/14_midterm_review.html#central-limit-theorem-what-you-need-to-know",
    "title": "Midterm Review",
    "section": "Central Limit Theorem: What You Need to Know",
    "text": "Central Limit Theorem: What You Need to Know\n\n\n\nThe CLT in plain language\n\n\nFor a random sample of size \\(n\\) from ANY population with mean \\(\\mu\\) and SD \\(\\sigma\\):\nThe sampling distribution of \\(\\bar{X}\\) is approximately normal when \\(n\\) is large (\\(\\ge 30\\))\nWith:\n\nMean = \\(\\mu\\)\nStandard Error = \\(\\sigma / \\sqrt{n}\\)\n\n\n\n\n\n\nWhy this matters:\n\nWe can use normal distribution tools even if data aren‚Äôt normal\nLarger samples ‚Üí smaller standard error ‚Üí more precise estimates\nThis is the foundation for confidence intervals and hypothesis tests!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#standard-error-vs.-standard-deviation",
    "href": "lessons/14_midterm_review/14_midterm_review.html#standard-error-vs.-standard-deviation",
    "title": "Midterm Review",
    "section": "Standard Error vs.¬†Standard Deviation",
    "text": "Standard Error vs.¬†Standard Deviation\n\n\n\nDon‚Äôt confuse these!\n\n\nStandard Deviation (\\(s\\) or \\(\\sigma\\)):\n\nMeasures spread of individual observations\nDescribes variability in the data\nFormula: \\(s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\)\n\n\n\nStandard Error (SE):\n\nMeasures uncertainty of the sample mean\nDescribes variability of \\(\\bar{x}\\) across (theoretical) samples\nFormula: \\(SE = \\frac{s}{\\sqrt{n}}\\)\n\n\n\n\n\n\nKey insight: SE gets smaller as \\(n\\) increases, but \\(s\\) stays roughly the same!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#example-clt-in-action",
    "href": "lessons/14_midterm_review/14_midterm_review.html#example-clt-in-action",
    "title": "Midterm Review",
    "section": "Example: CLT in Action",
    "text": "Example: CLT in Action\nPopulation: Mean = 5.1 hours, SD = 1.9 hours, right-skewed\nSample: n = 40\nWhat‚Äôs the sampling distribution of \\(\\bar{X}\\)?\n\n# Parameters\nmu &lt;- 5.1\nsigma &lt;- 1.9\nn &lt;- 40\n\n# Sampling distribution\nmean_xbar &lt;- mu\nse_xbar &lt;- sigma / sqrt(n)\n\nmean_xbar\n\n[1] 5.1\n\nse_xbar\n\n[1] 0.3004164\n\n# Example probability about the sample mean, P(Xbar &gt; 5.6)\npnorm(5.6, mean = mean_xbar, sd = se_xbar, lower.tail = FALSE)\n\n[1] 0.04802059\n\n\n\n\nSampling distribution: approximately Normal(mean = \\(mu\\), sd = \\(\\frac{s}{\\sqrt{n}}\\)). Even though the original data are right-skewed!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#confidence-interval-formula",
    "href": "lessons/14_midterm_review/14_midterm_review.html#confidence-interval-formula",
    "title": "Midterm Review",
    "section": "Confidence Interval Formula",
    "text": "Confidence Interval Formula\n\n\n\nGeneral form\n\n\n\\[\\text{point estimate} \\pm \\text{critical value} \\times SE\\]\nFor a mean:\n\\[\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\]\nWhere:\n\n\\(\\bar{x}\\) = sample mean\n\\(t^*\\) = critical value from t-distribution with \\(df = n-1\\)\n\\(s\\) = sample standard deviation\n\n\\(n\\) = sample size"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#calculating-a-95-ci-in-r-12",
    "href": "lessons/14_midterm_review/14_midterm_review.html#calculating-a-95-ci-in-r-12",
    "title": "Midterm Review",
    "section": "Calculating a 95% CI in R (1/2)",
    "text": "Calculating a 95% CI in R (1/2)\n\n\n# Sample data\nn &lt;- 25\nxbar &lt;- 14.2\ns &lt;- 1.8\nconfidence_level &lt;- 0.95\n\nalpha &lt;- 1 - confidence_level\n\n# Step 1: Find critical value\nt_star &lt;- qt(1 - alpha / 2, df = n - 1)\n\n# OR: qt(0.975, df = 24)\nt_star\n\n[1] 2.063899\n\n# Step 2: Calculate standard error\nSE &lt;- s / sqrt(n)\nSE\n\n[1] 0.36"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#calculating-a-95-ci-in-r-22",
    "href": "lessons/14_midterm_review/14_midterm_review.html#calculating-a-95-ci-in-r-22",
    "title": "Midterm Review",
    "section": "Calculating a 95% CI in R (2/2)",
    "text": "Calculating a 95% CI in R (2/2)\n\n# Step 3: Calculate margin of error\nmargin_error &lt;- t_star * SE\nmargin_error\n\n[1] 0.7430035\n\n# Step 4: Build the interval\nlower &lt;- xbar - margin_error\nupper &lt;- xbar + margin_error\n\nc(lower, upper)\n\n[1] 13.457 14.943"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#interpreting-confidence-intervals",
    "href": "lessons/14_midterm_review/14_midterm_review.html#interpreting-confidence-intervals",
    "title": "Midterm Review",
    "section": "Interpreting Confidence Intervals",
    "text": "Interpreting Confidence Intervals\n\n\n\nCorrect interpretation\n\n\n‚ÄúWe are 95% confident that the population mean is between 13.5 and 14.9.‚Äù\nWhat this means:\n\nIf we repeated this process many times (new samples, new CIs)\nAbout 95% of those intervals would contain the true \\(\\mu\\)\nWe don‚Äôt know if this specific interval contains \\(\\mu\\), but we‚Äôre using a reliable method\n\n\n\n\n\n\n\n\n\nCommon mistakes - DON‚ÄôT SAY:\n\n\n\n‚ùå ‚ÄúThere‚Äôs a 95% probability that \\(\\mu\\) is in this interval‚Äù\n‚ùå ‚Äú95% of the data are in this interval‚Äù\n‚ùå ‚ÄúWe‚Äôre 95% sure the sample mean is in this interval‚Äù"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#what-affects-ci-width",
    "href": "lessons/14_midterm_review/14_midterm_review.html#what-affects-ci-width",
    "title": "Midterm Review",
    "section": "What Affects CI Width?",
    "text": "What Affects CI Width?\n\n\nMargin of error = \\(t^* \\times \\frac{s}{\\sqrt{n}}\\)\n\n\nTo get a narrower CI:\n\nIncrease sample size (\\(n\\) ‚Üë ‚Üí SE ‚Üì ‚Üí narrower CI)\nDecrease confidence level (95% ‚Üí 90% ‚Üí smaller \\(t^*\\) ‚Üí narrower CI)\n\nBut this means less confidence!\n\nReduce variability (\\(s\\) ‚Üì ‚Üí SE ‚Üì ‚Üí narrower CI)\n\nOften not under our control\n\n\n\n\nTrade-off: Precision vs.¬†Confidence"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#the-hypothesis-testing-framework",
    "href": "lessons/14_midterm_review/14_midterm_review.html#the-hypothesis-testing-framework",
    "title": "Midterm Review",
    "section": "The Hypothesis Testing Framework",
    "text": "The Hypothesis Testing Framework\n\n\nSix steps:\n\nState hypotheses: \\(H_0\\) and \\(H_A\\)\nSet significance level: Usually \\(\\alpha = 0.05\\)\nCheck assumptions: Independence, normality/large sample\nCalculate test statistic: \\(t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\\)\nFind p-value: Probability of seeing data this extreme if \\(H_0\\) true\nMake conclusion: Reject \\(H_0\\) if p-value &lt; \\(\\alpha\\)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#writing-hypotheses",
    "href": "lessons/14_midterm_review/14_midterm_review.html#writing-hypotheses",
    "title": "Midterm Review",
    "section": "Writing Hypotheses",
    "text": "Writing Hypotheses\n\n\n\nTemplate\n\n\n\\(H_0: \\mu = \\mu_0\\) (null value)\n\\(H_A: \\mu \\neq \\mu_0\\) (two-sided) OR \\(\\mu &gt; \\mu_0\\) OR \\(\\mu &lt; \\mu_0\\) (one-sided)\n\n\n\n\n\nExample: Is mean body temperature different from 98.6¬∞F?\n\n\\(H_0: \\mu = 98.6\\)\n\\(H_A: \\mu \\neq 98.6\\)\n\n\n\nIn words:\n\n\\(H_0\\): The population mean body temperature is 98.6¬∞F\n\\(H_A\\): The population mean body temperature is not 98.6¬∞F"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#p-values-what-they-mean",
    "href": "lessons/14_midterm_review/14_midterm_review.html#p-values-what-they-mean",
    "title": "Midterm Review",
    "section": "P-values: What They Mean",
    "text": "P-values: What They Mean\n\n\n\nDefinition\n\n\nThe p-value is the probability of observing data as extreme as (or more extreme than) what we observed, assuming \\(H_0\\) is true.\n\n\n\n\n\nInterpretation guide:\n\np-value &lt; 0.05 ‚Üí Strong evidence against \\(H_0\\) ‚Üí Reject \\(H_0\\)\np-value ‚â• 0.05 ‚Üí Insufficient evidence ‚Üí Fail to reject \\(H_0\\)\n\n\n\n\n\n\nWhat p-values are NOT\n\n\n\n‚ùå NOT the probability that \\(H_0\\) is true\n‚ùå NOT the probability of making an error\n‚ùå NOT a measure of effect size or importance"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#one-sample-t-test-in-r",
    "href": "lessons/14_midterm_review/14_midterm_review.html#one-sample-t-test-in-r",
    "title": "Midterm Review",
    "section": "One-Sample t-test in R",
    "text": "One-Sample t-test in R\n\n# Using raw data\nt.test(data$variable, \n       mu = null_value, \n       alternative = \"two.sided\")  # or \"less\" or \"greater\"\n\n\n\nExample:\n\n# Test if mean pulse rate is different from 72 bpm\ndata(\"nhanes.samp\")\n\nt.test(nhanes.samp$Pulse, \n       mu = 72, \n       alternative = \"two.sided\")"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#understanding-t.test-output",
    "href": "lessons/14_midterm_review/14_midterm_review.html#understanding-t.test-output",
    "title": "Midterm Review",
    "section": "Understanding t.test() Output",
    "text": "Understanding t.test() Output\n\n\n\n    One Sample t-test\n\ndata:  nhanes.samp$Pulse\nt = 2.1383, df = 170, p-value = 0.03392\nalternative hypothesis: true mean is not equal to 72\n95 percent confidence interval:\n 72.15999 76.00376\nsample estimates:\nmean of x \n 74.08187 \n\n\n\n\nWhat to report:\n\nt-statistic: How many SEs away from null value\np-value: Evidence against \\(H_0\\)\n95% CI: Range of plausible values for \\(\\mu\\)\nSample mean: Our point estimate"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#connection-cis-and-hypothesis-tests",
    "href": "lessons/14_midterm_review/14_midterm_review.html#connection-cis-and-hypothesis-tests",
    "title": "Midterm Review",
    "section": "Connection: CIs and Hypothesis Tests",
    "text": "Connection: CIs and Hypothesis Tests\n\n\n\nKey relationship\n\n\nFor a two-sided test at \\(\\alpha = 0.05\\):\nIf the 95% CI does NOT contain \\(\\mu_0\\), then we reject \\(H_0: \\mu = \\mu_0\\)\nIf the 95% CI DOES contain \\(\\mu_0\\), then we fail to reject \\(H_0\\)\n\n\n\n\n\nBoth methods use the same math - just different framing!\n\nCI: ‚ÄúWhat values are plausible for \\(\\mu\\)?‚Äù\nHypothesis test: ‚ÄúIs this specific value plausible?‚Äù"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#statistical-significance-vs.-practical-significance",
    "href": "lessons/14_midterm_review/14_midterm_review.html#statistical-significance-vs.-practical-significance",
    "title": "Midterm Review",
    "section": "Statistical Significance vs.¬†Practical Significance",
    "text": "Statistical Significance vs.¬†Practical Significance\n\n\n\nDon‚Äôt confuse these!\n\n\nStatistical significance (p &lt; 0.05):\n\nEvidence that there‚Äôs a real effect\nDoesn‚Äôt tell you if the effect matters\n\n\n\nPractical/Clinical significance:\n\nEffect is large enough to matter in real-world terms\nYou must judge this based on context\n\n\n\n\n\n\nExample: A drug lowers blood pressure by 0.5 mmHg (p = 0.001)\n\nStatistically significant? ‚úÖ Yes\nClinically meaningful? ‚ùå No (too small to affect patient outcomes)"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#common-mistakes-to-avoid",
    "href": "lessons/14_midterm_review/14_midterm_review.html#common-mistakes-to-avoid",
    "title": "Midterm Review",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\nForgetting to check assumptions before running tests\nConfusing standard deviation and standard error\nUsing lower.tail = TRUE when you need FALSE (or vice versa)\nMisinterpreting p-values and confidence intervals\nForgetting to include na.rm = TRUE when there are missing values\nNot rendering your document before submitting\n\n\n\nPro tip: When using pbinom() or ppois(), sketch a quick picture to check if you want the left or right tail!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#exam-strategy",
    "href": "lessons/14_midterm_review/14_midterm_review.html#exam-strategy",
    "title": "Midterm Review",
    "section": "Exam Strategy",
    "text": "Exam Strategy\nTime management:\n\nDon‚Äôt get stuck on one question\nMove on and come back if needed\nLeave buffer time for rendering and checking\n\n\n\nInterpretation questions:\n\nWrite in complete sentences\nReference numbers from your calculations\nConnect to context (not just abstract statistics)\n\n\n\nCoding questions:\n\nShow your work (don‚Äôt just give answers)\nUse comments to explain your logic\nCheck that your code actually runs!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#resources",
    "href": "lessons/14_midterm_review/14_midterm_review.html#resources",
    "title": "Midterm Review",
    "section": "Resources",
    "text": "Resources\nDuring the exam:\n\nLecture slides (especially the summary slides)\nHomework solutions (you‚Äôve seen similar questions!)\nR help: ?t.test, ?pnorm, etc.\n\n\n\nAfter you submit:\n\nThe exam will close Monday at 11 PM\nSolutions will be available after\nWe‚Äôll get feedback to you within a week\nRemember: This is a learning experience!"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#your-turn",
    "href": "lessons/14_midterm_review/14_midterm_review.html#your-turn",
    "title": "Midterm Review",
    "section": "Your Turn!",
    "text": "Your Turn!\nWhat questions do you have?\n\nConcepts that are still unclear?\nR functions you‚Äôre unsure about?\nSpecific exam questions you want to discuss?\n\n\n\nRemember:\n\nExam opens today at 3 PM\nYou have until Monday at 11 PM\nYou‚Äôve got this! üí™"
  },
  {
    "objectID": "lessons/14_midterm_review/14_midterm_review.html#good-luck",
    "href": "lessons/14_midterm_review/14_midterm_review.html#good-luck",
    "title": "Midterm Review",
    "section": "Good luck!",
    "text": "Good luck!\nYou‚Äôre well prepared:\n\n‚úÖ You‚Äôve done the homework\n‚úÖ You‚Äôve come to class\n‚úÖ You‚Äôve practiced with R\n‚úÖ You know where to find help\n\n\n\nTrust your preparation and think carefully about each question.\n\n\n\nBMSC 620 | Midterm Review"
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html",
    "title": "Response to Muddy Points",
    "section": "",
    "text": "Most of you felt the pace of the lecture was about right. Several comments highlighted the distinction between paired and independent t-tests and the R project workflow as particularly clear. I‚Äôll focus below on a few of the muddy points that came up."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#pacing-and-what-worked",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#pacing-and-what-worked",
    "title": "Response to Muddy Points",
    "section": "",
    "text": "Most of you felt the pace of the lecture was about right. Several comments highlighted the distinction between paired and independent t-tests and the R project workflow as particularly clear. I‚Äôll focus below on a few of the muddy points that came up."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#conceptual-clarifications",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#conceptual-clarifications",
    "title": "Response to Muddy Points",
    "section": "Conceptual Clarifications",
    "text": "Conceptual Clarifications\n\nHypothesis Testing Ethics: Can You Change Your Hypothesis After Seeing Data?\n‚ÄúWhat if we failed to reject the null, then tested the opposite direction?‚Äù\nThis is an excellent ethical question that gets at the heart of hypothesis testing. You should not reframe a confirmatory hypothesis after looking at the data. Here‚Äôs why:\nThe entire hypothesis testing framework is built on specifying your hypothesis before collecting data. When you set \\(\\alpha = 0.05\\), you‚Äôre accepting a 5% chance of a false positive. But if you:\n\nTest one direction (e.g., caffeine increases tapping) ‚Üí get \\(p = 0.10\\)\nThen test the other direction (caffeine decreases tapping) ‚Üí get \\(p = 0.03\\)\n\nYou‚Äôve now done two tests, each with a 5% false positive rate. Your actual false positive rate is higher than 5% (this is the multiple testing problem we‚Äôll discuss later in the course). Conceptually, you are giving yourself multiple chances to find significance after seeing the data.\nWhat you CAN do:\n\nReport the result as exploratory: ‚ÄúWe found a non-significant trend toward increased tapping. Interestingly, there was a significant decrease‚Ä¶‚Äù\nUse the finding to design a new study with an a priori hypothesis\nBe transparent in publications: ‚ÄúThis was a post-hoc analysis‚Äù\n\nThe key is transparency about what was pre-specified vs discovered during analysis.\n\n\nToo Many Options: What Should I Actually Use?\n‚ÄúGiving all the options confuses me - what do you mainly use?‚Äù\nFair feedback! I show you multiple approaches so you can understand different code you might encounter, but here‚Äôs what I recommend you actually use:\nFor t-tests, use this approach:\n# Two independent samples\nt.test(outcome ~ group, data = mydata)\n\n# Two independent samples (long format)\nt.test(outcome ~ group, data = mydata) \n\n# Paired samples (long format - one outcome column, one time/condition column)\nt.test(outcome ~ group, data = mydata, paired = TRUE)\n\n# Paired samples (wide format - separate before/after columns)\nt.test(x = mydata$after, y = mydata$before, paired = TRUE)\n\n# One sample\nt.test(mydata$variable, mu = 0)\nIf you remember only one thing: use the formula interface for two-sample tests, and add paired = TRUE only when the same units are measured twice.\nWhy this approach?\n\nWorks with tidyverse piping\nClear syntax showing what you‚Äôre comparing\nEasy to modify (just add paired = TRUE or change mu)\nYou‚Äôll see this format in most modern R code\n\nYou can ignore the rstatix package methods for now unless you‚Äôre specifically doing grouped analyses. I mention them so you‚Äôll recognize them if you see them in other people‚Äôs code or Stack Overflow."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#the-here-package",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#the-here-package",
    "title": "Response to Muddy Points",
    "section": "The here Package",
    "text": "The here Package\n‚ÄúI think Here is confusing still‚Äù\nLet me break this down with a concrete example. Say your project structure looks like this:\nmy_project/\n‚îú‚îÄ‚îÄ my_project.Rproj\n‚îú‚îÄ‚îÄ code/\n‚îÇ   ‚îî‚îÄ‚îÄ analysis.R\n‚îî‚îÄ‚îÄ data/\n    ‚îî‚îÄ‚îÄ nhanes.csv\nWithout here: If you‚Äôre working in analysis.R, you might write:\ndata &lt;- read_csv(\"../data/nhanes.csv\")  # Fragile! Depends on where you run code\nWith here:\nlibrary(here)\ndata &lt;- read_csv(here(\"data\", \"nhanes.csv\"))  # Always works!\nThe magic: here() always builds paths from your project root (where the .Rproj file lives), regardless of:\n\nWhat folder your script is in\nWhether you run code line-by-line or knit the whole document\n\nWhether you‚Äôre on Mac, PC, or different computers\n\nThink of it as: here() says ‚Äústart at my project folder, then go into data folder, then grab nhanes.csv‚Äù\nWhen to use it: Anytime you‚Äôre reading or writing files in your project. You‚Äôll get practice with this in upcoming homework.\nIf this still feels abstract right now, that‚Äôs normal. It usually ‚Äúclicks‚Äù the first time a project breaks without here()."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#understanding-t.test-arguments",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#understanding-t.test-arguments",
    "title": "Response to Muddy Points",
    "section": "Understanding t.test() Arguments",
    "text": "Understanding t.test() Arguments\n\nWhy mu = 0 Sometimes But Not Always?\n‚ÄúWhy set mu = 0 for DiffChol but not when comparing two columns?‚Äù\nGreat observation! The key thing to understand: mu = 0 is the default for ALL t-tests ‚Äî I just chose when to write it explicitly.\nOne-sample t-test:\nt.test(chol$DiffChol, mu = 0)  # Explicit\nt.test(chol$DiffChol)           # Same thing - mu = 0 is default\nTwo-sample t-test (paired):\nt.test(x = chol$After, y = chol$Before, paired = TRUE)           # mu = 0 by default\nt.test(x = chol$After, y = chol$Before, paired = TRUE, mu = 0)   # Could write this too\nWhy I sometimes write it explicitly:\nIn the one-sample example with DiffChol, I wrote mu = 0 to emphasize what we‚Äôre testing: ‚ÄúIs the mean difference equal to zero?‚Äù It makes the null hypothesis more visible in the code.\nIn the two-sample paired example, I left it off because it‚Äôs the default and the syntax already makes it clear we‚Äôre comparing before and after values.\nBoth are testing difference = 0 ‚Äî I just chose to be explicit about it in the one-sample case for teaching purposes. You could write mu = 0 in every t-test call, or leave it off in all of them. The code does the same thing either way. The definition of the difference depends on the test (one-sample, paired, or two-sample), but the default null value does not.\n\n\nPaired vs Independent: The Resistance Model Question\n‚ÄúWould a resistance model be paired or independent?‚Äù\nThis is a nuanced question! Let‚Äôs think through it:\nPaired data requires: The same biological unit measured twice, or closely matched units.\nYour scenario: Resistant cells vs naive cells from the same original culture.\nThis is independent samples because:\n\nThey‚Äôre different cells (not the same cells measured twice)\nEven though they share an ancestor, they‚Äôve undergone different selection pressures\nYou‚Äôre comparing two distinct populations that have diverged\n\nWhen it WOULD be paired:\n\nIf you measured gene expression in cells, then treated them, then measured again (same cells, before/after)\nIf you had matched tumor samples from the same patient (primary vs metastatic site)\n\nThe key question: ‚ÄúAm I measuring the exact same thing twice, or two related but distinct things?‚Äù In your case, it‚Äôs the latter. Shared origin does not automatically imply pairing ‚Äî pairing requires a one-to-one linkage between measurements.\nIn practice, shared background like this is better handled with blocking or mixed models, which is out of scope for this course. But for t-test decision rules, this is not paired data.\nI think about this example like: ‚ÄúIf I accidentally swapped the labels on three of my ‚Äòresistant‚Äô wells, could I still reconstruct exactly which ‚Äònaive‚Äô wells they were supposed to be paired with?‚Äù In a true paired design (like a patient‚Äôs left and right eye), the answer is yes. In a lineage model, the answer is no ‚Äî the pairing is not intrinsic.\nLeft and right eyes are paired because they are two measurements on the same indivisible experimental unit; resistant and naive lineages are not, because they are separate populations whose relationship exists only through experimental history, not identity."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#r-packages-and-installation",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#r-packages-and-installation",
    "title": "Response to Muddy Points",
    "section": "R Packages and Installation",
    "text": "R Packages and Installation\n‚ÄúI think it will be clearer once I start working with it‚Äù\nYou‚Äôre right - this becomes much more intuitive with practice! Just remember:\nOne-time setup (per computer):\ninstall.packages(\"packagename\")  # Downloads from internet\nEvery R session:\nlibrary(packagename)  # Loads into your current session\nCommon confusion: You only need to install once, but you need to library() in every script/document that uses it.\nIf you get stuck: The error message ‚Äúthere is no package called ‚ÄòX‚Äô‚Äù means you need to install it. The error ‚Äúcould not find function ‚ÄòY‚Äô‚Äù often means you forgot to load the library."
  },
  {
    "objectID": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#looking-ahead",
    "href": "lessons/13_comparing_two_means/13_comparing_two_means_muddy_points.html#looking-ahead",
    "title": "Response to Muddy Points",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nWe‚Äôll continue practicing these concepts, and you‚Äôll get more comfortable with the workflow as we go. Don‚Äôt hesitate to come to office hours if anything remains unclear!"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#learning-objectives-today",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#learning-objectives-today",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Learning objectives (today)",
    "text": "Learning objectives (today)\nBy the end of class, you should be able to:\n\nOpen and navigate RStudio\nCreate, edit, save, and render a Quarto (.qmd) document\nUse basic Markdown to format text in a Quarto document\nCreate and run simple R code chunks and render the output to HTML"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#what-is-r",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#what-is-r",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "What is R?",
    "text": "What is R?\n\n\n\nA programming language\nFocus on statistical modeling and data analysis\n\nimport data, manipulate data, run statistics, make plots\n\nUseful for data science\nGreat visualizations\nAlso useful for most anything else you‚Äôd want to tell a computer to do\nInterfaces with other languages i.e.¬†python, C++, bash\n\n\n\n\nFor the history and details: Wikipedia\n\nan interpreted language (run it through a command line)\nprocedural programming with functions\nWhy ‚ÄúR‚Äù?? Scheme inspired S (invented at Bell Labs in 1976) which inspired R since 1st letters of original authors (free and open source! in 2000)"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#what-is-rstudio",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#what-is-rstudio",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\n\nR is a programming language\n\nRStudio is an integrated development environment (IDE)\n= an interface to use R (with perks!)\n\n\nModern Dive"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#open-rstudio-on-your-computer-not-r",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#open-rstudio-on-your-computer-not-r",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Open RStudio on your computer (not R!)",
    "text": "Open RStudio on your computer (not R!)\n\nModern Dive"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#rstudio-anatomy",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#rstudio-anatomy",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "RStudio anatomy",
    "text": "RStudio anatomy\n\nEmma RandRead more about RStudio‚Äôs layout in Section 3.4 of ‚ÄúGetting Used to R, RStudio, and R Markdown‚Äù (Ismay and Kennedy 2016)"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#example-creating-an-html-file",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#example-creating-an-html-file",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Example: creating an html file",
    "text": "Example: creating an html file\n\n\n.qmd file\n\n\n\n\n\n\n\n\n.html output"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#quarto-.qmd-file-code-text",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#quarto-.qmd-file-code-text",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Quarto = .qmd file = Code + text",
    "text": "Quarto = .qmd file = Code + text\nA .qmd file is where you write your work.\nRendering turns it into something you can read and submit.\nIf you edit the .qmd, re-render to update the .html.\n\nArtwork from ‚ÄúHello, Quarto‚Äù keynote by Julia Lowndes and Mine √áetinkaya-Rundel, presented at RStudio Conference 2022. Illustrated by Allison Horst."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#before-we-get-further-in-.qmd-files",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#before-we-get-further-in-.qmd-files",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Before we get further in .qmd files",
    "text": "Before we get further in .qmd files\n\nIf you would like to code along, make sure to have RStudio open.\n\n\n\nSteps for making a Quarto file\n\nCreate a Quarto file (.qmd)\nEdit a Quarto file (.qmd)\nSave the Quarto file (.qmd)\nCreate html file"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#create-a-quarto-file-.qmd",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#create-a-quarto-file-.qmd",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "1. Create a Quarto file (.qmd)",
    "text": "1. Create a Quarto file (.qmd)\n\n\nTwo options:\n\nclick on File \\(\\rightarrow\\) New File \\(\\rightarrow\\) Quarto Document‚Ä¶\\(\\rightarrow\\) OK,\nor in upper left corner of RStudio click on  \\(\\rightarrow\\) \n\nPop-up window selections:\n\nEnter a title and your name\nSelect HTML output format (default)\nEngine: select Knitr\nEditor: Select Use visual markdown editor\nClick Create"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#the-top-block-yaml---for-later",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#the-top-block-yaml---for-later",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "The top block (YAML) - for later",
    "text": "The top block (YAML) - for later\nThat block controls document settings.\nWe will come back to it later. For now: do not change it."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#edit-a-quarto-file-.qmd",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#edit-a-quarto-file-.qmd",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "2. Edit a Quarto file (.qmd)",
    "text": "2. Edit a Quarto file (.qmd)\n\n\n\nAfter clicking on Create, you should then see the following in your editor window:\n\n\n\n\nYou can try editing the text or changing the code!\n\nMake sure you are only editing at the ‚ÄúQuarto‚Äù header and below"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#save-the-quarto-file-.qmd",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#save-the-quarto-file-.qmd",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "3. Save the Quarto file (.qmd)",
    "text": "3. Save the Quarto file (.qmd)\n\nSave the file by\n\nselecting File -&gt; Save,\nor clicking on  (towards the left above the scripting window),\nor keyboard shortcut\n\nPC: Ctrl + s\nMac: Command + s\n\n\nYou will need to specify\n\na filename to save the file as\n\nALWAYS use .qmd as the filename extension for Quarto files\n\nthe folder to save the file in \nFor now, save it to your desktop, or wherever you know you will find it again."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#create-html-file",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#create-html-file",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "4. Create html file",
    "text": "4. Create html file\nWe create the html file by rendering the .qmd file.\nTwo options:\n\nclick on the Render icon  at the top of the editor window,\nor use keyboard shortcuts\n\nMac: Command+Shift+K\nPC: Ctrl+Shift+K\n\n\n\nA new window will open with the html output.\nYou will now see both .qmd and .html files in the folder where you saved the .qmd file.\n\n\n\n\n\n\n\nNote\n\n\n\nThe template .qmd file that RStudio creates will render to an html file by default.\nThe output format can be changed to create a Word doc, pdf, slides, etc."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#tip-changing-the-render-view",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#tip-changing-the-render-view",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Tip: changing the render view",
    "text": "Tip: changing the render view\n\nYou can change where your .html file pops up\nI have it set to open in the ‚ÄúViewer Pane‚Äù in the bottom right"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#qmd-vs.-its-.html-output",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#qmd-vs.-its-.html-output",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": ".qmd vs.¬†its .html output",
    "text": ".qmd vs.¬†its .html output\n\n\n.qmd file\n\n\n\n\n\n\n\n\n.html output"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#file-naming-for-assignments",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#file-naming-for-assignments",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "File naming for assignments",
    "text": "File naming for assignments\nUse a consistent naming convention so we can grade efficiently:\nLastname_FirstInitial_HW00.qmd\nSubmit both:\n\n.qmd\n.html"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Formatting text",
    "text": "Formatting text\n\nbold, italics, superscripts & subscripts, strikethrough, verbatim, etc.\n\n\nText is formatted through a markup language called Markdown (Wikipedia)\n\nOther markup languages include html (webapges) and LaTeX (math)\nAll text formatting is specified via code\n‚ÄúMarkdown is a plain text format that is designed to be easy to write, and, even more importantly, easy to read‚Äù 1\n\nNewer versions of RStudio include a Visual editor as well that makes formatting text similar to using a word processor.\n\n\n\n\n\n\nFrom Quarto‚Äôs Markdown Basics webpage, https://quarto.org/docs/authoring/markdown-basics.html"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text-visual-editor",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text-visual-editor",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Formatting text: Visual editor",
    "text": "Formatting text: Visual editor\n\nUsing the Visual editor is similar to using a wordprocessor, such as Word\nKeyboard shortcuts usually work as well (shown for Mac below)"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#practice",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#practice",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Practice",
    "text": "Practice\n\nPart 1\n\nUsing the visual editor, practice formatting text in your qmd file, such as making text bold, italicized, and in code format.\nAdd 1st, 2nd, and 3rd level headers\nAdd a list with a\n\nsub-list (bullet and/or numbered)\n\nAdd a table\nAdd whatever else you are interested in!\n\nPart 2\n\nSwitch back to the Source editor and examine the markdown code that was used for the formatting.\n\n\nQuestions:\n\nWhat went smoothly?\nWhat hurdles did you encounter?"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#how-this-connects-to-homework-0",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#how-this-connects-to-homework-0",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "How this connects to Homework 0",
    "text": "How this connects to Homework 0\nEverything you practiced today is exactly what you need for HW 0:\n\nEditing text with Markdown\nCreating and running R code chunks\nSaving a .qmd file\nRendering to an .html file\n\nFor Homework 0, you will:\n\nStart from a provided .qmd template\nMake small edits\nRender successfully\nSubmit both the .qmd and .html"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text-markdown",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#formatting-text-markdown",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Formatting text: Markdown",
    "text": "Formatting text: Markdown\n\n\n\n\n\n\n\nMarkdown:\nOutput:\n\n\n\n\n*This text is in italics*, but _so is this text_.\nThis text is in italics, but so is this text.\n\n\n**Bold** also has __2 options__\nBold also has 2 options\n\n\n~~Should this be deleted?~~\nShould this be deleted?\n\n\nNeed^super^ or~sub~ scripts?\nNeedsuper orsub scripts?\n\n\n`Code is often formatted as verbatim`\nCode is often formatted as verbatim\n\n\n&gt;This is a block quote.\n\nThis is a block quote."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#headers",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#headers",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Headers",
    "text": "Headers\n\nOrganize your documents using headers to create sections and subsections\nUse # at the beginning of the line to create headers\n\n\n\nText in editor:\n\n\n\n\n\n\nOutput:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nMake sure there is no space before the #, and there IS a space after the # in order for the header to work properly."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#rstudio-tip",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#rstudio-tip",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "RStudio tip",
    "text": "RStudio tip\nYou can easily navigate through your .qmd file if you use headers to outline your text"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#code-chunks",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#code-chunks",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Code chunks",
    "text": "Code chunks\n\n\n.qmd file\n\n\n\n\n\n\n\n\n.html output"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#create-a-code-chunk",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#create-a-code-chunk",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Create a code chunk",
    "text": "Create a code chunk\nRecommended (fastest): keyboard shortcut\n\nMac: Command + Option + I\nWindows: Ctrl + Alt + I\n\n\nOther ways (if you forget the shortcut):\n\nClick the Insert Code Chunk button () at top right of the editor window\nIn the Visual editor: Insert ‚Üí Executable Cell ‚Üí R"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#what-does-a-code-chunk-look-like",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#what-does-a-code-chunk-look-like",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "What does a code chunk look like?",
    "text": "What does a code chunk look like?\nAn empty code chunk looks like this:\nVisual editor\n\nSource editor\n\n\n\n\n\n\n\nImportant\n\n\nNote that a code chunks start with ```{r} and ends with ```. Make sure there is no space before ```."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#enter-and-run-code-12",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#enter-and-run-code-12",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Enter and run code (1/2)",
    "text": "Enter and run code (1/2)\n\n\n1. Type R code inside a code chunk\n2. Run code (recommended): keyboard shortcut\n\nMac: Ctrl + Return\nWindows: Ctrl + Return\n\n\n\nOutput appears in the Console pane.\n\nOther ways to run code:\n\nPlace the cursor on a line and click the Run button ()\nHighlight multiple lines and choose Run Selected Line(s)"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#enter-and-run-code-22",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#enter-and-run-code-22",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Enter and run code (2/2)",
    "text": "Enter and run code (2/2)\n\n\nRun all code in a chunk by\n\nby clicking the play button in the top right corner of the chunk\n\nThe code output appears below the code chunk\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output should also appear in the Console.\nSettings can be changed so that the output appears only in the Console and not below the code chunk:\n\nSelect  (to right of Render button) and then Chunk Output in Console."
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#useful-keyboard-shortcuts",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#useful-keyboard-shortcuts",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "Useful keyboard shortcuts",
    "text": "Useful keyboard shortcuts\nFull list of keyboard shortcuts\n¬†\n\n\n\n\n\n\n\n\naction\nmac\nwindows/linux\n\n\n\n\nRun code in qmd (or script)\ncmd + enter\nctrl + enter\n\n\n&lt;-\noption + -\nalt + -\n\n\ninterrupt currently running command\nesc\nesc\n\n\nin console, retrieve previously run code\nup/down\nup/down\n\n\nkeyboard shortcut help\noption + shift + k\nalt + shift + k\n\n\n\n\n\nPractice\nTry typing code below in your qmd (with shortcut) and evaluating it:\n\ny &lt;- 5\ny"
  },
  {
    "objectID": "lessons/03_intro_to_r/03_intro_to_r.html#yaml-metadata",
    "href": "lessons/03_intro_to_r/03_intro_to_r.html#yaml-metadata",
    "title": "Introduction to R, RStudio, and Quarto",
    "section": "YAML metadata",
    "text": "YAML metadata\n\n\nThe block at the top controls document settings. We‚Äôll come back to it later. For now, don‚Äôt touch it.\n\n\n\nBMSC 620 | Intro to R, RStudio, and Quarto"
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. Overall, the material from our first week was reported as quite clear, which is great to hear. Below I address the main points that came up as muddy or unclear."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#thanks-for-the-feedback",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#thanks-for-the-feedback",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. Overall, the material from our first week was reported as quite clear, which is great to hear. Below I address the main points that came up as muddy or unclear."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#mean-vs.-standard-deviation-notation-barx-s-vs.-mu-sigma",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#mean-vs.-standard-deviation-notation-barx-s-vs.-mu-sigma",
    "title": "Muddy Points",
    "section": "1. Mean vs.¬†standard deviation notation (\\(\\bar{x}\\), \\(s\\) vs.¬†\\(\\mu\\), \\(\\sigma\\))",
    "text": "1. Mean vs.¬†standard deviation notation (\\(\\bar{x}\\), \\(s\\) vs.¬†\\(\\mu\\), \\(\\sigma\\))\nOne question that came up was why we sometimes use symbols like Œº and œÉ instead of xÃÑ (x-bar) and s, particularly when drawing or describing a normal curve.\nA helpful rule of thumb:\n\nxÃÑ (x-bar) and s are sample statistics ‚Äî they summarize data you actually observed.\nŒº (mu) and œÉ (sigma) are population parameters ‚Äî they describe an underlying population or theoretical distribution.\n\nWhen we draw a normal curve, we often label it with Œº and œÉ even if, in practice, we estimate those values using xÃÑ and s from data. This is just a convention and something we will revisit once we start formal inference.\nRelatedly, one person mentioned confusion about the ‚Äúsquared SD‚Äù:\n\nThe variance is the standard deviation squared.\nVariance has squared units, which is why we usually report the standard deviation instead."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#markdown-vs.-comments-in-.qmd-files",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#markdown-vs.-comments-in-.qmd-files",
    "title": "Muddy Points",
    "section": "2. Markdown vs.¬†comments in .qmd files",
    "text": "2. Markdown vs.¬†comments in .qmd files\nA few questions came up about when to use different symbols in Quarto files:\n\n# inside an R code chunk is a code comment (for humans, not output).\n&lt;!-- --&gt; is an HTML comment in the markdown text (also not shown in output).\n&gt; creates a block quote, which does appear in the rendered document.\n\nIn short: - Use comments (# or &lt;!-- --&gt;) for notes to yourself or graders. - Use block quotes (&gt;) when you want text to appear as part of the document."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#source-vs.-visual-editor",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#source-vs.-visual-editor",
    "title": "Muddy Points",
    "section": "3. Source vs.¬†Visual editor",
    "text": "3. Source vs.¬†Visual editor\nSome people weren‚Äôt sure why we would use the Source editor at this point.\nFor now, think of this as:\n\nVisual editor: helpful for getting started, especially if you‚Äôre new.\nSource editor: shows the underlying text and structure of the document.\n\nThey are just two ways of editing the same file. Over time, you may find that the Source editor gives you more control, but you are free to use whichever view feels more comfortable right now."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#is-.qmd-something-people-actually-use",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#is-.qmd-something-people-actually-use",
    "title": "Muddy Points",
    "section": "4. Is .qmd something people actually use?",
    "text": "4. Is .qmd something people actually use?\nYes ‚Äî documents that combine code, text, and output are very common in statistics and data analysis.\nSome people use: - Quarto (.qmd) - R Markdown (.Rmd) - Jupyter notebooks - Similar tools in Python or other languages\nWe are using Quarto in this course because it supports reproducible analysis and clear communication in one place. The skills you learn here will transfer easily to other tools."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#pace-and-in-class-practice",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#pace-and-in-class-practice",
    "title": "Muddy Points",
    "section": "5. Pace and in-class practice",
    "text": "5. Pace and in-class practice\nA small number of people mentioned that the R portion felt a little fast, especially for those completely new to R.\nThat is expected early on. The goal of in-class practice is exposure, not mastery in the moment. It‚Äôs okay if you don‚Äôt finish everything during class ‚Äî we‚Äôll continue to reinforce these ideas through homework and repeated use."
  },
  {
    "objectID": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#final-note",
    "href": "lessons/02_intro_to_data_cont/02_intro_to_data_cont_and_intro_to_r_muddy_points.html#final-note",
    "title": "Muddy Points",
    "section": "Final note",
    "text": "Final note\nIf something still feels muddy after this clarification, that‚Äôs okay. Many ideas in statistics (and in R) only become clear after you see them used multiple times.\nPlease keep using the post-class check-ins. They are genuinely helpful for guiding what we revisit or slow down on."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. The comments were thoughtful and specific, which is incredibly helpful for improving pacing and clarity.\nBelow I‚Äôve grouped the most common muddy points into a few themes and addressed each one."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#thanks-for-the-feedback",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#thanks-for-the-feedback",
    "title": "Muddy Points",
    "section": "",
    "text": "Thank you to everyone who submitted post-class feedback. The comments were thoughtful and specific, which is incredibly helpful for improving pacing and clarity.\nBelow I‚Äôve grouped the most common muddy points into a few themes and addressed each one."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#a-note-on-pacing",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#a-note-on-pacing",
    "title": "Muddy Points",
    "section": "A note on pacing",
    "text": "A note on pacing\nSeveral comments mentioned that the end of class felt rushed, particularly around functions, R packages, and libraries.\nI tried to cover too much in the final 15 minutes, and that made it hard to follow along, especially if you encountered any errors or needed to catch up.\n\nWhat the pacing feedback shows\nLooking at the post-class survey:\n\n53% felt the pace was about right\n33% felt it was slightly too fast\n13% felt it was slightly too slow\n\nThis tells me that while the overall pace worked for many of you, a significant portion found it too fast, especially toward the end.\n\n\nGoing forward\nI‚Äôll adjust by:\n\nLeaving more buffer time at the end of class rather than rushing to cover everything\nSlowing down when introducing new R functions\nGiving you more time to type along and troubleshoot errors as they come up\nBeing more intentional about what‚Äôs ‚Äúessential for now‚Äù vs.¬†‚Äúwe‚Äôll revisit this later‚Äù\n\nThe reality is that R has a learning curve, especially if you‚Äôre new to programming. Some of the functions we covered (like seq() or inspecting datasets) were meant as examples or reference material, not things you need to master immediately.\n\n\nWhat you can do\nIf the pace feels too fast:\n\nFocus on running the code and getting it to work, even if you don‚Äôt fully understand every detail yet\nUse the help system (?function_name) to review functions after class\nCome to office hours or reach out if something didn‚Äôt click\nRemember that we‚Äôll be using these same tools repeatedly, so you‚Äôll get more comfortable with practice\n\nThanks for the honest feedback. It helps me calibrate for future classes."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-does-quarto-sometimes-say-object-not-found-even-though-i-assigned-it",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-does-quarto-sometimes-say-object-not-found-even-though-i-assigned-it",
    "title": "Muddy Points",
    "section": "Why does Quarto sometimes say ‚Äúobject not found‚Äù even though I assigned it?",
    "text": "Why does Quarto sometimes say ‚Äúobject not found‚Äù even though I assigned it?\nSeveral people described seeing an error like:\nError: object 'x' not found\neven though the code that creates the object appears earlier in the Quarto document.\nThis usually happens because code chunks have not been run in order.\nKey points:\n\nAn object only exists if the chunk that creates it has actually been executed\nWriting code in a Quarto document does not automatically run it\nIf a later chunk runs before an earlier one, R will report ‚Äúobject not found‚Äù\nRestarting R or opening a new session clears all previously created objects\n\nWhen the error suddenly disappears, it is usually because:\n\nyou ran an earlier chunk\nyou rendered the document from the top\nor you ran all chunks in order"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#view-vs-view-in-r",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#view-vs-view-in-r",
    "title": "Muddy Points",
    "section": "View() vs view() in R",
    "text": "View() vs view() in R\nSeveral people ran into an error like:\nError in view(iris) : could not find function \"view\"\nThis happens because R is case-sensitive.\nIn R:\n\nView() (capital V) is a built-in RStudio function that opens a data viewer\nview() (lowercase v) does not exist, so R throws an error\n\nFor example:\n\nView(iris)   # works\nview(iris)   # error\n\nThis is a common early mistake and nothing to worry about. Many R functions rely on exact capitalization, so even small differences in case can cause errors.\nIf you see an error saying a function ‚Äúcould not be found,‚Äù one of the first things to check is whether the function name is spelled and capitalized correctly."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#understanding-function-arguments-the-seq-example",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#understanding-function-arguments-the-seq-example",
    "title": "Muddy Points",
    "section": "Understanding function arguments: the seq() example",
    "text": "Understanding function arguments: the seq() example\nOne muddy point was about understanding what from = 1, to = 12, by = 3 means in the seq() function.\nThis is actually a great question because it gets at how all R functions work, not just seq().\n\nWhat seq() does\nThe seq() function generates a sequence of numbers. For example:\n\nseq(from = 1, to = 12, by = 3)\n\n[1]  1  4  7 10\n\n\nThis creates a sequence that:\n\nStarts at 1 (from = 1)\nEnds at 12 (to = 12)\nIncreases by 3 each step (by = 3)\n\nSo you get: 1, 4, 7, 10\n\n\nArgument order doesn‚Äôt matter when you name them\nOne key point about R functions: when you name the arguments, the order doesn‚Äôt matter:\n\nseq(from = 1, to = 12, by = 3)\n\n[1]  1  4  7 10\n\nseq(by = 3, to = 12, from = 1)\n\n[1]  1  4  7 10\n\n\nBoth produce exactly the same result because R knows which value goes with which argument.\n\n\nWhen you don‚Äôt name them, argument order does matter\n\nseq(1, 12, 3)\n\n[1]  1  4  7 10\n\nseq(3, 12, 1)\n\n [1]  3  4  5  6  7  8  9 10 11 12\n\n\n\n\nHow to learn about any function\nThe most important takeaway: whenever you see a function you don‚Äôt recognize (or want to remember how it works), use the help system:\n\n?seq\n\nThis will show you:\n\nWhat arguments the function takes\nWhat each argument means\nExamples of how to use it\n\nThis works for any function in R. Get in the habit of typing ?function_name whenever you‚Äôre unsure.\n\n\nWhy I used seq() as an example\nI used seq() not because you need to memorize it for this class, but to illustrate how functions work in general: they take named inputs (arguments) and produce outputs. The specific function doesn‚Äôt matter as much as understanding that pattern."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-assign-objects-b---c310-instead-of-just-running-code",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-assign-objects-b---c310-instead-of-just-running-code",
    "title": "Muddy Points",
    "section": "Why assign objects (b <- c(3:10)) instead of just running code?",
    "text": "Why assign objects (b &lt;- c(3:10)) instead of just running code?\nThis was a great question and came up because I ran c(3:10) live in class.\nI used that line only to demonstrate what the c() function does, and to show that in this case it produces the same result as 3:10. It was not meant to be an example of analysis code you would normally write.\nIn general:\n\nc(3:10) creates a vector and prints it to the console\nb &lt;- c(3:10) creates the same vector and stores it so it can be reused later\n\nAssigning objects allows you to:\n\nreuse results\nbuild analyses step-by-step\ndebug your work\nwrite reproducible code\n\nIn practice, almost everything we do in R involves creating objects and then working with them. When you see code run without assignment, it is usually just for demonstration or quick inspection."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#inspecting-a-new-dataset-how-to-apply-this-to-your-own-data",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#inspecting-a-new-dataset-how-to-apply-this-to-your-own-data",
    "title": "Muddy Points",
    "section": "Inspecting a new dataset: how to apply this to your own data",
    "text": "Inspecting a new dataset: how to apply this to your own data\nOne comment noted that the dataset inspection portion felt unclear, especially in terms of how to apply it to a dataset of your own.\nThat‚Äôs completely understandable. The goal of those functions is not to memorize them, but to develop a consistent first step whenever you load or receive a new dataset.\nWhen you read in any dataset, a good default workflow is:\n\ndim(data)\nnames(data)\nstr(data)\nhead(data)\ntail(data)\n\nEach of these answers a different, important question:\n\ndim() ‚Äì How many rows and columns are there?\nnames() ‚Äì What are the variable (column) names?\nstr() ‚Äì What type of data is each variable (numeric, character, factor, etc.)?\nhead() / tail() ‚Äì What do the first or last few rows actually look like?\n\nTogether, these help you understand:\n\nwhat information you have\nhow variables are stored\nwhether the data look like you expect them to\n\nYou can think of this as the R equivalent of ‚Äúopening a spreadsheet and scrolling around,‚Äù but in a more systematic and reproducible way.\nGoing forward, when you work with your own datasets (for homework or projects), these should be the first things you run after importing data."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#proportion-tables-why-prop.tableirisspecies-gives-an-error",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#proportion-tables-why-prop.tableirisspecies-gives-an-error",
    "title": "Muddy Points",
    "section": "Proportion tables: why prop.table(iris$Species) gives an error",
    "text": "Proportion tables: why prop.table(iris$Species) gives an error\nOne question came up at the end of class about the following error:\nError in Summary.factor(‚Ä¶):\n'sum' not meaningful for factors\nThis happened when running:\n\nprop.table(iris$Species)\n\nThe key issue is that prop.table() expects a table as its input, not a raw column or vector.\nYou can see this in the help file:\n\n?prop.table\n\nThe first argument to prop.table() should be a table of counts, which is usually created with table().\nFor example:\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\ncreates a table of counts for each species. Then:\n\nprop.table(table(iris$Species))\n\n\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\n\ncomputes the proportions.\nWhen you run:\n\nprop.table(iris$Species)\n\nR tries to treat the factor as if it were numeric and attempts to compute sums internally, which leads to the error:\n'sum' not meaningful for factors\nSo the fix is not about changing the data, but about giving the function the type of object it expects.\nA good general pattern to remember is:\n\nFirst, create a table of counts with table()\nThen, compute proportions with prop.table()"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-nest-functions-like-prop.tabletablex",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#why-nest-functions-like-prop.tabletablex",
    "title": "Muddy Points",
    "section": "Why nest functions like prop.table(table(x))?",
    "text": "Why nest functions like prop.table(table(x))?\nOne question was: ‚ÄúWhy are the nested table functions necessary? Is there a cleaner way to code this?‚Äù\nThis is a great question about R‚Äôs design philosophy.\n\nWhy the nesting is necessary\nEach function does one specific job:\n\ntable() creates a frequency table (counts)\nprop.table() converts counts to proportions\n\nR‚Äôs approach is to have many small, focused functions that do one thing well, rather than fewer functions that try to do everything.\nSo to get proportions, you need:\n\nFirst, count the frequencies: table(x)\nThen, convert to proportions: prop.table(table(x))\n\n\n\nIs there a cleaner way?\nYou could save the intermediate step to make it more readable:\n\n# Option 1: nested (what we've been doing)\nprop.table(table(iris$Species))\n\n# Option 2: save intermediate step\nspecies_counts &lt;- table(iris$Species)\nspecies_props &lt;- prop.table(species_counts)\nspecies_props\n\nOption 2 is more verbose but can be easier to read and debug, especially when you‚Äôre learning.\n\n\nThe tidyverse approach\nLater in the course, we‚Äôll learn the dplyr package, which has functions that work differently and can feel more intuitive:\n\nlibrary(dplyr)\n\niris %&gt;%\n  count(Species) %&gt;%\n  mutate(proportion = n / sum(n))\n\nThis reads more like English: ‚Äútake iris, count by Species, then calculate proportions.‚Äù\n\n\nFor now\nThe table() and prop.table() approach is the base R way and is worth learning because:\n\nIt works without any packages\nIt‚Äôs widely used\nUnderstanding it helps you understand R‚Äôs function design\n\nBut I hear you that the nesting can feel awkward. We‚Äôll see other approaches as the course progresses."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#marginal-vs.-conditional-distributions",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#marginal-vs.-conditional-distributions",
    "title": "Muddy Points",
    "section": "Marginal vs.¬†Conditional Distributions",
    "text": "Marginal vs.¬†Conditional Distributions\nOne muddy point was about the difference between marginal and conditional distributions.\nThis is a really important distinction, so let‚Äôs break it down with a concrete example.\n\nA Simple Example: Gender and Smoking Status\nImagine we have data on 100 people, classified by gender and smoking status:\n\n# Create example data\nsmoking_data &lt;- matrix(c(15, 35, 25, 25), \n                       nrow = 2,\n                       dimnames = list(\n                         Gender = c(\"Male\", \"Female\"),\n                         Smoker = c(\"Yes\", \"No\")\n                       ))\nsmoking_data\n\n        Smoker\nGender   Yes No\n  Male    15 25\n  Female  35 25\n\n\n\n\nMarginal Distribution: Looking at ONE variable\nMarginal distributions answer questions like: ‚ÄúWhat proportion of our sample is male?‚Äù or ‚ÄúWhat proportion smokes?‚Äù\nYou get these by summing across rows or columns:\n\n# Marginal distribution for Gender (sum across columns)\nrowSums(smoking_data)\n\n  Male Female \n    40     60 \n\n# As proportions\nprop.table(rowSums(smoking_data))\n\n  Male Female \n   0.4    0.6 \n\n\nThis tells us: 40% of our sample is male, 60% is female. We‚Äôre ignoring smoking status entirely.\n\n# Marginal distribution for Smoker (sum across rows)\ncolSums(smoking_data)\n\nYes  No \n 50  50 \n\n# As proportions\nprop.table(colSums(smoking_data))\n\nYes  No \n0.5 0.5 \n\n\nThis tells us: 50% of our sample smokes, 50% doesn‚Äôt. We‚Äôre ignoring gender entirely.\n\n\nConditional Distribution: Looking at relationships\nConditional distributions answer questions like: ‚ÄúAmong males, what proportion smokes?‚Äù or ‚ÄúAmong smokers, what proportion is male?‚Äù\nYou calculate these within a specific row or column:\n\n# Conditional distribution of smoking GIVEN gender\n# (proportions within each row)\nprop.table(smoking_data, margin = 1)\n\n        Smoker\nGender         Yes        No\n  Male   0.3750000 0.6250000\n  Female 0.5833333 0.4166667\n\n\nThis tells us:\n\nAmong males: 38% smoke, 63% don‚Äôt\nAmong females: 58% smoke, 42% don‚Äôt\n\nThis is P(Smoker | Gender) ‚Äî the probability of smoking given someone‚Äôs gender.\n\n\nThe Key Difference\n\nMarginal: What‚Äôs the overall distribution of one variable? (Ignores other variables)\nConditional: What‚Äôs the distribution of one variable within a specific group of another variable? (Shows relationships)\n\n\n\nWhy This Matters\nConditional distributions let you see if variables are related:\n\nIf smoking rates are the same for males and females, gender and smoking might be independent\nIf smoking rates differ by gender, there‚Äôs a relationship between these variables\n\nWe‚Äôll use this concept throughout the course when we talk about associations and relationships between variables."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#installing-packages-what-does-comment-it-out-mean",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#installing-packages-what-does-comment-it-out-mean",
    "title": "Muddy Points",
    "section": "Installing packages: what does ‚Äúcomment it out‚Äù mean?",
    "text": "Installing packages: what does ‚Äúcomment it out‚Äù mean?\nOne muddy point was about what I meant when I said to ‚Äúcode it out‚Äù after installing a package.\nI thought I said ‚Äúcomment it out‚Äù (at least I meant to), which is R terminology for turning code into a comment so it doesn‚Äôt run anymore.\n\nThe workflow for installing packages\nHere‚Äôs the typical workflow:\nStep 1: Install the package (only once)\nWhen you first need a package, you install it:\n\ninstall.packages(\"ggplot2\")\n\nStep 2: Comment it out after installation\nAfter the package is installed on your computer, you add a # at the beginning of that line to turn it into a comment:\n\n# install.packages(\"ggplot2\")\n\nThis way:\n\nThe code is still visible in your script (you remember what package you needed)\nBut it won‚Äôt run every time you run your script (since it‚Äôs already installed)\nIf someone else uses your script, they can see what packages are needed and uncomment it if needed\n\nStep 3: Load the package (every time)\nAt the top of your script, you load the package every time you use it:\n\nlibrary(ggplot2)\n\n\n\nWhy comment instead of delete?\nYou could delete the install.packages() line entirely, but commenting it out is often better because:\n\nIt documents what packages your script needs\nIf you share your script with someone else, they can see what to install\nIf you need to reinstall R or use a different computer, you have a record\n\n\n\nSummary\n\ninstall.packages() ‚Üí run once, then comment out with #\nlibrary() ‚Üí include at the top of every script, runs every time\n\nSorry for any confusion with my wording in class!"
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#package-conflicts-how-often-is-this-a-problem",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#package-conflicts-how-often-is-this-a-problem",
    "title": "Muddy Points",
    "section": "Package conflicts: how often is this a problem?",
    "text": "Package conflicts: how often is this a problem?\nOne question was: ‚ÄúHow often will it be a problem installing R packages that break other R packages?‚Äù\nGood news: this is rare in practice, especially with the packages we‚Äôll use in this course.\n\nWhen conflicts happen\nThe most common ‚Äúconflict‚Äù you‚Äôll see isn‚Äôt packages breaking each other, but rather two packages having functions with the same name. For example:\n\nlibrary(dplyr)\nlibrary(MASS)\n\nBoth packages have a function called select(). When you load both, R will warn you:\nThe following object is masked from 'package:dplyr':\n    select\nThis means the select() from the package loaded second (MASS) will be used by default.\n\n\nHow to handle this\nIf you need a specific version of a function, you can specify the package explicitly:\n\ndplyr::select()  # uses dplyr's version\nMASS::select()   # uses MASS's version\n\n\n\nBottom line\n\nTrue package incompatibility (where one package actually breaks another) is uncommon\nFunction name conflicts are more common but easy to manage\nR will warn you when conflicts occur\nFor this course, the packages we use are all compatible with each other\n\nDon‚Äôt worry about this as you‚Äôre getting started. If a conflict comes up, we‚Äôll address it together."
  },
  {
    "objectID": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#working-directories-and-file-locations",
    "href": "lessons/04_categorical_data_and_tables/03_categorical_data_and_r_basics_muddy_points.html#working-directories-and-file-locations",
    "title": "Muddy Points",
    "section": "Working directories and file locations",
    "text": "Working directories and file locations\nQuestions came up about:\n\nwhat your working directory is\nhow it differs from where files are saved\nwhy errors appear when setting directories\n\nWe‚Äôll cover this more carefully soon, especially once we start importing data and working with multiple files.\nWhen working with a Quarto document (.qmd) like in the homework, your working directory will be wherever you have the .qmd saved and RStudio should produce the .html file there. For what we‚Äôve been learning in R you shouldn‚Äôt have to worry about working directories yet.\nWe‚Äôll cover this more once we start importing data and working with multiple files."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#roadmap-for-today",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#roadmap-for-today",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Roadmap for Today",
    "text": "Roadmap for Today\n\n\nPart 1: From CIs to Hypothesis Tests\n\nReview: CIs answer ‚Äúwhat are plausible values?‚Äù\nNew question: ‚ÄúIs a specific value plausible?‚Äù\nThe logic of hypothesis testing\n\nPart 2: Hypothesis Testing Framework\n\nNull and alternative hypotheses\nSignificance level (\\(\\alpha\\))\nTest statistics\nP-values\n\n\nPart 3: One-Sample t-Tests\n\nWhen to use a one-sample t-test\nCalculating the t-statistic\nInterpreting p-values\nMaking conclusions\n\nPart 4: Conducting Tests in R\n\nUsing t.test() function\nInterpreting R output\nConnecting CIs and hypothesis tests\n\nPart 5: Wrap-up\n\nCommon mistakes\nBest practices"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#review-what-we-learned-last-time",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#review-what-we-learned-last-time",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Review: What we learned last time",
    "text": "Review: What we learned last time\nLast time we learned about confidence intervals:\n\nA 95% CI gives us a range of plausible values for \\(\\mu\\)\nIt‚Äôs based on sample data: \\(\\bar{x} \\pm t^* \\times \\frac{s}{\\sqrt{n}}\\)\nInterpretation: ‚ÄúWe are 95% confident that \\(\\mu\\) is in this interval‚Äù\n\n\n\nExample from last time:\nSample of 50 adults: \\(\\bar{x} = 66.1\\) inches, \\(s = 3.5\\) inches\n95% CI: (65.12, 67.08)\nConclusion: We‚Äôre 95% confident the population mean height is between 65.12 and 67.08 inches."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#a-different-kind-of-question",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#a-different-kind-of-question",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "A different kind of question",
    "text": "A different kind of question\nCIs answer: ‚ÄúWhat are plausible values for \\(\\mu\\)?‚Äù\n\n\nBut sometimes we want to know: ‚ÄúIs a specific value plausible?‚Äù\n\n\n\n\nCI approach:\n\nCalculate interval (65.12, 67.08)\nSee if our value of interest is in it\nIf 66 inches is in the interval ‚Üí plausible\nIf 70 inches is NOT in the interval ‚Üí implausible\n\n\nHypothesis test approach:\n\nStart with a specific claim about \\(\\mu\\)\nUse our data to evaluate evidence against that claim\nGet a number (p-value) that quantifies the strength of evidence\n\n\n\n\nBoth approaches use the same underlying statistics - just framed differently!\nIn fact, for two-sided tests, a hypothesis test at \\(\\alpha = 0.05\\) will always agree with a 95% confidence interval."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#motivating-example-body-temperature",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#motivating-example-body-temperature",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Motivating example: Body temperature",
    "text": "Motivating example: Body temperature\nThe traditional claim: Average human body temperature is 98.6¬∞F\n\n\nHistorical context:\n\nGerman physician Carl Wunderlich established 98.6¬∞F in 1851\nBased on 25,000 patients in Leipzig, Germany\nThis value has been used for over 170 years\n\n\n\nRecent evidence suggests it might be lower:\n\n1992 JAMA study: sample mean = 98.25¬∞F (n = 130, s = 0.733)\nMore recent studies suggest even lower (around 97.9¬∞F)\n\n\n\n\n\n\nResearch Question\n\n\nBased on the 1992 data, is there evidence that the population mean body temperature is different from 98.6¬∞F?"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#two-approaches-to-answer-this-question",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#two-approaches-to-answer-this-question",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Two approaches to answer this question",
    "text": "Two approaches to answer this question\n\n\n\n\n\nApproach 1: Confidence Interval\n\n\nQuestion: Is 98.6¬∞F a plausible value?\n\n\nMethod:\n\nCalculate 95% CI for \\(\\mu\\)\nSee if 98.6 falls in the interval\n\n\n\nWhat we get:\n\nA range of plausible values\nYes/no answer: ‚ÄúIs 98.6 plausible?‚Äù\n\n\n\n\n\n\n\n\nApproach 2: Hypothesis Test\n\n\nQuestion: How strong is evidence against 98.6¬∞F?\n\n\nMethod:\n\nAssume \\(\\mu = 98.6\\) is true\nCalculate how unusual our data is\nGet a p-value\n\n\n\nWhat we get:\n\nStrength of evidence against 98.6\nCan compare to different values\n\n\n\n\n\nKey point: Both use the same math, different framing!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#approach-1-using-a-confidence-interval",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#approach-1-using-a-confidence-interval",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Approach 1: Using a confidence interval",
    "text": "Approach 1: Using a confidence interval\nFrom our data: \\(\\bar{x} = 98.25\\), \\(s = 0.733\\), \\(n = 130\\)\n\n\n\n# Calculate 95% CI\nn &lt;- 130\nxbar &lt;- 98.25\ns &lt;- 0.733\n\nt_star &lt;- qt(0.975, df = n - 1)\nSE &lt;- s / sqrt(n)\n\nlower &lt;- xbar - t_star * SE\nupper &lt;- xbar + t_star * SE\n\nc(lower, upper)\n\n[1] 98.1228 98.3772\n\n\n\n\nConclusion: We are 95% confident that the (population) mean body temperature is between 98.12¬∞F and 98.38¬∞F, which is discernibly different than 98.6¬∞F.\n\n\n98.6¬∞F is NOT in this interval, so it‚Äôs not a plausible value for the population mean. There‚Äôs evidence the true mean is lower than 98.6¬∞F."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-the-ci-approach",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-the-ci-approach",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Visualizing the CI approach",
    "text": "Visualizing the CI approach\n\nThe claimed value (98.6¬∞F) falls outside our confidence interval - this suggests it‚Äôs not plausible."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-logic-of-hypothesis-testing",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-logic-of-hypothesis-testing",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "The logic of hypothesis testing",
    "text": "The logic of hypothesis testing\n\n\n\n\nStart with an assumption (the null hypothesis)\n\n‚ÄúThe population mean is 98.6¬∞F‚Äù\n\nCollect data and see if it‚Äôs consistent with that assumption\n\nWe observed \\(\\bar{x} = 98.25¬∞F\\)\n\nAsk: ‚ÄúIf the assumption were true, how unusual would our data be?‚Äù\n\nThis gives us the p-value\n\nIf our data would be very unusual under the assumption\n\nWe have evidence against the assumption\nWe reject the null hypothesis\n\n\n\n\nAnalogy: Like a jury trial - we assume innocence (null hypothesis) unless evidence is strong enough to reject it."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#what-is-random-here-revisited",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#what-is-random-here-revisited",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "What is random here? (Revisited)",
    "text": "What is random here? (Revisited)\nRemember from our sampling distribution lecture:\n\n\nIf the null hypothesis is true (\\(\\mu = 98.6\\)):\n\nThe population has mean \\(\\mu = 98.6\\)\nOur sample is random\nOur sample mean \\(\\bar{x}\\) is random\n\\(\\bar{x}\\) has a sampling distribution centered at 98.6\n\n\n\nThe hypothesis test asks:\n‚ÄúGiven that the sampling distribution is centered at 98.6, how likely is it to get a sample mean as extreme as 98.25 (or more extreme)?‚Äù\n\n\nIf that‚Äôs very unlikely ‚Üí evidence against the null hypothesis"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-1-state-the-hypotheses",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-1-state-the-hypotheses",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 1: State the hypotheses",
    "text": "Step 1: State the hypotheses\nEvery hypothesis test has two competing hypotheses:\n\n\n\nNull Hypothesis (\\(H_0\\))\n\n\nThe null hypothesis is the status quo or claim of ‚Äúno effect/no difference‚Äù\n\nUsually states that a parameter equals a specific value\nWhat we assume is true unless we have strong evidence against it\nFor our example: \\(H_0: \\mu = 98.6\\)\n\n\n\n\n\n\n\n\n\nAlternative Hypothesis (\\(H_A\\))\n\n\nThe alternative hypothesis is what the researcher wants to show\n\nClaims the parameter is different from (or greater/less than) the null value\nWhat we conclude if we have sufficient evidence\nFor our example: \\(H_A: \\mu \\neq 98.6\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#writing-hypotheses-symbols-and-words",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#writing-hypotheses-symbols-and-words",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Writing hypotheses: Symbols and words",
    "text": "Writing hypotheses: Symbols and words\nFor our body temperature example:\n\n\nIn symbols:\n\\[H_0: \\mu = 98.6\\] \\[H_A: \\mu \\neq 98.6\\]\n\n\nIn words:\n\n\\(H_0\\): The population mean body temperature is 98.6¬∞F\n\\(H_A\\): The population mean body temperature is not 98.6¬∞F\n\n\n\nKey points:\n\nThe null hypothesis uses = (equals sign)\nThe alternative uses \\(\\neq\\), \\(&gt;\\), or \\(&lt;\\)\nWe call 98.6 the ‚Äúnull value‚Äù and often write it as \\(\\mu_0\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#one-sided-vs.-two-sided-alternatives",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#one-sided-vs.-two-sided-alternatives",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "One-sided vs.¬†two-sided alternatives",
    "text": "One-sided vs.¬†two-sided alternatives\nThe alternative hypothesis can take three forms:\n\n\n\n\n\n\n\nTwo-sided\n\n\n\\[H_A: \\mu \\neq \\mu_0\\]\nUse when: You don‚Äôt have a prior belief about direction\nExample: Is the mean different from 98.6?\nMost conservative and common\n\n\n\n\n\n\n\nOne-sided (greater)\n\n\n\\[H_A: \\mu &gt; \\mu_0\\]\nUse when: You only care if it‚Äôs higher\nExample: Is the mean greater than 98.6?\nLess common\n\n\n\n\n\n\n\nOne-sided (less)\n\n\n\\[H_A: \\mu &lt; \\mu_0\\]\nUse when: You only care if it‚Äôs lower\nExample: Is the mean less than 98.6?\nLess common\n\n\n\n\n\n\nDefault: Use two-sided unless you have a strong reason to be one-sided\nImportantly, the choice of one- vs two-sided must be made before seeing the data ‚Äî not after."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-2-set-the-significance-level-alpha",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-2-set-the-significance-level-alpha",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 2: Set the significance level (\\(\\alpha\\))",
    "text": "Step 2: Set the significance level (\\(\\alpha\\))\nBefore collecting data, we decide our threshold for ‚Äústrong evidence‚Äù\n\n\n\n\n\nSignificance Level (\\(\\alpha\\))\n\n\nThe significance level is the threshold below which we‚Äôll reject \\(H_0\\)\n\nMost common: \\(\\alpha = 0.05\\) (5%)\nMeans we‚Äôre willing to wrongly reject \\(H_0\\) at most 5% of the time\n\nIf \\(H_0\\) were true and we repeated this study many times, about 5% of those studies would lead us to reject it just by chance\n\nConnected to confidence level: \\(\\alpha = 1 - \\text{confidence level}\\)\n\n\n\n\nCommon choices:\n\n\\(\\alpha = 0.05\\) (95% confidence) - most common\n\\(\\alpha = 0.01\\) (99% confidence) - more stringent\n\\(\\alpha = 0.10\\) (90% confidence) - more lenient\n\n\n\nFor our example: We‚Äôll use \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-3-check-assumptions",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-3-check-assumptions",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 3: Check assumptions",
    "text": "Step 3: Check assumptions\nBefore conducting any hypothesis test, verify the assumptions:\nFor a one-sample t-test:\n\nIndependence: Observations are independent of each other\n\nRandom sampling helps ensure this\n\nNormality or large sample:\n\nData are approximately normally distributed, OR\nSample size is large (\\(n \\geq 30\\)) so we can use CLT\n\n\n\n\nFor our body temperature example:\n\n‚úì Sample of 130 individuals (presumably independent)\n‚úì \\(n = 130 \\geq 30\\), so CLT applies\nWe can proceed with the test!\n\n\n\n\nImportant\n\n\nIf assumptions are violated, the test may not be valid. Consider non-parametric alternatives."
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-4-calculate-the-test-statistic",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-4-calculate-the-test-statistic",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 4: Calculate the test statistic",
    "text": "Step 4: Calculate the test statistic\nThe test statistic measures how far our sample mean is from the null value, in standard error units.\n\n\n\nt-statistic formula\n\n\n\\[t = \\frac{\\bar{x} - \\mu_0}{SE} = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\]\nwhere:\n\n\\(\\bar{x}\\) = sample mean\n\\(\\mu_0\\) = null value (from \\(H_0\\))\n\\(s\\) = sample standard deviation\n\\(n\\) = sample size\n\n\n\n\n\n\nInterpretation:\n\n\\(t\\) tells us how many standard errors \\(\\bar{x}\\) is from \\(\\mu_0\\)\nLarge absolute values of \\(t\\) ‚Üí strong evidence against \\(H_0\\)\nUnder \\(H_0\\), \\(t\\) follows a t-distribution with \\(df = n - 1\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#calculating-the-t-statistic-example",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#calculating-the-t-statistic-example",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Calculating the t-statistic: Example",
    "text": "Calculating the t-statistic: Example\n\n\nFor our body temperature data:\n\n\\(\\bar{x} = 98.25\\)\n\\(\\mu_0 = 98.6\\) (from \\(H_0\\))\n\\(s = 0.733\\)\n\\(n = 130\\)\n\n\n\n# Calculate t-statistic\nxbar &lt;- 98.25\nmu_0 &lt;- 98.6\ns &lt;- 0.733\nn &lt;- 130\n\nSE &lt;- s / sqrt(n)\nt_stat &lt;- (xbar - mu_0) / SE\n\nSE\n\n[1] 0.06428835\n\nt_stat\n\n[1] -5.444221\n\n\n\n\n\nInterpretation: Our sample mean is about 5.45 standard errors below the null value. This seems pretty far!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-the-test-statistic",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-the-test-statistic",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Visualizing the test statistic",
    "text": "Visualizing the test statistic\n\nOur observed t-statistic is way out in the tail - this will lead to a small p-value!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-5-calculate-the-p-value-12",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-5-calculate-the-p-value-12",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 5: Calculate the p-value (1/2)",
    "text": "Step 5: Calculate the p-value (1/2)\n\n\n\nWhat is a p-value?\n\n\nThe p-value is the probability of observing a test statistic as extreme as (or more extreme than) what we actually observed, assuming \\(H_0\\) is true.\n\n\n\n\n\nFor a two-sided test: We care about both tails\n\\[\\text{p-value} = P(|T| \\geq |t_{observed}| \\mid H_0 \\text{ is true})\\]\nWhere:\n\n\\(T\\) = a randomly chosen t-statistic from the null distribution\n\\(t_{observed}\\) = the t-statistic computed from our sample\n\n\n\nIn plain language:\n‚ÄúGiven the null hypothesis is true, what‚Äôs the probability of getting a sample mean at least as far from \\(\\mu_0\\) as ours?‚Äù"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-5-calculate-the-p-value-22",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-5-calculate-the-p-value-22",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 5: Calculate the p-value (2/2)",
    "text": "Step 5: Calculate the p-value (2/2)\nIn R:\nFor a two-sided hypothesis test, the p-value is the probability of seeing a test statistic at least as far from zero as the one we observed, in either direction. So we\n\nTake the absolute value of the t-statistic (distance from zero),\nFind the probability of being that far out in one tail,\nMultiply by 2 to account for both tails.\n\n\n# Calculate t-statistic\nxbar &lt;- 98.25\nmu_0 &lt;- 98.6\ns &lt;- 0.733\nn &lt;- 130\n\nSE &lt;- s / sqrt(n)\nt_stat &lt;- (xbar - mu_0) / SE\n\n# Calculate p-value (two-sided)\np_value &lt;- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)\np_value\n\n[1] 2.530265e-07"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#interpreting-p-values",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#interpreting-p-values",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Interpreting p-values",
    "text": "Interpreting p-values\n\n\n\nP-value interpretation guidelines\n\n\n\n\nSmall p-value (&lt; \\(\\alpha\\)):\n\nOur data would be very unusual if \\(H_0\\) were true\nStrong evidence against \\(H_0\\)\nWe reject \\(H_0\\)\n\n\nLarge p-value (‚â• \\(\\alpha\\)):\n\nOur data are not that unusual if \\(H_0\\) were true\nInsufficient evidence against \\(H_0\\)\nWe fail to reject \\(H_0\\) (we don‚Äôt say ‚Äúaccept‚Äù!)\n\n\n\n\n\n\n\nFor our example:\n\np-value \\(\\approx\\) 0.0000003 (very small!)\nThis is way less than \\(\\alpha = 0.05\\)\nWe reject \\(H_0\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#common-p-value-misconceptions",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#common-p-value-misconceptions",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Common p-value misconceptions",
    "text": "Common p-value misconceptions\n\n\n\nWhat p-values ARE NOT\n\n\nWRONG: ‚ÄúThe probability that \\(H_0\\) is true‚Äù\n\n\\(H_0\\) is either true or false (not a probability)\nP-value assumes \\(H_0\\) IS true\n\nWRONG: ‚ÄúThe probability of making a mistake by rejecting \\(H_0\\)‚Äù\n\nThat‚Äôs the significance level \\(\\alpha\\) (set in advance)\nP-value is calculated from data\n\nWRONG: ‚ÄúThe effect size or importance‚Äù\n\nSmall p-value just means ‚Äúunusual under \\(H_0\\)‚Äù\nDoesn‚Äôt tell you if the difference matters practically\n\n\n\n\n\n\nCORRECT: P-value = ‚ÄúHow surprising is our data if \\(H_0\\) were true?‚Äù"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-6-make-a-conclusion",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#step-6-make-a-conclusion",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Step 6: Make a conclusion",
    "text": "Step 6: Make a conclusion\nDecision rule:\n\nIf p-value &lt; \\(\\alpha\\): Reject \\(H_0\\)\nIf p-value ‚â• \\(\\alpha\\): Fail to reject \\(H_0\\)\n\n\n\nFor our example:\np-value \\(\\approx\\) 0.0000003 &lt; 0.05, so we reject \\(H_0\\)\n\n\nFormal conclusion:\n‚ÄúAt the \\(\\alpha\\) = 0.05 significance level, we reject the null hypothesis. There is statistically significant evidence that the population mean body temperature is different from 98.6¬∞F.‚Äù\n\n\nContextual conclusion:\n‚ÄúBased on this sample of 130 individuals, the data provide strong evidence that the average human body temperature is not 98.6¬∞F. The sample suggests the true average is closer to 98.25¬∞F.‚Äù"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-t.test-function",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-t.test-function",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "The t.test() function",
    "text": "The t.test() function\nR makes hypothesis testing easy with the t.test() function:\n\n\n\nt.test(x, mu = 0, alternative = \"two.sided\", conf.level = 0.95)\n\n\n\nKey arguments:\n\nx = vector of data (or formula)\nmu = null value (\\(\\mu_0\\))\nalternative = ‚Äútwo.sided‚Äù, ‚Äúless‚Äù, or ‚Äúgreater‚Äù\nconf.level = confidence level (default 0.95)\n\n\n\nFor our example (using summary statistics):\nWe don‚Äôt have the raw data, but we can work with what we have‚Ä¶"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#manual-calculation-with-summary-statistics",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#manual-calculation-with-summary-statistics",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Manual calculation with summary statistics",
    "text": "Manual calculation with summary statistics\nWhen you only have summary statistics (not raw data), you can still test:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Our summary statistics\nxbar &lt;- 98.25\ns &lt;- 0.733\nn &lt;- 130\nmu_0 &lt;- 98.6\n\n# Calculate t-statistic\nt_stat &lt;- (xbar - mu_0) / (s / sqrt(n))\nt_stat\n\n[1] -5.444221\n\n# Calculate p-value (two-sided)\np_value &lt;- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)\np_value\n\n[1] 2.530265e-07\n\n# Calculate 95% CI\nt_crit &lt;- qt(0.975, df = n - 1)\nci &lt;- c(xbar - t_crit * (s / sqrt(n)),\n        xbar + t_crit * (s / sqrt(n)))\nci\n\n[1] 98.1228 98.3772"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#example-with-raw-data",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#example-with-raw-data",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Example with raw data",
    "text": "Example with raw data\nLet‚Äôs use the full body temperature dataset:\n\n# Load the data\n# See ?readr::read_csv\nbodytemp &lt;- readr::read_csv(here::here(\"data\", \n                                       \"BodyTemperatures.csv\"))\n\n# See ?janitor::clean_names\nbodytemp &lt;- bodytemp |&gt; \n  janitor::clean_names()\n\n# Look at the data\ndplyr::glimpse(bodytemp)\n\nRows: 130\nColumns: 3\n$ temperature &lt;dbl&gt; 96.3, 96.7, 96.9, 97.0, 97.1, 97.1, 97.1, 97.2, 97.3, 97.4‚Ä¶\n$ gender      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ heart_rate  &lt;dbl&gt; 70, 71, 74, 80, 73, 75, 82, 64, 69, 70, 68, 72, 78, 70, 75‚Ä¶"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#conducting-the-t-test-in-r",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#conducting-the-t-test-in-r",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Conducting the t-test in R",
    "text": "Conducting the t-test in R\n\n# Perform one-sample t-test\n# H0: mu = 98.6 vs HA: mu != 98.6\ntest_result &lt;- t.test(bodytemp$temperature, \n                      mu = 98.6, \n                      alternative = \"two.sided\")\n\n# Display results\ntest_result\n\n\n    One Sample t-test\n\ndata:  bodytemp$temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#understanding-the-r-output",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#understanding-the-r-output",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Understanding the R output",
    "text": "Understanding the R output\n\n\n\n    One Sample t-test\n\ndata:  bodytemp$temperature\nt = -5.4548, df = 129, p-value = 2.411e-07\nalternative hypothesis: true mean is not equal to 98.6\n95 percent confidence interval:\n 98.12200 98.37646\nsample estimates:\nmean of x \n 98.24923 \n\n\nLet‚Äôs break down what R tells us:\nt.test() output includes:\n\nt-statistic: how many SEs away from \\(\\mu_0\\)\ndegrees of freedom: \\(n - 1\\)\np-value: probability of seeing this (or more extreme) if \\(H_0\\) true\nconfidence interval: 95% CI for \\(\\mu\\)\nsample estimate: our sample mean"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#interpreting-our-results",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#interpreting-our-results",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Interpreting our results",
    "text": "Interpreting our results\n\n\nFrom our output:\n\n\\(t = -5.45\\)\n\\(df = 129\\)\np-value &lt; 0.0001\n95% CI: (98.12, 98.38)\n\\(\\bar{x} = 98.25\\)\n\n\nWhat this means:\n\nSample mean is 5.45 SEs below 98.6\nVery strong evidence against \\(H_0\\)\nWe‚Äôre 95% confident the true mean is between 98.12 and 98.38\nBoth approaches agree: 98.6 is not plausible"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#using-the-broom-package-for-tidy-output",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#using-the-broom-package-for-tidy-output",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Using the broom package for tidy output",
    "text": "Using the broom package for tidy output\nThe broom package makes output easier to work with:\n\nlibrary(broom)\n\n# Tidy the output\ntidy_result &lt;- tidy(test_result)\ntidy_result\n\n# A tibble: 1 √ó 8\n  estimate statistic     p.value parameter conf.low conf.high method alternative\n     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      \n1     98.2     -5.45 0.000000241       129     98.1      98.4 One S‚Ä¶ two.sided  \n\n# Now it's a nice tibble we can manipulate\ntidy_result %&gt;%\n  select(estimate, statistic, p.value, conf.low, conf.high)\n\n# A tibble: 1 √ó 5\n  estimate statistic     p.value conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     98.2     -5.45 0.000000241     98.1      98.4\n\n\n\n\nThis is especially useful when running multiple tests or creating tables!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#using-rstatix",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#using-rstatix",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Using rstatix",
    "text": "Using rstatix\n\nlibrary(rstatix)\n\nt_test(data = bodytemp, \n       temperature ~ 1, \n       mu = 98.6, \n       conf.level = 0.95, \n       detailed = TRUE)\n\n# A tibble: 1 √ó 12\n  estimate .y.    group1 group2     n statistic       p    df conf.low conf.high\n*    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     98.2 tempe‚Ä¶ 1      null ‚Ä¶   130     -5.45 2.41e-7   129     98.1      98.4\n# ‚Ñπ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-our-test",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#visualizing-our-test",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Visualizing our test",
    "text": "Visualizing our test\nThis plot is descriptive ‚Äî the hypothesis test is not based on the histogram, but on the sampling distribution of the mean"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#connection-between-cis-and-hypothesis-tests",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#connection-between-cis-and-hypothesis-tests",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Connection between CIs and hypothesis tests",
    "text": "Connection between CIs and hypothesis tests\n\n\n\nKey relationship\n\n\nFor a two-sided test at significance level \\(\\alpha\\):\n\n\nIf the \\((1-\\alpha)√ó100\\%\\) CI does NOT contain \\(\\mu_0\\):\n‚Üí We reject \\(H_0\\) at level \\(\\alpha\\)\n\nIf the \\((1-\\alpha)√ó100\\%\\) CI DOES contain \\(\\mu_0\\):\n‚Üí We fail to reject \\(H_0\\) at level \\(\\alpha\\)\n\n\n\n\n\n\nFor our example:\n\n95% CI: (98.12, 98.38)\nDoes NOT contain 98.6\nSo we reject \\(H_0\\) at \\(\\alpha\\) = 0.05\nThis matches our p-value &lt; 0.05 conclusion\n\n\n\nThey‚Äôre two ways of saying the same thing!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#common-mistakes-to-avoid",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#common-mistakes-to-avoid",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Common mistakes to avoid",
    "text": "Common mistakes to avoid\n\n\n\nMistake 1: ‚ÄúAccepting‚Äù the null hypothesis\n\n\nWRONG: ‚ÄúWe accept \\(H_0\\)‚Äù\nCORRECT: ‚ÄúWe fail to reject \\(H_0\\)‚Äù\nWhy? Absence of evidence ‚â† evidence of absence. We never ‚Äúprove‚Äù \\(H_0\\) true.\n\n\n\n\n\n\n\n\nMistake 2: Confusing practical and statistical significance\n\n\nSmall p-value = statistically significant (unusual under \\(H_0\\))\nBUT doesn‚Äôt mean the effect is large or important!\nWith large \\(n\\), even tiny differences can be ‚Äúsignificant‚Äù"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#more-common-mistakes",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#more-common-mistakes",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "More common mistakes",
    "text": "More common mistakes\n\n\n\nMistake 3: P-hacking\n\n\nDON‚ÄôT:\n\nRun multiple tests and only report significant ones\nTry different cutoffs until you get p &lt; 0.05\nAdd data until you get significance\n\nThis inflates Type I error rate!\n\n\n\n\n\n\nMistake 4: Ignoring assumptions\n\n\nAlways check:\n\nIndependence of observations\nSample size or normality\nNo extreme outliers (for small samples)\n\nIf violated, results may not be trustworthy"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#best-practices-for-hypothesis-testing",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#best-practices-for-hypothesis-testing",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Best practices for hypothesis testing",
    "text": "Best practices for hypothesis testing\n\n\n\n\nBefore collecting data:\n\nState your hypotheses clearly\nChoose your significance level (\\(\\alpha\\))\nDetermine your sample size\nPlan your analysis\n\n\n\nAfter collecting data:\n\nCheck assumptions\nCalculate test statistic and p-value\nMake a decision (reject or fail to reject)\nState conclusion in context\nReport confidence interval too!\n\n\nAlways:\n\nBe transparent about your methods\nReport exact p-values (not just ‚Äú&lt; 0.05‚Äù)\nDiscuss practical significance, not just statistical"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#reporting-your-results",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#reporting-your-results",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Reporting your results",
    "text": "Reporting your results\nGood statistical reporting includes:\n\nDescriptive statistics: \\(\\bar{x}\\), \\(s\\), \\(n\\)\nTest details: Which test, hypotheses, \\(\\alpha\\) level\nResults: Test statistic, df, p-value\nConfidence interval: Gives effect size estimate\nConclusion in context: What does it mean?\n\n\n\nExample:\n‚ÄúA one-sample t-test was conducted to determine if mean body temperature differs from 98.6¬∞F. The sample (n = 130) had a mean of 98.25¬∞F (SD = 0.733). The test was statistically significant (t(129) = -5.45, p &lt; 0.001, 95% CI: [98.12 to 98.38]), indicating that population mean body temperature is likely lower than the traditional 98.6¬∞F value.‚Äù\nOr\n‚ÄúThere is strong evidence (p &lt; 0.001) suggesting the population mean body temperature is no longer 98.6¬∞F (one-sample t-test). The recent data estimate mean body temperature to be 98.25¬∞F (95% CI: 98.12 to 98.38).‚Äù"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#what-we-learned-today",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#what-we-learned-today",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "What we learned today",
    "text": "What we learned today\nConceptual understanding:\n\nHypothesis tests evaluate evidence against a claim (\\(H_0\\))\nP-values measure ‚Äúhow surprising‚Äù our data are if \\(H_0\\) is true\nSmall p-value ‚Üí reject \\(H_0\\), large p-value ‚Üí fail to reject \\(H_0\\)\nHypothesis tests and CIs are two sides of the same coin\n\n\n\nTechnical skills:\n\nState null and alternative hypotheses\nCalculate t-statistics and p-values\nUse t.test() in R\nInterpret output correctly\nConnect CIs and hypothesis tests"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-six-steps-of-hypothesis-testing",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#the-six-steps-of-hypothesis-testing",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "The six steps of hypothesis testing",
    "text": "The six steps of hypothesis testing\n\nState hypotheses (\\(H_0\\) and \\(H_A\\))\nSet significance level (usually \\(\\alpha\\) = 0.05)\nCheck assumptions (independence, normality/large n)\nCalculate test statistic (\\(t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\\))\nFind p-value (probability of seeing this or more extreme)\nMake conclusion (reject or fail to reject \\(H_0\\), with context)\n\n\n\nRemember: The p-value is NOT the probability that \\(H_0\\) is true!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#key-formulas-for-reference",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#key-formulas-for-reference",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Key formulas for reference",
    "text": "Key formulas for reference\nTest statistic:\n\\[t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\\]\n\n\nDegrees of freedom:\n\\[df = n - 1\\]\n\n\nDecision rule:\n\nIf p-value &lt; ‚Üí Reject \\(H_0\\)\nIf p-value ‚â• ‚Üí Fail to reject \\(H_0\\)\n\n\n\nConnection to CI:\n\nIf \\((1-\\alpha)√ó100\\%\\) CI excludes \\(\\mu_0\\) ‚Üí Reject \\(H_0\\)\nIf \\((1-\\alpha)√ó100\\%\\) CI includes \\(\\mu_0\\) ‚Üí Fail to reject \\(H_0\\)"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#looking-ahead",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#looking-ahead",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "Looking ahead",
    "text": "Looking ahead\nNext time:\n\nPaired t-tests (dependent samples)\nTwo-sample t-tests (independent samples)\nMore hypothesis testing practice\n\n\n\nFor now:\n\nPractice stating hypotheses correctly\nGet comfortable with p-value interpretation\nWork on connecting CIs and hypothesis tests\nUse R to conduct tests\n\n\n\n\n\n\nRemember\n\n\nStatistical significance (p &lt; 0.05) doesn‚Äôt automatically mean practical importance. Always think about the context and effect size!"
  },
  {
    "objectID": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#whats-next",
    "href": "lessons/12_hypothesis_testing/12_hypothesis_testing.html#whats-next",
    "title": "Hypothesis Testing: Concepts and One-Sample t-Tests",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nCI‚Äôs and hypothesis testing for different scenarios:\n\n\n\n\n\n\n\n\n\n\n\nDay\nSection\nPopulation parameter\nSymbol\nPoint estimate\nSymbol\n\n\n\n\n9\n5.1\nPopulation mean\n\\(\\mu\\)\nSample mean\n\\(\\bar{x}\\)\n\n\n10\n5.2\nPopulation mean of paired differences\n\\(\\mu_d\\) or \\(\\delta\\)\nSample mean of paired differences\n\\(\\bar{x}_{d}\\)\n\n\n10\n5.3\nDifferences in population means\n\\(\\mu_1-\\mu_2\\)\nDifferences in sample means\n\\(\\bar{x}_1 - \\bar{x}_2\\)\n\n\n13\n8.1\nPopulation proportion\n\\(p\\)\nSample proportions\n\\(\\widehat{p}\\)\n\n\n14\n8.2\nDifferences in population proportions\n\\(p_1-p_2\\)\nDifferences in sample proportions\n\\(\\widehat{p}_1-\\widehat{p}_2\\)\n\n\n\n\n\n\nBMSC 620 | Hypothesis Testing"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#learning-objectives-today",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#learning-objectives-today",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Learning objectives (today)",
    "text": "Learning objectives (today)\nBy the end of class, you should be able to:\n\nDefine and distinguish a target population and a sample\nDescribe common sampling methods and why bias can happen\nCompare experiments vs observational studies (and what each can conclude)"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#why-we-care-about-study-design",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#why-we-care-about-study-design",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Why we care about study design",
    "text": "Why we care about study design\n\nStatistics helps answer questions with data.\nBut the design determines what the data can support:\n\nWho is included?\nHow are they selected?\nWhat kind of study is it?\nWhat comparisons are valid?\n\n\nThese decisions determine what conclusions we can (and cannot) draw."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#data-collection-principles-1.3",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#data-collection-principles-1.3",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Data collection principles (1.3)",
    "text": "Data collection principles (1.3)\n\nPopulation vs.¬†sample\nSampling methods\nExperiments vs.¬†Observational studies"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#population-vs.-sample",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#population-vs.-sample",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Population vs.¬†sample",
    "text": "Population vs.¬†sample\n\n\n(Target) Population\n\nGroup of interest being studied\nGroup from which the sample is selected\n\nstudies often have inclusion and/or exclusion criteria\n\nAlmost always too expensive or logistically impossible to collect data for every case in a population\n\n\n\nSample\n\nGroup on which data are collected\nA subset (of measurements) from the population\n\n\n\nWe use information from a sample to learn about the population from which it was drawn."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-14",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-14",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Sampling methods (1/4)",
    "text": "Sampling methods (1/4)\nA good sampling method produces a representative sample: one whose characteristics are similar to those of the population.\n\n\nSimple random sample (SRS)\n\nEach individual of a population has the same chance of being sampled\nRandomly sampled\nConsidered best way to sample\n\n\n\n\n\n\n\n\n\nConvenience sample\n\nEasily accessible individuals are more likely to be included in the sample than other individuals\nConsidered a common ‚Äúpitfall‚Äù"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-24-reality-check",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-24-reality-check",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Sampling methods (2/4): Reality check",
    "text": "Sampling methods (2/4): Reality check\nEven good sampling plans don‚Äôt guarantee representative samples\n\n\nNon-response bias\n\nNon-response rates can be high\nAre all groups within a population being reached?\nUnrepresentative sample\n\nCan lead to skewed results\n\n\n\n\n\n\n\n\n‚ÄúRandom‚Äù samples can be unrepresentative by random chance\n\nIn a SRS each case in the population has an equal chance of being included in the sample\nBut by random chance alone a random sample might contain a higher proportion of one group over another\nEx: a SRS might by chance include 70% men (unlikely, but theoretically possible)"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-34",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-34",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Sampling methods (3/4)",
    "text": "Sampling methods (3/4)\n\n\n\nSimple random sample (SRS)\n\nEach individual of a population has the same chance of being sampled\nStatistical methods taught in this class assume a SRS!\n\nStratified sampling\n\nDivide population into groups (strata) before selecting cases within each stratum (often via SRS)\nUsually cases within a strata are similar, but are different from other strata with respect to the outcome of interest, such as gender or age groups"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-44",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#sampling-methods-44",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Sampling methods (4/4)",
    "text": "Sampling methods (4/4)\n\n\n\nCluster sample\n\nFirst divide population into groups (clusters)\nThen sample a fixed number of clusters, and include all observations from chosen clusters\nClusters are often hospitals, clinicians, schools, etc., where each cluster will have similar services/ policies/ etc.\nCases within clusters usually very diverse\nExample: sample zip codes in Oregon, then include all households in the sampled zip codes.\n\nMultistage sample\n\nSimilar to a cluster sample, but randomly sample individuals within each selected cluster instead of including everyone\nExample: sample zip codes in Oregon, then randomly sample households in the zip codes (i.e.¬†include some households in the sampled zip codes)."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#two-basic-study-designs",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#two-basic-study-designs",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Two basic study designs",
    "text": "Two basic study designs\n\n\nExperiment\nResearchers directly influence how data arise\n\nSuch as: assigning groups of individuals to different treatments and assessing how the outcome varies across treatment groups\nThree major parts to an experiment\n\nControl\nRandomization\nReplication\n\n\n\nObservational study\nResearchers merely observe and record data, without interfering with how the data arise\n\nFor example, to investigate why certain diseases develop, researchers might collect data by conducting surveys, reviewing medical records, or following a cohort of many similar individuals.\nOften the only available way to study your research question\n\nDue to ethical considerations, funds, or availability of data"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#experiments-12",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#experiments-12",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Experiments (1/2)",
    "text": "Experiments (1/2)\n\n\n\n\nControl\n\nResearchers limit variability by carefully selecting participants\nInclusion and exclusion criteria reduce the influence of extraneous variables\nHelps ensure the sample is appropriate and relevant to the research question\n\nRandomization\n\nGroup assignment is usually random to ensure similar (balanced) study arms for all variables (observed and unobserved)\nRandomization allows study arm differences in outcomes to be attributed to treatment rather than variability in patient characteristics\n\nTreatment is the only systematic difference between groups\nEstablish causality\n\nBlocking (stratification): group individuals into blocks (strata) before randomizing if there are certain characteristics that may influence the outcome other than treatment (i.e.¬†gender, age group)\nDifferent than random sampling: sampling decides who enters the study; randomization decides which treatment they receive"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#experiments-22",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#experiments-22",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Experiments (2/2)",
    "text": "Experiments (2/2)\n\nReplication\n\nAccomplished by collecting a sufficiently large sample\nResults usually more reliable with a large sample size\n\nOften less variability\nMore likely to be representative of population"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#observational-studies",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#observational-studies",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Observational studies",
    "text": "Observational studies\nSome research questions cannot be studied experimentally due to ethical, practical, or logistical constraints.\n\nData are observed and recorded without interference\n\nResearchers do not assign treatments or exposures\n\nOften done via surveys, electronic health records, or medical chart reviews\nAssociations between variables can be established, but not causality\n\nIndividuals with different characteristics may also differ in other ways that influence response\n\nConfounding variables (lurking variable)\n\nVariables associated with both the explanatory and response variables"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#observational-studies-prospective-vs.-retrospective-studies",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#observational-studies-prospective-vs.-retrospective-studies",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Observational studies: prospective vs.¬†retrospective studies",
    "text": "Observational studies: prospective vs.¬†retrospective studies\nMany observational studies follow cohorts ‚Äî groups of individuals observed over time.\n\n\n\nProspective\n\nIdentifies participants and collects information at scheduled times or as events unfold.\n\n\nRetrospective\n\nCollect data after events have taken place, such as from medical records\n\n\n¬†\nSome studies can have prospective and retrospective data.\nExample: The Cancer Care Outcomes Research and Surveillance Consortium (CanCORS) enrolled participants with lung or colorectal cancer, collected information about diagnosis, treatment, and previous health behavior (retrospective), but also maintained contact with participants to gather data about long-term outcomes (prospective)."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#comparing-study-designs",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#comparing-study-designs",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Comparing study designs",
    "text": "Comparing study designs\n\nScience Media Centre"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#systematic-reviews-example",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#systematic-reviews-example",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Systematic Reviews example",
    "text": "Systematic Reviews example\n\n\n\nSTEM: Systematically Testing the Evidence on Marijuana\n\n\n\n\n\nSTEM is a collaborative project between the US Department of Veterans Affairs and the Center for Evidence-based Policy at Oregon Health & Science University.\nThe project is funded by the US Department of Veterans Affairs: Office of Rural Health."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#from-study-design-to-data",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#from-study-design-to-data",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "From study design to data",
    "text": "From study design to data\nSo far, we‚Äôve focused on:\n\nhow studies are designed\n\nhow data are collected\n\nNow we shift to:\n\nwhat data look like once we have them\n\nhow data are stored and summarized"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#intro-to-data-1.2",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#intro-to-data-1.2",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Intro to Data (1.2)",
    "text": "Intro to Data (1.2)\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#a-first-look-at-data-in-r",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#a-first-look-at-data-in-r",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "A first look at data in R",
    "text": "A first look at data in R\n\nToday is about exposure, not mastery\nWe will revisit all of this slowly\nRight now: focus on concepts, not syntax"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#how-are-data-stored-how-do-we-use-them",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#how-are-data-stored-how-do-we-use-them",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "How are data stored, how do we use them?",
    "text": "How are data stored, how do we use them?\n\nOften, data are in an Excel sheet, or a plain text file (.csv, .txt)\n.csv files open in Excel automatically, but actually are plain text\nUsually, columns are variables/measures and rows are observations (i.e.¬†a person‚Äôs measurements)\n\nData in R\n\nWe can import data from many file types, including .csv, .txt., and .xlsx\n\nWe will cover this on a later date\n\nOnce imported, R typically stores data as data frames, or tibbles if using the tidyverse package (more on this later).\n\nFor our purposes, these are essentially the same, and I will tend to use the terms interchangeably.\nThese are examples of what we call object types in R."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#data-frame-example",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#data-frame-example",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Data frame example",
    "text": "Data frame example\n\n\n\ndf &lt;- data.frame(\n  IDs=1:3, \n  gender=c(\"male\", \"female\", \"Male\"), \n  age=c(28, 35.5, 31),\n  trt = c(\"control\", \"1\", \"1\"),\n  Veteran = c(FALSE, TRUE, TRUE)\n  )\ndf\n\n  IDs gender  age     trt Veteran\n1   1   male 28.0 control   FALSE\n2   2 female 35.5       1    TRUE\n3   3   Male 31.0       1    TRUE\n\n\n\nVectors vs.¬†data frames\n\na data frame is a collection (or array or table) of vectors\n\n\n\n\n\n\n\nDifferent columns can be of different data types (i.e.¬†numeric vs.¬†text)\nBoth numeric and text can be stored within a column (stored together as text).\nVectors and data frames are examples of objects in R.\n\nThere are other types of R objects to store data, such as matrices, lists."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#observations-variables",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#observations-variables",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Observations & variables",
    "text": "Observations & variables\n\n\n\ndf\n\n  IDs gender  age     trt Veteran\n1   1   male 28.0 control   FALSE\n2   2 female 35.5       1    TRUE\n3   3   Male 31.0       1    TRUE\n\n\n\n\n\nISLBS\n\n\n\n\n\nBook refers to a dataset as a data matrix\nRows are usually observations\nColumns are usually variables\nHow many observations are in this dataset?\nWhat are the variable types in this dataset?"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#variable-column-types",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#variable-column-types",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Variable (column) types",
    "text": "Variable (column) types\n\n\n\n\n\n\n\n\n\nR type\nvariable type\ndescription\n\n\n\n\ninteger\ndiscrete\ninteger-valued numbers\n\n\ndouble or numeric\ncontinuous\nnumbers that are decimals\n\n\nfactor\ncategorical\ncategorical variables stored with levels (groups)\n\n\ncharacter\ncategorical\ntext, ‚Äústrings‚Äù\n\n\nlogical\ncategorical\nboolean (TRUE, FALSE)\n\n\n\n\n\nView the structure of our data frame to see what the variable types are:\n\n\n\nstr(df)\n\n'data.frame':   3 obs. of  5 variables:\n $ IDs    : int  1 2 3\n $ gender : chr  \"male\" \"female\" \"Male\"\n $ age    : num  28 35.5 31\n $ trt    : chr  \"control\" \"1\" \"1\"\n $ Veteran: logi  FALSE TRUE TRUE"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#fishers-or-andersons-iris-data-set",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#fishers-or-andersons-iris-data-set",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Fisher‚Äôs (or Anderson‚Äôs) Iris data set",
    "text": "Fisher‚Äôs (or Anderson‚Äôs) Iris data set\nData description:\n\nn = 150\n3 species of Iris flowers (Setosa, Virginica, and Versicolour)\n\n50 measurements of each type of Iris\n\nvariables:\n\nsepal length, sepal width, petal length, petal width, and species\n\n\nCan the iris species be determined by these variables?\n\n\n\nGareth Duffy"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#view-the-iris-dataset",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#view-the-iris-dataset",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "View the iris dataset",
    "text": "View the iris dataset\n\n\nThe iris dataset is already pre-loaded in base R and ready to use.  \n\n\n\n\n\n\n\nView(iris)\n\n\nA new tab in the scripting window should appear with the iris dataset."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#data-structure",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#data-structure",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Data structure",
    "text": "Data structure\n\nWhat are the different variable types in this data set?\n\n\n\n\nstr(iris)   # structure of data\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#data-set-summary",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#data-set-summary",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Data set summary",
    "text": "Data set summary\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#data-set-info",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#data-set-info",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Data set info",
    "text": "Data set info\n\ndim(iris)\n\n[1] 150   5\n\nnrow(iris)\n\n[1] 150\n\nncol(iris)\n\n[1] 5\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\""
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#view-the-beginning-or-end-of-a-dataset",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#view-the-beginning-or-end-of-a-dataset",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "View the beginning or end of a dataset",
    "text": "View the beginning or end of a dataset\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#specify-how-many-rows-to-view-at-beginning-or-end-of-a-dataset",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#specify-how-many-rows-to-view-at-beginning-or-end-of-a-dataset",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Specify how many rows to view at beginning or end of a dataset",
    "text": "Specify how many rows to view at beginning or end of a dataset\n\nhead(iris, 3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\ntail(iris, 2)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#the",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#the",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "The $",
    "text": "The $\n\nSuppose we want to single out the column of petal width values.\nOne way to do this is to use the $\n\nDatSetName$VariableName\n\n\n\niris$Petal.Width\n\n  [1] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3\n [19] 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.2 0.2\n [37] 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3\n [55] 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3\n [73] 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3\n [91] 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8\n[109] 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8\n[127] 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3\n[145] 2.5 2.3 1.9 2.0 2.3 1.8"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#example-using-the",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#example-using-the",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Example using the $",
    "text": "Example using the $\nThe $ is helpful if you want to create a new dataset for just that one variable, or, more commonly, if you want to calculate summary statistics for that one variable.\n\n\n\nmean(iris$Petal.Width)\n\n[1] 1.199333\n\nsd(iris$Petal.Width)\n\n[1] 0.7622377\n\nmedian(iris$Petal.Width)\n\n[1] 1.3"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#inline-code",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#inline-code",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Inline code",
    "text": "Inline code\n\n\nWith markdown you can also report R code output inline with the text instead of using a chunk.\n\n\n\nText in editor:\n\n\n\n\n\n\nOutput:\nThe mean petal width for all 3 species combined is 1.2 (SD = 0.8) cm.\n\n\nReporting summary statistics this way in a report, makes the numbers computationally reproducible.\nFor example, if this were for an abstract and a year later you are wondering where the numbers came from, your R code will tell you exactly which dataset was used to calculate the values."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#table-1-example",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#table-1-example",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Table 1 example",
    "text": "Table 1 example\n\n\n\n\n\n\n\n\nAre We on the Same Page?: A Cross-Sectional Study of Patient-Clinician Goal Concordance in Rheumatoid Arthritis\nJ Barton et al.\nArthritis Care & Research.\n2021 Sep 27 https://pubmed.ncbi.nlm.nih.gov/34569172/"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mean",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mean",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of center: mean",
    "text": "Measures of center: mean\n\nSample mean: the average value of observations\n\\[\\bar{x} = \\frac{x_1+x_2+\\cdots+x_n}{n} = \\sum_{i=1}^{n}\\frac{x_i}{n}\\]\nwhere \\(x_1, x_2, \\ldots, x_n\\) represent the \\(n\\) observed values in a sample\n\n\nExample: What is the mean age in the toy dataset df defined earlier?\n\n\ndf\n\n  IDs gender  age     trt Veteran\n1   1   male 28.0 control   FALSE\n2   2 female 35.5       1    TRUE\n3   3   Male 31.0       1    TRUE\n\nmean(df$age)\n\n[1] 31.5"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-median",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-median",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of center: median",
    "text": "Measures of center: median\n\n\nThe median is the middle value of the observations in a sample.\nThe median is the 50th percentile, meaning\n\n50% of observations lie below and\n50% of observations lie above the median.\n\n\n\n\n\n\n\nIf the number of observations is\n\nodd: the median is the middle observed value\neven: the median is the average of the two middle observed values\n\n\n\n\n\ndf$age\n\n[1] 28.0 35.5 31.0\n\nmedian(df$age)\n\n[1] 31\n\nmedian(c(df$age, 67))\n\n[1] 33.25"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mean-vs.-median",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mean-vs.-median",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of center: mean vs.¬†median",
    "text": "Measures of center: mean vs.¬†median\n\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mode",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-center-mode",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of center: mode",
    "text": "Measures of center: mode\nmode: the most frequent value in a dataset"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-standard-deviation-sd-13",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-standard-deviation-sd-13",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of spread: standard deviation (SD) (1/3)",
    "text": "Measures of spread: standard deviation (SD) (1/3)\nstandard deviation is (approximately) the average distance between a typical observation and the mean\n\nAn observation‚Äôs deviation is the distance between its value \\(x\\) and the sample mean \\(\\bar{x}\\): deviation = \\(x - \\bar{x}\\)."
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-sd-23",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-sd-23",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of spread: SD (2/3)",
    "text": "Measures of spread: SD (2/3)\n\nThe sample variance \\(s^2\\) is the sum of squared deviations divided by the number of observations minus 1.\n\n\\[\ns^2 =\n\\frac{(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 + \\cdots + (x_n - \\bar{x})^2}{n - 1}\n=\n\\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})^2}{n - 1}\n\\] where \\(x_1, x_2, \\dots, x_n\\) represent the \\(n\\) observed values.\n¬†\n\nThe standard deviation \\(s\\) (or \\(sd\\)) is the square root of the variance.\n\n\\[\ns\n= \\sqrt{s^2}\n= \\sqrt{\\frac{1}{n - 1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\]"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-sd-33",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-sd-33",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of spread: SD (3/3)",
    "text": "Measures of spread: SD (3/3)\n\n\n\nLet‚Äôs calculate the sample standard deviation for our toy example\n\n\ndf$age\n\n[1] 28.0 35.5 31.0\n\n\n\n\nmean(df$age)\n\n[1] 31.5\n\nsd(df$age)\n\n[1] 3.774917\n\n\n\n\\(s = \\sqrt{\\sum_{i=1}^{n}\\frac{(x_i - \\bar{x})^2}{n-1}} =\\)"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#empirical-rule-one-way-to-think-about-the-sd-12",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#empirical-rule-one-way-to-think-about-the-sd-12",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Empirical Rule: one way to think about the SD (1/2)",
    "text": "Empirical Rule: one way to think about the SD (1/2)\n\n\n\nFor symmetric bell-shaped data, about\n\n68% of the data are within 1 SD of the mean\n95% of the data are within 2 SD‚Äôs of the mean\n99.7% of the data are within 3 SD‚Äôs of the mean\n\nThese percentages are based off of percentages of a true normal distribution.\n\n\n\n\nhttps://statistics-made-easy.com/empirical-rule/"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#empirical-rule-one-way-to-think-about-the-sd-22",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#empirical-rule-one-way-to-think-about-the-sd-22",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Empirical Rule: one way to think about the SD (2/2)",
    "text": "Empirical Rule: one way to think about the SD (2/2)\n\n\n\nhist(iris$Sepal.Width)\n\n\n\n\n\n\n\n\n\n\nmean(iris$Sepal.Width)\n\n[1] 3.057333\n\nsd(iris$Sepal.Width)\n\n[1] 0.4358663"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-interquartile-range-iqr-12",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-interquartile-range-iqr-12",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of spread: interquartile range (IQR) (1/2)",
    "text": "Measures of spread: interquartile range (IQR) (1/2)\nThe \\(p^{th}\\) percentile is the observation such that \\(p\\%\\) of the remaining observations fall below this observation.\n\nThe first quartile \\(Q_1\\) is the \\(25^{th}\\) percentile.\nThe second quartile \\(Q_2\\), i.e., the median, is the \\(50^{th}\\) percentile.\nThe third quartile \\(Q_3\\) is the \\(75^{th}\\) percentile.\n\nThe interquartile range (IQR) is the distance between the third and first quartiles. \\[IQR = Q_3 - Q_1\\]\n\nIQR is the width of the middle half of the data"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-iqr-22",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#measures-of-spread-iqr-22",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Measures of spread: IQR (2/2)",
    "text": "Measures of spread: IQR (2/2)\n5 number summary\n\nsummary(iris$Sepal.Width)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   2.800   3.000   3.057   3.300   4.400 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the IQR of the sepal widths?\n\nquantile(iris$Sepal.Width, c(.25, .75))\n\n25% 75% \n2.8 3.3 \n\ndiff(quantile(iris$Sepal.Width, c(.25, .75)))\n\n75% \n0.5 \n\nIQR(iris$Sepal.Width)\n\n[1] 0.5"
  },
  {
    "objectID": "lessons/01_intro_to_data/01_intro_to_data.html#robust-estimates",
    "href": "lessons/01_intro_to_data/01_intro_to_data.html#robust-estimates",
    "title": "Introduction to Data & Numerical Summaries",
    "section": "Robust estimates",
    "text": "Robust estimates\nSummary statistics are called robust estimates if extreme observations (outliers) have little effect on their values\n\n\n\nEstimate\nRobust?\n\n\n\n\nSample mean\n‚ùå\n\n\nMedian\n‚úÖ\n\n\nStandard deviation\n‚ùå\n\n\nIQR\n‚úÖ\n\n\nRange\n‚ùå\n\n\n\n\nFor samples with extreme values or skewed distributions, the median and IQR often provide a more stable summary of center and spread than the mean, standard deviation, or range.\nThe range depends only on the smallest and largest observations, so a single outlier can dramatically change its value.\n\n\n\n\nBMSC 620 | Intro to Data & Numerical Summaries"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Note\n\n\n\nYou do not need to read every section below. Each heading addresses a specific muddy point raised in class. Feel free to focus on the ones most relevant to you."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#overview",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#overview",
    "title": "Muddy Points",
    "section": "Overview",
    "text": "Overview\nThank you for your feedback on yesterday‚Äôs lecture! The pacing feedback was excellent - 93% felt it was ‚Äúabout right‚Äù and only 7% ‚Äúslightly too fast,‚Äù which tells me the pace is working well for most of you. I‚Äôll continue being mindful of pacing as we move forward.\nSeveral themes emerged from your muddy points. Let me address them:"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#the-about-in-probability-interpretations",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#the-about-in-probability-interpretations",
    "title": "Muddy Points",
    "section": "The ‚ÄúAbout‚Äù in Probability Interpretations",
    "text": "The ‚ÄúAbout‚Äù in Probability Interpretations\nThe Question:\n\n‚ÄúFor the blood pressure percentiles, all of the interpretations have statements like ‚Äò95% of men have DBP below about 99.7 mmHg.‚Äô Do you include the ‚Äòabout‚Äô because it‚Äôs rounded from the R output value? Would I say ‚Äò95% of men have DBP below 99.73824 mmHg‚Äô or is the ‚Äòabout‚Äô phrasing required by the actual mathematical formula?‚Äù\n\nThe Answer:\nGreat question! The ‚Äúabout‚Äù serves multiple purposes:\n\nReason 1: Acknowledging Model Uncertainty\nThe normal distribution is a model of reality, not reality itself. Real blood pressure distributions are only approximately normal. So when we say ‚Äúabout 99.7 mmHg,‚Äù we‚Äôre acknowledging that:\n\nThe model is an approximation\nReal biological data has natural variability\nThe exact cutoff is somewhat fuzzy\n\n\n\nReason 2: Practical Precision\nIn context, reporting ‚Äú99.73824 mmHg‚Äù implies false precision:\n\nBlood pressure is typically measured to the nearest whole number\nThe extra decimal places suggest more certainty than we actually have\n‚ÄúAbout 100 mmHg‚Äù or ‚Äúabout 99.7 mmHg‚Äù is more honest\n\n\n\nWhen to Use ‚ÄúAbout‚Äù\nUse ‚Äúabout‚Äù when:\n\nInterpreting real-world data (blood pressure, heights, test scores)\nRounding R output for readability\nThe context doesn‚Äôt demand exact precision\n\nYou can omit ‚Äúabout‚Äù when:\n\nThe problem asks for a precise calculation\nYou‚Äôre reporting the exact R output in a technical context\nThe value is exact by definition (like standardized z-scores)\n\nBottom line: Using ‚Äúabout‚Äù shows good statistical judgment. It acknowledges that models are approximations and that excessive precision can be misleading."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#pnorm-and-lower.tail",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#pnorm-and-lower.tail",
    "title": "Muddy Points",
    "section": "pnorm() and lower.tail",
    "text": "pnorm() and lower.tail\nThe Question:\n\n‚ÄúFor pnorm in R, is the ‚Äòlower.tail‚Äô automatically equal true if not included in the function?‚Äù\n\nThe Answer:\nYes! The default is lower.tail = TRUE.\n\nWhat This Means\n# These are equivalent:\npnorm(1.96)\npnorm(1.96, lower.tail = TRUE)\n# Both give P(Z ‚â§ 1.96) ‚âà 0.975\n\n\nWhen to Use lower.tail = FALSE\nUse this when you want the upper tail probability:\n# P(Z &gt; 1.96)\npnorm(1.96, lower.tail = FALSE)  # ‚âà 0.025\n\n\nVisual Guide\n\n\n\n\n\n\n\n\n\nPro tip: Instead of using lower.tail = FALSE, you can also use the relationship:\n# These are equivalent:\npnorm(1.96, lower.tail = FALSE)\n1 - pnorm(1.96)\nChoose whichever feels more intuitive to you!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#continuous-distributions-intervals-and-single-points",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#continuous-distributions-intervals-and-single-points",
    "title": "Muddy Points",
    "section": "Continuous Distributions: Intervals and Single Points",
    "text": "Continuous Distributions: Intervals and Single Points\nThe Question:\n\n‚ÄúWhy are intervals always inclusive on a continuous distribution? Why is probability of a single point at a continuous distribution always 0? When do you use ‚Äòlower.tail = FALSE‚Äô?‚Äù\n\nGreat Questions! Let me break these down:\n\nWhy is P(X = exact value) = 0?\nFor continuous distributions, there are infinitely many possible values in any interval.\nThink about height:\n\nWhat‚Äôs the probability someone is exactly 170.00000‚Ä¶ cm tall?\nNot 170.001 cm or 169.999 cm, but precisely 170?\n\nThe probability is essentially 0 because any single point is infinitesimal compared to the infinite continuum.\nImportant: This doesn‚Äôt mean it‚Äôs impossible; it just means the probability is so small (infinitely small) that it‚Äôs mathematically zero.\n\n\nWhy doesn‚Äôt it matter if we include endpoints?\nBecause P(X = exact value) = 0, these are all equivalent:\n# All of these give the SAME answer for continuous distributions:\npnorm(1.96) - pnorm(0)     # P(0 &lt; Z &lt; 1.96)\npnorm(1.96) - pnorm(0)     # P(0 ‚â§ Z ‚â§ 1.96)\npnorm(1.96) - pnorm(0)     # P(0 &lt; Z ‚â§ 1.96)\npnorm(1.96) - pnorm(0)     # P(0 ‚â§ Z &lt; 1.96)\nAdding or removing a single point (like including/excluding exactly 0 or exactly 1.96) doesn‚Äôt change the probability because each single point contributes 0.\n\n\nWhen to use lower.tail = FALSE\nAlready covered above, but the key is:\n\nlower.tail = TRUE (default): P(X ‚â§ value)\nlower.tail = FALSE: P(X &gt; value)"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#normal-approximation-vs.-exact-binomial",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#normal-approximation-vs.-exact-binomial",
    "title": "Muddy Points",
    "section": "Normal Approximation vs.¬†Exact Binomial",
    "text": "Normal Approximation vs.¬†Exact Binomial\nThe Question:\n\n‚ÄúWhy would you use normal approximation if you can use exact (binomial) and it‚Äôs more accurate and requires fewer lines of code?‚Äù\n\nExcellent question! Here‚Äôs why:\n\nHistorical Context\nThe normal approximation was developed before computers existed.\nWhen statisticians had to calculate probabilities by hand or using printed tables:\n\nComputing \\(\\binom{1000}{487}\\) was essentially impossible\nNormal tables were available in the back of every textbook\nThe approximation was much faster and ‚Äúgood enough‚Äù\n\n\n\nModern Practice\nToday, with R, you‚Äôre absolutely right:\n# Exact (better!)\npbinom(487, size = 1000, prob = 0.5)\n\n# Approximation (more work, less accurate)\npnorm(487.5, mean = 500, sd = sqrt(250))\nUse the exact binomial when you can!\n\n\nWhen Normal Approximation Still Matters\nThere are a few cases where we still use it:\n\nVery large n: When n is extremely large (n &gt; 10,000), even computers can struggle with exact binomial calculations, and the normal approximation works very well\nTheoretical understanding: It helps you understand the connection between discrete and continuous distributions - a key concept in statistics\nHistorical methods: Some older statistical techniques were built on normal approximations, and understanding them helps you read older research\nConceptual foundation: The Central Limit Theorem (coming soon!) relies on this same approximation idea\n\nBottom line: In practice, prefer the exact binomial. But understanding why the normal approximation works helps build your statistical intuition.\n\n\nSummary: Exact vs.¬†Normal Approximation (When to Use Which)\n\nExact Binomial\nUses the true binomial probability formula:\ndbinom(k, size = n, prob = p)  # P(X = k)\npbinom(k, size = n, prob = p)  # P(X ‚â§ k)\nAdvantages:\n\nCompletely accurate\nNo approximation error\nEasy in R\n\nDisadvantages:\n\nCan be slow for very large n\nWasn‚Äôt practical before computers\n\n\n\nNormal Approximation\nTreats the binomial as approximately normal when n is large:\n# Approximate a Binomial(n, p) with Normal(Œº = np, œÉ¬≤ = np(1-p))\npnorm(k + 0.5, mean = n*p, sd = sqrt(n*p*(1-p)))\nAdvantages:\n\nFast even for huge n\nConnects discrete and continuous ideas\n\nDisadvantages:\n\nLess accurate (especially for small n or extreme p)\nRequires continuity correction (the + 0.5)\nMore work in R\n\n\n\nWhen is the Approximation Good?\nRules of thumb:\n\nnp ‚â• 10 and n(1-p) ‚â• 10\n\nOr more conservatively:\n\nnp ‚â• 5 and n(1-p) ‚â• 5\n\nIf these conditions aren‚Äôt met, stick with the exact binomial!\n\n\nKey takeaway\nIn this course, use the exact binomial when possible.\nWe study the normal approximation to understand why it works and how discrete and continuous distributions connect."
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#outliers-in-normal-distributions",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#outliers-in-normal-distributions",
    "title": "Muddy Points",
    "section": "Outliers in Normal Distributions",
    "text": "Outliers in Normal Distributions\nThe Question:\n\n‚ÄúIn a boxplot we can call any observations that fall beyond 1.5x IQR (not standard deviation) above or below the 75th/25th percentile as outliers. In normal distributions given that 95% of observances fall within 2 SDs/ z-score of 2, can we call anything beyond 2 an outlier? Beyond 3 since these are considered ‚Äòvery rare‚Äô? Or is there a different metric that can be used?‚Äù\n\nGreat Connection to Make!\nThere‚Äôs some confusion here about boxplot rules vs.¬†z-scores, so let me clarify:\n\nBoxplot Rule (IQR Method)\nBoxplots define outliers as:\n\nBelow Q1 - 1.5√óIQR\nAbove Q3 + 1.5√óIQR\n\nThis is a data-driven rule that works for any distribution shape.\nNote: This is 1.5 times the interquartile range (IQR), not 1.5 standard deviations!\n\n\nZ-Score Method for Outliers\nFor normal distributions, common thresholds are:\n|z| &gt; 2: Somewhat unusual (about 5% of data falls here)\n\nNot necessarily ‚Äúoutliers‚Äù but worth noting\nThis is where roughly 95% of data falls within ¬±2 SD\n\n|z| &gt; 3: Very unusual (about 0.3% of data falls here)\n\nOften considered outliers\nThese are quite rare in truly normal data\n\n|z| &gt; 4: Extremely unusual (about 0.006% of data falls here)\n\nAlmost certainly outliers or errors\nVery rare in normal distributions\n\n\n\nWhich Method to Use?\nUse the z-score method when:\n\nYou‚Äôre confident the data is approximately normal\nYou want to identify unusually extreme values\nYou‚Äôre working with standardized scores\n\nUse the IQR method when:\n\nYou don‚Äôt know if the data is normal\nThe data might be skewed\nYou want a robust method that works for any distribution\n\nBottom line: There‚Äôs no single ‚Äúcorrect‚Äù threshold. In practice:\n\n|z| &gt; 3 is a reasonable outlier cutoff for normal data\nThe IQR method (boxplot rule) is more robust for unknown distributions\nAlways visualize your data and use domain knowledge!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#quick-refresher-on-binomial-distribution",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#quick-refresher-on-binomial-distribution",
    "title": "Muddy Points",
    "section": "Quick Refresher on Binomial Distribution",
    "text": "Quick Refresher on Binomial Distribution\nThe Request:\n\n‚ÄúI think the binomial distribution stuff relied a lot on previous knowledge so a quick refresher from Monday‚Äôs class would have been nice‚Äù\n\nFair point! Here‚Äôs a quick recap:\n\nWhat is a Binomial Random Variable?\nA binomial counts the number of successes in n independent trials, where:\n\nEach trial has only two outcomes (success/failure)\nProbability of success p is the same for every trial\nTrials are independent\n\nNotation: X ~ Binomial(n, p)\n\n\nKey R Functions\n# P(X = k): exactly k successes\ndbinom(k, size = n, prob = p)\n\n# P(X ‚â§ k): at most k successes  \npbinom(k, size = n, prob = p)\n\n# P(X &gt; k): more than k successes\npbinom(k, size = n, prob = p, lower.tail = FALSE)\n\n\nExample\n‚ÄúFlip a fair coin 10 times. What‚Äôs the probability of exactly 6 heads?‚Äù\ndbinom(6, size = 10, prob = 0.5)\nGoing forward, I‚Äôll make sure to include brief refreshers when building on previous material!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#deriving-equations-and-establishing-values",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#deriving-equations-and-establishing-values",
    "title": "Muddy Points",
    "section": "Deriving Equations and Establishing Values",
    "text": "Deriving Equations and Establishing Values\nThe Concern:\n\n‚ÄúDeriving the equations and how we established certain values was a little unclear.‚Äù\n\nMy Response:\nYou‚Äôre not expected to derive distribution formulas from scratch - that‚Äôs advanced probability theory.\nWhat matters is:\n\nRecognizing when to use each distribution (binomial for counting successes, normal for continuous measurements, Poisson for rare events)\nUnderstanding what the parameters mean (n and p for binomial, Œº and œÉ for normal, Œª for Poisson)\nUsing R correctly to calculate probabilities\nInterpreting results in context\n\nThe derivations are shown to give you insight into why the formulas work and to connect mathematical theory to practice - not because you need to reproduce them.\nIf specific derivations are still unclear, feel free to ask in office hours and I can walk through the intuition!"
  },
  {
    "objectID": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#questions",
    "href": "lessons/10_normal_poisson/10_normal_poisson_muddy_points.html#questions",
    "title": "Muddy Points",
    "section": "Questions?",
    "text": "Questions?\nIf anything is still muddy, please:\n\nCome to office hours\nAsk in class\n\nThanks for the thoughtful feedback! üìä"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#todays-plan",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#todays-plan",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Today‚Äôs plan",
    "text": "Today‚Äôs plan\n\nTools for exploratory data analysis (EDA)\nData wrangling with dplyr\nSummary tables with janitor and rstatix\nData visualization with ggplot2"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#what-is-exploratory-data-analysis",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#what-is-exploratory-data-analysis",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "What is exploratory data analysis?",
    "text": "What is exploratory data analysis?\nExploratory Data Analysis (EDA) is the process of:\n\nInspecting and summarizing data\nIdentifying patterns, outliers, and relationships\nUnderstanding the structure before formal analysis\n\n\n\nEDA helps answer questions like:\n\nWhat variables do I have?\nWhat does the distribution look like?\nAre there missing values?\nHow do variables relate to each other?"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-tidyverse-ecosystem",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-tidyverse-ecosystem",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The tidyverse ecosystem",
    "text": "The tidyverse ecosystem\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-tidyverse-philosophy",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-tidyverse-philosophy",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The tidyverse philosophy",
    "text": "The tidyverse philosophy\nThe tidyverse is a collection of R packages designed for data science.\n\n\n\n\nKey principles:\n\nConsistent syntax across packages\nFunctions designed to work together\nHuman-readable code\nWorks well with the pipe operator %&gt;%\n\n\n\n\nggplot2 - data visualisation\ndplyr - data manipulation\ntidyr - tidy data\nreadr - read rectangular data\npurrr - functional programming\ntibble - modern data frames\nstringr - string manipulation\nforcats - factors\nand many more ‚Ä¶"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#packages-for-eda",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#packages-for-eda",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Packages for EDA",
    "text": "Packages for EDA\n\n\nPackages we‚Äôll use today:\n\ndplyr - data manipulation\nggplot2 - visualization\njanitor - clean tables\nrstatix - summary statistics\nskimr - quick data summaries\n\n\n\nNot all from the tidyverse, but came after and follow the philosophy."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#tidy-data1",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#tidy-data1",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Tidy data1",
    "text": "Tidy data1\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nSource: R for Data Science. Grolemund and Wickham."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#todays-dataset-nhanes",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#todays-dataset-nhanes",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Today‚Äôs dataset: NHANES",
    "text": "Today‚Äôs dataset: NHANES\nNational Health and Nutrition Examination Survey (NHANES)\n\nCDC survey assessing health and nutritional status of adults and children in the US\nCombines interviews, physical examinations, and laboratory tests\nToday we‚Äôll use a sample of adult participants\n\n\n\nLoading the data:\n\nlibrary(oibiostat)\ndata(\"nhanes.samp.adult\")"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#first-look-at-the-data",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#first-look-at-the-data",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "First look at the data",
    "text": "First look at the data\nAlways start by getting a sense of what‚Äôs in your dataset.\n\n\n\n\nHow many rows and columns?\n\ndim(nhanes.samp.adult)\n\n[1] 135  76\n\n\nWhat are the variable names?\n\nnames(nhanes.samp.adult)\n\n [1] \"ID\"               \"SurveyYr\"         \"Gender\"           \"Age\"             \n [5] \"AgeDecade\"        \"AgeMonths\"        \"Race1\"            \"Race3\"           \n [9] \"Education\"        \"MaritalStatus\"    \"HHIncome\"         \"HHIncomeMid\"     \n[13] \"Poverty\"          \"HomeRooms\"        \"HomeOwn\"          \"Work\"            \n[17] \"Weight\"           \"Length\"           \"HeadCirc\"         \"Height\"          \n[21] \"BMI\"              \"BMICatUnder20yrs\" \"BMI_WHO\"          \"Pulse\"           \n[25] \"BPSysAve\"         \"BPDiaAve\"         \"BPSys1\"           \"BPDia1\"          \n[29] \"BPSys2\"           \"BPDia2\"           \"BPSys3\"           \"BPDia3\"          \n[33] \"Testosterone\"     \"DirectChol\"       \"TotChol\"          \"UrineVol1\"       \n[37] \"UrineFlow1\"       \"UrineVol2\"        \"UrineFlow2\"       \"Diabetes\"        \n[41] \"DiabetesAge\"      \"HealthGen\"        \"DaysPhysHlthBad\"  \"DaysMentHlthBad\" \n[45] \"LittleInterest\"   \"Depressed\"        \"nPregnancies\"     \"nBabies\"         \n[49] \"Age1stBaby\"       \"SleepHrsNight\"    \"SleepTrouble\"     \"PhysActive\"      \n[53] \"PhysActiveDays\"   \"TVHrsDay\"         \"CompHrsDay\"       \"TVHrsDayChild\"   \n[57] \"CompHrsDayChild\"  \"Alcohol12PlusYr\"  \"AlcoholDay\"       \"AlcoholYear\"     \n[61] \"SmokeNow\"         \"Smoke100\"         \"Smoke100n\"        \"SmokeAge\"        \n[65] \"Marijuana\"        \"AgeFirstMarij\"    \"RegularMarij\"     \"AgeRegMarij\"     \n[69] \"HardDrugs\"        \"SexEver\"          \"SexAge\"           \"SexNumPartnLife\" \n[73] \"SexNumPartYear\"   \"SameSex\"          \"SexOrientation\"   \"PregnantNow\"     \n\n\n\nWhat does the first few rows look like?\n\nhead(nhanes.samp.adult, 3)\n\n# A tibble: 3 √ó 76\n     ID SurveyYr Gender   Age AgeDecade AgeMonths Race1 Race3 Education   \n  &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;       \n1 63147 2011_12  male      41 \" 40-49\"         NA White White Some College\n2 57165 2009_10  male      48 \" 40-49\"        586 Black &lt;NA&gt;  High School \n3 69465 2011_12  female    50 \" 50-59\"         NA White White College Grad\n# ‚Ñπ 67 more variables: MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,\n#   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;, Work &lt;fct&gt;, Weight &lt;dbl&gt;,\n#   Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;, Height &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   BMICatUnder20yrs &lt;fct&gt;, BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,\n#   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;, BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;,\n#   BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;, Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;,\n#   TotChol &lt;dbl&gt;, UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;, ‚Ä¶"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#tibbles-tidyverse-data-frames",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#tibbles-tidyverse-data-frames",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Tibbles: tidyverse data frames",
    "text": "Tibbles: tidyverse data frames\nA tibble is the tidyverse version of a data frame.\n\nnhanes.samp.adult\n\n# A tibble: 135 √ó 76\n      ID SurveyYr Gender   Age AgeDecade AgeMonths Race1   Race3 Education     \n * &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;         \n 1 63147 2011_12  male      41 \" 40-49\"         NA White   White Some College  \n 2 57165 2009_10  male      48 \" 40-49\"        586 Black   &lt;NA&gt;  High School   \n 3 69465 2011_12  female    50 \" 50-59\"         NA White   White College Grad  \n 4 57313 2009_10  female    74 \" 70+\"          889 White   &lt;NA&gt;  College Grad  \n 5 56047 2009_10  female    27 \" 20-29\"        329 White   &lt;NA&gt;  9 - 11th Grade\n 6 57056 2009_10  male      26 \" 20-29\"        316 Mexican &lt;NA&gt;  High School   \n 7 54643 2009_10  female    41 \" 40-49\"        503 White   &lt;NA&gt;  College Grad  \n 8 53095 2009_10  female    52 \" 50-59\"        632 White   &lt;NA&gt;  9 - 11th Grade\n 9 67434 2011_12  male      56 \" 50-59\"         NA White   White College Grad  \n10 60273 2009_10  male      39 \" 30-39\"        472 Black   &lt;NA&gt;  9 - 11th Grade\n# ‚Ñπ 125 more rows\n# ‚Ñπ 67 more variables: MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,\n#   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;, Work &lt;fct&gt;, Weight &lt;dbl&gt;,\n#   Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;, Height &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   BMICatUnder20yrs &lt;fct&gt;, BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,\n#   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;, BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;,\n#   BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;, Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;, ‚Ä¶\n\n\n\n\nBenefits of tibbles:\n\nPrints only first 10 rows (doesn‚Äôt flood console)\nShows column types\nNever converts strings to factors automatically"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#glimpse---quick-data-structure",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#glimpse---quick-data-structure",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "glimpse() - quick data structure",
    "text": "glimpse() - quick data structure\n¬†\nglimpse() from the dplyr package shows you the structure of your data in a compact format.\n\nglimpse(nhanes.samp.adult)\n\nRows: 135\nColumns: 76\n$ ID               &lt;int&gt; 63147, 57165, 69465, 57313, 56047, 57056, 54643, 5309‚Ä¶\n$ SurveyYr         &lt;fct&gt; 2011_12, 2009_10, 2011_12, 2009_10, 2009_10, 2009_10,‚Ä¶\n$ Gender           &lt;fct&gt; male, male, female, female, female, male, female, fem‚Ä¶\n$ Age              &lt;int&gt; 41, 48, 50, 74, 27, 26, 41, 52, 56, 39, 32, 72, 35, 2‚Ä¶\n$ AgeDecade        &lt;fct&gt;  40-49,  40-49,  50-59,  70+,  20-29,  20-29,  40-49,‚Ä¶\n$ AgeMonths        &lt;int&gt; NA, 586, NA, 889, 329, 316, 503, 632, NA, 472, 391, 8‚Ä¶\n$ Race1            &lt;fct&gt; White, Black, White, White, White, Mexican, White, Wh‚Ä¶\n$ Race3            &lt;fct&gt; White, NA, White, NA, NA, NA, NA, NA, White, NA, NA, ‚Ä¶\n$ Education        &lt;fct&gt; Some College, High School, College Grad, College Grad‚Ä¶\n$ MaritalStatus    &lt;fct&gt; Married, Married, Divorced, Widowed, NeverMarried, Ne‚Ä¶\n$ HHIncome         &lt;fct&gt; 25000-34999, 25000-34999, 35000-44999, 45000-54999, 7‚Ä¶\n$ HHIncomeMid      &lt;int&gt; 30000, 30000, 40000, 50000, 87500, 12500, 60000, 2500‚Ä¶\n$ Poverty          &lt;dbl&gt; 1.41, 1.36, 2.16, 4.16, 3.51, 0.39, 2.33, 0.05, 5.00,‚Ä¶\n$ HomeRooms        &lt;int&gt; 6, 6, 10, 7, 7, 5, 9, 6, 7, 6, 4, 12, 6, 6, 8, 1, 5, ‚Ä¶\n$ HomeOwn          &lt;fct&gt; Own, Own, Own, Own, Own, Own, Own, Other, Own, Own, R‚Ä¶\n$ Work             &lt;fct&gt; NotWorking, NotWorking, NotWorking, NotWorking, Worki‚Ä¶\n$ Weight           &lt;dbl&gt; 106.8, 77.4, 70.5, 61.7, 70.3, 92.6, 55.6, 82.0, 88.2‚Ä¶\n$ Length           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ HeadCirc         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ Height           &lt;dbl&gt; 188.8, 168.2, 161.8, 158.1, 168.1, 165.8, 155.6, 156.‚Ä¶\n$ BMI              &lt;dbl&gt; 30.00, 27.36, 26.90, 24.68, 24.88, 33.69, 22.96, 33.5‚Ä¶\n$ BMICatUnder20yrs &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ BMI_WHO          &lt;fct&gt; NA, 25.0_to_29.9, 25.0_to_29.9, 18.5_to_24.9, 18.5_to‚Ä¶\n$ Pulse            &lt;int&gt; 88, 70, 76, 64, 74, 78, 82, 96, 44, 60, 72, 88, 66, 6‚Ä¶\n$ BPSysAve         &lt;int&gt; 112, 123, 152, 132, 107, 126, 111, 114, 137, 122, 124‚Ä¶\n$ BPDiaAve         &lt;int&gt; 76, 69, 103, 81, 58, 75, 76, 71, 77, 78, 89, 66, 66, ‚Ä¶\n$ BPSys1           &lt;int&gt; 114, 128, 144, 146, 106, 126, 116, 116, 134, 124, 128‚Ä¶\n$ BPDia1           &lt;int&gt; 78, 78, 104, 84, 62, 86, 72, 66, 78, 70, 94, 72, 62, ‚Ä¶\n$ BPSys2           &lt;int&gt; 114, 126, 150, 130, 108, 130, 112, 116, 140, 120, 124‚Ä¶\n$ BPDia2           &lt;int&gt; 76, 76, 106, 80, 52, 74, 76, 72, 76, 80, 90, 64, 66, ‚Ä¶\n$ BPSys3           &lt;int&gt; 110, 120, 154, 134, 106, 122, 110, 112, 134, 124, 124‚Ä¶\n$ BPDia3           &lt;int&gt; 76, 62, 100, 82, 64, 76, 76, 70, 78, 76, 88, 68, 66, ‚Ä¶\n$ Testosterone     &lt;dbl&gt; 390.16, NA, 8.17, NA, NA, NA, NA, NA, 327.89, NA, NA,‚Ä¶\n$ DirectChol       &lt;dbl&gt; 1.19, 1.22, 2.43, NA, 1.84, 1.40, 1.24, 1.60, 1.11, 0‚Ä¶\n$ TotChol          &lt;dbl&gt; 4.84, 3.75, 5.92, NA, 4.78, 6.96, 5.77, 6.03, 5.25, 5‚Ä¶\n$ UrineVol1        &lt;int&gt; 57, 49, 30, 33, 150, 100, 17, 56, 104, 272, 120, 29, ‚Ä¶\n$ UrineFlow1       &lt;dbl&gt; 0.074, 0.551, 1.304, 0.673, 0.342, 0.917, 0.283, 0.34‚Ä¶\n$ UrineVol2        &lt;int&gt; NA, NA, 114, 122, NA, NA, 61, NA, NA, NA, NA, 49, NA,‚Ä¶\n$ UrineFlow2       &lt;dbl&gt; NA, NA, 1.118, 1.220, NA, NA, 0.407, NA, NA, NA, NA, ‚Ä¶\n$ Diabetes         &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, Yes, No, No, ‚Ä¶\n$ DiabetesAge      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ HealthGen        &lt;fct&gt; Fair, Fair, Vgood, Vgood, Fair, Fair, Good, Fair, NA,‚Ä¶\n$ DaysPhysHlthBad  &lt;int&gt; 12, 20, 0, 0, 2, 0, 4, 0, NA, 0, 20, 2, 0, 2, NA, 7, ‚Ä¶\n$ DaysMentHlthBad  &lt;int&gt; 30, 30, 0, 0, 0, 0, 5, 5, NA, 0, 10, 0, 8, 3, NA, 14,‚Ä¶\n$ LittleInterest   &lt;fct&gt; Several, None, None, None, None, Several, Several, No‚Ä¶\n$ Depressed        &lt;fct&gt; Several, None, None, None, None, None, Several, Most,‚Ä¶\n$ nPregnancies     &lt;int&gt; NA, NA, 3, 3, 2, NA, 3, 2, NA, NA, 7, 3, NA, NA, NA, ‚Ä¶\n$ nBabies          &lt;int&gt; NA, NA, 3, 3, 2, NA, 3, 2, NA, NA, 2, 3, NA, NA, NA, ‚Ä¶\n$ Age1stBaby       &lt;int&gt; NA, NA, 27, 23, 17, NA, 31, 22, NA, NA, 23, 20, NA, N‚Ä¶\n$ SleepHrsNight    &lt;int&gt; 9, 3, 6, 6, 6, 6, 6, 4, 7, 4, 8, 8, 7, 6, 4, 4, 5, 8,‚Ä¶\n$ SleepTrouble     &lt;fct&gt; Yes, Yes, Yes, No, No, No, No, Yes, No, No, No, No, Y‚Ä¶\n$ PhysActive       &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, No, Yes, No, Yes, No, ‚Ä¶\n$ PhysActiveDays   &lt;int&gt; NA, 3, 4, 7, NA, NA, NA, NA, 4, NA, 3, NA, NA, NA, NA‚Ä¶\n$ TVHrsDay         &lt;fct&gt; 1_hr, NA, 1_hr, NA, NA, NA, NA, NA, 2_hr, NA, NA, NA,‚Ä¶\n$ CompHrsDay       &lt;fct&gt; 1_hr, NA, 1_hr, NA, NA, NA, NA, NA, More_4_hr, NA, NA‚Ä¶\n$ TVHrsDayChild    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ CompHrsDayChild  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ Alcohol12PlusYr  &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, NA, Yes, Yes, ‚Ä¶\n$ AlcoholDay       &lt;int&gt; 2, NA, 1, 1, 5, 12, 1, 12, NA, NA, NA, 1, 1, 11, NA, ‚Ä¶\n$ AlcoholYear      &lt;int&gt; 2, 0, 364, 52, 24, 168, 4, 364, NA, 0, 0, 4, 2, 52, N‚Ä¶\n$ SmokeNow         &lt;fct&gt; NA, No, NA, No, Yes, Yes, No, Yes, NA, NA, NA, NA, NA‚Ä¶\n$ Smoke100         &lt;fct&gt; No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, No, No, No,‚Ä¶\n$ Smoke100n        &lt;fct&gt; Non-Smoker, Smoker, Non-Smoker, Smoker, Smoker, Smoke‚Ä¶\n$ SmokeAge         &lt;int&gt; NA, 11, NA, 18, 14, 14, 10, 30, NA, NA, NA, NA, NA, N‚Ä¶\n$ Marijuana        &lt;fct&gt; Yes, Yes, No, NA, Yes, Yes, Yes, No, NA, No, Yes, NA,‚Ä¶\n$ AgeFirstMarij    &lt;int&gt; 16, 17, NA, NA, 11, 14, 11, NA, NA, NA, 17, NA, NA, 2‚Ä¶\n$ RegularMarij     &lt;fct&gt; No, Yes, No, NA, Yes, Yes, Yes, No, NA, No, Yes, NA, ‚Ä¶\n$ AgeRegMarij      &lt;int&gt; NA, 17, NA, NA, 16, 14, 11, NA, NA, NA, 20, NA, NA, N‚Ä¶\n$ HardDrugs        &lt;fct&gt; Yes, No, No, NA, No, Yes, No, No, NA, No, Yes, NA, No‚Ä¶\n$ SexEver          &lt;fct&gt; Yes, Yes, Yes, NA, Yes, Yes, Yes, Yes, NA, Yes, Yes, ‚Ä¶\n$ SexAge           &lt;int&gt; 15, 17, 17, NA, 13, 15, 15, 17, NA, 21, 16, NA, 17, 1‚Ä¶\n$ SexNumPartnLife  &lt;int&gt; 50, 81, 4, NA, 10, 8, 3, 5, NA, 5, 45, NA, 4, 1, NA, ‚Ä¶\n$ SexNumPartYear   &lt;int&gt; 1, 10, 1, NA, 3, 1, 1, 0, NA, 5, 2, NA, 1, 1, NA, 2, ‚Ä¶\n$ SameSex          &lt;fct&gt; No, No, No, NA, No, No, No, No, NA, No, Yes, NA, No, ‚Ä¶\n$ SexOrientation   &lt;fct&gt; Heterosexual, Heterosexual, Heterosexual, NA, Heteros‚Ä¶\n$ PregnantNow      &lt;fct&gt; NA, NA, NA, NA, No, NA, No, NA, NA, NA, No, NA, NA, N‚Ä¶\n\n\n\n\n\nEach row shows: variable name, type, and first few values\nEasier to read than str() for large datasets"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#skim---comprehensive-summary",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#skim---comprehensive-summary",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "skim() - comprehensive summary",
    "text": "skim() - comprehensive summary\nskim() from the skimr package gives you detailed summaries and mini visualizations.\n\nskim(nhanes.samp.adult)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The pipe operator: %>%",
    "text": "The pipe operator: %&gt;%\nThe pipe operator %&gt;% takes the output from one function and passes it as the first argument to the next function.\nThink of it as: ‚Äúand then‚Ä¶‚Äù\n\n\nI want to find my keys, then start my car, then drive to work, then park my car.\n\n\n\n\nNested\n\npark(drive(start_car(find(\"keys\")), \n           to = \"work\"))\n\n\nPiped\n\nfind(\"keys\") %&gt;%\n  start_car() %&gt;%\n  drive(to = \"work\") %&gt;%\n  park()"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator-1",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator-1",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The pipe operator: %>%",
    "text": "The pipe operator: %&gt;%\n\n\nWithout pipes (nested)\n\n\nRead from inside-out\n\nhead(nhanes.samp.adult, 3)\n\n# A tibble: 3 √ó 76\n     ID SurveyYr Gender   Age AgeDecade AgeMonths Race1 Race3 Education   \n  &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;       \n1 63147 2011_12  male      41 \" 40-49\"         NA White White Some College\n2 57165 2009_10  male      48 \" 40-49\"        586 Black &lt;NA&gt;  High School \n3 69465 2011_12  female    50 \" 50-59\"         NA White White College Grad\n# ‚Ñπ 67 more variables: MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,\n#   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;, Work &lt;fct&gt;, Weight &lt;dbl&gt;,\n#   Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;, Height &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   BMICatUnder20yrs &lt;fct&gt;, BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,\n#   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;, BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;,\n#   BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;, Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;,\n#   TotChol &lt;dbl&gt;, UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;, ‚Ä¶\n\n\n\nWith pipes\n\n\nRead left to right\n\nnhanes.samp.adult %&gt;% \n  head(3)\n\n# A tibble: 3 √ó 76\n     ID SurveyYr Gender   Age AgeDecade AgeMonths Race1 Race3 Education   \n  &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;       \n1 63147 2011_12  male      41 \" 40-49\"         NA White White Some College\n2 57165 2009_10  male      48 \" 40-49\"        586 Black &lt;NA&gt;  High School \n3 69465 2011_12  female    50 \" 50-59\"         NA White White College Grad\n# ‚Ñπ 67 more variables: MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,\n#   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;, Work &lt;fct&gt;, Weight &lt;dbl&gt;,\n#   Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;, Height &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   BMICatUnder20yrs &lt;fct&gt;, BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,\n#   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;, BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;,\n#   BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;, Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;,\n#   TotChol &lt;dbl&gt;, UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;, ‚Ä¶"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator-2",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-pipe-operator-2",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The pipe operator: %>%",
    "text": "The pipe operator: %&gt;%\n\n\nWithout pipes (nested)\n\n\nHarder to read when operations stack up:\n\nmean(filter(nhanes.samp.adult, \n            Diabetes == \"Yes\")$BMI, \n     na.rm = TRUE)\n\n\nWith pipes\n\n\nMore readable for complex operations:\n\nnhanes.samp.adult %&gt;%\n  filter(Diabetes == \"Yes\") %&gt;%\n  pull(BMI) %&gt;%\n  mean(na.rm = TRUE)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#dplyr-the-grammar-of-data-manipulation",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#dplyr-the-grammar-of-data-manipulation",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "dplyr: The grammar of data manipulation",
    "text": "dplyr: The grammar of data manipulation\ndplyr provides a consistent set of verbs for data manipulation:\n\n\n\n\n\nFunction\nWhat it does\n\n\n\n\nfilter()\nKeep rows that meet conditions\n\n\nselect()\nKeep or drop columns\n\n\nmutate()\nCreate or modify columns\n\n\narrange()\nSort rows\n\n\ngroup_by()\nGroup data for summaries\n\n\nsummarize()\nCalculate summary statistics\n\n\n\n\n\nThese verbs can be chained together with %&gt;% for powerful data transformations."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#filter---subsetting-rows",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#filter---subsetting-rows",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "filter() - subsetting rows",
    "text": "filter() - subsetting rows\nfilter() keeps rows that meet specified conditions.\n\n\n\n\nSingle condition\n\nnhanes.samp.adult %&gt;%\n  filter(Diabetes == \"Yes\")\n\n\n\nMultiple conditions (AND)\n\nnhanes.samp.adult %&gt;%\n  filter(Gender == \"female\", \n         Age &gt; 50)\n\n# OR \n\nnhanes.samp.adult %&gt;%\n  filter(Gender == \"female\" & \n         Age &gt; 50)\n\n\nUsing OR (|)\n\nnhanes.samp.adult %&gt;%\n  filter(Diabetes == \"Yes\" | \n         Age &gt; 70)\n\n\n\nNumeric comparisons\n\nnhanes.samp.adult %&gt;%\n  filter(BMI &gt;= 30)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#comparison-operators-in-r",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#comparison-operators-in-r",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Comparison operators in R",
    "text": "Comparison operators in R\nWhen using filter(), you‚Äôll use these comparison operators:\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n&gt;\nGreater than\n\n\n&gt;=\nGreater than or equal to\n\n\n&lt;\nLess than\n\n\n&lt;=\nLess than or equal to\n\n\n& or ,\nAND (both conditions must be true)\n\n\n|\nOR (at least one condition must be true)\n\n\nis.na()\nCheck if value is missing"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#select---choosing-columns",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#select---choosing-columns",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "select() - choosing columns",
    "text": "select() - choosing columns\nselect() lets you keep or remove specific columns.\n\n\n\n\nSelect specific columns\n\nnhanes.samp.adult %&gt;%\n  select(Age, Gender, BMI)\n\n\n\nSelect a range of columns\n\nnhanes.samp.adult %&gt;%\n  select(Age:Education)\n\n\nDrop columns (i.e.¬†de-select)\n\nnhanes.samp.adult %&gt;%\n  select(-ID)\n\n¬†\nSelect by pattern\n\nnhanes.samp.adult %&gt;%\n  select(starts_with(\"B\"))"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate---creating-new-variables",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate---creating-new-variables",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "mutate() - creating new variables",
    "text": "mutate() - creating new variables\nmutate() creates new columns or modifies existing ones.\n\n\nImportant: mutate() doesn‚Äôt change your original data unless you save it!\n\n\nCreate a single new column\n\nnhanes.samp.adult %&gt;%\n  mutate(height_m = Height / 100) %&gt;%\n  select(ID, Height, height_m)\n\n# A tibble: 135 √ó 3\n      ID Height height_m\n   &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 63147   189.     1.89\n 2 57165   168.     1.68\n 3 69465   162.     1.62\n 4 57313   158.     1.58\n 5 56047   168.     1.68\n 6 57056   166.     1.66\n 7 54643   156.     1.56\n 8 53095   156.     1.56\n 9 67434   181.     1.81\n10 60273   178.     1.78\n# ‚Ñπ 125 more rows"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate-with-case_when",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate-with-case_when",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "mutate() with case_when()",
    "text": "mutate() with case_when()\ncase_when() is useful for creating categorical variables based on conditions.\n\nnhanes.samp.adult %&gt;%\n  mutate(bmi_category = case_when(\n    BMI &lt; 18.5 ~ \"Underweight\",\n    BMI &lt; 25 ~ \"Normal\",\n    BMI &lt; 30 ~ \"Overweight\",\n    BMI &gt;= 30 ~ \"Obese\"\n  )) %&gt;%\n  select(ID, BMI, bmi_category) %&gt;%\n  head(5)  # Just show first 5 rows\n\n# A tibble: 5 √ó 3\n     ID   BMI bmi_category\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;       \n1 63147  30   Obese       \n2 57165  27.4 Overweight  \n3 69465  26.9 Overweight  \n4 57313  24.7 Normal      \n5 56047  24.9 Normal      \n\n\n\n\n\ncase_when() evaluates conditions in order\nUse ~ to separate condition from result\n\nFirst matching condition wins"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate---multiple-columns-at-once",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#mutate---multiple-columns-at-once",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "mutate() - multiple columns at once",
    "text": "mutate() - multiple columns at once\nYou can create several new variables in one mutate() call.\n\nnhanes.samp.adult %&gt;%\n  mutate(\n    height_m = Height / 100,\n    weight_kg = Weight * 0.453592,\n    bmi_calculated = weight_kg / (height_m^2)\n  ) %&gt;%\n  select(ID, Height, Weight, BMI, height_m, weight_kg, bmi_calculated)\n\n# A tibble: 135 √ó 7\n      ID Height Weight   BMI height_m weight_kg bmi_calculated\n   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 63147   189.  107.   30       1.89      48.4           13.6\n 2 57165   168.   77.4  27.4     1.68      35.1           12.4\n 3 69465   162.   70.5  26.9     1.62      32.0           12.2\n 4 57313   158.   61.7  24.7     1.58      28.0           11.2\n 5 56047   168.   70.3  24.9     1.68      31.9           11.3\n 6 57056   166.   92.6  33.7     1.66      42.0           15.3\n 7 54643   156.   55.6  23.0     1.56      25.2           10.4\n 8 53095   156.   82    33.5     1.56      37.2           15.2\n 9 67434   181.   88.2  26.8     1.81      40.0           12.2\n10 60273   178.  119    37.5     1.78      54.0           17.0\n# ‚Ñπ 125 more rows"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-2-3-minutes",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-2-3-minutes",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick practice (2-3 minutes)",
    "text": "Quick practice (2-3 minutes)\nUsing the nhanes.samp.adult data and pipes:\n\nFilter to people with diabetes\nSelect the columns: Age, Gender, BMI, Diabetes\nCreate a new column called age_group that is:\n\n‚ÄúUnder 50‚Äù if Age &lt; 50\n‚Äú50 or older‚Äù if Age &gt;= 50\n\n\n(Hint: Use filter(), select(), and mutate() with case_when())"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-solution",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-solution",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick practice: solution",
    "text": "Quick practice: solution\n\nnhanes.samp.adult %&gt;%\n  filter(Diabetes == \"Yes\") %&gt;%\n  select(Age, Gender, BMI, Diabetes) %&gt;%\n  mutate(age_group = case_when(\n    Age &lt; 50 ~ \"Under 50\",\n    Age &gt;= 50 ~ \"50 or older\"\n  ))\n\n# A tibble: 13 √ó 5\n     Age Gender   BMI Diabetes age_group  \n   &lt;int&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;fct&gt;    &lt;chr&gt;      \n 1    32 female  45.5 Yes      Under 50   \n 2    63 male    37.7 Yes      50 or older\n 3    49 male    34.6 Yes      Under 50   \n 4    36 male    38.7 Yes      Under 50   \n 5    38 female  31.7 Yes      Under 50   \n 6    55 male    22.6 Yes      50 or older\n 7    57 female  29.2 Yes      50 or older\n 8    59 female  21.6 Yes      50 or older\n 9    70 female  31.8 Yes      50 or older\n10    61 female  38.7 Yes      50 or older\n11    33 female  42.8 Yes      Under 50   \n12    58 female  34.3 Yes      50 or older\n13    57 male    40.4 Yes      50 or older"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#arrange---sorting-rows",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#arrange---sorting-rows",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "arrange() - sorting rows",
    "text": "arrange() - sorting rows\narrange() sorts rows by one or more variables.\n\n\n\n\nSort ascending (default)\n\nnhanes.samp.adult %&gt;%\n  select(ID, Age, BMI) %&gt;%\n  arrange(Age) %&gt;% \n  head(8)\n\n\nSort descending\n\nnhanes.samp.adult %&gt;%\n  select(ID, Age, BMI) %&gt;%\n  arrange(desc(Age)) %&gt;% \n  head(8)\n\nUse desc() to sort in descending order."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#arrange---multiple-columns",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#arrange---multiple-columns",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "arrange() - multiple columns",
    "text": "arrange() - multiple columns\nYou can sort by multiple variables at once.\n\nnhanes.samp.adult %&gt;%\n  select(ID, Gender, Age, BMI) %&gt;%\n  arrange(Gender, desc(Age)) %&gt;%\n  head(8)\n\n# A tibble: 8 √ó 4\n     ID Gender   Age   BMI\n  &lt;int&gt; &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt;\n1 61964 female    80  19.2\n2 57313 female    74  24.7\n3 59171 female    74  32.0\n4 58284 female    72  25.2\n5 67897 female    71  17.1\n6 67285 female    70  36.6\n7 67668 female    70  31.8\n8 69421 female    68  25.9\n\n\nSorts by Gender first, then by Age (descending) within each gender group."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#group_by---preparing-for-summaries",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#group_by---preparing-for-summaries",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "group_by() - preparing for summaries",
    "text": "group_by() - preparing for summaries\ngroup_by() groups your data by one or more variables.\n\nWhat if I want to quickly look at group differences?\nIt will not change how the data look, but changes the actions of following functions\n\n\n\nBy itself, it doesn‚Äôt change how the data looks:\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender)\n\n# A tibble: 135 √ó 76\n# Groups:   Gender [2]\n      ID SurveyYr Gender   Age AgeDecade AgeMonths Race1   Race3 Education     \n   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;         \n 1 63147 2011_12  male      41 \" 40-49\"         NA White   White Some College  \n 2 57165 2009_10  male      48 \" 40-49\"        586 Black   &lt;NA&gt;  High School   \n 3 69465 2011_12  female    50 \" 50-59\"         NA White   White College Grad  \n 4 57313 2009_10  female    74 \" 70+\"          889 White   &lt;NA&gt;  College Grad  \n 5 56047 2009_10  female    27 \" 20-29\"        329 White   &lt;NA&gt;  9 - 11th Grade\n 6 57056 2009_10  male      26 \" 20-29\"        316 Mexican &lt;NA&gt;  High School   \n 7 54643 2009_10  female    41 \" 40-49\"        503 White   &lt;NA&gt;  College Grad  \n 8 53095 2009_10  female    52 \" 50-59\"        632 White   &lt;NA&gt;  9 - 11th Grade\n 9 67434 2011_12  male      56 \" 50-59\"         NA White   White College Grad  \n10 60273 2009_10  male      39 \" 30-39\"        472 Black   &lt;NA&gt;  9 - 11th Grade\n# ‚Ñπ 125 more rows\n# ‚Ñπ 67 more variables: MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,\n#   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;, Work &lt;fct&gt;, Weight &lt;dbl&gt;,\n#   Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;, Height &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   BMICatUnder20yrs &lt;fct&gt;, BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,\n#   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;, BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;,\n#   BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;, Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;, ‚Ä¶\n\n\nNotice the ‚ÄúGroups: Gender [2]‚Äù at the top - the data is now grouped, but not summarized."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#group_by-with-summarize",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#group_by-with-summarize",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "group_by() with summarize()",
    "text": "group_by() with summarize()\nThe real power of group_by() comes when combined with summarize().\n\n\n\n\nWithout grouping\n\nnhanes.samp.adult %&gt;%\n  summarize(\n    mean_bmi = mean(BMI, na.rm = TRUE),\n    sd_bmi = sd(BMI, na.rm = TRUE), \n    n = n()\n  )\n\n# A tibble: 1 √ó 3\n  mean_bmi sd_bmi     n\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n1     29.1   7.55   135\n\n\n\nWith grouping by Gender\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender) %&gt;%\n  summarize(\n    mean_bmi = mean(BMI, na.rm = TRUE),\n    sd_bmi = sd(BMI, na.rm = TRUE),\n    n = n()\n  )\n\n# A tibble: 2 √ó 4\n  Gender mean_bmi sd_bmi     n\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n1 female     29.0   8.81    70\n2 male       29.2   5.97    65\n\n\n\nn() counts the number of observations in each group."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#chaining-multiple-dplyr-verbs",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#chaining-multiple-dplyr-verbs",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Chaining multiple dplyr verbs",
    "text": "Chaining multiple dplyr verbs\nYou can chain operations together to answer complex questions.\n\n\nQuestion: What is the mean BMI for people over age 50, by diabetes status?\n\nnhanes.samp.adult %&gt;%\n  filter(Age &gt; 50) %&gt;%\n  select(Age, BMI, Diabetes) %&gt;%\n  group_by(Diabetes) %&gt;%\n  summarize(\n    n = n(),\n    mean_bmi = mean(BMI, na.rm = TRUE),\n    sd_bmi = sd(BMI, na.rm = TRUE)\n  )\n\n# A tibble: 2 √ó 4\n  Diabetes     n mean_bmi sd_bmi\n  &lt;fct&gt;    &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 No          39     28.1   6.30\n2 Yes          8     32.0   7.16"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#summary-statistics-with-rstatix",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#summary-statistics-with-rstatix",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Summary statistics with rstatix",
    "text": "Summary statistics with rstatix\nget_summary_stats() in rstatix package provides pipe-friendly functions for summary statistics.\n\n\n\n\nSummary for one variable\n\nnhanes.samp.adult %&gt;%\n  get_summary_stats(BMI, \n                    type = \"mean_sd\")\n\n# A tibble: 1 √ó 4\n  variable     n  mean    sd\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 BMI        135  29.1  7.55\n\n\n\nSummary by groups\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender) %&gt;%\n  get_summary_stats(BMI, \n                    type = \"mean_sd\")\n\n# A tibble: 2 √ó 5\n  Gender variable     n  mean    sd\n  &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 female BMI         70  29.0  8.82\n2 male   BMI         65  29.2  5.97\n\n\n\n\n\nOther types: \"median_iqr\", \"five_number\", \"full\", \"common\""
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#multiple-variables-and-groups",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#multiple-variables-and-groups",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Multiple variables and groups",
    "text": "Multiple variables and groups\nget_summary_stats() can handle multiple variables at once.\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender, Diabetes) %&gt;%\n  get_summary_stats(BMI, Height, Weight, type = \"mean_sd\")\n\n# A tibble: 12 √ó 6\n   Gender Diabetes variable     n  mean    sd\n   &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 female No       BMI         62  28.3  8.75\n 2 female No       Height      62 163.   7.57\n 3 female No       Weight      62  75.7 25.9 \n 4 female Yes      BMI          8  34.4  7.73\n 5 female Yes      Height       8 161.   7.11\n 6 female Yes      Weight       8  90.0 22.6 \n 7 male   No       BMI         60  28.8  5.69\n 8 male   No       Height      60 176.   6.97\n 9 male   No       Weight      60  89.6 18.1 \n10 male   Yes      BMI          5  34.8  7.15\n11 male   Yes      Height       5 178.   9.28\n12 male   Yes      Weight       5 109.  22.0"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-check-putting-it-together",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-check-putting-it-together",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick check: putting it together",
    "text": "Quick check: putting it together\nUsing what you‚Äôve learned, try to answer:\nWhat is the mean age and BMI for each combination of Gender and Diabetes status?\n\n\nHints:\n\nUse group_by() with two variables\nUse get_summary_stats() or summarize()\nInclude n() to count observations"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-check-solution",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-check-solution",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick check: solution",
    "text": "Quick check: solution\n\n\nUsing rstatix\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender, Diabetes) %&gt;%\n  get_summary_stats(Age, BMI, \n                    type = \"mean_sd\")\n\n# A tibble: 8 √ó 6\n  Gender Diabetes variable     n  mean    sd\n  &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 female No       Age         62  42.2 16.2 \n2 female No       BMI         62  28.3  8.75\n3 female Yes      Age          8  51   14.5 \n4 female Yes      BMI          8  34.4  7.73\n5 male   No       Age         60  45.4 16.4 \n6 male   No       BMI         60  28.8  5.69\n7 male   Yes      Age          5  52   10.2 \n8 male   Yes      BMI          5  34.8  7.15\n\n\n\nUsing dplyr summarize\n\nnhanes.samp.adult %&gt;%\n  group_by(Gender, Diabetes) %&gt;%\n  summarize(\n    n = n(),\n    mean_age = mean(Age, na.rm = TRUE),\n    mean_bmi = mean(BMI, na.rm = TRUE)\n  )\n\n# A tibble: 4 √ó 5\n# Groups:   Gender [2]\n  Gender Diabetes     n mean_age mean_bmi\n  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 female No          62     42.2     28.3\n2 female Yes          8     51       34.4\n3 male   No          60     45.4     28.8\n4 male   Yes          5     52       34.8"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#summary-tables-with-janitor",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#summary-tables-with-janitor",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Summary tables with janitor",
    "text": "Summary tables with janitor\ntabyl() in the janitor package makes frequency tables much easier than base R.\n\n\n\n\nOne-way frequency table\n\nnhanes.samp.adult %&gt;%\n  tabyl(Gender)\n\n Gender  n   percent\n female 70 0.5185185\n   male 65 0.4814815\n\n\nGives you counts (n), percentages (percent), and includes missing values automatically.\n\nTwo-way table (cross-tabulation)\n\nnhanes.samp.adult %&gt;%\n  tabyl(Gender, Diabetes)\n\n Gender No Yes\n female 62   8\n   male 60   5"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#enhancing-tables-with-janitor-adorn-functions",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#enhancing-tables-with-janitor-adorn-functions",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Enhancing tables with janitor adorn functions",
    "text": "Enhancing tables with janitor adorn functions\njanitor has ‚Äúadorn‚Äù functions to format tables nicely.\n\n\n\n\nAdd percentages\n\nnhanes.samp.adult %&gt;%\n  tabyl(Gender, Diabetes) %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1)\n\n Gender    No   Yes\n female 88.6% 11.4%\n   male 92.3%  7.7%\n\n\n\nAdd totals\n\nnhanes.samp.adult %&gt;%\n  tabyl(Gender, Diabetes) %&gt;%\n  adorn_totals(c(\"row\", \"col\"))\n\n Gender  No Yes Total\n female  62   8    70\n   male  60   5    65\n  Total 122  13   135"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#combining-adorn-functions",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#combining-adorn-functions",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Combining adorn functions",
    "text": "Combining adorn functions\nYou can chain multiple adorn functions together.\n\nnhanes.samp.adult %&gt;%\n  tabyl(Gender, Diabetes) %&gt;%\n  adorn_totals(c(\"row\", \"col\")) %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()\n\n Gender          No        Yes        Total\n female 88.6%  (62) 11.4%  (8) 100.0%  (70)\n   male 92.3%  (60)  7.7%  (5) 100.0%  (65)\n  Total 90.4% (122)  9.6% (13) 100.0% (135)\n\n\n\n\n\nadorn_ns() adds the counts alongside percentages\nOrder matters: calculate totals first, then percentages"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#data-visualization-with-ggplot2",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#data-visualization-with-ggplot2",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Data visualization with ggplot2",
    "text": "Data visualization with ggplot2\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#why-visualize-data",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#why-visualize-data",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Why visualize data?",
    "text": "Why visualize data?\nVisualizations help us:\n\nUnderstand distributions\nIdentify outliers and patterns\nCompare groups\nCommunicate findings"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#anscombes-quartet",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#anscombes-quartet",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Anscombe‚Äôs Quartet",
    "text": "Anscombe‚Äôs Quartet\nFour datasets with identical summary statistics but very different patterns:\n\nAll four have the same mean, SD, and correlation - but look how different they are!"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-datasaurus-dozen",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-datasaurus-dozen",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The Datasaurus Dozen",
    "text": "The Datasaurus Dozen\nSimilar to Anscombe‚Äôs quartet, The Datasaurus Dozen is a compilation of 13 data sets with similar numerical summaries and radically different visual summaries. See a great discussion of this dataset by the creators, Justin Matejka and George Fitzmaurice here\n\nAll 13 datasets have nearly identical summary statistics: Mean X = 54.3, Y = 47.8 SD X = 16.77, Y = 26.94 Cor = -0.06"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-grammar-of-graphics",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#the-grammar-of-graphics",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "The grammar of graphics",
    "text": "The grammar of graphics\nggplot2 implements the grammar of graphics - a framework for describing plots.\n\n\nEvery ggplot has three essential components:\n\nData - the dataset you‚Äôre plotting\nAesthetics (aes()) - mappings from data to visual properties (x, y, color, size, etc.)\nGeoms - geometric objects that represent the data (points, lines, bars, etc.)\n\n\n\nBasic template:\n\nggplot(data = DATA, \n       mapping = aes(x = X_VAR, y = Y_VAR)) +\n  geom_SOMETHING()\n\n\n\nNotice we use + (not %&gt;%) to add layers to a ggplot."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#basics-of-a-ggplot",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#basics-of-a-ggplot",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Basics of a ggplot",
    "text": "Basics of a ggplot"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#grammar-of-ggplot2",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#grammar-of-ggplot2",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Grammar of ggplot2",
    "text": "Grammar of ggplot2\n\n\n\n\n\n\n\n\nBeyond the basics:\n\nScales control how data values map to visual properties\nFacets create subplots\nCoordinates adjust the coordinate system\nThemes control visual appearance\n\nMost of these have good defaults - we‚Äôll focus on the essential three components today."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Building a ggplot step by step",
    "text": "Building a ggplot step by step\nStep 1: Just data\n\nggplot(data = nhanes.samp.adult)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step-1",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step-1",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Building a ggplot step by step",
    "text": "Building a ggplot step by step\nStep 2: Add mapping\n\nggplot(nhanes.samp.adult, aes(x = BMI))"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step-2",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#building-a-ggplot-step-by-step-2",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Building a ggplot step by step",
    "text": "Building a ggplot step by step\nStep 3: Add geom\n\nggplot(nhanes.samp.adult, aes(x = BMI)) +\n  geom_histogram()"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#your-first-ggplot-histogram",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#your-first-ggplot-histogram",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Your first ggplot: histogram",
    "text": "Your first ggplot: histogram\nHistogram - shows the distribution of a single numeric variable.\n\n\nggplot(data = nhanes.samp.adult, \n       mapping = aes(x = BMI)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nWhat does this tell us?\n\nMost people have BMI between 20-35\nDistribution is slightly right-skewed\nSome people with very high BMI (outliers)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#customizing-histograms",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#customizing-histograms",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Customizing histograms",
    "text": "Customizing histograms\nYou can control the appearance of histograms.\n\n\n\n\nAdjust bin width\n\nggplot(nhanes.samp.adult, \n       aes(x = BMI)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\nAdjust number of bins\n\nggplot(nhanes.samp.adult, \n       aes(x = BMI)) +\n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\n\nTry different values to find what best reveals patterns in your data."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#boxplots---comparing-distributions",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#boxplots---comparing-distributions",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Boxplots - comparing distributions",
    "text": "Boxplots - comparing distributions\nBoxplot - shows the distribution across groups.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Gender, y = BMI)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nBoxplot components:\n\nBox: middle 50% of data (IQR)\nLine in box: median\nWhiskers: extend to most extreme non-outlier values\nPoints: potential outliers"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#boxplot-by-multiple-groups",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#boxplot-by-multiple-groups",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Boxplot by multiple groups",
    "text": "Boxplot by multiple groups\nWe can compare distributions across multiple categorical variables.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Diabetes, y = BMI)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nPeople with diabetes tend to have higher BMI."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adding-color-to-boxplots",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adding-color-to-boxplots",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Adding color to boxplots",
    "text": "Adding color to boxplots\nColor can be mapped to a variable using aes().\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Gender, \n           y = BMI, \n           fill = Diabetes)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nfill controls the fill color of shapes.\ncolor would control the outline color."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#scatterplots---relationship-between-two-numeric-variables",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#scatterplots---relationship-between-two-numeric-variables",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Scatterplots - relationship between two numeric variables",
    "text": "Scatterplots - relationship between two numeric variables\nScatterplot - shows the relationship between two numeric variables.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Height, y = Weight)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nWhat we see:\n\nPositive relationship\nTaller people tend to weigh more\nSome variability"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#enhancing-scatterplots-with-color",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#enhancing-scatterplots-with-color",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Enhancing scatterplots with color",
    "text": "Enhancing scatterplots with color\nMap a third variable to color to see patterns.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Height, \n           y = Weight, \n           color = Gender)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nNow we can see if the relationship differs by gender."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adjusting-point-transparency",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adjusting-point-transparency",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Adjusting point transparency",
    "text": "Adjusting point transparency\nWhen points overlap, transparency (alpha) helps.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Height, \n           y = Weight, \n           color = Gender)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nalpha ranges from 0 (transparent) to 1 (opaque)."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#bar-charts---categorical-data",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#bar-charts---categorical-data",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Bar charts - categorical data",
    "text": "Bar charts - categorical data\nBar chart - shows counts or frequencies of categories.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Diabetes)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\ngeom_bar() automatically counts observations in each category."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#grouped-bar-charts",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#grouped-bar-charts",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Grouped bar charts",
    "text": "Grouped bar charts\nCompare categories across groups by mapping a variable to fill.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Gender, \n           fill = Diabetes)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nBy default, bars are stacked."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#position-adjustments-for-bar-charts",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#position-adjustments-for-bar-charts",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Position adjustments for bar charts",
    "text": "Position adjustments for bar charts\n\n\nStacked (default)\n\nggplot(nhanes.samp.adult, \n       aes(x = Gender, \n           fill = Diabetes)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nSide-by-side\n\nggplot(nhanes.samp.adult, \n       aes(x = Gender, \n           fill = Diabetes)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adding-labels-and-titles",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#adding-labels-and-titles",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Adding labels and titles",
    "text": "Adding labels and titles\nMake your plots more informative with labels.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = Height, y = Weight)) +\n  geom_point(alpha = 0.5) +\n  labs(\n    title = \"Height vs Weight in NHANES\",\n    subtitle = \"Adult participants\",\n    x = \"Height (cm)\",\n    y = \"Weight (kg)\",\n    caption = \"Data: NHANES\"\n  )"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#faceting---small-multiples",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#faceting---small-multiples",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Faceting - small multiples",
    "text": "Faceting - small multiples\nFacets create separate panels for subgroups.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = BMI)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~Gender)\n\n\n\n\n\n\n\n\n\n\n\nfacet_wrap() creates a panel for each level of a variable."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#faceting-by-two-variables",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#faceting-by-two-variables",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Faceting by two variables",
    "text": "Faceting by two variables\nCreate a grid of panels with two variables.\n\n\nggplot(nhanes.samp.adult, \n       aes(x = BMI)) +\n  geom_histogram(bins = 30) +\n  facet_grid(Gender ~ Diabetes)\n\n\n\n\n\n\n\n\n\n\n\nfacet_grid() creates rows √ó columns layout."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#combining-dplyr-and-ggplot2",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#combining-dplyr-and-ggplot2",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Combining dplyr and ggplot2",
    "text": "Combining dplyr and ggplot2\nYou can pipe data directly into ggplot()!\n\n\nnhanes.samp.adult %&gt;%\n  filter(Age &gt;= 50) %&gt;%\n  ggplot(aes(x = Height, y = Weight)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Height vs Weight (Age ‚â• 50)\")\n\n\n\n\n\n\n\n\n\n\n\nPipe %&gt;% passes data to ggplot().\nThen use + to add layers."
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#saving-your-work",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#saving-your-work",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Saving your work",
    "text": "Saving your work\nRemember: dplyr operations don‚Äôt modify the original data unless you save them.\n\n\n\n\nSave filtered data\n\nadults_diabetes &lt;- nhanes.samp.adult %&gt;%\n  filter(Diabetes == \"Yes\")\n\n# Check it worked\nnrow(adults_diabetes)\n\n[1] 13\n\n\n\nSave data with new variables\n\nnhanes_with_categories &lt;- \n  nhanes.samp.adult %&gt;%\n  mutate(\n    bmi_category = case_when(\n      BMI &lt; 18.5 ~ \"Underweight\",\n      BMI &lt; 25 ~ \"Normal\",\n      BMI &lt; 30 ~ \"Overweight\",\n      BMI &gt;= 30 ~ \"Obese\"\n    )\n  )"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#saving-plots",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#saving-plots",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Saving plots",
    "text": "Saving plots\nSave plots to files with ggsave().\n\n# Create a plot\np &lt;- ggplot(nhanes.samp.adult, aes(x = BMI)) +\n  geom_histogram(bins = 30) +\n  labs(title = \"Distribution of BMI\")\n\n# Save it\nggsave(\"bmi_histogram.png\", plot = p, \n       width = 8, height = 6, dpi = 300)\n\n\n\nTips:\n\nggsave() saves the last plot if you don‚Äôt specify plot =\nCommon formats: .png, .pdf, .jpg\nAdjust width and height in inches\nUse dpi = 300 for publication quality"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#common-ggplot2-geoms",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#common-ggplot2-geoms",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Common ggplot2 geoms",
    "text": "Common ggplot2 geoms\n\n\n\n\n\n\n\n\nGeom\nUse case\nVariables needed\n\n\n\n\ngeom_histogram()\nDistribution of one numeric variable\nx\n\n\ngeom_density()\nSmooth distribution curve\nx\n\n\ngeom_boxplot()\nCompare distributions across groups\nx (categorical), y (numeric)\n\n\ngeom_point()\nRelationship between two numeric variables\nx, y\n\n\ngeom_line()\nTrends over time or ordered data\nx, y\n\n\ngeom_bar()\nCounts of categorical data\nx\n\n\ngeom_col()\nPre-computed values\nx, y"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-5-minutes",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-5-minutes",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick practice (5 minutes)",
    "text": "Quick practice (5 minutes)\nUsing what you‚Äôve learned, create:\n\nA scatterplot of Age vs BMI\nColor the points by Diabetes status\nAdd appropriate labels\nAdd transparency to see overlapping points\n\n\n\nBonus: Facet by Gender"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-solution-1",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#quick-practice-solution-1",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Quick practice: solution",
    "text": "Quick practice: solution\n\nggplot(nhanes.samp.adult, \n       aes(x = Age, y = BMI, color = Diabetes)) +\n  geom_point(alpha = 0.5) +\n  labs(\n    title = \"Relationship between Age and BMI\",\n    subtitle = \"NHANES adult sample\",\n    x = \"Age (years)\",\n    y = \"Body Mass Index (kg/m¬≤)\"\n  ) +\n  facet_wrap(~Gender)"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#eda-workflow-summary",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#eda-workflow-summary",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "EDA workflow summary",
    "text": "EDA workflow summary\n1. Import and inspect\n\nLoad data\nCheck dimensions, variable names, and types\nLook for missing values\n\n2. Summarize\n\nCalculate summary statistics\nCreate frequency tables\nGroup by relevant variables\n\n3. Visualize\n\nPlot distributions (histograms, boxplots)\nExplore relationships (scatterplots)\nCompare groups (facets, colors)\n\n4. Iterate\n\nAsk new questions based on what you find\nFilter, transform, and visualize again"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#key-takeaways",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#key-takeaways",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nPipes (%&gt;%) chain operations together for readable code\ndplyr verbs manipulate data:\n\nfilter() - subset rows\nselect() - choose columns\nmutate() - create/modify variables\ngroup_by() + summarize() - calculate summaries by group\n\njanitor::tabyl() creates clean frequency tables\nrstatix::get_summary_stats() provides pipe-friendly summary statistics\nggplot2 builds visualizations using data + aesthetics + geoms\nNothing changes your original data unless you save it with &lt;-"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#resources-for-learning-more",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#resources-for-learning-more",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Resources for learning more",
    "text": "Resources for learning more\nTidyverse documentation:\n\nhttps://dplyr.tidyverse.org/\nhttps://ggplot2.tidyverse.org/\n\n\n\nBooks (free online):\n\nR for Data Science (2e) by Hadley Wickham & Garrett Grolemund\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practical Introduction by Kieran Healy\nModern Dive by Chester Ismay & Albert Kim\n\n\n\nCheat sheets:\n\nData transformation with dplyr\nData visualization with ggplot2"
  },
  {
    "objectID": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#practice-exercises",
    "href": "lessons/08_eda_and_data_viz/08_eda_and_data_viz.html#practice-exercises",
    "title": "Exploratory Data Analysis and Data Visualization",
    "section": "Practice exercises",
    "text": "Practice exercises\nTry these on your own to reinforce what you learned:\n\nFilter the data to people with BMI &gt; 30\nCreate a scatterplot of Age vs BMI\nCalculate mean height by gender\nMake a histogram of Age\nCreate a two-way table of Gender and Diabetes status\n\n\n\n\nBMSC 620 | EDA + Data Viz"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#recap-what-we-did-last-time",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#recap-what-we-did-last-time",
    "title": "Bayes‚Äô Theorem",
    "section": "Recap: What we did last time",
    "text": "Recap: What we did last time\n\n\nLast class, we calculated the Positive Predictive Value (PPV) using a contingency table:\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n990\n1,080\n\n\nTest -\n10\n8,910\n8,920\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\\[P(\\text{Disease} \\mid \\text{Test +}) = \\frac{90}{1,080} \\approx 0.083\\]\n\n\nToday we‚Äôll see the formula that lets us calculate this directly."
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#the-question-were-asking",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#the-question-were-asking",
    "title": "Bayes‚Äô Theorem",
    "section": "The question we‚Äôre asking",
    "text": "The question we‚Äôre asking\n\n\nWe want to flip the conditional probability:\n\n\n\n\nWhat we know:\n\n\\(P(\\text{Test +} \\mid \\text{Disease})\\) (sensitivity)\n\\(P(\\text{Test +} \\mid \\text{No Disease})\\) (1 - specificity)\n\\(P(\\text{Disease})\\) (prevalence)\n\n\nWhat we want:\n\n\\(P(\\text{Disease} \\mid \\text{Test +})\\) (PPV)\n\n\n\n\nBayes‚Äô Theorem gives us a formula to ‚Äúflip‚Äù the conditional."
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-general-form",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-general-form",
    "title": "Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem: General form",
    "text": "Bayes‚Äô Theorem: General form\n\n\n\\[\nP(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)}\n\\]\n\n\nIn words:\n\n\\(P(A \\mid B)\\) = posterior (what we want to know)\n\\(P(B \\mid A)\\) = likelihood (what we can measure)\n\\(P(A)\\) = prior (base rate)\n\\(P(B)\\) = marginal probability of \\(B\\)"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-medical-testing-version",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-medical-testing-version",
    "title": "Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem: Medical testing version",
    "text": "Bayes‚Äô Theorem: Medical testing version\n\n\nFor our diagnostic test:\n\\[\nP(\\text{Disease} \\mid \\text{Test +}) = \\frac{P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease})}{P(\\text{Test +})}\n\\]\n\n\nIn words:\n\n\\(P(\\text{Disease} \\mid \\text{Test +})\\) = PPV (what we want)\n\\(P(\\text{Test +} \\mid \\text{Disease})\\) = sensitivity (what test manufacturer tells us)\n\\(P(\\text{Disease})\\) = prevalence (base rate in population)\n\\(P(\\text{Test +})\\) = overall rate of positive tests"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#the-tricky-part-ptexttest",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#the-tricky-part-ptexttest",
    "title": "Bayes‚Äô Theorem",
    "section": "The tricky part: \\(P(\\text{Test +})\\)",
    "text": "The tricky part: \\(P(\\text{Test +})\\)\n\n\nHow do we find \\(P(\\text{Test +})\\)?\n\n\nThere are two ways to test positive:\n\nHave disease AND test positive: \\(P(\\text{Disease and Test +})\\)\nNo disease AND test positive: \\(P(\\text{No Disease and Test +})\\)\n\n\n\nUsing the law of total probability:\n\\[\nP(\\text{Test +}) = P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease}) + P(\\text{Test +} \\mid \\text{No Disease}) \\times P(\\text{No Disease})\n\\]"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-complete-formula",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-theorem-complete-formula",
    "title": "Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem: Complete formula",
    "text": "Bayes‚Äô Theorem: Complete formula\n\n\n\\[\nP(\\text{Disease} \\mid \\text{Test +}) = \\frac{P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease})}{P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease}) + P(\\text{Test +} \\mid \\text{No Disease}) \\times P(\\text{No Disease})}\n\\]\n\n\nThis looks complicated, but we have all the pieces!"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#applying-bayes-theorem-to-our-example",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#applying-bayes-theorem-to-our-example",
    "title": "Bayes‚Äô Theorem",
    "section": "Applying Bayes‚Äô Theorem to our example",
    "text": "Applying Bayes‚Äô Theorem to our example\n\n\nGiven:\n\nSensitivity = 90% = \\(P(\\text{Test +} \\mid \\text{Disease}) = 0.90\\)\nSpecificity = 90%, so \\(P(\\text{Test +} \\mid \\text{No Disease}) = 0.10\\)\nPrevalence = 1% = \\(P(\\text{Disease}) = 0.01\\)\nTherefore: \\(P(\\text{No Disease}) = 0.99\\)"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-1-calculate-the-numerator",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-1-calculate-the-numerator",
    "title": "Bayes‚Äô Theorem",
    "section": "Step 1: Calculate the numerator",
    "text": "Step 1: Calculate the numerator\n\n\n\\[\n\\begin{aligned}\n\\text{Numerator} &= P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease}) \\\\\n&= 0.90 \\times 0.01 \\\\\n&= 0.009\n\\end{aligned}\n\\]\n\n\nThis represents the true positives (people who have disease AND test positive)."
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-2-calculate-the-denominator",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-2-calculate-the-denominator",
    "title": "Bayes‚Äô Theorem",
    "section": "Step 2: Calculate the denominator",
    "text": "Step 2: Calculate the denominator\n\n\n\\[\n\\begin{aligned}\n\\text{Denominator} &= P(\\text{Test +} \\mid \\text{Disease}) \\times P(\\text{Disease}) \\\\\n&\\quad + P(\\text{Test +} \\mid \\text{No Disease}) \\times P(\\text{No Disease}) \\\\\n&= (0.90 \\times 0.01) + (0.10 \\times 0.99) \\\\\n&= 0.009 + 0.099 \\\\\n&= 0.108\n\\end{aligned}\n\\]\n\n\nThis represents all positive tests (true positives + false positives)."
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-3-calculate-ppv",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#step-3-calculate-ppv",
    "title": "Bayes‚Äô Theorem",
    "section": "Step 3: Calculate PPV",
    "text": "Step 3: Calculate PPV\n\n\n\\[\n\\begin{aligned}\nP(\\text{Disease} \\mid \\text{Test +}) &= \\frac{0.009}{0.108} \\\\\n&\\approx 0.083 \\\\\n&= 8.3\\%\n\\end{aligned}\n\\]\n\n\nSame answer as before! But now we calculated it directly from the formula."
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#connecting-to-the-contingency-table",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#connecting-to-the-contingency-table",
    "title": "Bayes‚Äô Theorem",
    "section": "Connecting to the contingency table",
    "text": "Connecting to the contingency table\n\n\n\n\nBayes‚Äô Theorem:\n\\[\n\\frac{0.90 \\times 0.01}{(0.90 \\times 0.01) + (0.10 \\times 0.99)} = 0.083\n\\]\n\n\nNumerator: true positives\nDenominator: all positives\n\nContingency table:\n\n\n\n\n\n\n\n\n\n\nDisease\nNo Disease\nTotal\n\n\n\n\nTest +\n90\n990\n1,080\n\n\nTest -\n10\n8,910\n8,920\n\n\nTotal\n100\n9,900\n10,000\n\n\n\n\n\n\\[\\frac{\\textcolor{red}{90}}{\\textcolor{purple}{1,080}} = 0.083\\]\n\n\n\nThe formula gives us the proportions directly!"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#why-is-this-useful",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#why-is-this-useful",
    "title": "Bayes‚Äô Theorem",
    "section": "Why is this useful?",
    "text": "Why is this useful?\n\n\nWithout Bayes‚Äô Theorem:\n\nBuild entire contingency table\nNeed to choose a population size\nMore steps, more chances for errors\n\n\n\nWith Bayes‚Äô Theorem:\n\nPlug numbers directly into formula\nGet answer immediately\nWorks with any probabilities (don‚Äôt need counts)\n\n\n\nBoth approaches work - use whichever makes more sense to you!"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#what-to-remember-about-bayes-theorem",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#what-to-remember-about-bayes-theorem",
    "title": "Bayes‚Äô Theorem",
    "section": "What to remember about Bayes‚Äô Theorem",
    "text": "What to remember about Bayes‚Äô Theorem\n\n\nThe formula:\n\\[\nP(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)}\n\\]\n\n\nKey concepts:\n\nBayes‚Äô Theorem ‚Äúflips‚Äù conditional probabilities\nAlways consider base rates (priors)\nLow prevalence ‚Üí low PPV, even with accurate tests\nCan use formula OR contingency table (both work!)\nPosterior = (Likelihood √ó Prior) / Evidence"
  },
  {
    "objectID": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-vs.-contingency-tables",
    "href": "lessons/07_bayes-theorem/07_bayes_theorem.html#bayes-vs.-contingency-tables",
    "title": "Bayes‚Äô Theorem",
    "section": "Bayes vs.¬†Contingency tables",
    "text": "Bayes vs.¬†Contingency tables\n\n\n\n\nContingency table approach:\nPros:\n\nVisual and intuitive\nSee all relationships\nGood for teaching\n\nCons:\n\nRequires choosing population size\nMore steps\nCan‚Äôt easily see effect of changing parameters\n\n\nBayes‚Äô Theorem approach:\nPros:\n\nDirect calculation\nWorks with proportions\nEasy to see how prevalence affects PPV\n\nCons:\n\nFormula can seem abstract\nNeed to remember to calculate denominator\n\n\n\n\nUse whichever approach makes more sense to you!\n\n\n\nBMSC 620 | Bayes‚Äô Theorem"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#learning-objectives",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#learning-objectives",
    "title": "Random Variables and Binomial Distribution",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of today‚Äôs class, you should be able to:\n\nDefine random variables and distinguish between discrete and continuous random variables\nCalculate the expected value (mean) and variance of discrete random variables\nCalculate the expected value and variance of linear combinations of random variables\nIdentify when the Binomial distribution is appropriate and calculate probabilities using it"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#roadmap-for-today",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#roadmap-for-today",
    "title": "Random Variables and Binomial Distribution",
    "section": "Roadmap for Today",
    "text": "Roadmap for Today\nPart 1: Random Variables (Section 3.1)\n\nWhat are random variables?\nExpected value and variance\nLinear combinations of random variables\n\nPart 2: Binomial Distribution (Section 3.2)\n\nBernoulli distribution\nBinomial distribution\nCalculating probabilities with the Binomial"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#motivation-from-data-to-probability-models",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#motivation-from-data-to-probability-models",
    "title": "Random Variables and Binomial Distribution",
    "section": "Motivation: From Data to Probability Models",
    "text": "Motivation: From Data to Probability Models\nSo far we‚Äôve worked with:\n\nData points: \\(x_1, x_2, x_3, \\ldots, x_n\\) (observed values)\nSample statistics: mean, variance, standard deviation\n\nNow we‚Äôre moving to:\n\nRandom variables: mathematical models for uncertain outcomes\nProbability distributions: theoretical descriptions of random phenomena\nParameters: population-level quantities (like \\(\\mu\\) and \\(\\sigma\\))"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#random-variables-vs-observed-data",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#random-variables-vs-observed-data",
    "title": "Random Variables and Binomial Distribution",
    "section": "Random Variables vs Observed Data",
    "text": "Random Variables vs Observed Data\n\n\n\nThree related (but different) ideas\n\n\n\nRandom variable:\n\\(X\\) = the random process before we observe anything\nObserved data:\n\\(x_1, x_2, \\dots, x_n\\) = the numbers we actually observe\nProbability distribution:\nDescribes how \\(X\\) behaves before data are collected\n\n\n\n\nKey idea:\nData are realizations of a random variable, not the random variable itself."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#what-is-a-random-variable",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#what-is-a-random-variable",
    "title": "Random Variables and Binomial Distribution",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\n\n\nDefinition: Random Variable\n\n\nA random variable (r.v.) assigns numerical values to the outcomes of a random phenomenon.\n\n\n\nNotation:\n\nWe use capital letters like \\(X\\), \\(Y\\), \\(Z\\) for random variables\nWe use lowercase letters like \\(x\\), \\(y\\), \\(z\\) for specific values\n\nKey idea: A random variable connects random outcomes to numbers and probabilities"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-rolling-a-die",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-rolling-a-die",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Rolling a Die",
    "text": "Example: Rolling a Die\nSuppose you roll a fair 6-sided die. Let \\(X\\) be the outcome of the roll.\nQuestion 1: What is the probability distribution of \\(X\\)?\n\n\n\n\n\\(x\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(P(X=x)\\)\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n\n\n\nNote:\n\nEach outcome has equal probability (fair die)\nProbabilities sum to 1: \\(\\sum_{x=1}^6 P(X=x) = 1\\)\nAll outcomes are disjoint (mutually exclusive)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#probability-distributions-quick-review",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#probability-distributions-quick-review",
    "title": "Random Variables and Binomial Distribution",
    "section": "Probability Distributions: Quick Review",
    "text": "Probability Distributions: Quick Review\n\n\n\nRules for a Probability Distribution\n\n\nA probability distribution must satisfy three rules:\n\nThe outcomes must be disjoint (mutually exclusive)\nEach probability must be between 0 and 1\nThe probabilities must sum to 1\n\n\n\n\nThese are the same rules we learned in our probability unit!\n\n\n\n\n\nProbability Distributions (Discrete)\n\n\nFor a discrete random variable, the probability mass function (pmf) is\n\\[\nf(x) = P(X = x)\n\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#discrete-vs.-continuous-random-variables",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#discrete-vs.-continuous-random-variables",
    "title": "Random Variables and Binomial Distribution",
    "section": "Discrete vs.¬†Continuous Random Variables",
    "text": "Discrete vs.¬†Continuous Random Variables\n\n\n\n\n\nDiscrete Random Variable\n\n\nA discrete r.v. takes on:\n\nA finite number of values, OR\nA countably infinite number of values\n\nExamples:\n\nNumber of heads in 10 coin flips\nNumber of students in a class\nNumber of COVID cases per day\n\n\n\n\n\n\n\n\nContinuous Random Variable\n\n\nA continuous r.v. can take:\n\nAny real value in an interval\nAny value in a union of intervals\n\nExamples:\n\nHeight\nBlood pressure\nTime until an event occurs\n\n\n\n\n\n\nToday‚Äôs focus: Discrete random variables (continuous coming soon!)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#expected-value-mean",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#expected-value-mean",
    "title": "Random Variables and Binomial Distribution",
    "section": "Expected Value (Mean)",
    "text": "Expected Value (Mean)\nThe expected value of a random variable is its long-run average value.\n\n\n\nDefinition: Expected Value of a Discrete R.V.\n\n\nIf \\(X\\) takes on outcomes \\(x_1, \\ldots, x_k\\) with probabilities \\(P(X=x_1), \\ldots, P(X=x_k)\\), then:\n\\[E(X) = \\mu = \\sum_{i=1}^k x_i \\cdot P(X=x_i)\\]\nThe expected value is a weighted average where weights are probabilities.\n\n\n\nNotation: \\(E(X)\\) or \\(\\mu\\) (mu)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-expected-value-of-rolling-a-die",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-expected-value-of-rolling-a-die",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Expected Value of Rolling a Die",
    "text": "Example: Expected Value of Rolling a Die\nQuestion 2: What is the expected outcome when rolling a fair die?\n\n\\[\\begin{aligned}\nE(X) &= \\sum_{x=1}^6 x \\cdot P(X=x) \\\\\n&= 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} \\\\\n&= \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} \\\\\n&= \\frac{21}{6} = 3.5\n\\end{aligned}\\]\n\n\nInterpretation: If you rolled the die many times, the average would approach 3.5\nNote: The expected value doesn‚Äôt have to be a possible outcome!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-unfair-die",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-unfair-die",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Unfair Die",
    "text": "Example: Unfair Die\nQuestion 3: What if the die is not fair?\n\n\n\n\\(x\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(P(X=x)\\)\n1/9\n1/9\n1/9\n1/9\n2/9\n3/9\n\n\n\n\n\\[\\begin{aligned}\nE(X) &= 1 ( \\frac{1}{9}) + 2(\\frac{1}{9}) + 3(\\frac{1}{9}) + 4(\\frac{1}{9}) + 5(\\frac{2}{9}) + 6 (\\frac{3}{9}) \\\\\n&= (\\frac{1 + 2 + 3 + 4}{9})  + (\\frac{10}{9}) + (\\frac{18}{9}) \\\\\n&= (\\frac{38}{9}) \\\\\n&= 4.222 \\dots\n\\end{aligned}\\]\n\n\nThe die is ‚Äúloaded‚Äù toward higher values (mean is 4.22 vs.¬†3.5 for fair die)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#variance-and-standard-deviation",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#variance-and-standard-deviation",
    "title": "Random Variables and Binomial Distribution",
    "section": "Variance and Standard Deviation",
    "text": "Variance and Standard Deviation\nJust like with data, we measure spread with variance and standard deviation.\n\n\n\nDefinition: Variance of a Discrete R.V.\n\n\nIf \\(X\\) has expected value \\(\\mu = E(X)\\), then:\n\\[\\text{Var}(X) = \\sigma^2 = \\sum_{i=1}^k (x_i - \\mu)^2 \\cdot P(X=x_i)\\]\nThe standard deviation is: \\(SD(X) = \\sigma = \\sqrt{\\text{Var}(X)}\\)\n\n\n\nKey idea: Squared deviations from the mean, weighted by probabilities"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-variance-of-a-fair-die",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-variance-of-a-fair-die",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Variance of a Fair Die",
    "text": "Example: Variance of a Fair Die\nWe found \\(E(X) = 3.5\\). What is \\(\\text{Var}(X)\\)?\n\n\\[\\begin{aligned}\n\\text{Var}(X) &= \\sum_{x=1}^6 (x - 3.5)^2 \\cdot P(X=x) \\\\\n&= (1-3.5)^2 \\cdot \\frac{1}{6} + (2-3.5)^2 \\cdot \\frac{1}{6} + \\cdots + (6-3.5)^2 \\cdot \\frac{1}{6} \\\\\n&= \\frac{6.25 + 2.25 + 0.25 + 0.25 + 2.25 + 6.25}{6} \\\\\n&= \\frac{17.5}{6} \\approx 2.92\n\\end{aligned}\\]\n\n\nStandard deviation: \\(SD(X) = \\sqrt{2.92} \\approx 1.71\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#pause-for-a-quick-example",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#pause-for-a-quick-example",
    "title": "Random Variables and Binomial Distribution",
    "section": "Pause for a Quick Example",
    "text": "Pause for a Quick Example\nApgar scores for newborns\nJust after birth, each child is rated on the Apgar scale, with scores determined by color, heart rate, reflex irritability, muscle tone, and respiratory effort.\n\n\nLet \\(X\\) = Apgar score. Historical data suggests the following probability distribution:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n\\(P(X=x)\\)\n0.002\n0.001\n0.002\n0.005\n0.02\n0.04\n0.18\n0.37\n0.25\n0.12\n0.01\n\n\n\n\n\nQuestions:\n\nWhat is \\(E(X)\\)?\nWhat is \\(\\text{Var}(X)\\)?"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-apgar-score-example-12",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-apgar-score-example-12",
    "title": "Random Variables and Binomial Distribution",
    "section": "Solution: Apgar Score Example (1/2)",
    "text": "Solution: Apgar Score Example (1/2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n\\(P(X=x)\\)\n0.002\n0.001\n0.002\n0.005\n0.02\n0.04\n0.18\n0.37\n0.25\n0.12\n0.01\n\n\n\n\n\n1. Expected value:\n\\[\\begin{aligned}\nE(X) = \\mu &= 0(0.002) + 1(0.001) + 2(0.002) + 3(0.005) +  \\cdots + 8(0.25) + 9(0.12) + 10(0.01) \\\\\n&= 0 + 0.001 + 0.004 + 0.015 + \\cdots + 2.00 + 1.08 + 0.10 \\\\\n&= 7.17\n\\end{aligned}\\]\nThe average Apgar score is about 7.2."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-apgar-score-example-22",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-apgar-score-example-22",
    "title": "Random Variables and Binomial Distribution",
    "section": "Solution: Apgar Score Example (2/2)",
    "text": "Solution: Apgar Score Example (2/2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n\\(P(X=x)\\)\n0.002\n0.001\n0.002\n0.005\n0.02\n0.04\n0.18\n0.37\n0.25\n0.12\n0.01\n\n\n\n\n\n2. Variance:\n\\[\\begin{aligned}\n\\text{Var}(X) &= \\sum_{x=0}^{10} (x - 7.17)^2 \\cdot P(X=x) \\\\\n&= (0-7.17)^2(0.002) + (1-7.17)^2(0.001) + \\cdots + (10-7.17)^2(0.01) \\\\\n&= 0.103 + 0.038 + 0.053 + 0.087 + 0.201 + 0.188 \\\\\n&\\quad + 0.246 + 0.011 + 0.171 + 0.402 + 0.080 \\\\\n&= 1.58\n\\end{aligned}\\]\n\nStandard deviation: \\(SD(X) = \\sqrt{1.58} \\approx 1.26\\)\nInterpretation: Most babies score between 6 and 9 (within 1 SD of the mean)."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#linear-combinations-of-random-variables",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#linear-combinations-of-random-variables",
    "title": "Random Variables and Binomial Distribution",
    "section": "Linear Combinations of Random Variables",
    "text": "Linear Combinations of Random Variables\nOften in research, we combine multiple measurements into a composite score.\n\n\n\nDefinition: Linear Combination\n\n\nIf \\(X\\) and \\(Y\\) are random variables and \\(a\\) and \\(b\\) are constants:\n\\[aX + bY\\]\nis a linear combination of the random variables.\n\n\n\nExamples in biomedical research:\n\nComposite health scores (sum of multiple domains)\nWeighted risk scores\nTotal costs (sum of different service types)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#expected-value-of-linear-combinations",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#expected-value-of-linear-combinations",
    "title": "Random Variables and Binomial Distribution",
    "section": "Expected Value of Linear Combinations",
    "text": "Expected Value of Linear Combinations\n\n\n\nTheorem: Expected Value of Linear Combinations\n\n\nIf \\(X\\) and \\(Y\\) are random variables and \\(a\\) and \\(b\\) are constants:\n\\[E(aX + bY) = aE(X) + bE(Y)\\]\nand\n\\[E(aX + b) = aE(X) + b\\]\n\n\n\nKey properties:\n\nExpectation is linear - it distributes over addition\nWorks whether or not \\(X\\) and \\(Y\\) are independent\nConstants factor out: \\(E(cX) = cE(X)\\)\n\nThis is intuitive: The average of a sum is the sum of the averages!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-clinical-trial-health-score-setup",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-clinical-trial-health-score-setup",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Clinical Trial Health Score (Setup)",
    "text": "Example: Clinical Trial Health Score (Setup)\nIn a clinical trial, researchers measure three patient-reported outcomes (PROs):\n\nPain score \\((X_1)\\): Scale 0-10, where 0 = no pain\n\n\\(E(X_1) = 4\\), \\(SD(X_1) = 2\\)\n\nMobility score \\((X_2)\\): Scale 0-10, where 10 = full mobility\n\n\\(E(X_2) = 6\\), \\(SD(X_2) = 1.5\\)\n\nQuality of life score \\((X_3)\\): Scale 0-10, where 10 = excellent\n\n\\(E(X_3) = 5\\), \\(SD(X_3) = 2.5\\)\n\n\nA composite health score is calculated as: \\[H = X_1 + X_2 + X_3\\]\nAssume the three scores are independent (one doesn‚Äôt influence the others)."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-expected-composite-score",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-expected-composite-score",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Expected Composite Score",
    "text": "Example: Expected Composite Score\nQuestion: What is the expected composite health score?\n\n\\[\\begin{aligned}\nE(H) &= E(X_1 + X_2 + X_3) \\\\\n&= E(X_1) + E(X_2) + E(X_3) \\\\\n&= 4 + 6 + 5 \\\\\n&= 15\n\\end{aligned}\\]\n\n\nInterpretation: On average, patients have a composite health score of 15 out of 30."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#variance-of-linear-combinations",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#variance-of-linear-combinations",
    "title": "Random Variables and Binomial Distribution",
    "section": "Variance of Linear Combinations",
    "text": "Variance of Linear Combinations\n\n\n\nTheorem: Variance of Linear Combinations\n\n\nIf \\(X\\) and \\(Y\\) are INDEPENDENT random variables and \\(a\\) and \\(b\\) are constants:\n\\[\\mathrm{Var}(aX + bY) = a^2\\mathrm{Var}(X) + b^2\\mathrm{Var}(Y)\\]\n\n\n\n\n\n\nGeneral formula when not independent\n\n\nThe general formula is\n\\[\\mathrm{Var}(aX + bY) = a^2\\mathrm{Var}(X) + b^2\\mathrm{Var}(Y) + 2ab\\, \\mathrm{Cov}(X,Y)\\] If independent, \\(\\mathrm{Cov}(X,Y) = 0\\).\n\n\n\nThe standard deviation is the square root of the variance."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-variance-of-composite-score",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-variance-of-composite-score",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Variance of Composite Score",
    "text": "Example: Variance of Composite Score\nQuestion: What is the variance and standard deviation of the composite health score?\nRecall: \\(H = X_1 + X_2 + X_3\\)\n\n\\(\\text{Var}(X_1) = 2^2 = 4\\)\n\\(\\text{Var}(X_2) = 1.5^2 = 2.25\\)\n\n\\(\\text{Var}(X_3) = 2.5^2 = 6.25\\)\n\n\n\\[\\begin{aligned}\n\\text{Var}(H) &= \\text{Var}(X_1 + X_2 + X_3) \\\\\n&= \\text{Var}(X_1) + \\text{Var}(X_2) + \\text{Var}(X_3) \\\\\n&= 4 + 2.25 + 6.25 \\\\\n&= 12.5\n\\end{aligned}\\]\n\n\n\\[SD(H) = \\sqrt{12.5} \\approx 3.54\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-weighted-composite-score",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-weighted-composite-score",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Weighted Composite Score",
    "text": "Example: Weighted Composite Score\nNow suppose researchers want to weight the scores differently:\n\\[H_{\\text{weighted}} = 0.5X_1 + 0.3X_2 + 0.2X_3\\]\n\nWeights sum to 1, so this is a weighted average (0-10 scale), not a total score.\nGives more weight to pain and mobility than quality of life.\n\n\n\nQuestions:\n\nWhat is \\(E(H_{\\text{weighted}})\\)?\nWhat is \\(\\text{Var}(H_{\\text{weighted}})\\)?"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-weighted-composite-score",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#solution-weighted-composite-score",
    "title": "Random Variables and Binomial Distribution",
    "section": "Solution: Weighted Composite Score",
    "text": "Solution: Weighted Composite Score\n1. Expected value:\n\\[\\begin{aligned}\nE(H_{\\text{weighted}}) &= E(0.5X_1 + 0.3X_2 + 0.2X_3) \\\\\n&= 0.5E(X_1) + 0.3E(X_2) + 0.2E(X_3) \\\\\n&= 0.5(4) + 0.3(6) + 0.2(5) \\\\\n&= 2 + 1.8 + 1.0 \\\\\n&= 4.8\n\\end{aligned}\\]\n\n2. Variance:\n\\[\\begin{aligned}\n\\text{Var}(H_{\\text{weighted}}) &= (0.5)^2\\text{Var}(X_1) + (0.3)^2\\text{Var}(X_2) + (0.2)^2\\text{Var}(X_3) \\\\\n&= 0.25(4) + 0.09(2.25) + 0.04(6.25) \\\\\n&= 1.0 + 0.20 + 0.25 \\\\\n&= 1.45\n\\end{aligned}\\]\n\\[SD(H_{\\text{weighted}}) = \\sqrt{1.45} \\approx 1.20\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#key-takeaways-linear-combinations",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#key-takeaways-linear-combinations",
    "title": "Random Variables and Binomial Distribution",
    "section": "Key Takeaways: Linear Combinations",
    "text": "Key Takeaways: Linear Combinations\nExpected value: \\[E(aX + bY) = aE(X) + bE(Y)\\]\n\nLinear property\nNo independence needed\nConstants factor out\n\nVariance: \\[\\text{Var}(aX + bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y)\\]\n\nRequires independence\nConstants are squared\nStandard deviations don‚Äôt simply add\n\n\n\nWhy this matters: Many biomedical measures are composite scores!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binary-outcomes",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binary-outcomes",
    "title": "Random Variables and Binomial Distribution",
    "section": "Binary Outcomes",
    "text": "Binary Outcomes\nMany situations involve two possible outcomes:\n\nFlipping a coin: heads or tails\nMedical test: positive or negative\n\nSurgery outcome: success or failure\nManufacturing: defective or non-defective\n\nWe call these binary or Bernoulli trials:\n\nOne outcome is called a ‚Äúsuccess‚Äù (probability \\(p\\))\nThe other is called a ‚Äúfailure‚Äù (probability \\(q = 1-p\\))"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#bernoulli-distribution",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#bernoulli-distribution",
    "title": "Random Variables and Binomial Distribution",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\n\n\nDefinition: Bernoulli Random Variable\n\n\nIf \\(X\\) is a random variable that takes:\n\nValue 1 with probability \\(p\\) (success)\nValue 0 with probability \\(1-p\\) (failure)\n\nThen \\(X\\) is a Bernoulli random variable.\nNotation: \\(X \\sim \\text{Bernoulli}(p)\\) or \\(X \\sim \\text{Bern}(p)\\)\n\n\n\nParameter: \\(p\\) is the probability of success (between 0 and 1)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#bernoulli-mean-and-variance",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#bernoulli-mean-and-variance",
    "title": "Random Variables and Binomial Distribution",
    "section": "Bernoulli: Mean and Variance",
    "text": "Bernoulli: Mean and Variance\n\n\n\nTheorem: Mean and Variance of Bernoulli R.V.\n\n\nIf \\(X \\sim \\text{Bernoulli}(p)\\), then:\n\\[E(X) = p\\] \\[\\text{Var}(X) = p(1-p)\\]\n\n\n\nExample with diabetes:\n\nAmong US adults aged 65-74, about 20.3% have diabetes\nDefine \\(X = 1\\) if a randomly selected adult has diabetes, \\(X = 0\\) otherwise\n\\(E(X) = 0.203\\)\n\\(\\text{Var}(X) = 0.203(0.797) = 0.162\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#from-bernoulli-to-binomial",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#from-bernoulli-to-binomial",
    "title": "Random Variables and Binomial Distribution",
    "section": "From Bernoulli to Binomial",
    "text": "From Bernoulli to Binomial\nWhat if we repeat a Bernoulli trial multiple times?\nExample: Randomly select 10 adults aged 65-74. How many have diabetes?\n\nEach person: Bernoulli(0.203)\nTotal number with diabetes: Binomial(10, 0.203)\n\n\n\n\nKey Relationship\n\n\n\\[\\text{Binomial}(n, p) = \\text{Sum of } n \\text{ independent Bernoulli}(p) \\text{ trials}\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#from-bernoulli-to-binomial-continued",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#from-bernoulli-to-binomial-continued",
    "title": "Random Variables and Binomial Distribution",
    "section": "From Bernoulli to Binomial (continued)",
    "text": "From Bernoulli to Binomial (continued)\n\nThe Bernoulli distribution is a special case of the Binomial distribution where \\(n=1\\)\n\nSpecifically: \\[\\text{Binomial}(1, p) = \\text{Bernoulli}(p) \\]\n\nTo get a Binomial distribution, we simply extend the scenario from a single trial to multiple independent trials.\n\nIf we conduct \\(n\\) independent Bernoulli trials with the same success probability \\(p\\), the total number of successes across these \\(n\\) trials will follow a Binomial distribution"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-distribution-definition",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-distribution-definition",
    "title": "Random Variables and Binomial Distribution",
    "section": "Binomial Distribution: Definition",
    "text": "Binomial Distribution: Definition\n\n\n\nDefinition: Binomial Random Variable\n\n\n\\(X\\) is a Binomial random variable if:\n\nThere are \\(n\\) independent trials\nEach trial has two outcomes: success or failure\nProbability of success is \\(p\\) (same for all trials)\n\\(X\\) counts the total number of successes\n\nNotation: \\(X \\sim \\text{Binomial}(n, p)\\) or \\(X \\sim \\text{Binom}(n, p)\\)\n\n\n\nParameters: \\(n\\) (number of trials) and \\(p\\) (probability of success)\nPossible values: \\(X \\in \\{0, 1, 2, \\ldots, n\\}\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#when-not-to-use-a-binomial-model",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#when-not-to-use-a-binomial-model",
    "title": "Random Variables and Binomial Distribution",
    "section": "When NOT to Use a Binomial Model",
    "text": "When NOT to Use a Binomial Model\n\n\n\nCommon Pitfalls\n\n\nA Binomial model is NOT appropriate when:\n\nTrials are not independent\n\nExample: sampling without replacement from a small population\n(Probabilities change after each draw)\n\nProbability of success is not constant\n\nExample: different subjects have different risk levels\n(\\(p\\) varies across trials)\n\n\n\n\n\nRule of thumb: If independence or constant \\(p\\) is violated ‚Üí not Binomial"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#derivation-by-example",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#derivation-by-example",
    "title": "Random Variables and Binomial Distribution",
    "section": "Derivation by example",
    "text": "Derivation by example\nApproximately 20.3% of US adults aged 65-74 have diabetes.\nHere, let‚Äôs define\n\n‚ÄúSuccess‚Äù (S) to be the event that a person has diabetes, then\n‚ÄúFailure‚Äù (F) is the event that a person does not have diabetes.\n\nAmong US adults aged 65-74:\n\n\\(P(\\text{has diabetes}) = 0.203 = p\\)\n\\(P(\\text{no diabetes}) = 1 - p = 0.797\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#define-an-experiment",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#define-an-experiment",
    "title": "Random Variables and Binomial Distribution",
    "section": "Define an experiment",
    "text": "Define an experiment\nSuppose we conduct an experiment in which \\(n = 3\\) US adults aged 65-74 are tested for diabetes.\n\nThe testing of each adult represents a trial.\nThe outcome from each trial is either a success (has diabetes) or a failure (does not have diabetes).\nThe outcome (S/F) of any one trial is not influenced by earlier outcomes nor does it affect later outcomes (independent trials).\nThe probability of having diabetes (\\(p = 0.203\\)) is the same for each adult sampled."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#possible-outcomes",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#possible-outcomes",
    "title": "Random Variables and Binomial Distribution",
    "section": "Possible outcomes",
    "text": "Possible outcomes\nWith 3 trials and 2 possible outcomes (S/F), there are 8 possible arrangements.\n\n\n\n\\(FFF\\)\n\\(FSS\\)\n\n\n\\(FFS\\)\n\\(SFS\\)\n\n\n\\(FSF\\)\n\\(SSF\\)\n\n\n\\(SFF\\)\n\\(SSS\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#define-the-rv",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#define-the-rv",
    "title": "Random Variables and Binomial Distribution",
    "section": "Define the rv",
    "text": "Define the rv\nLet \\(X =\\) the number of adults that have diabetes among the \\(n = 3\\) sampled.\n\n\nRe-organize the possible arrangements:\n\n\\(X = 0 \\Longleftrightarrow FFF\\)\n\\(X = 1 \\Longleftrightarrow FFS \\cup FSF \\cup SFF\\)\n\\(X = 2 \\Longleftrightarrow FSS \\cup SFS \\cup SSF\\)\n\\(X = 3 \\Longleftrightarrow SSS\\)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities",
    "title": "Random Variables and Binomial Distribution",
    "section": "Compute the probabilities",
    "text": "Compute the probabilities\n\n\nCase: \\(X = 0\\) (no one has diabetes)\n\\[\\begin{aligned}\nP(X = 0) &= P(FFF) \\\\\n&\\overset{\\text{ind.}}{=} (1 - p)(1 - p)(1 - p) \\\\\n&= (1 - p)^3 = 0.797^3 \\approx 0.506\n\\end{aligned}\\]\nBecause of the general multiplication rule for independent events, we simplified the event \\(FFF\\) into the product of \\(n = 3\\) separate terms."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued",
    "title": "Random Variables and Binomial Distribution",
    "section": "Compute the probabilities (continued)",
    "text": "Compute the probabilities (continued)\n\n\nCase: \\(X = 1\\) (exactly 1 has diabetes)\n\n\\(FFS \\Longrightarrow (1 - p)(1 - p)p = p(1 - p)^2\\)\n\\(FSF \\Longrightarrow (1 - p)p(1 - p) = p(1 - p)^2\\)\n\\(SFF \\Longrightarrow p(1 - p)(1 - p) = p(1 - p)^2\\)\n\n\n\nSubstitute for \\(p\\) and \\((1-p)\\) then for each \\(p(1 - p)^2 = (0.203)(0.797)^2 \\approx 0.129\\).\n\n\n\\[\\begin{aligned}\nP(X = 1) &= P(FFS \\cup FSF \\cup SFF) \\\\\n&= P(FFS) + P(FSF) + P(SFF) \\\\\n&= 3p(1 - p)^2 \\approx 3(0.129) = 0.387\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued-1",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued-1",
    "title": "Random Variables and Binomial Distribution",
    "section": "Compute the probabilities (continued)",
    "text": "Compute the probabilities (continued)\n\n\nCase: \\(X = 2\\) (exactly 2 have diabetes)\nSimilar reasoning gives\n\n\\(FSS \\Longrightarrow (1 - p)pp = p^2(1 - p)\\)\n\\(SFS \\Longrightarrow p(1 - p)p = p^2(1 - p)\\)\n\\(SSF \\Longrightarrow pp(1 - p) = p^2(1 - p)\\)\n\n\n\nEach of the three parts is approximately \\(0.033\\)\n\n\n\\[\\begin{aligned}\nP(X = 2) &= P(FSS \\cup SFS \\cup SSF) \\\\\n&= P(FSS) + P(SFS) + P(SSF) \\\\\n&= 3p^2(1 - p) \\approx 3(0.033) = 0.099\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued-2",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#compute-the-probabilities-continued-2",
    "title": "Random Variables and Binomial Distribution",
    "section": "Compute the probabilities (continued)",
    "text": "Compute the probabilities (continued)\n\n\nCase: \\(X = 3\\) (all 3 have diabetes)\n\\[\\begin{aligned}\nP(X = 3) &= P(SSS) \\\\\n&= ppp \\\\\n&= p^3 = (0.203)^3 \\approx 0.008\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#the-pattern-emerges",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#the-pattern-emerges",
    "title": "Random Variables and Binomial Distribution",
    "section": "The Pattern Emerges",
    "text": "The Pattern Emerges\nLooking at our calculations:\n\n\n\n\\(X\\)\nNumber of arrangements\nProbability\n\n\n\n\n0\n1\n\\(1 \\times (0.203)^0(0.797)^3 = 0.506\\)\n\n\n1\n3\n\\(3 \\times (0.203)^1(0.797)^2 = 0.387\\)\n\n\n2\n3\n\\(3 \\times (0.203)^2(0.797)^1 = 0.099\\)\n\n\n3\n1\n\\(1 \\times (0.203)^3(0.797)^0 = 0.008\\)\n\n\n\n\nPattern: \\[P(X = k) = (\\text{number of arrangements}) \\times p^k(1-p)^{n-k}\\]\nQuestion: How do we count the number of arrangements for any \\(n\\) and \\(k\\)?"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#counting-arrangements-n-choose-k",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#counting-arrangements-n-choose-k",
    "title": "Random Variables and Binomial Distribution",
    "section": "Counting Arrangements: ‚Äún choose k‚Äù",
    "text": "Counting Arrangements: ‚Äún choose k‚Äù\nThe number of ways to arrange \\(k\\) successes among \\(n\\) trials is:\n\\[\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\]\nThis is called the binomial coefficient or ‚Äún choose k‚Äù\nReminder: \\(n!\\) (read ‚Äún factorial‚Äù) means \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\)\n\nExample: \\(3! = 3 \\times 2 \\times 1 = 6\\)\nSpecial case: \\(0! = 1\\) (by definition)\n\n\nFor our example with \\(n=3\\):\n\n\\(\\binom{3}{0} = \\frac{3!}{0!3!} = \\frac{6}{1 \\times 6} = 1\\) ‚úì\n\\(\\binom{3}{1} = \\frac{3!}{1!2!} = \\frac{6}{1 \\times 2} = 3\\) ‚úì\n\\(\\binom{3}{2} = \\frac{3!}{2!1!} = \\frac{6}{2 \\times 1} = 3\\) ‚úì\n\\(\\binom{3}{3} = \\frac{3!}{3!0!} = \\frac{6}{6 \\times 1} = 1\\) ‚úì"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-distribution",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-distribution",
    "title": "Random Variables and Binomial Distribution",
    "section": "Binomial distribution",
    "text": "Binomial distribution\nThe final rule is\n\n\n\nDistribution of a Binomial random variable\n\n\nLet \\(X\\) be the total number of successes in \\(n\\) independent trials, each with probability \\(p\\) of a success. Then probability of observing exactly \\(k\\) successes in \\(n\\) independent trials is\n\\[P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k},  k= 0, 1, 2, \\dots, n \\]\n\n\n\nComponents:\n\n\\(\\binom{n}{k}\\): number of ways to arrange \\(k\\) successes in \\(n\\) trials\n\\(p^k\\): probability of \\(k\\) successes\n\\((1-p)^{n-k}\\): probability of \\(n-k\\) failures"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#verify-with-our-example",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#verify-with-our-example",
    "title": "Random Variables and Binomial Distribution",
    "section": "Verify with our example",
    "text": "Verify with our example\nDoes our formula work for \\(n=3, p=0.203\\)?\n\\[P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\]\n\n\n\n\n\\(k\\)\nFormula\nProbability\n\n\n\n\n0\n\\(\\binom{3}{0} (0.203)^0(0.797)^3\\)\n0.506\n\n\n1\n\\(\\binom{3}{1} (0.203)^1(0.797)^2\\)\n0.387\n\n\n2\n\\(\\binom{3}{2} (0.203)^2(0.797)^1\\)\n0.099\n\n\n3\n\\(\\binom{3}{3} (0.203)^3(0.797)^0\\)\n0.008\n\n\n\n\n\nMatches what we calculated by hand! ‚úì"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#now-extend-to-10-adults",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#now-extend-to-10-adults",
    "title": "Random Variables and Binomial Distribution",
    "section": "Now extend to 10 adults",
    "text": "Now extend to 10 adults\nNow we can easily calculate probabilities for \\(n=10\\) adults:\nSetup: \\(X \\sim \\text{Binomial}(n=10, p=0.203)\\)\n\n\nWithout the formula: We‚Äôd need to enumerate \\(2^{10} = 1024\\) possible arrangements!\n\n\nWith the formula: We can calculate any probability directly:\n\\[P(X = 4) = \\binom{10}{4} (0.203)^4 (0.797)^6 = \\frac{10!}{4!6!} (0.203)^4 (0.797)^6 \\approx 0.091\\]\n\n\nThe binomial formula saves us from tedious counting!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#r-makes-this-even-easier",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#r-makes-this-even-easier",
    "title": "Random Variables and Binomial Distribution",
    "section": "R Makes This Even Easier!",
    "text": "R Makes This Even Easier!\n\n\nWe can also use R to calculate binomial probabilities:\n\n# Verify our n=3 calculations\ndbinom(x = 0:3, size = 3, prob = 0.203)\n\n[1] 0.506261573 0.386842281 0.098530719 0.008365427\n\n\n\n\n\n# Calculate P(X = 4) for n=10\ndbinom(x = 4, size = 10, prob = 0.203)\n\n[1] 0.09140151\n\n\n¬†\nThis is especially helpful when you need many probabilities or when \\(n\\) is large!"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-mean-and-variance",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#binomial-mean-and-variance",
    "title": "Random Variables and Binomial Distribution",
    "section": "Binomial: Mean and Variance",
    "text": "Binomial: Mean and Variance\n\n\n\nTheorem: Mean and Variance of Binomial R.V.\n\n\nIf \\(X \\sim \\text{Binomial}(n, p)\\), then:\n\\[E(X) = np\\] \\[\\text{Var}(X) = np(1-p)\\] \\[SD(X) = \\sqrt{np(1-p)}\\]\n\n\n\nIntuition:\n\nIf each trial has probability \\(p\\) of success, and we do \\(n\\) trials, we expect \\(np\\) successes on average\nThe variance formula comes from summing \\(n\\) independent Bernoulli variances"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-diabetes-in-older-adults-10-people",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-diabetes-in-older-adults-10-people",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Diabetes in Older Adults (10 people)",
    "text": "Example: Diabetes in Older Adults (10 people)\n\n\nApproximately 20.3% of US adults aged 65-74 have diabetes. Suppose we randomly select 10 adults in this age group (independently).\n\n\nLet \\(X\\) = number with diabetes among the 10 people\nSetup: \\(X \\sim \\text{Binomial}(n=10, p=0.203)\\)\n\n\n\nQuestion 1: What is the expected value of \\(X\\)?\n\\[E(X) = np = 10(0.203) = 2.03\\]\n\n\n\n\nQuestion 2: What is the standard deviation of \\(X\\)?\n\\[SD(X) = \\sqrt{np(1-p)} = \\sqrt{10(0.203)(0.797)} = \\sqrt{1.618} \\approx 1.27\\]"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-exactly-4-with-diabetes",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-exactly-4-with-diabetes",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: Exactly 4 with Diabetes",
    "text": "Example: Exactly 4 with Diabetes\nQuestion 3: What is the probability that exactly 4 of the 10 have diabetes?\n\\[P(X = 4) = \\binom{10}{4} (0.203)^4 (0.797)^6\\]\n\n\\[= \\frac{10!}{4! \\cdot 6!} (0.203)^4 (0.797)^6 = 210 \\times 0.0017 \\times 0.256 \\approx 0.091\\]\n\n\nIn R:\n\ndbinom(x = 4, size = 10, prob = 0.203)\n\n[1] 0.09140151\n\n\n\n\n\ndbinom gives the pmf: \\(P(X = x)\\) for a discrete distribution. (probability at a specific value)\nR uses ‚Äúd‚Äù for these functions to stand for ‚Äúdensity‚Äù; for discrete distributions it returns the probability mass."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-at-most-3-with-diabetes",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-at-most-3-with-diabetes",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: At Most 3 with Diabetes",
    "text": "Example: At Most 3 with Diabetes\nQuestion 4: What is the probability that at most 3 have diabetes?\n\\[P(X \\leq 3) = P(X=0) + P(X=1) + P(X=2) + P(X=3)\\]\n\nWe could calculate each term, but there‚Äôs an easier way!\n\n\n\n\nIn R:\n\npbinom(q = 3, size = 10, prob = 0.203)\n\n[1] 0.8737821\n\n\n\n\nThe p in pbinom stands for ‚Äúcumulative probability‚Äù, \\(P(X \\leq k)\\)\n\n\nResult: About 87% chance that 3 or fewer have diabetes"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-at-least-5-with-diabetes",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#example-at-least-5-with-diabetes",
    "title": "Random Variables and Binomial Distribution",
    "section": "Example: At Least 5 with Diabetes",
    "text": "Example: At Least 5 with Diabetes\nQuestion 5: What is the probability that at least 5 have diabetes?\n\\[P(X \\geq 5) = P(X=5) + P(X=6) + \\cdots + P(X=10)\\]\n\nApproach 1: Use complement rule \\[P(X \\geq 5) = 1 - P(X \\leq 4)\\]\n\n1 - pbinom(q = 4, size = 10, prob = 0.203)\n\n[1] 0.03481642\n\n\n\n\n\n\nApproach 2: Use lower.tail = FALSE\n\npbinom(q = 4, size = 10, prob = 0.203, lower.tail = FALSE)\n\n[1] 0.03481642\n\n\nResult: About 3.4% chance that 5 or more have diabetes"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#r-functions-for-binomial-distribution",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#r-functions-for-binomial-distribution",
    "title": "Random Variables and Binomial Distribution",
    "section": "R Functions for Binomial Distribution",
    "text": "R Functions for Binomial Distribution\n\n\n\n\n\n\n\n\n\n\nFunction\nWhat it does\nExample\n\n\n\n\ndbinom()\nProbability at specific value: \\(P(X=k)\\)\ndbinom(x = 4, size = 10, prob = 0.203)\n\n\npbinom()\nCumulative probability: \\(P(X \\leq k)\\)\npbinom(q = 3, size = 10, prob = 0.203)\n\n\nqbinom()\nQuantile: Find \\(k\\) for given probability\nqbinom(p = 0.5, size = 10, prob = 0.203)\n\n\nrbinom()\nGenerate random samples\nrbinom(n = 100, size = 10, prob = 0.203)"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#visualizing-the-binomial-distribution",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#visualizing-the-binomial-distribution",
    "title": "Random Variables and Binomial Distribution",
    "section": "Visualizing the Binomial Distribution",
    "text": "Visualizing the Binomial Distribution"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#key-takeaways",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#key-takeaways",
    "title": "Random Variables and Binomial Distribution",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nRandom Variables:\n\nConnect random outcomes to numerical values and probabilities\nExpected value: weighted average using probabilities\nVariance: measures spread around the expected value\nLinear combinations: \\(E(aX+bY) = aE(X) + bE(Y)\\), but \\(\\text{Var}(aX+bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y)\\) (if independent)\n\nBinomial Distribution:\n\nModels number of successes in \\(n\\) independent trials\nParameters: \\(n\\) (trials) and \\(p\\) (success probability)\n\\(E(X) = np\\), \\(\\text{Var}(X) = np(1-p)\\)\nUse R functions: dbinom(), pbinom(), etc."
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#looking-ahead",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#looking-ahead",
    "title": "Random Variables and Binomial Distribution",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nWednesday:\n\nNormal distribution\nCentral Limit Theorem\nSampling distributions\n\nNext steps:\n\nReview textbook sections 3.1-3.2\nWork on HW 2 (due Tuesday, January 27)\nPractice calculating binomial probabilities in R"
  },
  {
    "objectID": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#questions",
    "href": "lessons/09_random_variables_binomial/09_random_variables_binomial.html#questions",
    "title": "Random Variables and Binomial Distribution",
    "section": "Questions?",
    "text": "Questions?\n\n\n\n\nBMSC 620 | Random Variables & Binomial Distribution"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "This page contains links to course materials, software setup, and shared resources. I will update it throughout the term.",
    "crumbs": [
      "Home",
      "Course info",
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#textbook-and-readings",
    "href": "resources.html#textbook-and-readings",
    "title": "Resources",
    "section": "Textbook and readings",
    "text": "Textbook and readings\n\nPrimary textbook\nIntroductory Statistics for the Life and Biomedical Sciences by Julie Vu and David Harrington\n\nThe textbook website is https://openintro.org/book/biostat/\nThe full PDF is free (with an optional contribution).\nA tablet-friendly PDF version with smaller margins is also available and may be easier to read.\n\n\n\nSupplementary reading (optional)\n\nAn Introduction to R (free pdf)",
    "crumbs": [
      "Home",
      "Course info",
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#course-platforms",
    "href": "resources.html#course-platforms",
    "title": "Resources",
    "section": "Course platforms",
    "text": "Course platforms\n\nSakai\nAssignments, submissions, and grades will be managed through Sakai, OHSU‚Äôs learning management system.\nLinks to Sakai assignments will be provided on this website.\n\n\nShared course folder (OneDrive)\nA shared OneDrive folder will be used to distribute datasets, handouts, and other course files that do not live directly on this website.\n\nThe folder will include datasets used in class and on homework.\nFiles will be organized by topic or week.\nLinks to specific files may also appear on the Schedule page.\n\nLink to class OneDrive folder\n\n\nOffice hours platform\nWebex will be used for virtual office hours when applicable.\nTo help sessions run smoothly:\n\nPlease stay muted until you want to ask a question.\nUse the chat to indicate when you have a question.\nVideo is encouraged but not required.",
    "crumbs": [
      "Home",
      "Course info",
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#statistical-software",
    "href": "resources.html#statistical-software",
    "title": "Resources",
    "section": "Statistical software",
    "text": "Statistical software\nWe will use R and RStudio for homework assignments and in-class examples.\nQuarto will be used for creating reproducible reports.\n\nInstallation\nPlease install the following software:\n\nR https://www.r-project.org/\nRStudio Desktop https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\nHelpful installation documentation is available here: https://rstudio-education.github.io/hopr/starting.html\nAlso, this handout by Meike Neiderhausen which contains some good additional resources for R.\nI encourage you to install these before the first class. We will reserve time early in the term to troubleshoot installation issues.\nIf you run into problems, please email me and include:\n\nYour operating system (Windows or Mac)\nThe full error message (copy/paste or screenshot)\nWhat you have already tried\n\n\n\nRStudio cheatsheets and shortcuts\nRStudio provides helpful reference materials for common tasks and packages.\n\nOfficial RStudio cheatsheets\nThese one-page reference guides are extremely helpful when learning R:\n\nAccess them in RStudio: Help ‚Üí Cheatsheets\nOr download directly: https://posit.co/resources/cheatsheets/\n\nMost relevant for this course:\n\nRStudio IDE Cheat Sheet - Overview of RStudio interface and keyboard shortcuts\nData Transformation with dplyr - The verbs we use for data manipulation\nData Visualization with ggplot2 - Creating effective visualizations\nR Markdown Cheat Sheet - Also applies to Quarto documents\n\nI recommend printing or bookmarking the dplyr and ggplot2 cheatsheets - you‚Äôll reference them frequently!\n\n\nKeyboard shortcuts\nLearning a few keyboard shortcuts will make your workflow much faster.\nView essential keyboard shortcuts - A quick reference for Mac and PC with the shortcuts you‚Äôll use most.\nThe most important ones:\n\nCmd/Ctrl + Shift + M - Insert pipe %&gt;%\nCmd/Ctrl + Enter - Run current line/selection\nCmd/Ctrl + Shift + C - Comment/uncomment lines\n\nYou can view all available shortcuts in RStudio: Tools ‚Üí Keyboard Shortcuts Help (or press Option/Alt + Shift + K)\n\n\n\nAdditional R resources (optional)\nThese resources are not required, but may be helpful if you want extra practice or alternative explanations.\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis: ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\nData and Analytics for Research Training Program: Look at Modules with R coding language\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry for Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder",
    "crumbs": [
      "Home",
      "Course info",
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#weekly-materials",
    "href": "resources.html#weekly-materials",
    "title": "Resources",
    "section": "Weekly materials",
    "text": "Weekly materials\nLecture slides, datasets, and handouts will be linked from the Schedule page by week, with files hosted either on this website or in the shared OneDrive folder.\n\nAttribution note: Portions of this Resources page were adapted from course materials by Nicky Wakim, with permission, and modified for BMSC 620.",
    "crumbs": [
      "Home",
      "Course info",
      "Resources"
    ]
  }
]