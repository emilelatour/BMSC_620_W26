---
title: "Introduction to Data & Numerical Summaries"
author: "Emile Latour, Nicky Wakim, Meike Niederhausen"
date: "`r library(here); source(here('class_dates.R')); w1d1`"
date-format: long
format:
  revealjs:
    theme: "../../assets/css/reveal-bmsc620_v4.scss"
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: "BMSC 620 | Intro to Data & Numerical Summaries"
    html-math-method: mathjax
    header-includes: |
      <style>
      #wrap {
        width: 1650px;
        height: 900px;
        margin: 0 auto;
        overflow: hidden;
        border: 1px solid #999;
        border-radius: 8px;
      }
      #frame {
        width: 1650px;
        height: 900px;
        border: 0;
        zoom: 1.25;
        -moz-transform: scale(1.25);
        -moz-transform-origin: 0 0;
      }
      </style>
execute:
  echo: true
  freeze: auto
---

```{r setup, include=FALSE}
library(here)
source(here("class_dates.R"))

library(tidyverse)
```

## Learning objectives (today)

By the end of class, you should be able to:

1. Define and distinguish a target population and a sample
2. Describe common sampling methods and why bias can happen
3. Compare experiments vs observational studies (and what each can conclude)

## Why we care about study design

* Statistics helps answer questions with data.

* But the design determines what the data can support:
  - Who is included?
  - How are they selected?
  - What kind of study is it?
  - What comparisons are valid?

These decisions determine what conclusions we can (and cannot) draw.

## Data collection principles (1.3)

* Population vs. sample
* Sampling methods
* Experiments vs. Observational studies


## Population vs. sample

\

### (Target) Population

* Group of interest being studied
* Group from which the sample is selected
  - studies often have _inclusion_ and/or _exclusion_ criteria
* Almost always too expensive or logistically impossible to collect data for every case in a population

\

### Sample

* Group on which data are collected
* A subset (of measurements) from the population

\

We use information from a sample to learn about the population from which it was drawn.


## Sampling methods (1/4) {.smaller}

A good sampling method produces a **representative** sample:
one whose characteristics are similar to those of the population.

::: columns
::: {.column width="49%"}
__Simple random sample (SRS)__  

* Each individual of a population has the _same chance_ of being sampled
* Randomly sampled
* Considered best way to sample

![](/img_slides/sampleRandomHealthPlan.png){fig-align="center"}

:::
::: {.column width="2%"}
:::

::: {.column width="49%"}
__Convenience sample__  

* Easily accessible individuals are _more likely_ to be included in the sample than other individuals
* Considered a common "pitfall"

![](/img_slides/sampleConvenienceHealthPlan.png){fig-align="center"}

:::
:::



## Sampling methods (2/4): Reality check {.smaller}

_Even good sampling plans don't guarantee representative samples_

::: columns
::: {.column width="49%"}
__Non-response bias__

* Non-response rates can be high
* Are all groups within a population being reached?
* Unrepresentative sample  

Can lead to skewed results

![](/img_slides/sampleNonResponseHealthPlan.png){fig-align="center"}

:::

::: {.column width="2%"}
:::

::: {.column width="49%"}
__"Random" samples can be unrepresentative by random chance__

* In a SRS each case in the population has an equal chance of being included in the sample
* But by random chance alone a random sample might contain a higher proportion of one group over another
* Ex: a SRS might by chance include 70% men (unlikely, but theoretically possible)

:::
:::

## Sampling methods (3/4) {.smaller}

::: columns
::: {.column width="50%"}
* __Simple random sample (SRS)__
  * Each individual of a population has the _same chance_ of being sampled
  * _Statistical methods taught in this class assume a SRS!_

* __Stratified sampling__
  * Divide population into groups (strata) before selecting cases within each stratum (often via SRS)
  * Usually cases within a strata are similar, but are different from other strata with respect to the outcome of interest, such as gender or age groups
:::

::: {.column width="50%"}
![](/img_slides/simple_stratified.png){fig-align="center"}
:::
:::

## Sampling methods (4/4) {.smaller}

::: columns
::: {.column width="50%"}
* __Cluster sample__
  * First divide population into groups (clusters)
  * Then sample a fixed number of clusters, and include _all_ observations from chosen clusters
  * Clusters are often hospitals, clinicians, schools, etc., where each cluster will have similar services/ policies/ etc. 
  * Cases within clusters usually very diverse
  * Example: sample zip codes in Oregon, then include **all** households in the sampled zip codes.


* __Multistage sample__
  * Similar to a cluster sample, but randomly sample individuals within each selected cluster instead of including everyone
  * Example: sample zip codes in Oregon, then randomly sample households in the zip codes (i.e. include **some** households in the sampled zip codes).
:::

::: {.column width="50%"}
![](/img_slides/cluster_multistage.png){fig-align="center"}

:::
:::

## Two basic study designs

::: columns
::: {.column width="50%"}
### Experiment
Researchers directly influence how data arise

- Such as: assigning groups of individuals to different treatments and assessing how the outcome varies across treatment groups

- Three major parts to an experiment
  - Control
  - Randomization
  - Replication
:::

::: {.column width="50%"}
### Observational study
Researchers merely observe and record data, without interfering
with how the data arise

- For example, to investigate why certain diseases develop, researchers
might collect data by conducting surveys, reviewing medical records, or following a cohort of
many similar individuals.

- Often the only available way to study your research question

  - Due to ethical considerations, funds, or availability of data
:::
:::

## Experiments (1/2) 


<!-- * Researchers assign individuals to different __treatment__ or __intervention groups__ -->
<!--   * __Control group__: often receive a __placebo__ or usual care -->
<!--   * Different treatment groups are often called __study arms__ -->

* __Control__
  * Researchers limit variability by carefully selecting participants
  * Inclusion and exclusion criteria reduce the influence of extraneous variables
  * Helps ensure the sample is appropriate and relevant to the research question

* __Randomization__
  * Group assignment is usually random to ensure similar (balanced) study arms for all variables (observed and unobserved)
  * Randomization allows study arm differences in outcomes to be attributed to treatment rather than variability in patient characteristics
      * Treatment is the only systematic difference between groups
      * Establish causality
  * __Blocking (stratification)__: group individuals into blocks (strata) before randomizing if there are certain characteristics that may influence the outcome other than treatment (i.e. gender, age group)
  * **Different than random sampling**: sampling decides *who enters the study*; randomization decides *which treatment they receive*


## Experiments (2/2) 


* __Replication__
  * Accomplished by collecting a sufficiently large sample
  * Results usually more reliable with a large sample size
      * Often less variability
      * More likely to be representative of population


## Observational studies 

Some research questions **cannot be studied experimentally** due to ethical, practical, or logistical constraints.

* Data are observed and recorded without interference
  * Researchers do not assign treatments or exposures
* Often done via surveys, electronic health records, or medical chart reviews
* Associations between variables can be established, **but not causality**
    * Individuals with different characteristics may also differ in other ways that influence response
* Confounding variables (lurking variable)
  * Variables associated with both the explanatory and response variables


## Observational studies: prospective vs. retrospective studies

Many observational studies follow **cohorts** — groups of individuals observed over time.

<br>

::: columns
::: {.column width="50%"}
### Prospective

- Identifies participants and collects information **at scheduled times or as events unfold**.
:::

::: {.column width="50%"}
### Retrospective

- Collect data **after events have taken place**, such as from medical records

:::
:::


&nbsp;

Some studies can have prospective and retrospective data.

**Example:** The Cancer Care Outcomes Research and Surveillance Consortium
(CanCORS) enrolled participants with lung or colorectal cancer, collected information about
diagnosis, treatment, and previous health behavior (retrospective), but also maintained contact with participants to gather data about long-term outcomes (prospective).

## Comparing study designs

![[Science Media Centre](https://www.sciencemediacentre.co.nz/coveringscience/types-of-scientific-evidence/)](/img_slides/strength_of_evidence.jpeg){fig-align="center"}



## Systematic Reviews example

![[STEM: Systematically Testing the Evidence on Marijuana](https://www.cannabisevidence.org/)](/img_slides/STEM_systematic_review.jpg){fig-align="center"}

::: columns
::: {.column width="85%"}
::: {style="font-size: 65%;"}
STEM is a collaborative project between the US Department of Veterans Affairs and the [Center for Evidence-based Policy](https://centerforevidencebasedpolicy.org/) at Oregon Health & Science University.  
The project is funded by the US Department of Veterans Affairs: Office of Rural Health.
:::
:::

::: {.column width="15%"}
![](/img_slides/logo_CenterEvidenceBasedPolicy.jpg){fig-align="center"}
:::
:::

## From study design to data

So far, we’ve focused on:

- how studies are designed  
- how data are collected  

Now we shift to:

- what data look like once we have them  
- how data are stored and summarized

## Intro to Data (1.2)

![[Artwork by @allison_horst](https://allisonhorst.com/r-packages-functions)](/img_slides/horst_data_cowboy.png){fig-align="center"}

## A first look at data in R
- Today is about *exposure*, not mastery
- We will revisit all of this slowly
- Right now: focus on concepts, not syntax


## How are data stored, how do we use them? 

- Often, data are in an Excel sheet, or a plain text file (.csv, .txt)
- .csv files open in Excel automatically, but actually are plain text
- Usually, columns are variables/measures and rows are observations (i.e. a person's measurements)

### Data in R 

* We can import data from many file types, including .csv, .txt., and .xlsx
    * We will cover this on a later date
* Once imported, R typically stores data as __data frames__, or __tibbles__ if using the `tidyverse` package (more on this later).
    * For our purposes, these are essentially the same, and I will tend to use the terms interchangeably.
    * These are examples of what we call __object types__ in R.



## Data frame example

::: columns
::: {.column width="54%"}

```{r}
df <- data.frame(
  IDs=1:3, 
  gender=c("male", "female", "Male"), 
  age=c(28, 35.5, 31),
  trt = c("control", "1", "1"),
  Veteran = c(FALSE, TRUE, TRUE)
  )
df
```

* __Vectors__ vs. __data frames__
    * a data frame is a collection (or array or table) of vectors

:::

::: {.column width="2%"}
:::

::: {.column width="44%"}
::: {style="font-size: 90%;"}
* Different columns can be of different data types (i.e. numeric vs. text)
* Both numeric and text can be stored within a column (stored together as *text*).

* Vectors and data frames are examples of _**objects**_ in R. 
  + There are other types of R objects to store data, such as matrices, lists.
:::
:::
:::


## Observations & variables

::: columns
::: {.column width="60%"}

```{r}
df
```

![[ISLBS](https://www.openintro.org/book/biostat/)](/img_slides/Fig1.8_variable_types.png){fig-align="center"}

:::
::: {.column width="40%"}
::: {style="font-size: 90%;"}
* Book refers to a dataset as a _data matrix_ 

* Rows are usually __observations__
* Columns are usually __variables__ 


* __[How many observations are in this dataset?]{style="color:green"}__

* __[What are the variable types in this dataset?]{style="color:green"}__
::: 
:::
:::




## Variable (column) types
::: {style="font-size: 70%;"}
R type | variable type| description
---|---|---
integer | discrete | integer-valued numbers
double or numeric | continuous| numbers that are decimals
factor  | categorical | categorical variables stored with levels (groups)
character | categorical | text, "strings"
logical | categorical | boolean (TRUE, FALSE)

<!-- Each variable (column) in a data frame can be of a different type. -->

* View the __structure__ of our data frame to see what the variable types are:
:::
```{r}
str(df)
```

<!-- * Note that the ID column is _integer_ type since the values are all whole numbers, although we likely would think of it as being a categorical variable and thus prefer it to be a factor. -->




## Fisher's (or Anderson's) Iris data set {.smaller}

Data description: 

* n = 150 
* 3 species of Iris flowers (Setosa, Virginica, and Versicolour)
  + 50 measurements of each type of Iris
* __variables__:
  + sepal length, sepal width, petal length, petal width, and species

_[Can the iris species be determined by these variables?]{style="color:purple"}_

<center><img src="/img_slides/Iris_types.png" width="70%" height="50%"><img src="/img_slides/Iris_parts.png" width="28%" height="50%"></center>
[Gareth Duffy](https://github.com/Datagatherer2357/Gareth-Duffy-GMIT-Project)



## View the `iris` dataset

::: {style="font-size: 80%;"}
* The `iris` dataset is already pre-loaded in *base* R and ready to use.
<!-- * Type the following command in the console window -->
<!--   - _Warning: this command cannot be rendered. It will give an error._ -->
:::

\

:::columns
::: {.column width="30%"}
```{r}
#| eval: false

View(iris)
```
::: {style="font-size: 80%;"}
A new tab in the scripting window should appear with the `iris` dataset.
:::
:::

::: {.column width="70%"}

![](/img_slides/screenshot_iris_View.png){fig-align="center"}
:::
:::


## Data structure

* What are the different __variable types__ in this data set?

\

```{r}
str(iris)   # structure of data
```




## Data set summary

```{r}
summary(iris)
```



## Data set info

```{r}
dim(iris)
nrow(iris)
ncol(iris)
names(iris)
```




## View the beginning or end of a dataset

```{r}
head(iris)
tail(iris)
```



## Specify how many rows to view at beginning or end of a dataset

```{r}
head(iris, 3)
tail(iris, 2)
```



## The `$`

- Suppose we want to single out the column of petal width values.
- One way to do this is to use the `$`
    * `DatSetName$VariableName`

```{r}
iris$Petal.Width
```



## Example using the `$`

The `$` is helpful if you want to create a new dataset for just that one variable, or, more commonly, if you want to calculate summary statistics for that one variable.

\

```{r}
mean(iris$Petal.Width)
sd(iris$Petal.Width)
median(iris$Petal.Width)
```



## Inline code

::: {style="font-size: 90%;"}
* With markdown you can also report __R code output inline__ with the text instead of using a chunk.

::: columns
::: {.column width="50%"}
Text in editor:

![](/img_slides/screenshot_code_inline_petalwidth.png){fig-align="center"}
:::

::: {.column width="50%"}

Output: 

The mean petal width for all 3 species combined is `r round(mean(iris$Petal.Width),1)` 
(SD = `r round(sd(iris$Petal.Width),1)`) cm.

:::
:::

- Reporting summary statistics this way in a report, makes the numbers computationally reproducible.
- For example, if this were for an abstract and a year later you are wondering where the numbers came from, your R code will tell you exactly which dataset was used to calculate the values.
:::


# Summarizing numerical data (1.4)


::: columns
::: {.column width="30%"}

Measures of center &  spread

:::

::: {.column width="70%"}

![[https://xkcd.com/937/](https://xkcd.com/937/)](/img_slides/xkcd_tornadoguard.png){fig-align="center"}

:::
:::



## Table 1 example

::: columns
::: {.column width="60%"}
![](/img_slides/Table1_Barton.png){fig-align="center"}
:::

::: {.column width="40%"}
*Are We on the Same Page?: A Cross-Sectional Study of Patient-Clinician Goal Concordance in Rheumatoid Arthritis*  
J Barton et al.  
Arthritis Care & Research.  
2021 Sep 27
[https://pubmed.ncbi.nlm.nih.gov/34569172/](https://pubmed.ncbi.nlm.nih.gov/34569172/) 
:::
:::



## Measures of center: mean

::: {style="font-size: 80%;"}
__[Sample mean]{style="color:darkorange"}__: the average value of observations

$$\bar{x} = \frac{x_1+x_2+\cdots+x_n}{n} = \sum_{i=1}^{n}\frac{x_i}{n}$$  

where $x_1, x_2, \ldots, x_n$ represent the $n$ observed values in a sample

\


__Example__: What is the mean age in the toy dataset `df` defined earlier?
:::

```{r}
#| eval: false
#| echo: false


df <- data.frame(
  IDs=1:3, 
  gender=c("male", "female", "Male"), 
  age=c(28, 35.5, 31),
  trt = c("control", "1", "1"),
  Veteran = c(FALSE, TRUE, TRUE)
  )
df
```


```{r}
df
mean(df$age)
```



## Measures of center: median

::: {style="font-size: 90%;"}
* The __[median]{style="color:darkorange"}__ is the middle value of the observations in a sample.  

* The median is the 50th percentile, meaning
  - 50% of observations lie below and
  - 50% of observations lie above the median.
:::

::: columns
::: {.column width="50%"}
::: {style="font-size: 90%;"}
* If the number of observations is 
  - odd: the median is the middle observed value
  - even: the median is the average of the two middle observed values
:::
:::

::: {.column width="50%"}
```{r}
df$age
median(df$age)
median(c(df$age, 67))
```

:::
:::


## Measures of center: mean vs. median

```{r}
#| echo: false
#| fig.height: 4
#| fig.width: 14

iris_long <- iris %>% pivot_longer(Sepal.Length:Petal.Width, names_to = "msr")

ggplot(iris_long, aes(x= value)) +
  facet_grid(cols = vars(msr)) +
  geom_histogram(color = "white") +
  labs(title = "Iris sepal and petal lengths & widths")

```

```{r}
summary(iris)
```


## Measures of center: mode

__[mode]{style="color:darkorange"}__: the most frequent value in a dataset

```{r}
#| echo: false
#| fig.height: 6
#| fig.width: 14

ggplot(iris_long, aes(x= value)) +
  facet_grid(cols = vars(msr)) +
  geom_histogram(color = "white") +
  labs(title = "Iris sepal and petal lengths & widths")

```



## Measures of spread: standard deviation (SD) (1/3) {.smaller}

__standard deviation__ is (approximately) the average distance between a typical observation and the mean 

- An observation's **deviation** is the distance between its value $x$ and the sample mean $\bar{x}$: deviation = $x - \bar{x}$.

```{r}
#| echo: false
#| fig.height: 4
#| fig.width: 14

sim_diff_sd <- data.frame(
  id = 1:100,
  sd1 = rnorm(1000, mean = 0, sd = 10),
  sd2 = rnorm(1000, mean = 0, sd = 30),
  sd3 = rnorm(1000, mean = 0, sd = 50)
)

sim_diff_sd_long <- sim_diff_sd %>%
  pivot_longer(sd1:sd3, names_to = "sd")

ggplot(sim_diff_sd_long, aes(x= value)) +
  facet_grid(cols = vars(sd)) +
  geom_histogram(color = "white") +
  labs(title = "Simulated data with different standard deviations")

```



## Measures of spread: SD  (2/3)

-   The **sample variance** $s^2$ is the sum of squared deviations divided by the number of observations minus 1. 

$$
s^2 =
\frac{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2 + \cdots + (x_n - \bar{x})^2}{n - 1}
=
\sum_{i=1}^{n} \frac{(x_i - \bar{x})^2}{n - 1}
$$
where $x_1, x_2, \dots, x_n$ represent the $n$ observed values.

 

-   The [**standard deviation**]{style="color:#E75B5C;"} $s$ (or $sd$) is the square root of the variance. 

$$
s 
= \sqrt{s^2}
= \sqrt{\frac{1}{n - 1}\sum_{i=1}^{n}(x_i - \bar{x})^2}
$$

## Measures of spread: SD  (3/3) 

::: columns
::: {.column width="40%"}

::: {style="font-size: 80%;"}
Let's calculate the sample standard deviation for our toy example
:::

```{r}
df$age

```

:::

::: {.column width="60%"}
```{r}
mean(df$age)
sd(df$age)
```

:::
:::

$s = \sqrt{\sum_{i=1}^{n}\frac{(x_i - \bar{x})^2}{n-1}} =$

<!-- \sqrt{\frac{({28 - 31.5)}^{2}+({35.5 - 31.5)}^{2}+({31 - 31.5)}^{2}}{3-1}} = 3.775 -->



## Empirical Rule: one way to think about the SD (1/2) 

::: {style="font-size: 80%;"}

::: columns
::: {.column width="40%"}
For symmetric bell-shaped data, about

* 68% of the data are within 1 SD of the mean
* 95% of the data are within 2 SD's of the mean
* 99.7% of the data are within 3 SD's of the mean

These percentages are based off of percentages of a true normal distribution.
:::
::: {.column width="60%"}

![[https://statistics-made-easy.com/empirical-rule/](https://statistics-made-easy.com/empirical-rule/)](/img_slides/empirical-rule.png){fig-align="center" width="660"}

:::
:::
:::


## Empirical Rule: one way to think about the SD (2/2)

::: columns
::: {.column width="50%"}
```{r}
#| fig.height: 8
hist(iris$Sepal.Width)

```

:::

::: {.column width="50%"}
```{r}
mean(iris$Sepal.Width)
sd(iris$Sepal.Width)
```

:::
:::


## Measures of spread: interquartile range (IQR) (1/2) {.smaller}

The $p^{th}$ percentile is the observation such that $p\%$ of the remaining observations fall below this observation.

  - The *first quartile* $Q_1$ is the $25^{th}$ percentile.
  - The *second quartile* $Q_2$, i.e., the median, is the $50^{th}$ percentile.
  - The *third quartile* $Q_3$ is the $75^{th}$ percentile.
    
The __[interquartile range (IQR)]{style="color:darkorange"}__ is the distance between the third and first quartiles.
$$IQR = Q_3 - Q_1$$

* IQR is the width of the *middle half* of the data



## Measures of spread: IQR (2/2)

__[5 number summary]{style="color:darkorange"}__
```{r}
summary(iris$Sepal.Width)
```

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
#| fig.height: 5
#| fig.width: 5

hist(iris$Sepal.Width)
```

:::

::: {.column width="60%"}
What is the IQR of the sepal widths?

```{r}
quantile(iris$Sepal.Width, c(.25, .75))
diff(quantile(iris$Sepal.Width, c(.25, .75)))

IQR(iris$Sepal.Width)
```

:::
:::


## Robust estimates

Summary statistics are called __[robust estimates]{style="color:darkorange"}__ if extreme observations (outliers) have little effect on their values


| Estimate           | Robust? |
|--------------------|---------|
| Sample mean        | ❌      |
| Median             | ✅      |
| Standard deviation | ❌      |
| IQR                | ✅      |
| Range              | ❌      |


-   For samples with extreme values or skewed distributions, the **median and IQR** often provide a more stable summary of center and spread than the mean, standard deviation, or range.

- The **range** depends only on the smallest and largest observations, so a single outlier can dramatically change its value.
